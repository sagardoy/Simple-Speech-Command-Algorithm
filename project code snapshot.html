<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>Capstone - Simple Command Recognition Algorithm</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Simple-Command-Recognition-Using-Neural-Networks"><strong>Simple Command Recognition Using Neural Networks</strong><a class="anchor-link" href="#Simple-Command-Recognition-Using-Neural-Networks">&#182;</a></h4><p>Tyler Sagardoy<br>
Udacity Machine Learning Nanodegree Capstone Project<br>
June 2018</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This report details my project to build an algorithm that can understand a small library of 10 simple commands while being able to ignore, or distinguish from, unknown commands. Using Mel-Frequency Capestral Coefficients to regularize and convey communicated information, I'll train a 1-dimensional convolutional neural network using RMSprop to minimize the categorical crossentropy log loss to process and interpret the information in order to make a prediction as to the intended command.</p>
<p>I begin by discussing trends in command recognition, followed by a review of my project objective, a description of the data used for model training, and an outline of my project. I proceed to discuss steps taken during data preprocessing, including a brief overview of Mel-Frequency Capestral Coefficients and how they are applied, before discussing the architectures of the 3 networks to be trained. Each network was trained against hyperparameters in dropout rates, learning rates, and leaky rectified linear unit activation kernel alphas resulting in 81 separately trained models. From these models, I select the one that scores best when applied against an exclusive set of testing data and build a simple speech recognition algorithm from it.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Simple-Command-Recognition,-Rise-&amp;-Market-Trends">Simple Command Recognition, Rise &amp; Market Trends<a class="anchor-link" href="#Simple-Command-Recognition,-Rise-&amp;-Market-Trends">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Within the past few years, voice command and activation has become a popular trend in user experience and design. Voice command allows for technologies to meet specific consumer demands, such as providing a user interface when hands or vision is occupied – a reason 61 percent of users state why they use voice command – or when one is in the car or on the go – the primary setting for voice usage in 55 percent of instances (Young, 2016). According to Google CEO Sundar Pichai, 20 percent of all queries made in 2016 on Google apps and Android devices were voice searches (Sterling, 2016).</p>
<p>The future looks bright for voice command. Comscore estimates that 50 percent of searches will be conducted by voice by 2020 (Young, 2016). While that figure may be highly optimistic, a study of 39 leading SEO experts identified voice usage as one of the top 3 important trends in search (Alameda Internet Marketing, 2016). While these estimates speak to the Internet search industry exclusively, the enthusiasm for voice activation in this industry portends demand for adoption in other industries.</p>
<p>As independent makers and entrepreneurs develop their products to feature this new and exciting interface method, or learn about it for the first time, many find that their needs for voice commands are minimal – only limited to a handful of basic operational commands. Many robust voice recognition algorithms are extraneous, costly, and unnecessary for many projects. Therefore, an opportunity exists to develop an open-source speech recognition algorithm intended for smaller developers and entry-level enthusiasts.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Project-Purpose,-Objectives-&amp;-Objectives">Project Purpose, Objectives &amp; Objectives<a class="anchor-link" href="#Project-Purpose,-Objectives-&amp;-Objectives">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The purpose of this report is to provide an algorithm that understands a small selection of simple audio commands. The selection of commands the algorithm should understand should be “Yes,” “No”, “Up”, “Down”, “Left”, “Right”, “On”, “Off”, “Stop” and “Go”.</p>
<p>I selected this project originally to compete in the TensorFlow Speech Recognition Challenge hosted by Kaggle and sponsored by Google; however, I used the data, guidance and competition objectives to outline my own goals and I narrowed the scope of my project to accomplish my primary objective - training a simple 1-D convolutional neural network to accurately predict with at least 80% accuracy the library of ten words. For words and sounds that the algorithm isn't explicitly trained on, the algorithm will be trained to classify in a catch-all 'other' category.</p>
<p>Some of the principles I incorporated into my project include:</p>
<ul>
<li>Use the standard 16-bit [16000,1] integer tensor format for audio PCM-decoded at 16000 Mbps as an algorithm input</li>
<li>Output will be a [1, 11] tensor representing the prediction of the algorithm. Values will be between 0 and 1</li>
<li>Regularize decoded audio into tensors of Mel-Frequency Cepstral Coefficients (MFCCs)</li>
<li>Objectively work to minimize the number of layers in the architecture to maintain some simplicity within the model and to minimize runtime</li>
<li>Use convolutional layers with a wide convolution window and moderate stride to identify speech patterns within inputs</li>
<li>Use pooling layers to reduce dimensionality between convolutional layers</li>
<li>Hyperparameters that I changed with each model were the dropbout rate, the learning rate, and the alpha of the rectified linear unit kernels (0,-0.1, 1)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Dataset-&amp;-Inputs">Dataset &amp; Inputs<a class="anchor-link" href="#Dataset-&amp;-Inputs">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The algorithm will be trained and tested using the Speech Commands Dataset released by Google on August 3, 2017. The data contains 64,727 one-second audio clips of 30 short words. The audio files were crowdsourced by Google with the goal of collecting single-word commands (rather than words as said and used in conversation). A group of 20 core words were recorded with most speakers saying them 5 times. An additional group 10 words were recorded to help distinguish unrecognized words; most speakers recorded these words once. The core words consist of “Yes,” “No”, “Up”, “Down”, “Left”, “Right”, “On”, “Off”, “Stop”, “Go” and the numbers zero through nine. Auxiliary words consist of "Bed", "Bird", "Cat", "Dog", "Happy", "House", "Marvin", "Sheila", "Tree" and "Wow".</p>
<p>This algorithm will take as inputs
•   An file of PCM-encoded data to be decoded into a 16-bit [16000, 1] integer tensor
•   Output will be a [1, 11] tensor representing the prediction of the algorithm. Values will be between 0 and 1.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Comparative-Benchmark">Comparative Benchmark<a class="anchor-link" href="#Comparative-Benchmark">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With 10 command labels and an additional ‘non-command’ label included in the library, a naïve algorithm that outputs only one label would be correct 1 out of 11 times, or 9.1% of the time. For purposes of assessing whether a CNN has any predictive power, I will use this low 9.1% threshold. However, for practical and usability purposes, I hope to train a CNN that has at least 80% accuracy – a threshold that would have put me within the top quartile of competitors, indicating that my model performed better than 75.0% of all other models.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Evaluation-Metrics">Evaluation Metrics<a class="anchor-link" href="#Evaluation-Metrics">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Models will be evaluated using Multiclass Accuracy, defined as the ratio of correct classifications over total classifications. The logic behind this evaluation is rather straight-forward: out of the number of testing cases, how many did the algorithm respond correctly?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Project-Outline">Project Outline<a class="anchor-link" href="#Project-Outline">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The procedural outline is as follows:</p>
<ol>
<li>Download the Speech Commands Dataset from Google and Kaggle.</li>
<li>Decode the PCM-encoded audio files at 16000 Mbps into standardized 16-bit integer tensor of shape [16000, 1].</li>
<li>Preprocess data into tensors of Mel-Frequency Cepstral Coefficients (MFCCs) </li>
<li>Divide dataset into training, testing, and validation sets with inputs and one-hot encoded targets.</li>
<li>Define the architectures for the networks.</li>
<li>Compile and train models, retaining only the models with the best classification accuracy on the validation set</li>
<li>Use the test set to calculate Multiclass Accuracy and obtain at least 80.0% on one of the models trained.</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="1.-Download-Speech-Commands-Dataset-from-Google-and-Kaggle">1. Download Speech Commands Dataset from Google and Kaggle<a class="anchor-link" href="#1.-Download-Speech-Commands-Dataset-from-Google-and-Kaggle">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As described by Kaggle, the Speech Commands Dataset is a set of 64,727 1-second .wav audio files, each containing a single spoken English word. These words are from a small set of commands, and are spoken by a variety of different speakers. The audio files are organized into folders based on the word they contain, and this data set is designed to help train simple machine learning models. The dataset for this project was downloaded at <a href="https://www.kaggle.com/c/tensorflow-speech-recognition-challenge/data">https://www.kaggle.com/c/tensorflow-speech-recognition-challenge/data</a>. Data was released by Google on August 3, 2017.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="2.-Decode-Audio-Files">2. Decode Audio Files<a class="anchor-link" href="#2.-Decode-Audio-Files">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="2a.-Download-and-Import-Necessary-Python-Libraries">2a. Download and Import Necessary Python Libraries<a class="anchor-link" href="#2a.-Download-and-Import-Necessary-Python-Libraries">&#182;</a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Before I begin decoding the Speech Command Dataset audio files, I need to download necessary libraries, modules and utilities into my programming environment, and import them into my iPython kernel. The libraries (and versions) I will be using are:</p>
<ul>
<li>SciPy (v0.19.1) - Python's scientific computing library; used in this project to directly decode PCM-encoded audio files at a rate of 16000 Mbps and to perform Discrete Cosine Transforms during MFCC calculations</li>
<li>Numpy (v1.13.3) - library useful for handling and processing arrays of values and objects; used in this project to manage data and for performing Discrete Fourier Transforms during MFCC calculations</li>
<li>Keras (v2.1.6) with TensorFlow (v1.8.0) backengine - Keras provides a high-level programming interface for deep learning and neural network development; Keras runs on top of TensorFlow, a library and engine for dataflow programming; used in this project to develop and train the neural networks and for one-hot encoding all target labels</li>
<li>Glob - standard Python file searching library; used in this project to extrapolate filenames and paths for all audio files</li>
<li>OS - standard Python operating system interface; used in this project to combine strings and values into valid file pathnames</li>
<li>Math - standard Python mathematical functions; used in this project to calculate frequency bins in MFCC calculations</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">scipy.io</span> <span class="k">import</span> <span class="n">wavfile</span>
<span class="kn">from</span> <span class="nn">scipy.fftpack</span> <span class="k">import</span> <span class="n">dct</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="k">import</span> <span class="n">np_utils</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="k">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">EarlyStopping</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">load_model</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Conv1D</span><span class="p">,</span> <span class="n">ZeroPadding1D</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">AveragePooling1D</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\Tyler\Anaconda3\envs\tfspeech\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="2b.-Generate-Lists-of-Training,-Validation-&amp;-Testing-FIlenames">2b. Generate Lists of Training, Validation &amp; Testing FIlenames<a class="anchor-link" href="#2b.-Generate-Lists-of-Training,-Validation-&amp;-Testing-FIlenames">&#182;</a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The dataset downloaded from Keras contained two presorted lists of audio filepaths for validation and training lists. For purposes of transparency and ease, I made a third list of training files by first creating a list of all audio filepaths, then removing any filepaths that were found in either the validation or training lists. The list was saved with the other two lists.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># set directory path</span>
<span class="n">dir_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s1">&#39;__file__&#39;</span><span class="p">)),</span> <span class="s1">&#39;audio/audio&#39;</span><span class="p">)</span>

<span class="c1"># import pre-selected list of testing and validation audio filenames</span>
<span class="n">testing_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span><span class="s1">&#39;testing_list.txt&#39;</span><span class="p">)</span>
<span class="n">testing_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="n">testing_path</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Retrieved testing_list from &quot;</span><span class="o">+</span> <span class="n">testing_path</span><span class="o">+</span> <span class="s2">&quot;. Size is &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">testing_list</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">validation_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span><span class="s1">&#39;validation_list.txt&#39;</span><span class="p">)</span>
<span class="n">validation_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="n">validation_path</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Retrieved testing_list from &quot;</span><span class="o">+</span> <span class="n">validation_path</span> <span class="o">+</span> <span class="s2">&quot;. Size is &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">validation_list</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>

<span class="c1"># generate exclusive list of training audio filenames</span>
<span class="n">audio_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="s1">&#39;audio&#39;</span><span class="p">)</span>
<span class="n">all_files_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">audio_path</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="s1">&#39;*.wav&#39;</span><span class="p">)))</span>
<span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="s1">&#39;audio/all_files_list.txt&#39;</span><span class="p">,</span><span class="n">all_files_list</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%.100s</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">audio_path_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">audio_path</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span>

<span class="c1"># create training_list by removing paths if in testing_list or validation_list</span>
<span class="n">training_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">ndenumerate</span><span class="p">(</span><span class="n">all_files_list</span><span class="p">):</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="n">audio_path_length</span><span class="p">:]</span>
    <span class="n">all_files_list</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="n">value</span><span class="p">],</span><span class="n">testing_list</span><span class="p">)</span><span class="o">==</span><span class="kc">False</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="n">value</span><span class="p">],</span><span class="n">validation_list</span><span class="p">)</span><span class="o">==</span><span class="kc">False</span><span class="p">:</span>
        <span class="n">training_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">training_list</span><span class="p">,</span> <span class="n">all_files_list</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">training_list</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; is the shape of the training_list.&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="s1">&#39;audio/training_list.txt&#39;</span><span class="p">,</span><span class="n">training_list</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%.100s</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Retrieved testing_list from C:\Users\Tyler\Desktop\Capstone WIP\audio\testing_list.txt. Size is (6835,).
Retrieved testing_list from C:\Users\Tyler\Desktop\Capstone WIP\audio\validation_list.txt. Size is (6798,).
(51088,) is the shape of the training_list.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="3.-Calculating-Mel-Frequency-Cepstral-Coefficients-(MFCCs)">3. Calculating Mel-Frequency Cepstral Coefficients (MFCCs)<a class="anchor-link" href="#3.-Calculating-Mel-Frequency-Cepstral-Coefficients-(MFCCs)">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This project owes immense gratitude to Practical Cryptography for their excellent tutorial on Mel Frequency Cepstral Coefficients (MFCCs). MFCCs are a widely used tool in Speech Recognition and the logic behind them is fairly simple: human beings communicate by producing sounds through manipulation of their vocal tract (e.g. shape of tongue, position of tongue near teeth, shape of lips, etc.). That is, sound carries information about what is physically being communicated. In short durations, this information is manifested across ranges in the audio power spectrum. MFCCs describe the shape of this information.</p>
<p>To calculate MFCCs for each audio file, I first split the audio files into 2.5ms frames of 400 samples each. For this analysis, I added a stride of 200 samples - thus resulting in 79 frames total. For each frame, I performed a Discrete Fourier Transform to convert the signal from the time domain to the frequency domain. Since DFTs return complex numbers signifying both phase and amplitude, and because I'm only interested in the amplitudes of frequencies (and therefore real numbers), I calculate the periodogram estimate of the power spectrum by squaring each frequency power and dividing the result by the number of samples in the frame size. Only the first half of frequencies are kept; the rest are dropped.</p>
<p>Signals are now converted from frequency to Mels, which relates perceived pitch of a sound to its actual measured frequency. We aggregate these signals by frequency into overlaping bins of triangular filters to measure broader definitions of pitch. These bins span the reach of the human vocal spectrum (300hz to 8000hz). In typical MFCC calculations, between 20 and 40 filters are used in the filterbank. For this project, I use 26. The log of the summation of the energies in each filterbank is taken. We are left with a waveform described by 26 log filterbank energies. This waveform is decomposed using a Discrete Cosine Transform; the results are the MFCCs, describing the shape of the wavelength the power of pitches within the frame. In this analysis, only coefficients 2 - 13 are kept. In practice, typically the first half of coefficients are kept.</p>
<p>Once all frames are compiled, we are left with an array of 79 overlapping frames, each with 12 MFCCs.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># given a filename, mfcc_conversion returns mel frequency cepstral coefficients array</span>
<span class="c1"># mfcc_conversion returns array of (79,12) representing 79 audio frames described by 12 coefficients</span>
<span class="k">def</span> <span class="nf">mfcc_conversion</span><span class="p">(</span><span class="n">audio_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">sample_rate</span> <span class="o">=</span> <span class="mi">16000</span><span class="p">,</span> <span class="n">frame_size</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span> <span class="n">stride_size</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">nfft</span> <span class="o">=</span> <span class="mi">512</span><span class="p">):</span>
    <span class="c1"># decode audio</span>
    <span class="n">decoded_audio</span> <span class="o">=</span> <span class="n">audio_decoder</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">audio_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)))</span>    
    <span class="n">audio</span> <span class="o">=</span> <span class="n">decoded_audio</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">16000</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    
    <span class="n">first_index</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">mfcc_coefficients</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>
    <span class="c1"># apply the following for each signal frame</span>
    <span class="k">while</span> <span class="n">first_index</span> <span class="o">&lt;=</span> <span class="n">audio</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">frame_size</span><span class="p">:</span>
        <span class="n">last_index</span> <span class="o">=</span> <span class="n">first_index</span><span class="o">+</span><span class="n">frame_size</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="n">audio</span><span class="p">[</span><span class="n">first_index</span><span class="p">:</span><span class="n">last_index</span><span class="p">,:]</span>
        
        <span class="c1"># calculate discrete Fourier transform</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">nfft</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="c1"># calculate the periodogram estimate of the power spectrum; drop last half of values</span>
        <span class="n">power_spectrum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">frame</span><span class="p">))</span><span class="o">/</span><span class="n">frame_size</span>
        <span class="n">power_spectrum</span> <span class="o">=</span> <span class="n">power_spectrum</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="nb">int</span><span class="p">(</span><span class="n">nfft</span><span class="o">/</span><span class="mi">2</span><span class="p">),:]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">power_spectrum</span> <span class="o">=</span> <span class="n">power_spectrum</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">power_spectrum</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span>
        <span class="c1"># print(power_spectrum)</span>
        
        <span class="c1"># apply the mel filterbank to the power spectra, sum the energy in each filter</span>
            <span class="c1"># frequencies on which to define mel filterbanks</span>
        <span class="n">mel_freqs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">300</span><span class="p">,</span> <span class="mf">383.4</span><span class="p">,</span> <span class="mf">473.8</span><span class="p">,</span> <span class="mf">571.7</span><span class="p">,</span> <span class="mf">677.8</span><span class="p">,</span> <span class="mf">792.7</span><span class="p">,</span> <span class="mf">917.3</span><span class="p">,</span> <span class="mf">1052.2</span><span class="p">,</span> <span class="mf">1198.3</span><span class="p">,</span> <span class="mf">1356.7</span><span class="p">,</span> <span class="mf">1528.3</span><span class="p">,</span>
                              <span class="mf">1714.2</span><span class="p">,</span> <span class="mf">1915.6</span><span class="p">,</span> <span class="mf">2133.7</span><span class="p">,</span> <span class="mf">2370.1</span><span class="p">,</span> <span class="mf">2626.3</span><span class="p">,</span> <span class="mf">2903.7</span><span class="p">,</span> <span class="mf">3204.4</span><span class="p">,</span> <span class="mf">3530.1</span><span class="p">,</span> <span class="mf">3882.9</span><span class="p">,</span> <span class="mf">4265.2</span><span class="p">,</span>
                              <span class="mf">4679.4</span><span class="p">,</span> <span class="mf">5128.2</span><span class="p">,</span> <span class="mf">5614.4</span><span class="p">,</span> <span class="mf">6141.1</span><span class="p">,</span> <span class="mf">6711.8</span><span class="p">,</span> <span class="mf">7330.1</span><span class="p">,</span> <span class="mi">8000</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">vfunc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">bin_index</span><span class="p">)</span>
        <span class="n">mel_bins</span> <span class="o">=</span> <span class="n">vfunc</span><span class="p">(</span><span class="n">mel_freqs</span><span class="p">,</span> <span class="n">nfft</span><span class="o">=</span><span class="n">nfft</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">)</span>
        <span class="c1"># print(mel_bins)</span>
        
            <span class="c1"># calculate filterbank</span>
        <span class="n">mel_filterbank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">26</span><span class="p">,</span><span class="mi">256</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mel_filterbank</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">mel_filterbank</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">mel_bin_min</span> <span class="o">=</span> <span class="n">mel_bins</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">mel_bin_mid</span> <span class="o">=</span> <span class="n">mel_bins</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">mel_bin_max</span> <span class="o">=</span> <span class="n">mel_bins</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">j</span> <span class="o">&gt;=</span> <span class="n">mel_bin_min</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">mel_bin_mid</span><span class="p">:</span>
                    <span class="nb">filter</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">j</span> <span class="o">-</span> <span class="n">mel_bin_min</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">mel_bin_mid</span> <span class="o">-</span> <span class="n">mel_bin_min</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">j</span> <span class="o">&gt;=</span> <span class="n">mel_bin_mid</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">mel_bin_max</span><span class="p">:</span>
                    <span class="nb">filter</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">mel_bin_max</span><span class="o">-</span> <span class="n">j</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">mel_bin_max</span> <span class="o">-</span> <span class="n">mel_bin_mid</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nb">filter</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">mel_filterbank</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="nb">filter</span>
                
                <span class="c1"># apply filterbank to power spectra and calculate log filterbank energies</span>
        <span class="n">logbankenergies</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">mel_filterbank</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">mel_filterbank</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">mel_filters</span> <span class="o">=</span> <span class="n">mel_filterbank</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span>
            <span class="n">bankenergy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">power_spectrum</span><span class="p">,</span><span class="n">mel_filters</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span>
            <span class="n">logbankenergies</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">bankenergy</span><span class="p">)</span>
            
        
        <span class="c1"># take the discrete cosine transform of the log filterbank energies</span>
        <span class="n">log_dct</span> <span class="o">=</span> <span class="n">dct</span><span class="p">(</span><span class="n">logbankenergies</span><span class="p">)</span>
        
        <span class="c1"># saving DCT coefficients 2-13; discard rest</span>
        <span class="n">log_dct</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">log_dct</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">13</span><span class="p">])</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">first_index</span><span class="o">/</span><span class="n">stride_size</span>
        <span class="n">mfcc_coefficients</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">mfcc_coefficients</span><span class="p">,</span> <span class="n">log_dct</span><span class="p">))</span>
                
        <span class="c1"># set up next frame</span>
        <span class="n">first_index</span> <span class="o">=</span> <span class="n">first_index</span> <span class="o">+</span> <span class="n">stride_size</span>
    
    <span class="k">return</span> <span class="n">mfcc_coefficients</span>

<span class="c1"># calculates bin index given frequency and sample_rate</span>
<span class="k">def</span> <span class="nf">bin_index</span><span class="p">(</span><span class="n">frequency</span><span class="p">,</span> <span class="n">nfft</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">):</span>
    <span class="nb">bin</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">((</span><span class="n">nfft</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">frequency</span><span class="o">/</span><span class="n">sample_rate</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">bin</span>

<span class="c1"># decodes audio given a file name</span>
<span class="k">def</span> <span class="nf">audio_decoder</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="n">rate</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">wavfile</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&lt;=</span><span class="mi">16000</span><span class="p">:</span>
        <span class="n">difference</span> <span class="o">=</span> <span class="mi">16000</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">difference</span><span class="p">,)))</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">16000</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="4.-Prepare-Data-and-One-Hot-Encoded-Targets">4. Prepare Data and One-Hot Encoded Targets<a class="anchor-link" href="#4.-Prepare-Data-and-One-Hot-Encoded-Targets">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="4a.-Calculating-training,-validation,-and-testing-MFCC-datasets">4a. Calculating training, validation, and testing MFCC datasets<a class="anchor-link" href="#4a.-Calculating-training,-validation,-and-testing-MFCC-datasets">&#182;</a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Each list of audio files is decoded into MFCC data arrays and saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># initialize MFCC data arrays in memory</span>
<span class="n">x_training</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">79</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span> <span class="nb">float</span><span class="p">)</span>
<span class="n">x_validation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">79</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span> <span class="nb">float</span><span class="p">)</span>
<span class="n">x_testing</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">79</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span> <span class="nb">float</span><span class="p">)</span>

<span class="n">audio_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;audio&#39;</span><span class="p">,</span><span class="s1">&#39;audio&#39;</span><span class="p">))</span>

<span class="c1"># decode training_list</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">training_list</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">mfccs</span> <span class="o">=</span> <span class="n">mfcc_conversion</span><span class="p">(</span><span class="n">training_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">mfccs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">mfccs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">x_training</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">x_training</span><span class="p">,</span> <span class="n">mfccs</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;data/x_training&#39;</span><span class="p">,</span> <span class="n">x_training</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training list audio decode complete.&quot;</span><span class="p">)</span>

<span class="c1"># decode validation_list</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">validation_list</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">mfccs</span> <span class="o">=</span> <span class="n">mfcc_conversion</span><span class="p">(</span><span class="n">validation_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">mfccs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">mfccs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">x_validation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">x_validation</span><span class="p">,</span> <span class="n">mfccs</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;data/x_validation&#39;</span><span class="p">,</span> <span class="n">x_validation</span><span class="p">)</span>    
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation list audio decode complete.&quot;</span><span class="p">)</span>

<span class="c1"># decode testing_list</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">testing_list</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">mfccs</span> <span class="o">=</span> <span class="n">mfcc_conversion</span><span class="p">(</span><span class="n">testing_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">mfccs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">mfccs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">x_testing</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">x_testing</span><span class="p">,</span> <span class="n">mfccs</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;data/x_testing&#39;</span><span class="p">,</span> <span class="n">x_testing</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing list audio decode complete.&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="4b.-Categorizing-Targets">4b. Categorizing Targets<a class="anchor-link" href="#4b.-Categorizing-Targets">&#182;</a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The models will train on targets reflecting 1 of 11 types of classifications - the 10 words and an 'other' catchall category for unknown sounds. To get these target labels, I look at the parent folder of the audio files and classify as one of 11 numbers. I then use Keras to turn my integer labels into one-hot encoded vectors of size 11, and add a dimension at axis 1 in order for the model to process. I save the results to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># audio targets are determined by the name of their parent folder</span>
<span class="k">def</span> <span class="nf">audio_categorizer</span><span class="p">(</span><span class="n">x_arr</span><span class="p">):</span>
    <span class="n">y_arr</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">ndenumerate</span><span class="p">(</span><span class="n">x_arr</span><span class="p">):</span>
        <span class="n">cat_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cat_name</span> <span class="o">==</span> <span class="s2">&quot;yes&quot;</span><span class="p">:</span>
            <span class="n">y_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_arr</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cat_name</span> <span class="o">==</span> <span class="s2">&quot;no&quot;</span><span class="p">:</span>
            <span class="n">y_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_arr</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cat_name</span> <span class="o">==</span> <span class="s2">&quot;up&quot;</span><span class="p">:</span>
            <span class="n">y_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_arr</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cat_name</span> <span class="o">==</span> <span class="s2">&quot;down&quot;</span><span class="p">:</span>
            <span class="n">y_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_arr</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cat_name</span> <span class="o">==</span> <span class="s2">&quot;left&quot;</span><span class="p">:</span>
            <span class="n">y_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_arr</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cat_name</span> <span class="o">==</span> <span class="s2">&quot;right&quot;</span><span class="p">:</span>
            <span class="n">y_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_arr</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cat_name</span> <span class="o">==</span> <span class="s2">&quot;on&quot;</span><span class="p">:</span>
            <span class="n">y_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_arr</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cat_name</span> <span class="o">==</span> <span class="s2">&quot;off&quot;</span><span class="p">:</span>
            <span class="n">y_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_arr</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cat_name</span> <span class="o">==</span> <span class="s2">&quot;stop&quot;</span><span class="p">:</span>
            <span class="n">y_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_arr</span><span class="p">,</span><span class="mi">9</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cat_name</span> <span class="o">==</span> <span class="s2">&quot;go&quot;</span><span class="p">:</span>
            <span class="n">y_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_arr</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_arr</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y_arr</span> 

<span class="c1"># categorize training labels</span>
<span class="n">y_training</span> <span class="o">=</span> <span class="n">audio_categorizer</span><span class="p">(</span><span class="n">training_list</span><span class="p">)</span>
<span class="n">y_validation</span> <span class="o">=</span> <span class="n">audio_categorizer</span><span class="p">(</span><span class="n">validation_list</span><span class="p">)</span>
<span class="n">y_testing</span> <span class="o">=</span> <span class="n">audio_categorizer</span><span class="p">(</span><span class="n">testing_list</span><span class="p">)</span>

<span class="c1"># applying a one-hot encoding scheme</span>
<span class="n">y_training</span> <span class="o">=</span> <span class="n">np_utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_training</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<span class="n">y_validation</span> <span class="o">=</span> <span class="n">np_utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_validation</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<span class="n">y_testing</span> <span class="o">=</span> <span class="n">np_utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_testing</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>

<span class="c1"># add dimension for network processing</span>
<span class="n">y_training</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">y_training</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_validation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">y_validation</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_testing</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">y_testing</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The shape of training targets is &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">y_training</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The shape of validation targets is &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">y_validation</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The shape of testing targets is &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">y_testing</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

<span class="c1"># save MFCC datasets for future use</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;data/y_training&#39;</span><span class="p">,</span> <span class="n">y_training</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;data/y_validation&#39;</span><span class="p">,</span> <span class="n">y_validation</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;data/y_testing&#39;</span><span class="p">,</span> <span class="n">y_testing</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>The shape of training targets is (51088, 1, 11)
The shape of validation targets is (6798, 1, 11)
The shape of testing targets is (6835, 1, 11)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="5.-Model-Architecture">5. Model Architecture<a class="anchor-link" href="#5.-Model-Architecture">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For model training and evaluation, I developed three different model architectures representing three different types of reasoning. In developing these architectures, I sought to balance these (often-competing) principles:</p>
<ul>
<li>Objectively work to minimize the number of layers in the architecture to maintain some simplicity within the model and to minimize runtime</li>
<li>Use convolutional layers with a wide-enough convolution window and stride to identify patterns</li>
<li>Use pooling layers to reduce dimensionality between convolutional layers</li>
</ul>
<p>Each of the network uses 1-dimensional convolutional layers that slide along the time axis, convoluting MFCCs and reducing the size of the first dimension of the audio data. The idea behind each of these networks is to recognize patterns among MFCCs across time. Differentiating features among these three models were the size of the convolution windows, the overlapping stride of the windows, the number of filters, and the number of layers. The three networks I built are:</p>
<ol>
<li>Large Windows/Few Layers/Many Filters - this model consists of 1 padding layer, 2 convolutional layers with window size of 10 and stride of 5 each, an average pooling layer, and a dense output layer. The convolutional layers have 50 and 100 filters, respetively. Dropout layers have been added after each convolutional layer. </li>
<li>Small Windows/Fewer Filters - this model consists of 5 sets of convolutional layers with window size of 3 and strides of 2 followed by a dense output layer. Each convolutional layer has 20 filters. Dropout layers have been added after each convolutional layer. </li>
<li>Moderate Windows/Increasing Filters - this model consists of a set of 1 padding and 2 convolutional layers with window size 4 and stride 2, followed by another set of 1 padding and 3 convolutional layers with small window sizes. The number of filters increase with each additional layer until the final dense output layer. Dropout layers have been added after each convolutional layer. </li>
</ol>
<p>Hyperparameters that I changed with each model were the dropbout rate (0%,25%,50%), the learning rate (0.01, 0.05, 0.10), and the alpha of the rectified linear unit kernels (0,-0.1, -0.5). Therefore, the total number of models evaluated was 81.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Model_1 is the Large Windows/Many Filters network</span>
<span class="k">def</span> <span class="nf">model_1_architecture</span><span class="p">(</span><span class="n">dropout_rate</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ZeroPadding1D</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">79</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span><span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">AveragePooling1D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="c1"># Model_2 is the Small Windows/Fewer Filters network</span>
<span class="k">def</span> <span class="nf">model_2_architecture</span><span class="p">(</span><span class="n">dropout_rate</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">79</span><span class="p">,</span> <span class="mi">12</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="c1"># Model_3 is the Moderate Windows/Increasing Filters network</span>
<span class="k">def</span> <span class="nf">model_3_architecture</span><span class="p">(</span><span class="n">dropout_rate</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ZeroPadding1D</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">79</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span><span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ZeroPadding1D</span><span class="p">(</span><span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">model_1_architecture</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model 1 Network Summary&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">model_2_architecture</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model 2 Network Summary&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model 3 Network Summary&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model_3_architecture</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model 1 Network Summary
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
zero_padding1d_1 (ZeroPaddin (None, 80, 12)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 15, 50)            6050      
_________________________________________________________________
dropout_1 (Dropout)          (None, 15, 50)            0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 2, 100)            50100     
_________________________________________________________________
dropout_2 (Dropout)          (None, 2, 100)            0         
_________________________________________________________________
average_pooling1d_1 (Average (None, 1, 100)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 1, 11)             1111      
=================================================================
Total params: 57,261
Trainable params: 57,261
Non-trainable params: 0
_________________________________________________________________
Model 2 Network Summary
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_3 (Conv1D)            (None, 39, 20)            740       
_________________________________________________________________
dropout_3 (Dropout)          (None, 39, 20)            0         
_________________________________________________________________
conv1d_4 (Conv1D)            (None, 19, 20)            1220      
_________________________________________________________________
dropout_4 (Dropout)          (None, 19, 20)            0         
_________________________________________________________________
conv1d_5 (Conv1D)            (None, 9, 20)             1220      
_________________________________________________________________
dropout_5 (Dropout)          (None, 9, 20)             0         
_________________________________________________________________
conv1d_6 (Conv1D)            (None, 4, 20)             1220      
_________________________________________________________________
dropout_6 (Dropout)          (None, 4, 20)             0         
_________________________________________________________________
conv1d_7 (Conv1D)            (None, 1, 20)             1220      
_________________________________________________________________
dropout_7 (Dropout)          (None, 1, 20)             0         
_________________________________________________________________
dense_2 (Dense)              (None, 1, 11)             231       
=================================================================
Total params: 5,851
Trainable params: 5,851
Non-trainable params: 0
_________________________________________________________________
Model 3 Network Summary
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
zero_padding1d_2 (ZeroPaddin (None, 82, 12)            0         
_________________________________________________________________
conv1d_8 (Conv1D)            (None, 40, 10)            490       
_________________________________________________________________
dropout_8 (Dropout)          (None, 40, 10)            0         
_________________________________________________________________
conv1d_9 (Conv1D)            (None, 19, 20)            820       
_________________________________________________________________
dropout_9 (Dropout)          (None, 19, 20)            0         
_________________________________________________________________
zero_padding1d_3 (ZeroPaddin (None, 20, 20)            0         
_________________________________________________________________
conv1d_10 (Conv1D)           (None, 9, 40)             3240      
_________________________________________________________________
dropout_10 (Dropout)         (None, 9, 40)             0         
_________________________________________________________________
conv1d_11 (Conv1D)           (None, 3, 60)             7260      
_________________________________________________________________
dropout_11 (Dropout)         (None, 3, 60)             0         
_________________________________________________________________
conv1d_12 (Conv1D)           (None, 1, 80)             14480     
_________________________________________________________________
dropout_12 (Dropout)         (None, 1, 80)             0         
_________________________________________________________________
dense_3 (Dense)              (None, 1, 11)             891       
=================================================================
Total params: 27,181
Trainable params: 27,181
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="6.-Model-Training">6. Model Training<a class="anchor-link" href="#6.-Model-Training">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For network training, I trained the model on random batches of 1000 files per epoch over 60 epochs to ensure that most, if not all, of my 51,100 training data is used. I used the RMSprop optimization algorithm to minimize categorical crossentropy log loss and validated my models comparing both log loss from training and validation. Only the models that minimize log loss are saved to disk. I also enabled early stopping to be triggered after 10 epochs of no improvement in log loss.</p>
<p>Hyperparameters - dropbout rates, learning rates, and the leaky rectified linear unit alpha - were toggled for each of the 3 models resulting in 81 trained models.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_1_train</span><span class="p">(</span><span class="n">x_training</span><span class="p">,</span> <span class="n">y_training</span><span class="p">,</span><span class="n">x_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                  <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">relu_alpha</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">60</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model_1_architecture</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="n">dir_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s1">&#39;__file__&#39;</span><span class="p">)),</span><span class="s1">&#39;models&#39;</span><span class="p">)</span>
    <span class="n">file_name</span> <span class="o">=</span> <span class="s1">&#39;model1_dr&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;_lr&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;_ra&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">relu_alpha</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;.hdf5&#39;</span>
    <span class="n">checkpoint_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
    <span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="n">checkpoint_file</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">early_stopper</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hist</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_training</span><span class="p">,</span> <span class="n">y_training</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
                  <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_validation</span><span class="p">,</span> <span class="n">y_validation</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpointer</span><span class="p">,</span> <span class="n">early_stopper</span><span class="p">],</span> 
                  <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">model_2_train</span><span class="p">(</span><span class="n">x_training</span><span class="p">,</span> <span class="n">y_training</span><span class="p">,</span><span class="n">x_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span><span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                  <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">relu_alpha</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">60</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model_2_architecture</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="n">dir_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s1">&#39;__file__&#39;</span><span class="p">)),</span><span class="s1">&#39;models&#39;</span><span class="p">)</span>
    <span class="n">file_name</span> <span class="o">=</span> <span class="s1">&#39;model2_dr&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;_lr&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;_ra&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">relu_alpha</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;.hdf5&#39;</span>
    <span class="n">checkpoint_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
    <span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="n">checkpoint_file</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">early_stopper</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hist</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_training</span><span class="p">,</span> <span class="n">y_training</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
                  <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_validation</span><span class="p">,</span> <span class="n">y_validation</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpointer</span><span class="p">,</span><span class="n">early_stopper</span><span class="p">],</span> 
                  <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">model_3_train</span><span class="p">(</span><span class="n">x_training</span><span class="p">,</span> <span class="n">y_training</span><span class="p">,</span><span class="n">x_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span><span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                  <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">relu_alpha</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">60</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model_3_architecture</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    <span class="n">dir_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s1">&#39;__file__&#39;</span><span class="p">)),</span><span class="s1">&#39;models&#39;</span><span class="p">)</span>
    <span class="n">file_name</span> <span class="o">=</span> <span class="s1">&#39;model3_dr&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;_lr&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;_ra&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">relu_alpha</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;.hdf5&#39;</span>
    <span class="n">checkpoint_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
    <span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="n">checkpoint_file</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">early_stopper</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hist</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_training</span><span class="p">,</span> <span class="n">y_training</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
                  <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_validation</span><span class="p">,</span> <span class="n">y_validation</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpointer</span><span class="p">,</span><span class="n">early_stopper</span><span class="p">],</span> 
                  <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># load training and validation data into memory</span>
<span class="n">x_training</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;data/x_training.npy&#39;</span><span class="p">)</span>
<span class="n">x_validation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;data/x_validation.npy&#39;</span><span class="p">)</span>

<span class="n">y_training</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;data/y_training.npy&#39;</span><span class="p">)</span>
<span class="n">y_validation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;data/y_validation.npy&#39;</span><span class="p">)</span>

<span class="c1"># hyperparameters</span>
<span class="n">dropout_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.50</span><span class="p">]</span>
<span class="n">learning_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.05</span><span class="p">,</span><span class="mf">0.10</span><span class="p">]</span>
<span class="n">relu_alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="o">-</span><span class="mf">0.5</span><span class="p">]</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">60</span>

<span class="k">for</span> <span class="n">dropout_rate</span> <span class="ow">in</span> <span class="n">dropout_rates</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">learning_rate</span> <span class="ow">in</span> <span class="n">learning_rates</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">relu_alpha</span> <span class="ow">in</span> <span class="n">relu_alphas</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">model_1_train</span><span class="p">(</span><span class="n">x_training</span><span class="p">,</span> <span class="n">y_training</span><span class="p">,</span><span class="n">x_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span>
                                         <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
                                         <span class="n">relu_alpha</span><span class="o">=</span><span class="n">relu_alpha</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">model_2_train</span><span class="p">(</span><span class="n">x_training</span><span class="p">,</span> <span class="n">y_training</span><span class="p">,</span><span class="n">x_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span>
                                         <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
                                         <span class="n">relu_alpha</span><span class="o">=</span><span class="n">relu_alpha</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">model_3_train</span><span class="p">(</span><span class="n">x_training</span><span class="p">,</span> <span class="n">y_training</span><span class="p">,</span><span class="n">x_validation</span><span class="p">,</span><span class="n">y_validation</span><span class="p">,</span>
                                         <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
                                         <span class="n">relu_alpha</span><span class="o">=</span><span class="n">relu_alpha</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>
    
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 5s - loss: 2.7634 - acc: 0.5947 - val_loss: 1.1854 - val_acc: 0.6203

Epoch 00001: val_loss improved from inf to 1.18544, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra0.hdf5
Epoch 2/60
 - 4s - loss: 0.9945 - acc: 0.6972 - val_loss: 0.8687 - val_acc: 0.7242

Epoch 00002: val_loss improved from 1.18544 to 0.86875, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra0.hdf5
Epoch 3/60
 - 4s - loss: 0.7447 - acc: 0.7624 - val_loss: 0.8318 - val_acc: 0.7287

Epoch 00003: val_loss improved from 0.86875 to 0.83176, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra0.hdf5
Epoch 4/60
 - 4s - loss: 0.6096 - acc: 0.8050 - val_loss: 0.6863 - val_acc: 0.7823

Epoch 00004: val_loss improved from 0.83176 to 0.68626, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra0.hdf5
Epoch 5/60
 - 4s - loss: 0.5254 - acc: 0.8321 - val_loss: 0.6418 - val_acc: 0.7966

Epoch 00005: val_loss improved from 0.68626 to 0.64185, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra0.hdf5
Epoch 6/60
 - 4s - loss: 0.4703 - acc: 0.8484 - val_loss: 0.6501 - val_acc: 0.7970

Epoch 00006: val_loss did not improve from 0.64185
Epoch 7/60
 - 4s - loss: 0.4209 - acc: 0.8644 - val_loss: 0.5871 - val_acc: 0.8173

Epoch 00007: val_loss improved from 0.64185 to 0.58708, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra0.hdf5
Epoch 8/60
 - 4s - loss: 0.3799 - acc: 0.8764 - val_loss: 0.5847 - val_acc: 0.8239

Epoch 00008: val_loss improved from 0.58708 to 0.58467, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra0.hdf5
Epoch 9/60
 - 4s - loss: 0.3517 - acc: 0.8868 - val_loss: 0.5662 - val_acc: 0.8382

Epoch 00009: val_loss improved from 0.58467 to 0.56616, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra0.hdf5
Epoch 10/60
 - 4s - loss: 0.3265 - acc: 0.8954 - val_loss: 0.5371 - val_acc: 0.8442

Epoch 00010: val_loss improved from 0.56616 to 0.53709, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra0.hdf5
Epoch 11/60
 - 4s - loss: 0.3031 - acc: 0.9020 - val_loss: 0.5134 - val_acc: 0.8508

Epoch 00011: val_loss improved from 0.53709 to 0.51339, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra0.hdf5
Epoch 12/60
 - 4s - loss: 0.2775 - acc: 0.9106 - val_loss: 0.5990 - val_acc: 0.8339

Epoch 00012: val_loss did not improve from 0.51339
Epoch 13/60
 - 4s - loss: 0.2563 - acc: 0.9168 - val_loss: 0.5741 - val_acc: 0.8404

Epoch 00013: val_loss did not improve from 0.51339
Epoch 14/60
 - 4s - loss: 0.2438 - acc: 0.9209 - val_loss: 0.6129 - val_acc: 0.8305

Epoch 00014: val_loss did not improve from 0.51339
Epoch 15/60
 - 4s - loss: 0.2326 - acc: 0.9248 - val_loss: 0.5820 - val_acc: 0.8466

Epoch 00015: val_loss did not improve from 0.51339
Epoch 16/60
 - 4s - loss: 0.2075 - acc: 0.9325 - val_loss: 0.5945 - val_acc: 0.8444

Epoch 00016: val_loss did not improve from 0.51339
Epoch 17/60
 - 4s - loss: 0.2037 - acc: 0.9334 - val_loss: 0.5656 - val_acc: 0.8510

Epoch 00017: val_loss did not improve from 0.51339
Epoch 18/60
 - 4s - loss: 0.1845 - acc: 0.9397 - val_loss: 0.5870 - val_acc: 0.8483

Epoch 00018: val_loss did not improve from 0.51339
Epoch 19/60
 - 4s - loss: 0.1716 - acc: 0.9442 - val_loss: 0.5817 - val_acc: 0.8554

Epoch 00019: val_loss did not improve from 0.51339
Epoch 20/60
 - 4s - loss: 0.1649 - acc: 0.9454 - val_loss: 0.6074 - val_acc: 0.8425

Epoch 00020: val_loss did not improve from 0.51339
Epoch 21/60
 - 4s - loss: 0.1537 - acc: 0.9507 - val_loss: 0.5925 - val_acc: 0.8535

Epoch 00021: val_loss did not improve from 0.51339
Epoch 00021: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 4s - loss: 1.6071 - acc: 0.6074 - val_loss: 1.4423 - val_acc: 0.6169

Epoch 00001: val_loss improved from inf to 1.44234, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 2/60
 - 3s - loss: 1.3399 - acc: 0.6375 - val_loss: 1.3359 - val_acc: 0.6233

Epoch 00002: val_loss improved from 1.44234 to 1.33587, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 3/60
 - 4s - loss: 1.2268 - acc: 0.6471 - val_loss: 1.2594 - val_acc: 0.6353

Epoch 00003: val_loss improved from 1.33587 to 1.25942, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 4/60
 - 3s - loss: 1.1321 - acc: 0.6606 - val_loss: 1.1694 - val_acc: 0.6503

Epoch 00004: val_loss improved from 1.25942 to 1.16936, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 5/60
 - 3s - loss: 1.0626 - acc: 0.6771 - val_loss: 1.0746 - val_acc: 0.6652

Epoch 00005: val_loss improved from 1.16936 to 1.07459, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 6/60
 - 3s - loss: 1.0036 - acc: 0.6896 - val_loss: 1.0263 - val_acc: 0.6781

Epoch 00006: val_loss improved from 1.07459 to 1.02630, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 7/60
 - 4s - loss: 0.9595 - acc: 0.6998 - val_loss: 0.9918 - val_acc: 0.6859

Epoch 00007: val_loss improved from 1.02630 to 0.99184, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 8/60
 - 3s - loss: 0.9135 - acc: 0.7106 - val_loss: 0.9428 - val_acc: 0.6998

Epoch 00008: val_loss improved from 0.99184 to 0.94284, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 9/60
 - 3s - loss: 0.8764 - acc: 0.7195 - val_loss: 0.9766 - val_acc: 0.6862

Epoch 00009: val_loss did not improve from 0.94284
Epoch 10/60
 - 3s - loss: 0.8426 - acc: 0.7300 - val_loss: 0.8788 - val_acc: 0.7155

Epoch 00010: val_loss improved from 0.94284 to 0.87882, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 11/60
 - 3s - loss: 0.8120 - acc: 0.7405 - val_loss: 0.8787 - val_acc: 0.7095

Epoch 00011: val_loss improved from 0.87882 to 0.87865, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 12/60
 - 3s - loss: 0.7873 - acc: 0.7473 - val_loss: 0.9105 - val_acc: 0.6967

Epoch 00012: val_loss did not improve from 0.87865
Epoch 13/60
 - 3s - loss: 0.7655 - acc: 0.7547 - val_loss: 0.8592 - val_acc: 0.7242

Epoch 00013: val_loss improved from 0.87865 to 0.85917, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 14/60
 - 3s - loss: 0.7457 - acc: 0.7601 - val_loss: 0.8232 - val_acc: 0.7339

Epoch 00014: val_loss improved from 0.85917 to 0.82318, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 15/60
 - 3s - loss: 0.7273 - acc: 0.7657 - val_loss: 0.7933 - val_acc: 0.7364

Epoch 00015: val_loss improved from 0.82318 to 0.79327, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 16/60
 - 3s - loss: 0.7085 - acc: 0.7720 - val_loss: 0.7752 - val_acc: 0.7424

Epoch 00016: val_loss improved from 0.79327 to 0.77523, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 17/60
 - 3s - loss: 0.6928 - acc: 0.7776 - val_loss: 0.8297 - val_acc: 0.7318

Epoch 00017: val_loss did not improve from 0.77523
Epoch 18/60
 - 3s - loss: 0.6773 - acc: 0.7814 - val_loss: 0.7517 - val_acc: 0.7573

Epoch 00018: val_loss improved from 0.77523 to 0.75169, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 19/60
 - 3s - loss: 0.6650 - acc: 0.7886 - val_loss: 0.7068 - val_acc: 0.7710

Epoch 00019: val_loss improved from 0.75169 to 0.70684, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 20/60
 - 3s - loss: 0.6545 - acc: 0.7909 - val_loss: 0.7664 - val_acc: 0.7540

Epoch 00020: val_loss did not improve from 0.70684
Epoch 21/60
 - 3s - loss: 0.6421 - acc: 0.7947 - val_loss: 0.7389 - val_acc: 0.7623

Epoch 00021: val_loss did not improve from 0.70684
Epoch 22/60
 - 3s - loss: 0.6273 - acc: 0.8006 - val_loss: 0.7514 - val_acc: 0.7555

Epoch 00022: val_loss did not improve from 0.70684
Epoch 23/60
 - 3s - loss: 0.6198 - acc: 0.8010 - val_loss: 0.6996 - val_acc: 0.7727

Epoch 00023: val_loss improved from 0.70684 to 0.69962, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 24/60
 - 3s - loss: 0.6118 - acc: 0.8038 - val_loss: 0.6807 - val_acc: 0.7751

Epoch 00024: val_loss improved from 0.69962 to 0.68072, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 25/60
 - 3s - loss: 0.6000 - acc: 0.8083 - val_loss: 0.6591 - val_acc: 0.7871

Epoch 00025: val_loss improved from 0.68072 to 0.65908, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 26/60
 - 3s - loss: 0.5890 - acc: 0.8121 - val_loss: 0.7508 - val_acc: 0.7661

Epoch 00026: val_loss did not improve from 0.65908
Epoch 27/60
 - 3s - loss: 0.5860 - acc: 0.8125 - val_loss: 0.7895 - val_acc: 0.7402

Epoch 00027: val_loss did not improve from 0.65908
Epoch 28/60
 - 3s - loss: 0.5735 - acc: 0.8171 - val_loss: 0.6924 - val_acc: 0.7811

Epoch 00028: val_loss did not improve from 0.65908
Epoch 29/60
 - 3s - loss: 0.5705 - acc: 0.8174 - val_loss: 0.7258 - val_acc: 0.7635

Epoch 00029: val_loss did not improve from 0.65908
Epoch 30/60
 - 3s - loss: 0.5600 - acc: 0.8198 - val_loss: 0.6250 - val_acc: 0.7964

Epoch 00030: val_loss improved from 0.65908 to 0.62499, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 31/60
 - 3s - loss: 0.5521 - acc: 0.8233 - val_loss: 0.6755 - val_acc: 0.7852

Epoch 00031: val_loss did not improve from 0.62499
Epoch 32/60
 - 3s - loss: 0.5422 - acc: 0.8263 - val_loss: 0.7279 - val_acc: 0.7698

Epoch 00032: val_loss did not improve from 0.62499
Epoch 33/60
 - 3s - loss: 0.5420 - acc: 0.8264 - val_loss: 0.6252 - val_acc: 0.8008

Epoch 00033: val_loss did not improve from 0.62499
Epoch 34/60
 - 3s - loss: 0.5312 - acc: 0.8307 - val_loss: 0.6144 - val_acc: 0.7980

Epoch 00034: val_loss improved from 0.62499 to 0.61435, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 35/60
 - 3s - loss: 0.5275 - acc: 0.8309 - val_loss: 0.6324 - val_acc: 0.7914

Epoch 00035: val_loss did not improve from 0.61435
Epoch 36/60
 - 3s - loss: 0.5217 - acc: 0.8342 - val_loss: 0.6739 - val_acc: 0.7879

Epoch 00036: val_loss did not improve from 0.61435
Epoch 37/60
 - 3s - loss: 0.5162 - acc: 0.8346 - val_loss: 0.6478 - val_acc: 0.7980

Epoch 00037: val_loss did not improve from 0.61435
Epoch 38/60
 - 3s - loss: 0.5094 - acc: 0.8382 - val_loss: 0.6208 - val_acc: 0.7971

Epoch 00038: val_loss did not improve from 0.61435
Epoch 39/60
 - 3s - loss: 0.5052 - acc: 0.8381 - val_loss: 0.5995 - val_acc: 0.8058

Epoch 00039: val_loss improved from 0.61435 to 0.59951, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 40/60
 - 3s - loss: 0.5002 - acc: 0.8409 - val_loss: 0.6166 - val_acc: 0.8013

Epoch 00040: val_loss did not improve from 0.59951
Epoch 41/60
 - 3s - loss: 0.4944 - acc: 0.8415 - val_loss: 0.6817 - val_acc: 0.7851

Epoch 00041: val_loss did not improve from 0.59951
Epoch 42/60
 - 3s - loss: 0.4906 - acc: 0.8432 - val_loss: 0.6564 - val_acc: 0.7817

Epoch 00042: val_loss did not improve from 0.59951
Epoch 43/60
 - 3s - loss: 0.4846 - acc: 0.8449 - val_loss: 0.6239 - val_acc: 0.8024

Epoch 00043: val_loss did not improve from 0.59951
Epoch 44/60
 - 3s - loss: 0.4818 - acc: 0.8461 - val_loss: 0.6101 - val_acc: 0.8110

Epoch 00044: val_loss did not improve from 0.59951
Epoch 45/60
 - 4s - loss: 0.4767 - acc: 0.8478 - val_loss: 0.6288 - val_acc: 0.7942

Epoch 00045: val_loss did not improve from 0.59951
Epoch 46/60
 - 4s - loss: 0.4726 - acc: 0.8489 - val_loss: 0.5895 - val_acc: 0.8122

Epoch 00046: val_loss improved from 0.59951 to 0.58955, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 47/60
 - 5s - loss: 0.4669 - acc: 0.8511 - val_loss: 0.6716 - val_acc: 0.8064

Epoch 00047: val_loss did not improve from 0.58955
Epoch 48/60
 - 4s - loss: 0.4656 - acc: 0.8520 - val_loss: 0.5827 - val_acc: 0.8147

Epoch 00048: val_loss improved from 0.58955 to 0.58272, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 49/60
 - 4s - loss: 0.4619 - acc: 0.8522 - val_loss: 0.5953 - val_acc: 0.8089

Epoch 00049: val_loss did not improve from 0.58272
Epoch 50/60
 - 4s - loss: 0.4562 - acc: 0.8555 - val_loss: 0.5892 - val_acc: 0.8088

Epoch 00050: val_loss did not improve from 0.58272
Epoch 51/60
 - 3s - loss: 0.4524 - acc: 0.8550 - val_loss: 0.5708 - val_acc: 0.8217

Epoch 00051: val_loss improved from 0.58272 to 0.57079, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 52/60
 - 3s - loss: 0.4520 - acc: 0.8561 - val_loss: 0.5791 - val_acc: 0.8111

Epoch 00052: val_loss did not improve from 0.57079
Epoch 53/60
 - 3s - loss: 0.4476 - acc: 0.8571 - val_loss: 0.6188 - val_acc: 0.8027

Epoch 00053: val_loss did not improve from 0.57079
Epoch 54/60
 - 4s - loss: 0.4454 - acc: 0.8573 - val_loss: 0.6032 - val_acc: 0.8049

Epoch 00054: val_loss did not improve from 0.57079
Epoch 55/60
 - 3s - loss: 0.4393 - acc: 0.8599 - val_loss: 0.5632 - val_acc: 0.8248

Epoch 00055: val_loss improved from 0.57079 to 0.56319, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5
Epoch 56/60
 - 3s - loss: 0.4357 - acc: 0.8604 - val_loss: 0.5666 - val_acc: 0.8220

Epoch 00056: val_loss did not improve from 0.56319
Epoch 57/60
 - 4s - loss: 0.4369 - acc: 0.8604 - val_loss: 0.5988 - val_acc: 0.8038

Epoch 00057: val_loss did not improve from 0.56319
Epoch 58/60
 - 3s - loss: 0.4306 - acc: 0.8629 - val_loss: 0.5634 - val_acc: 0.8155

Epoch 00058: val_loss did not improve from 0.56319
Epoch 59/60
 - 3s - loss: 0.4283 - acc: 0.8635 - val_loss: 0.5980 - val_acc: 0.8164

Epoch 00059: val_loss did not improve from 0.56319
Epoch 60/60
 - 3s - loss: 0.4269 - acc: 0.8634 - val_loss: 0.5941 - val_acc: 0.8076

Epoch 00060: val_loss did not improve from 0.56319
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 5s - loss: 1.5071 - acc: 0.6209 - val_loss: 1.2462 - val_acc: 0.6333

Epoch 00001: val_loss improved from inf to 1.24619, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra0.hdf5
Epoch 2/60
 - 4s - loss: 1.1054 - acc: 0.6669 - val_loss: 1.1146 - val_acc: 0.6524

Epoch 00002: val_loss improved from 1.24619 to 1.11465, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra0.hdf5
Epoch 3/60
 - 4s - loss: 0.9443 - acc: 0.6996 - val_loss: 1.0019 - val_acc: 0.6777

Epoch 00003: val_loss improved from 1.11465 to 1.00192, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra0.hdf5
Epoch 4/60
 - 4s - loss: 0.8250 - acc: 0.7351 - val_loss: 0.8619 - val_acc: 0.7136

Epoch 00004: val_loss improved from 1.00192 to 0.86193, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra0.hdf5
Epoch 5/60
 - 4s - loss: 0.7408 - acc: 0.7586 - val_loss: 0.7664 - val_acc: 0.7415

Epoch 00005: val_loss improved from 0.86193 to 0.76640, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra0.hdf5
Epoch 6/60
 - 4s - loss: 0.6617 - acc: 0.7852 - val_loss: 0.7219 - val_acc: 0.7670

Epoch 00006: val_loss improved from 0.76640 to 0.72193, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra0.hdf5
Epoch 7/60
 - 4s - loss: 0.6162 - acc: 0.7983 - val_loss: 0.7692 - val_acc: 0.7608

Epoch 00007: val_loss did not improve from 0.72193
Epoch 8/60
 - 4s - loss: 0.5750 - acc: 0.8121 - val_loss: 0.6539 - val_acc: 0.7835

Epoch 00008: val_loss improved from 0.72193 to 0.65389, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra0.hdf5
Epoch 9/60
 - 4s - loss: 0.5436 - acc: 0.8211 - val_loss: 0.6795 - val_acc: 0.7720

Epoch 00009: val_loss did not improve from 0.65389
Epoch 10/60
 - 4s - loss: 0.5113 - acc: 0.8322 - val_loss: 0.6200 - val_acc: 0.8013

Epoch 00010: val_loss improved from 0.65389 to 0.62003, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra0.hdf5
Epoch 11/60
 - 4s - loss: 0.4836 - acc: 0.8431 - val_loss: 0.6249 - val_acc: 0.8076

Epoch 00011: val_loss did not improve from 0.62003
Epoch 12/60
 - 4s - loss: 0.4648 - acc: 0.8463 - val_loss: 0.5991 - val_acc: 0.8104

Epoch 00012: val_loss improved from 0.62003 to 0.59907, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra0.hdf5
Epoch 13/60
 - 4s - loss: 0.4405 - acc: 0.8546 - val_loss: 0.5680 - val_acc: 0.8195

Epoch 00013: val_loss improved from 0.59907 to 0.56797, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra0.hdf5
Epoch 14/60
 - 4s - loss: 0.4235 - acc: 0.8611 - val_loss: 0.6671 - val_acc: 0.7817

Epoch 00014: val_loss did not improve from 0.56797
Epoch 15/60
 - 4s - loss: 0.4104 - acc: 0.8648 - val_loss: 0.5987 - val_acc: 0.8120

Epoch 00015: val_loss did not improve from 0.56797
Epoch 16/60
 - 4s - loss: 0.3922 - acc: 0.8708 - val_loss: 0.6073 - val_acc: 0.8044

Epoch 00016: val_loss did not improve from 0.56797
Epoch 17/60
 - 4s - loss: 0.3813 - acc: 0.8735 - val_loss: 0.5590 - val_acc: 0.8238

Epoch 00017: val_loss improved from 0.56797 to 0.55903, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra0.hdf5
Epoch 18/60
 - 4s - loss: 0.3658 - acc: 0.8787 - val_loss: 0.5662 - val_acc: 0.8158

Epoch 00018: val_loss did not improve from 0.55903
Epoch 19/60
 - 4s - loss: 0.3503 - acc: 0.8845 - val_loss: 0.5301 - val_acc: 0.8335

Epoch 00019: val_loss improved from 0.55903 to 0.53015, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra0.hdf5
Epoch 20/60
 - 4s - loss: 0.3397 - acc: 0.8877 - val_loss: 0.5735 - val_acc: 0.8255

Epoch 00020: val_loss did not improve from 0.53015
Epoch 21/60
 - 4s - loss: 0.3294 - acc: 0.8906 - val_loss: 0.5852 - val_acc: 0.8230

Epoch 00021: val_loss did not improve from 0.53015
Epoch 22/60
 - 4s - loss: 0.3222 - acc: 0.8926 - val_loss: 0.6238 - val_acc: 0.8077

Epoch 00022: val_loss did not improve from 0.53015
Epoch 23/60
 - 4s - loss: 0.3145 - acc: 0.8958 - val_loss: 0.5346 - val_acc: 0.8344

Epoch 00023: val_loss did not improve from 0.53015
Epoch 24/60
 - 4s - loss: 0.3014 - acc: 0.9002 - val_loss: 0.5216 - val_acc: 0.8533

Epoch 00024: val_loss improved from 0.53015 to 0.52161, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra0.hdf5
Epoch 25/60
 - 4s - loss: 0.2924 - acc: 0.9036 - val_loss: 0.6119 - val_acc: 0.8298

Epoch 00025: val_loss did not improve from 0.52161
Epoch 26/60
 - 4s - loss: 0.2873 - acc: 0.9045 - val_loss: 0.5226 - val_acc: 0.8497

Epoch 00026: val_loss did not improve from 0.52161
Epoch 27/60
 - 4s - loss: 0.2786 - acc: 0.9067 - val_loss: 0.5393 - val_acc: 0.8430

Epoch 00027: val_loss did not improve from 0.52161
Epoch 28/60
 - 4s - loss: 0.2708 - acc: 0.9095 - val_loss: 0.5812 - val_acc: 0.8467

Epoch 00028: val_loss did not improve from 0.52161
Epoch 29/60
 - 4s - loss: 0.2637 - acc: 0.9124 - val_loss: 0.5360 - val_acc: 0.8452

Epoch 00029: val_loss did not improve from 0.52161
Epoch 30/60
 - 4s - loss: 0.2581 - acc: 0.9138 - val_loss: 0.6567 - val_acc: 0.8242

Epoch 00030: val_loss did not improve from 0.52161
Epoch 31/60
 - 4s - loss: 0.2477 - acc: 0.9175 - val_loss: 0.5510 - val_acc: 0.8414

Epoch 00031: val_loss did not improve from 0.52161
Epoch 32/60
 - 4s - loss: 0.2463 - acc: 0.9168 - val_loss: 0.6522 - val_acc: 0.8239

Epoch 00032: val_loss did not improve from 0.52161
Epoch 33/60
 - 4s - loss: 0.2348 - acc: 0.9204 - val_loss: 0.6182 - val_acc: 0.8380

Epoch 00033: val_loss did not improve from 0.52161
Epoch 34/60
 - 4s - loss: 0.2312 - acc: 0.9228 - val_loss: 0.6712 - val_acc: 0.8151

Epoch 00034: val_loss did not improve from 0.52161
Epoch 00034: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 6s - loss: 2.6743 - acc: 0.5854 - val_loss: 1.1785 - val_acc: 0.6386

Epoch 00001: val_loss improved from inf to 1.17846, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 2/60
 - 5s - loss: 1.0359 - acc: 0.6872 - val_loss: 0.9694 - val_acc: 0.7073

Epoch 00002: val_loss improved from 1.17846 to 0.96944, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 3/60
 - 5s - loss: 0.7953 - acc: 0.7528 - val_loss: 0.8298 - val_acc: 0.7229

Epoch 00003: val_loss improved from 0.96944 to 0.82977, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 4/60
 - 5s - loss: 0.6679 - acc: 0.7906 - val_loss: 0.6582 - val_acc: 0.7896

Epoch 00004: val_loss improved from 0.82977 to 0.65820, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 5/60
 - 5s - loss: 0.5609 - acc: 0.8228 - val_loss: 0.6115 - val_acc: 0.8005

Epoch 00005: val_loss improved from 0.65820 to 0.61152, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 6/60
 - 5s - loss: 0.5043 - acc: 0.8398 - val_loss: 0.6888 - val_acc: 0.8032

Epoch 00006: val_loss did not improve from 0.61152
Epoch 7/60
 - 5s - loss: 0.4483 - acc: 0.8570 - val_loss: 0.7962 - val_acc: 0.7879

Epoch 00007: val_loss did not improve from 0.61152
Epoch 8/60
 - 5s - loss: 0.4141 - acc: 0.8686 - val_loss: 0.6016 - val_acc: 0.8192

Epoch 00008: val_loss improved from 0.61152 to 0.60163, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 9/60
 - 5s - loss: 0.3778 - acc: 0.8803 - val_loss: 0.5212 - val_acc: 0.8435

Epoch 00009: val_loss improved from 0.60163 to 0.52124, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 10/60
 - 5s - loss: 0.3532 - acc: 0.8861 - val_loss: 0.5327 - val_acc: 0.8382

Epoch 00010: val_loss did not improve from 0.52124
Epoch 11/60
 - 5s - loss: 0.3207 - acc: 0.8971 - val_loss: 0.5910 - val_acc: 0.8373

Epoch 00011: val_loss did not improve from 0.52124
Epoch 12/60
 - 5s - loss: 0.3011 - acc: 0.9009 - val_loss: 0.5400 - val_acc: 0.8420

Epoch 00012: val_loss did not improve from 0.52124
Epoch 13/60
 - 5s - loss: 0.2804 - acc: 0.9085 - val_loss: 0.5846 - val_acc: 0.8316

Epoch 00013: val_loss did not improve from 0.52124
Epoch 14/60
 - 5s - loss: 0.2565 - acc: 0.9172 - val_loss: 0.5377 - val_acc: 0.8469

Epoch 00014: val_loss did not improve from 0.52124
Epoch 15/60
 - 5s - loss: 0.2480 - acc: 0.9197 - val_loss: 0.5483 - val_acc: 0.8386

Epoch 00015: val_loss did not improve from 0.52124
Epoch 16/60
 - 5s - loss: 0.2319 - acc: 0.9247 - val_loss: 0.5530 - val_acc: 0.8372

Epoch 00016: val_loss did not improve from 0.52124
Epoch 17/60
 - 5s - loss: 0.2130 - acc: 0.9304 - val_loss: 0.6375 - val_acc: 0.8361

Epoch 00017: val_loss did not improve from 0.52124
Epoch 18/60
 - 5s - loss: 0.2022 - acc: 0.9333 - val_loss: 0.5994 - val_acc: 0.8436

Epoch 00018: val_loss did not improve from 0.52124
Epoch 19/60
 - 5s - loss: 0.1875 - acc: 0.9383 - val_loss: 0.5779 - val_acc: 0.8419

Epoch 00019: val_loss did not improve from 0.52124
Epoch 00019: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 5s - loss: 1.6908 - acc: 0.5841 - val_loss: 1.4468 - val_acc: 0.6183

Epoch 00001: val_loss improved from inf to 1.44678, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 2/60
 - 4s - loss: 1.3185 - acc: 0.6420 - val_loss: 1.2783 - val_acc: 0.6375

Epoch 00002: val_loss improved from 1.44678 to 1.27827, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 3/60
 - 4s - loss: 1.1822 - acc: 0.6566 - val_loss: 1.1723 - val_acc: 0.6502

Epoch 00003: val_loss improved from 1.27827 to 1.17229, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 4/60
 - 4s - loss: 1.0992 - acc: 0.6701 - val_loss: 1.1070 - val_acc: 0.6623

Epoch 00004: val_loss improved from 1.17229 to 1.10703, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 5/60
 - 4s - loss: 1.0299 - acc: 0.6828 - val_loss: 1.0639 - val_acc: 0.6652

Epoch 00005: val_loss improved from 1.10703 to 1.06390, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 6/60
 - 3s - loss: 0.9687 - acc: 0.6964 - val_loss: 1.0009 - val_acc: 0.6764

Epoch 00006: val_loss improved from 1.06390 to 1.00091, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 7/60
 - 3s - loss: 0.9137 - acc: 0.7114 - val_loss: 0.9626 - val_acc: 0.6930

Epoch 00007: val_loss improved from 1.00091 to 0.96262, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 8/60
 - 3s - loss: 0.8707 - acc: 0.7235 - val_loss: 0.8923 - val_acc: 0.7087

Epoch 00008: val_loss improved from 0.96262 to 0.89229, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 9/60
 - 3s - loss: 0.8373 - acc: 0.7311 - val_loss: 0.8826 - val_acc: 0.7056

Epoch 00009: val_loss improved from 0.89229 to 0.88260, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 10/60
 - 3s - loss: 0.8073 - acc: 0.7410 - val_loss: 0.8616 - val_acc: 0.7183

Epoch 00010: val_loss improved from 0.88260 to 0.86155, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 11/60
 - 3s - loss: 0.7839 - acc: 0.7483 - val_loss: 0.8790 - val_acc: 0.7179

Epoch 00011: val_loss did not improve from 0.86155
Epoch 12/60
 - 3s - loss: 0.7647 - acc: 0.7568 - val_loss: 0.8540 - val_acc: 0.7248

Epoch 00012: val_loss improved from 0.86155 to 0.85405, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 13/60
 - 3s - loss: 0.7446 - acc: 0.7605 - val_loss: 0.8671 - val_acc: 0.7254

Epoch 00013: val_loss did not improve from 0.85405
Epoch 14/60
 - 3s - loss: 0.7289 - acc: 0.7658 - val_loss: 0.7885 - val_acc: 0.7392

Epoch 00014: val_loss improved from 0.85405 to 0.78847, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 15/60
 - 3s - loss: 0.7104 - acc: 0.7729 - val_loss: 0.8857 - val_acc: 0.7321

Epoch 00015: val_loss did not improve from 0.78847
Epoch 16/60
 - 3s - loss: 0.6950 - acc: 0.7776 - val_loss: 0.8342 - val_acc: 0.7339

Epoch 00016: val_loss did not improve from 0.78847
Epoch 17/60
 - 3s - loss: 0.6837 - acc: 0.7806 - val_loss: 0.9115 - val_acc: 0.6943

Epoch 00017: val_loss did not improve from 0.78847
Epoch 18/60
 - 3s - loss: 0.6695 - acc: 0.7865 - val_loss: 0.7740 - val_acc: 0.7563

Epoch 00018: val_loss improved from 0.78847 to 0.77398, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 19/60
 - 3s - loss: 0.6552 - acc: 0.7906 - val_loss: 0.7511 - val_acc: 0.7548

Epoch 00019: val_loss improved from 0.77398 to 0.75108, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 20/60
 - 3s - loss: 0.6443 - acc: 0.7956 - val_loss: 0.7055 - val_acc: 0.7723

Epoch 00020: val_loss improved from 0.75108 to 0.70553, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 21/60
 - 3s - loss: 0.6286 - acc: 0.7987 - val_loss: 0.7453 - val_acc: 0.7630

Epoch 00021: val_loss did not improve from 0.70553
Epoch 22/60
 - 3s - loss: 0.6206 - acc: 0.8028 - val_loss: 0.7155 - val_acc: 0.7714

Epoch 00022: val_loss did not improve from 0.70553
Epoch 23/60
 - 3s - loss: 0.6079 - acc: 0.8066 - val_loss: 0.6929 - val_acc: 0.7752

Epoch 00023: val_loss improved from 0.70553 to 0.69288, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 24/60
 - 3s - loss: 0.6023 - acc: 0.8090 - val_loss: 0.7619 - val_acc: 0.7530

Epoch 00024: val_loss did not improve from 0.69288
Epoch 25/60
 - 3s - loss: 0.5908 - acc: 0.8113 - val_loss: 0.6557 - val_acc: 0.7841

Epoch 00025: val_loss improved from 0.69288 to 0.65571, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 26/60
 - 3s - loss: 0.5859 - acc: 0.8148 - val_loss: 0.6413 - val_acc: 0.7971

Epoch 00026: val_loss improved from 0.65571 to 0.64126, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 27/60
 - 3s - loss: 0.5774 - acc: 0.8162 - val_loss: 0.6719 - val_acc: 0.7866

Epoch 00027: val_loss did not improve from 0.64126
Epoch 28/60
 - 3s - loss: 0.5669 - acc: 0.8190 - val_loss: 0.6821 - val_acc: 0.7845

Epoch 00028: val_loss did not improve from 0.64126
Epoch 29/60
 - 3s - loss: 0.5580 - acc: 0.8236 - val_loss: 0.6406 - val_acc: 0.7967

Epoch 00029: val_loss improved from 0.64126 to 0.64056, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 30/60
 - 3s - loss: 0.5504 - acc: 0.8258 - val_loss: 0.6417 - val_acc: 0.7955

Epoch 00030: val_loss did not improve from 0.64056
Epoch 31/60
 - 3s - loss: 0.5455 - acc: 0.8268 - val_loss: 0.6092 - val_acc: 0.8077

Epoch 00031: val_loss improved from 0.64056 to 0.60917, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 32/60
 - 3s - loss: 0.5384 - acc: 0.8293 - val_loss: 0.6119 - val_acc: 0.8033

Epoch 00032: val_loss did not improve from 0.60917
Epoch 33/60
 - 3s - loss: 0.5333 - acc: 0.8306 - val_loss: 0.6214 - val_acc: 0.7963

Epoch 00033: val_loss did not improve from 0.60917
Epoch 34/60
 - 3s - loss: 0.5285 - acc: 0.8318 - val_loss: 0.6048 - val_acc: 0.8061

Epoch 00034: val_loss improved from 0.60917 to 0.60476, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 35/60
 - 3s - loss: 0.5220 - acc: 0.8349 - val_loss: 0.6054 - val_acc: 0.8038

Epoch 00035: val_loss did not improve from 0.60476
Epoch 36/60
 - 3s - loss: 0.5173 - acc: 0.8344 - val_loss: 0.6520 - val_acc: 0.7935

Epoch 00036: val_loss did not improve from 0.60476
Epoch 37/60
 - 3s - loss: 0.5152 - acc: 0.8377 - val_loss: 0.6142 - val_acc: 0.8063

Epoch 00037: val_loss did not improve from 0.60476
Epoch 38/60
 - 3s - loss: 0.5027 - acc: 0.8395 - val_loss: 0.6601 - val_acc: 0.7910

Epoch 00038: val_loss did not improve from 0.60476
Epoch 39/60
 - 3s - loss: 0.5029 - acc: 0.8398 - val_loss: 0.6722 - val_acc: 0.7949

Epoch 00039: val_loss did not improve from 0.60476
Epoch 40/60
 - 3s - loss: 0.4981 - acc: 0.8427 - val_loss: 0.5657 - val_acc: 0.8167

Epoch 00040: val_loss improved from 0.60476 to 0.56574, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 41/60
 - 3s - loss: 0.4948 - acc: 0.8429 - val_loss: 0.6382 - val_acc: 0.8026

Epoch 00041: val_loss did not improve from 0.56574
Epoch 42/60
 - 3s - loss: 0.4873 - acc: 0.8470 - val_loss: 0.5801 - val_acc: 0.8154

Epoch 00042: val_loss did not improve from 0.56574
Epoch 43/60
 - 3s - loss: 0.4869 - acc: 0.8453 - val_loss: 0.5677 - val_acc: 0.8155

Epoch 00043: val_loss did not improve from 0.56574
Epoch 44/60
 - 3s - loss: 0.4806 - acc: 0.8483 - val_loss: 0.6109 - val_acc: 0.8076

Epoch 00044: val_loss did not improve from 0.56574
Epoch 45/60
 - 3s - loss: 0.4794 - acc: 0.8475 - val_loss: 0.5830 - val_acc: 0.8152

Epoch 00045: val_loss did not improve from 0.56574
Epoch 46/60
 - 3s - loss: 0.4768 - acc: 0.8497 - val_loss: 0.5821 - val_acc: 0.8161

Epoch 00046: val_loss did not improve from 0.56574
Epoch 47/60
 - 3s - loss: 0.4706 - acc: 0.8502 - val_loss: 0.5947 - val_acc: 0.8123

Epoch 00047: val_loss did not improve from 0.56574
Epoch 48/60
 - 3s - loss: 0.4704 - acc: 0.8505 - val_loss: 0.5806 - val_acc: 0.8144

Epoch 00048: val_loss did not improve from 0.56574
Epoch 49/60
 - 3s - loss: 0.4640 - acc: 0.8520 - val_loss: 0.6032 - val_acc: 0.8088

Epoch 00049: val_loss did not improve from 0.56574
Epoch 50/60
 - 3s - loss: 0.4607 - acc: 0.8543 - val_loss: 0.5659 - val_acc: 0.8180

Epoch 00050: val_loss did not improve from 0.56574
Epoch 00050: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 5s - loss: 1.4391 - acc: 0.6242 - val_loss: 1.2091 - val_acc: 0.6361

Epoch 00001: val_loss improved from inf to 1.20911, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 2/60
 - 4s - loss: 1.0700 - acc: 0.6725 - val_loss: 1.0051 - val_acc: 0.6848

Epoch 00002: val_loss improved from 1.20911 to 1.00507, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 3/60
 - 4s - loss: 0.8987 - acc: 0.7158 - val_loss: 0.9856 - val_acc: 0.6948

Epoch 00003: val_loss improved from 1.00507 to 0.98565, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 4/60
 - 4s - loss: 0.7976 - acc: 0.7427 - val_loss: 0.8321 - val_acc: 0.7305

Epoch 00004: val_loss improved from 0.98565 to 0.83213, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 5/60
 - 4s - loss: 0.7256 - acc: 0.7665 - val_loss: 0.7725 - val_acc: 0.7511

Epoch 00005: val_loss improved from 0.83213 to 0.77249, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 6/60
 - 4s - loss: 0.6630 - acc: 0.7828 - val_loss: 0.8212 - val_acc: 0.7329

Epoch 00006: val_loss did not improve from 0.77249
Epoch 7/60
 - 4s - loss: 0.6237 - acc: 0.7961 - val_loss: 0.7639 - val_acc: 0.7592

Epoch 00007: val_loss improved from 0.77249 to 0.76395, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 8/60
 - 4s - loss: 0.5870 - acc: 0.8077 - val_loss: 0.7369 - val_acc: 0.7557

Epoch 00008: val_loss improved from 0.76395 to 0.73693, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 9/60
 - 4s - loss: 0.5522 - acc: 0.8190 - val_loss: 0.6312 - val_acc: 0.7935

Epoch 00009: val_loss improved from 0.73693 to 0.63122, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 10/60
 - 4s - loss: 0.5256 - acc: 0.8269 - val_loss: 0.7837 - val_acc: 0.7493

Epoch 00010: val_loss did not improve from 0.63122
Epoch 11/60
 - 4s - loss: 0.5015 - acc: 0.8352 - val_loss: 0.8081 - val_acc: 0.7574

Epoch 00011: val_loss did not improve from 0.63122
Epoch 12/60
 - 4s - loss: 0.4785 - acc: 0.8438 - val_loss: 0.5913 - val_acc: 0.8136

Epoch 00012: val_loss improved from 0.63122 to 0.59127, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 13/60
 - 4s - loss: 0.4598 - acc: 0.8496 - val_loss: 0.5781 - val_acc: 0.8129

Epoch 00013: val_loss improved from 0.59127 to 0.57811, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 14/60
 - 4s - loss: 0.4440 - acc: 0.8532 - val_loss: 0.5472 - val_acc: 0.8179

Epoch 00014: val_loss improved from 0.57811 to 0.54724, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 15/60
 - 4s - loss: 0.4229 - acc: 0.8609 - val_loss: 0.6201 - val_acc: 0.8017

Epoch 00015: val_loss did not improve from 0.54724
Epoch 16/60
 - 4s - loss: 0.4070 - acc: 0.8653 - val_loss: 0.6004 - val_acc: 0.8039

Epoch 00016: val_loss did not improve from 0.54724
Epoch 17/60
 - 4s - loss: 0.3887 - acc: 0.8701 - val_loss: 0.6104 - val_acc: 0.8066

Epoch 00017: val_loss did not improve from 0.54724
Epoch 18/60
 - 4s - loss: 0.3786 - acc: 0.8732 - val_loss: 0.5891 - val_acc: 0.8148

Epoch 00018: val_loss did not improve from 0.54724
Epoch 19/60
 - 4s - loss: 0.3690 - acc: 0.8780 - val_loss: 0.5454 - val_acc: 0.8260

Epoch 00019: val_loss improved from 0.54724 to 0.54541, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 20/60
 - 4s - loss: 0.3545 - acc: 0.8827 - val_loss: 0.5801 - val_acc: 0.8183

Epoch 00020: val_loss did not improve from 0.54541
Epoch 21/60
 - 4s - loss: 0.3453 - acc: 0.8849 - val_loss: 0.5892 - val_acc: 0.8189

Epoch 00021: val_loss did not improve from 0.54541
Epoch 22/60
 - 4s - loss: 0.3323 - acc: 0.8872 - val_loss: 0.5860 - val_acc: 0.8239

Epoch 00022: val_loss did not improve from 0.54541
Epoch 23/60
 - 4s - loss: 0.3250 - acc: 0.8899 - val_loss: 0.5444 - val_acc: 0.8292

Epoch 00023: val_loss improved from 0.54541 to 0.54435, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 24/60
 - 4s - loss: 0.3132 - acc: 0.8932 - val_loss: 0.5761 - val_acc: 0.8263

Epoch 00024: val_loss did not improve from 0.54435
Epoch 25/60
 - 4s - loss: 0.3076 - acc: 0.8969 - val_loss: 0.6667 - val_acc: 0.8189

Epoch 00025: val_loss did not improve from 0.54435
Epoch 26/60
 - 4s - loss: 0.2986 - acc: 0.8977 - val_loss: 0.5321 - val_acc: 0.8416

Epoch 00026: val_loss improved from 0.54435 to 0.53215, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.1.hdf5
Epoch 27/60
 - 4s - loss: 0.2889 - acc: 0.9019 - val_loss: 0.5798 - val_acc: 0.8232

Epoch 00027: val_loss did not improve from 0.53215
Epoch 28/60
 - 4s - loss: 0.2817 - acc: 0.9059 - val_loss: 0.5394 - val_acc: 0.8367

Epoch 00028: val_loss did not improve from 0.53215
Epoch 29/60
 - 4s - loss: 0.2675 - acc: 0.9105 - val_loss: 0.6595 - val_acc: 0.8007

Epoch 00029: val_loss did not improve from 0.53215
Epoch 30/60
 - 4s - loss: 0.2721 - acc: 0.9084 - val_loss: 0.5924 - val_acc: 0.8313

Epoch 00030: val_loss did not improve from 0.53215
Epoch 31/60
 - 4s - loss: 0.2589 - acc: 0.9124 - val_loss: 0.7038 - val_acc: 0.8179

Epoch 00031: val_loss did not improve from 0.53215
Epoch 32/60
 - 4s - loss: 0.2555 - acc: 0.9147 - val_loss: 0.5638 - val_acc: 0.8377

Epoch 00032: val_loss did not improve from 0.53215
Epoch 33/60
 - 4s - loss: 0.2427 - acc: 0.9177 - val_loss: 0.6152 - val_acc: 0.8235

Epoch 00033: val_loss did not improve from 0.53215
Epoch 34/60
 - 4s - loss: 0.2387 - acc: 0.9206 - val_loss: 0.6210 - val_acc: 0.8317

Epoch 00034: val_loss did not improve from 0.53215
Epoch 35/60
 - 4s - loss: 0.2347 - acc: 0.9199 - val_loss: 0.6227 - val_acc: 0.8289

Epoch 00035: val_loss did not improve from 0.53215
Epoch 36/60
 - 4s - loss: 0.2314 - acc: 0.9206 - val_loss: 0.5762 - val_acc: 0.8386

Epoch 00036: val_loss did not improve from 0.53215
Epoch 00036: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 5s - loss: 3.7196 - acc: 0.5821 - val_loss: 1.2195 - val_acc: 0.6383

Epoch 00001: val_loss improved from inf to 1.21948, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 2/60
 - 4s - loss: 1.1076 - acc: 0.6699 - val_loss: 0.9680 - val_acc: 0.6908

Epoch 00002: val_loss improved from 1.21948 to 0.96798, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 3/60
 - 4s - loss: 0.8131 - acc: 0.7438 - val_loss: 0.7713 - val_acc: 0.7474

Epoch 00003: val_loss improved from 0.96798 to 0.77132, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 4/60
 - 4s - loss: 0.6407 - acc: 0.7960 - val_loss: 0.6780 - val_acc: 0.7877

Epoch 00004: val_loss improved from 0.77132 to 0.67795, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 5/60
 - 4s - loss: 0.5533 - acc: 0.8226 - val_loss: 0.6749 - val_acc: 0.7944

Epoch 00005: val_loss improved from 0.67795 to 0.67493, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 6/60
 - 4s - loss: 0.4880 - acc: 0.8444 - val_loss: 0.5586 - val_acc: 0.8251

Epoch 00006: val_loss improved from 0.67493 to 0.55860, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 7/60
 - 4s - loss: 0.4244 - acc: 0.8630 - val_loss: 0.7175 - val_acc: 0.8004

Epoch 00007: val_loss did not improve from 0.55860
Epoch 8/60
 - 4s - loss: 0.3938 - acc: 0.8744 - val_loss: 0.5868 - val_acc: 0.8230

Epoch 00008: val_loss did not improve from 0.55860
Epoch 9/60
 - 4s - loss: 0.3558 - acc: 0.8849 - val_loss: 0.5473 - val_acc: 0.8247

Epoch 00009: val_loss improved from 0.55860 to 0.54728, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 10/60
 - 4s - loss: 0.3305 - acc: 0.8927 - val_loss: 0.6617 - val_acc: 0.7932

Epoch 00010: val_loss did not improve from 0.54728
Epoch 11/60
 - 4s - loss: 0.3034 - acc: 0.9009 - val_loss: 0.5245 - val_acc: 0.8476

Epoch 00011: val_loss improved from 0.54728 to 0.52448, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 12/60
 - 4s - loss: 0.2844 - acc: 0.9068 - val_loss: 0.5282 - val_acc: 0.8455

Epoch 00012: val_loss did not improve from 0.52448
Epoch 13/60
 - 4s - loss: 0.2626 - acc: 0.9140 - val_loss: 0.5321 - val_acc: 0.8508

Epoch 00013: val_loss did not improve from 0.52448
Epoch 14/60
 - 4s - loss: 0.2396 - acc: 0.9225 - val_loss: 0.5154 - val_acc: 0.8545

Epoch 00014: val_loss improved from 0.52448 to 0.51536, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 15/60
 - 4s - loss: 0.2222 - acc: 0.9270 - val_loss: 0.5687 - val_acc: 0.8364

Epoch 00015: val_loss did not improve from 0.51536
Epoch 16/60
 - 4s - loss: 0.2131 - acc: 0.9290 - val_loss: 0.6430 - val_acc: 0.8245

Epoch 00016: val_loss did not improve from 0.51536
Epoch 17/60
 - 4s - loss: 0.1921 - acc: 0.9376 - val_loss: 0.5372 - val_acc: 0.8485

Epoch 00017: val_loss did not improve from 0.51536
Epoch 18/60
 - 4s - loss: 0.1841 - acc: 0.9402 - val_loss: 0.5830 - val_acc: 0.8410

Epoch 00018: val_loss did not improve from 0.51536
Epoch 19/60
 - 4s - loss: 0.1659 - acc: 0.9448 - val_loss: 0.7162 - val_acc: 0.8166

Epoch 00019: val_loss did not improve from 0.51536
Epoch 20/60
 - 4s - loss: 0.1626 - acc: 0.9464 - val_loss: 0.7211 - val_acc: 0.8423

Epoch 00020: val_loss did not improve from 0.51536
Epoch 21/60
 - 4s - loss: 0.1406 - acc: 0.9539 - val_loss: 0.6947 - val_acc: 0.8420

Epoch 00021: val_loss did not improve from 0.51536
Epoch 22/60
 - 4s - loss: 0.1415 - acc: 0.9538 - val_loss: 0.5775 - val_acc: 0.8545

Epoch 00022: val_loss did not improve from 0.51536
Epoch 23/60
 - 4s - loss: 0.1287 - acc: 0.9585 - val_loss: 0.5987 - val_acc: 0.8528

Epoch 00023: val_loss did not improve from 0.51536
Epoch 24/60
 - 4s - loss: 0.1214 - acc: 0.9604 - val_loss: 0.6006 - val_acc: 0.8598

Epoch 00024: val_loss did not improve from 0.51536
Epoch 00024: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 4s - loss: 1.5435 - acc: 0.6137 - val_loss: 1.4147 - val_acc: 0.6233

Epoch 00001: val_loss improved from inf to 1.41472, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 2/60
 - 3s - loss: 1.3048 - acc: 0.6426 - val_loss: 1.2706 - val_acc: 0.6364

Epoch 00002: val_loss improved from 1.41472 to 1.27064, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 3/60
 - 3s - loss: 1.1913 - acc: 0.6577 - val_loss: 1.1995 - val_acc: 0.6433

Epoch 00003: val_loss improved from 1.27064 to 1.19951, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 4/60
 - 3s - loss: 1.1102 - acc: 0.6710 - val_loss: 1.1013 - val_acc: 0.6605

Epoch 00004: val_loss improved from 1.19951 to 1.10127, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 5/60
 - 3s - loss: 1.0449 - acc: 0.6829 - val_loss: 1.0557 - val_acc: 0.6686

Epoch 00005: val_loss improved from 1.10127 to 1.05570, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 6/60
 - 3s - loss: 0.9893 - acc: 0.6945 - val_loss: 1.0274 - val_acc: 0.6790

Epoch 00006: val_loss improved from 1.05570 to 1.02741, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 7/60
 - 3s - loss: 0.9410 - acc: 0.7062 - val_loss: 0.9624 - val_acc: 0.6912

Epoch 00007: val_loss improved from 1.02741 to 0.96236, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 8/60
 - 3s - loss: 0.9012 - acc: 0.7172 - val_loss: 0.9268 - val_acc: 0.7081

Epoch 00008: val_loss improved from 0.96236 to 0.92677, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 9/60
 - 3s - loss: 0.8674 - acc: 0.7244 - val_loss: 0.8973 - val_acc: 0.7095

Epoch 00009: val_loss improved from 0.92677 to 0.89731, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 10/60
 - 3s - loss: 0.8363 - acc: 0.7329 - val_loss: 0.8527 - val_acc: 0.7224

Epoch 00010: val_loss improved from 0.89731 to 0.85272, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 11/60
 - 4s - loss: 0.8083 - acc: 0.7412 - val_loss: 0.8389 - val_acc: 0.7282

Epoch 00011: val_loss improved from 0.85272 to 0.83892, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 12/60
 - 4s - loss: 0.7823 - acc: 0.7478 - val_loss: 0.8725 - val_acc: 0.7202

Epoch 00012: val_loss did not improve from 0.83892
Epoch 13/60
 - 5s - loss: 0.7641 - acc: 0.7548 - val_loss: 0.7777 - val_acc: 0.7492

Epoch 00013: val_loss improved from 0.83892 to 0.77772, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 14/60
 - 3s - loss: 0.7393 - acc: 0.7631 - val_loss: 0.7748 - val_acc: 0.7508

Epoch 00014: val_loss improved from 0.77772 to 0.77479, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 15/60
 - 4s - loss: 0.7232 - acc: 0.7669 - val_loss: 0.7820 - val_acc: 0.7473

Epoch 00015: val_loss did not improve from 0.77479
Epoch 16/60
 - 4s - loss: 0.7043 - acc: 0.7733 - val_loss: 0.7435 - val_acc: 0.7623

Epoch 00016: val_loss improved from 0.77479 to 0.74355, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 17/60
 - 4s - loss: 0.6843 - acc: 0.7803 - val_loss: 0.7701 - val_acc: 0.7563

Epoch 00017: val_loss did not improve from 0.74355
Epoch 18/60
 - 4s - loss: 0.6718 - acc: 0.7831 - val_loss: 0.7990 - val_acc: 0.7315

Epoch 00018: val_loss did not improve from 0.74355
Epoch 19/60
 - 4s - loss: 0.6540 - acc: 0.7897 - val_loss: 0.7225 - val_acc: 0.7692

Epoch 00019: val_loss improved from 0.74355 to 0.72251, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 20/60
 - 3s - loss: 0.6415 - acc: 0.7943 - val_loss: 0.7876 - val_acc: 0.7564

Epoch 00020: val_loss did not improve from 0.72251
Epoch 21/60
 - 3s - loss: 0.6302 - acc: 0.7983 - val_loss: 0.7265 - val_acc: 0.7743

Epoch 00021: val_loss did not improve from 0.72251
Epoch 22/60
 - 3s - loss: 0.6201 - acc: 0.8017 - val_loss: 0.7962 - val_acc: 0.7423

Epoch 00022: val_loss did not improve from 0.72251
Epoch 23/60
 - 4s - loss: 0.6076 - acc: 0.8060 - val_loss: 0.7361 - val_acc: 0.7598

Epoch 00023: val_loss did not improve from 0.72251
Epoch 24/60
 - 4s - loss: 0.5981 - acc: 0.8073 - val_loss: 0.6785 - val_acc: 0.7858

Epoch 00024: val_loss improved from 0.72251 to 0.67851, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 25/60
 - 4s - loss: 0.5911 - acc: 0.8099 - val_loss: 0.7421 - val_acc: 0.7639

Epoch 00025: val_loss did not improve from 0.67851
Epoch 26/60
 - 5s - loss: 0.5823 - acc: 0.8135 - val_loss: 0.6746 - val_acc: 0.7818

Epoch 00026: val_loss improved from 0.67851 to 0.67459, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 27/60
 - 4s - loss: 0.5705 - acc: 0.8162 - val_loss: 0.6914 - val_acc: 0.7758

Epoch 00027: val_loss did not improve from 0.67459
Epoch 28/60
 - 5s - loss: 0.5647 - acc: 0.8196 - val_loss: 0.6801 - val_acc: 0.7820

Epoch 00028: val_loss did not improve from 0.67459
Epoch 29/60
 - 3s - loss: 0.5568 - acc: 0.8218 - val_loss: 0.6546 - val_acc: 0.7889

Epoch 00029: val_loss improved from 0.67459 to 0.65464, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 30/60
 - 3s - loss: 0.5514 - acc: 0.8222 - val_loss: 0.7061 - val_acc: 0.7668

Epoch 00030: val_loss did not improve from 0.65464
Epoch 31/60
 - 3s - loss: 0.5459 - acc: 0.8252 - val_loss: 0.6817 - val_acc: 0.7885

Epoch 00031: val_loss did not improve from 0.65464
Epoch 32/60
 - 3s - loss: 0.5401 - acc: 0.8266 - val_loss: 0.6479 - val_acc: 0.7879

Epoch 00032: val_loss improved from 0.65464 to 0.64794, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 33/60
 - 3s - loss: 0.5314 - acc: 0.8291 - val_loss: 0.6642 - val_acc: 0.7892

Epoch 00033: val_loss did not improve from 0.64794
Epoch 34/60
 - 3s - loss: 0.5257 - acc: 0.8312 - val_loss: 0.6018 - val_acc: 0.8111

Epoch 00034: val_loss improved from 0.64794 to 0.60182, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 35/60
 - 3s - loss: 0.5206 - acc: 0.8326 - val_loss: 0.6500 - val_acc: 0.7961

Epoch 00035: val_loss did not improve from 0.60182
Epoch 36/60
 - 3s - loss: 0.5152 - acc: 0.8345 - val_loss: 0.6516 - val_acc: 0.7905

Epoch 00036: val_loss did not improve from 0.60182
Epoch 37/60
 - 3s - loss: 0.5094 - acc: 0.8365 - val_loss: 0.6232 - val_acc: 0.8026

Epoch 00037: val_loss did not improve from 0.60182
Epoch 38/60
 - 3s - loss: 0.5056 - acc: 0.8383 - val_loss: 0.6110 - val_acc: 0.8048

Epoch 00038: val_loss did not improve from 0.60182
Epoch 39/60
 - 3s - loss: 0.5011 - acc: 0.8384 - val_loss: 0.6788 - val_acc: 0.7863

Epoch 00039: val_loss did not improve from 0.60182
Epoch 40/60
 - 3s - loss: 0.4933 - acc: 0.8420 - val_loss: 0.6126 - val_acc: 0.8074

Epoch 00040: val_loss did not improve from 0.60182
Epoch 41/60
 - 3s - loss: 0.4926 - acc: 0.8411 - val_loss: 0.6337 - val_acc: 0.8032

Epoch 00041: val_loss did not improve from 0.60182
Epoch 42/60
 - 3s - loss: 0.4863 - acc: 0.8428 - val_loss: 0.7388 - val_acc: 0.7623

Epoch 00042: val_loss did not improve from 0.60182
Epoch 43/60
 - 3s - loss: 0.4843 - acc: 0.8451 - val_loss: 0.6499 - val_acc: 0.8032

Epoch 00043: val_loss did not improve from 0.60182
Epoch 44/60
 - 3s - loss: 0.4815 - acc: 0.8446 - val_loss: 0.5708 - val_acc: 0.8213

Epoch 00044: val_loss improved from 0.60182 to 0.57084, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 45/60
 - 3s - loss: 0.4720 - acc: 0.8483 - val_loss: 0.6412 - val_acc: 0.7899

Epoch 00045: val_loss did not improve from 0.57084
Epoch 46/60
 - 3s - loss: 0.4718 - acc: 0.8482 - val_loss: 0.6447 - val_acc: 0.7945

Epoch 00046: val_loss did not improve from 0.57084
Epoch 47/60
 - 3s - loss: 0.4694 - acc: 0.8496 - val_loss: 0.5860 - val_acc: 0.8124

Epoch 00047: val_loss did not improve from 0.57084
Epoch 48/60
 - 3s - loss: 0.4648 - acc: 0.8503 - val_loss: 0.5701 - val_acc: 0.8217

Epoch 00048: val_loss improved from 0.57084 to 0.57012, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 49/60
 - 3s - loss: 0.4598 - acc: 0.8521 - val_loss: 0.6915 - val_acc: 0.8027

Epoch 00049: val_loss did not improve from 0.57012
Epoch 50/60
 - 4s - loss: 0.4629 - acc: 0.8510 - val_loss: 0.6270 - val_acc: 0.8098

Epoch 00050: val_loss did not improve from 0.57012
Epoch 51/60
 - 4s - loss: 0.4553 - acc: 0.8532 - val_loss: 0.6032 - val_acc: 0.8051

Epoch 00051: val_loss did not improve from 0.57012
Epoch 52/60
 - 4s - loss: 0.4527 - acc: 0.8540 - val_loss: 0.6262 - val_acc: 0.8094

Epoch 00052: val_loss did not improve from 0.57012
Epoch 53/60
 - 4s - loss: 0.4518 - acc: 0.8544 - val_loss: 0.5690 - val_acc: 0.8151

Epoch 00053: val_loss improved from 0.57012 to 0.56898, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 54/60
 - 4s - loss: 0.4456 - acc: 0.8568 - val_loss: 0.6111 - val_acc: 0.8157

Epoch 00054: val_loss did not improve from 0.56898
Epoch 55/60
 - 4s - loss: 0.4476 - acc: 0.8566 - val_loss: 0.6083 - val_acc: 0.8148

Epoch 00055: val_loss did not improve from 0.56898
Epoch 56/60
 - 4s - loss: 0.4413 - acc: 0.8573 - val_loss: 0.6147 - val_acc: 0.8102

Epoch 00056: val_loss did not improve from 0.56898
Epoch 57/60
 - 4s - loss: 0.4382 - acc: 0.8594 - val_loss: 0.5529 - val_acc: 0.8292

Epoch 00057: val_loss improved from 0.56898 to 0.55292, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 58/60
 - 3s - loss: 0.4404 - acc: 0.8577 - val_loss: 0.5875 - val_acc: 0.8223

Epoch 00058: val_loss did not improve from 0.55292
Epoch 59/60
 - 3s - loss: 0.4333 - acc: 0.8605 - val_loss: 0.6117 - val_acc: 0.8114

Epoch 00059: val_loss did not improve from 0.55292
Epoch 60/60
 - 4s - loss: 0.4321 - acc: 0.8623 - val_loss: 0.6085 - val_acc: 0.8071

Epoch 00060: val_loss did not improve from 0.55292
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 6s - loss: 1.3905 - acc: 0.6307 - val_loss: 1.2758 - val_acc: 0.6337

Epoch 00001: val_loss improved from inf to 1.27581, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 2/60
 - 4s - loss: 1.0900 - acc: 0.6711 - val_loss: 1.0356 - val_acc: 0.6673

Epoch 00002: val_loss improved from 1.27581 to 1.03558, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 3/60
 - 6s - loss: 0.9695 - acc: 0.6976 - val_loss: 1.0011 - val_acc: 0.6796

Epoch 00003: val_loss improved from 1.03558 to 1.00111, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 4/60
 - 5s - loss: 0.8746 - acc: 0.7214 - val_loss: 0.8849 - val_acc: 0.7168

Epoch 00004: val_loss improved from 1.00111 to 0.88494, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 5/60
 - 5s - loss: 0.8117 - acc: 0.7397 - val_loss: 0.8041 - val_acc: 0.7410

Epoch 00005: val_loss improved from 0.88494 to 0.80412, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 6/60
 - 5s - loss: 0.7440 - acc: 0.7597 - val_loss: 0.9108 - val_acc: 0.7198

Epoch 00006: val_loss did not improve from 0.80412
Epoch 7/60
 - 5s - loss: 0.6906 - acc: 0.7765 - val_loss: 0.8510 - val_acc: 0.7284

Epoch 00007: val_loss did not improve from 0.80412
Epoch 8/60
 - 5s - loss: 0.6507 - acc: 0.7887 - val_loss: 0.7350 - val_acc: 0.7660

Epoch 00008: val_loss improved from 0.80412 to 0.73504, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 9/60
 - 5s - loss: 0.6056 - acc: 0.8027 - val_loss: 0.7268 - val_acc: 0.7586

Epoch 00009: val_loss improved from 0.73504 to 0.72683, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 10/60
 - 5s - loss: 0.5679 - acc: 0.8148 - val_loss: 0.6884 - val_acc: 0.7689

Epoch 00010: val_loss improved from 0.72683 to 0.68840, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 11/60
 - 4s - loss: 0.5388 - acc: 0.8237 - val_loss: 0.6362 - val_acc: 0.7927

Epoch 00011: val_loss improved from 0.68840 to 0.63616, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 12/60
 - 5s - loss: 0.5115 - acc: 0.8326 - val_loss: 0.5924 - val_acc: 0.8095

Epoch 00012: val_loss improved from 0.63616 to 0.59240, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 13/60
 - 5s - loss: 0.4885 - acc: 0.8382 - val_loss: 0.6110 - val_acc: 0.8044

Epoch 00013: val_loss did not improve from 0.59240
Epoch 14/60
 - 5s - loss: 0.4652 - acc: 0.8490 - val_loss: 0.6516 - val_acc: 0.8042

Epoch 00014: val_loss did not improve from 0.59240
Epoch 15/60
 - 5s - loss: 0.4457 - acc: 0.8543 - val_loss: 0.5864 - val_acc: 0.8129

Epoch 00015: val_loss improved from 0.59240 to 0.58641, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 16/60
 - 5s - loss: 0.4264 - acc: 0.8602 - val_loss: 0.6895 - val_acc: 0.7954

Epoch 00016: val_loss did not improve from 0.58641
Epoch 17/60
 - 4s - loss: 0.4110 - acc: 0.8649 - val_loss: 0.7114 - val_acc: 0.8007

Epoch 00017: val_loss did not improve from 0.58641
Epoch 18/60
 - 4s - loss: 0.4007 - acc: 0.8688 - val_loss: 0.5612 - val_acc: 0.8220

Epoch 00018: val_loss improved from 0.58641 to 0.56119, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 19/60
 - 4s - loss: 0.3838 - acc: 0.8738 - val_loss: 0.5842 - val_acc: 0.8139

Epoch 00019: val_loss did not improve from 0.56119
Epoch 20/60
 - 4s - loss: 0.3715 - acc: 0.8773 - val_loss: 0.5941 - val_acc: 0.8211

Epoch 00020: val_loss did not improve from 0.56119
Epoch 21/60
 - 4s - loss: 0.3622 - acc: 0.8814 - val_loss: 0.5345 - val_acc: 0.8291

Epoch 00021: val_loss improved from 0.56119 to 0.53447, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 22/60
 - 4s - loss: 0.3475 - acc: 0.8855 - val_loss: 0.6607 - val_acc: 0.8079

Epoch 00022: val_loss did not improve from 0.53447
Epoch 23/60
 - 4s - loss: 0.3403 - acc: 0.8876 - val_loss: 0.5651 - val_acc: 0.8266

Epoch 00023: val_loss did not improve from 0.53447
Epoch 24/60
 - 4s - loss: 0.3288 - acc: 0.8919 - val_loss: 0.8342 - val_acc: 0.7490

Epoch 00024: val_loss did not improve from 0.53447
Epoch 25/60
 - 4s - loss: 0.3222 - acc: 0.8932 - val_loss: 0.5762 - val_acc: 0.8148

Epoch 00025: val_loss did not improve from 0.53447
Epoch 26/60
 - 4s - loss: 0.3135 - acc: 0.8950 - val_loss: 0.6160 - val_acc: 0.8241

Epoch 00026: val_loss did not improve from 0.53447
Epoch 27/60
 - 4s - loss: 0.3016 - acc: 0.9006 - val_loss: 0.5186 - val_acc: 0.8382

Epoch 00027: val_loss improved from 0.53447 to 0.51863, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.5.hdf5
Epoch 28/60
 - 4s - loss: 0.2948 - acc: 0.9019 - val_loss: 0.5615 - val_acc: 0.8289

Epoch 00028: val_loss did not improve from 0.51863
Epoch 29/60
 - 4s - loss: 0.2847 - acc: 0.9051 - val_loss: 0.5890 - val_acc: 0.8130

Epoch 00029: val_loss did not improve from 0.51863
Epoch 30/60
 - 4s - loss: 0.2804 - acc: 0.9066 - val_loss: 0.6991 - val_acc: 0.8104

Epoch 00030: val_loss did not improve from 0.51863
Epoch 31/60
 - 4s - loss: 0.2794 - acc: 0.9077 - val_loss: 0.5342 - val_acc: 0.8283

Epoch 00031: val_loss did not improve from 0.51863
Epoch 32/60
 - 5s - loss: 0.2656 - acc: 0.9124 - val_loss: 0.5732 - val_acc: 0.8320

Epoch 00032: val_loss did not improve from 0.51863
Epoch 33/60
 - 5s - loss: 0.2600 - acc: 0.9140 - val_loss: 0.5909 - val_acc: 0.8280

Epoch 00033: val_loss did not improve from 0.51863
Epoch 34/60
 - 4s - loss: 0.2516 - acc: 0.9156 - val_loss: 0.6008 - val_acc: 0.8235

Epoch 00034: val_loss did not improve from 0.51863
Epoch 35/60
 - 4s - loss: 0.2478 - acc: 0.9164 - val_loss: 0.6031 - val_acc: 0.8286

Epoch 00035: val_loss did not improve from 0.51863
Epoch 36/60
 - 4s - loss: 0.2441 - acc: 0.9186 - val_loss: 0.5757 - val_acc: 0.8377

Epoch 00036: val_loss did not improve from 0.51863
Epoch 37/60
 - 4s - loss: 0.2378 - acc: 0.9199 - val_loss: 0.5846 - val_acc: 0.8363

Epoch 00037: val_loss did not improve from 0.51863
Epoch 00037: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 5s - loss: 2.9791 - acc: 0.5949 - val_loss: 1.1871 - val_acc: 0.6631

Epoch 00001: val_loss improved from inf to 1.18705, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra0.hdf5
Epoch 2/60
 - 4s - loss: 1.0093 - acc: 0.6930 - val_loss: 0.8700 - val_acc: 0.7280

Epoch 00002: val_loss improved from 1.18705 to 0.87000, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra0.hdf5
Epoch 3/60
 - 4s - loss: 0.7601 - acc: 0.7609 - val_loss: 0.7592 - val_acc: 0.7626

Epoch 00003: val_loss improved from 0.87000 to 0.75923, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra0.hdf5
Epoch 4/60
 - 4s - loss: 0.6136 - acc: 0.8059 - val_loss: 0.6385 - val_acc: 0.7989

Epoch 00004: val_loss improved from 0.75923 to 0.63852, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra0.hdf5
Epoch 5/60
 - 4s - loss: 0.5214 - acc: 0.8343 - val_loss: 0.6503 - val_acc: 0.7838

Epoch 00005: val_loss did not improve from 0.63852
Epoch 6/60
 - 4s - loss: 0.4662 - acc: 0.8516 - val_loss: 0.7415 - val_acc: 0.7941

Epoch 00006: val_loss did not improve from 0.63852
Epoch 7/60
 - 4s - loss: 0.4104 - acc: 0.8681 - val_loss: 0.5911 - val_acc: 0.8110

Epoch 00007: val_loss improved from 0.63852 to 0.59112, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra0.hdf5
Epoch 8/60
 - 4s - loss: 0.3734 - acc: 0.8784 - val_loss: 0.6305 - val_acc: 0.8060

Epoch 00008: val_loss did not improve from 0.59112
Epoch 9/60
 - 4s - loss: 0.3477 - acc: 0.8864 - val_loss: 0.5212 - val_acc: 0.8445

Epoch 00009: val_loss improved from 0.59112 to 0.52116, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra0.hdf5
Epoch 10/60
 - 4s - loss: 0.3147 - acc: 0.9002 - val_loss: 0.5478 - val_acc: 0.8447

Epoch 00010: val_loss did not improve from 0.52116
Epoch 11/60
 - 4s - loss: 0.2914 - acc: 0.9046 - val_loss: 0.5537 - val_acc: 0.8314

Epoch 00011: val_loss did not improve from 0.52116
Epoch 12/60
 - 4s - loss: 0.2746 - acc: 0.9106 - val_loss: 0.5246 - val_acc: 0.8457

Epoch 00012: val_loss did not improve from 0.52116
Epoch 13/60
 - 4s - loss: 0.2525 - acc: 0.9172 - val_loss: 0.5474 - val_acc: 0.8528

Epoch 00013: val_loss did not improve from 0.52116
Epoch 14/60
 - 4s - loss: 0.2304 - acc: 0.9251 - val_loss: 0.5374 - val_acc: 0.8445

Epoch 00014: val_loss did not improve from 0.52116
Epoch 15/60
 - 4s - loss: 0.2150 - acc: 0.9306 - val_loss: 0.6269 - val_acc: 0.8286

Epoch 00015: val_loss did not improve from 0.52116
Epoch 16/60
 - 4s - loss: 0.2017 - acc: 0.9330 - val_loss: 0.5269 - val_acc: 0.8610

Epoch 00016: val_loss did not improve from 0.52116
Epoch 17/60
 - 4s - loss: 0.1932 - acc: 0.9367 - val_loss: 0.5457 - val_acc: 0.8585

Epoch 00017: val_loss did not improve from 0.52116
Epoch 18/60
 - 4s - loss: 0.1788 - acc: 0.9406 - val_loss: 0.5732 - val_acc: 0.8335

Epoch 00018: val_loss did not improve from 0.52116
Epoch 19/60
 - 4s - loss: 0.1639 - acc: 0.9462 - val_loss: 0.5531 - val_acc: 0.8550

Epoch 00019: val_loss did not improve from 0.52116
Epoch 00019: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 5s - loss: 1.7069 - acc: 0.5836 - val_loss: 1.4501 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 1.45009, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 2/60
 - 3s - loss: 1.3211 - acc: 0.6443 - val_loss: 1.2719 - val_acc: 0.6378

Epoch 00002: val_loss improved from 1.45009 to 1.27187, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 3/60
 - 3s - loss: 1.1891 - acc: 0.6616 - val_loss: 1.1881 - val_acc: 0.6567

Epoch 00003: val_loss improved from 1.27187 to 1.18806, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 4/60
 - 3s - loss: 1.1096 - acc: 0.6740 - val_loss: 1.1323 - val_acc: 0.6592

Epoch 00004: val_loss improved from 1.18806 to 1.13227, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 5/60
 - 3s - loss: 1.0508 - acc: 0.6854 - val_loss: 1.0778 - val_acc: 0.6665

Epoch 00005: val_loss improved from 1.13227 to 1.07784, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 6/60
 - 3s - loss: 1.0030 - acc: 0.6943 - val_loss: 1.0685 - val_acc: 0.6748

Epoch 00006: val_loss improved from 1.07784 to 1.06849, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 7/60
 - 3s - loss: 0.9584 - acc: 0.7031 - val_loss: 1.1078 - val_acc: 0.6595

Epoch 00007: val_loss did not improve from 1.06849
Epoch 8/60
 - 3s - loss: 0.9189 - acc: 0.7110 - val_loss: 0.9712 - val_acc: 0.6873

Epoch 00008: val_loss improved from 1.06849 to 0.97115, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 9/60
 - 3s - loss: 0.8816 - acc: 0.7213 - val_loss: 0.9575 - val_acc: 0.6971

Epoch 00009: val_loss improved from 0.97115 to 0.95749, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 10/60
 - 3s - loss: 0.8508 - acc: 0.7312 - val_loss: 0.8655 - val_acc: 0.7184

Epoch 00010: val_loss improved from 0.95749 to 0.86546, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 11/60
 - 3s - loss: 0.8193 - acc: 0.7395 - val_loss: 0.8727 - val_acc: 0.7152

Epoch 00011: val_loss did not improve from 0.86546
Epoch 12/60
 - 3s - loss: 0.7914 - acc: 0.7482 - val_loss: 0.9792 - val_acc: 0.6839

Epoch 00012: val_loss did not improve from 0.86546
Epoch 13/60
 - 3s - loss: 0.7700 - acc: 0.7559 - val_loss: 0.8144 - val_acc: 0.7330

Epoch 00013: val_loss improved from 0.86546 to 0.81438, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 14/60
 - 3s - loss: 0.7457 - acc: 0.7633 - val_loss: 0.8323 - val_acc: 0.7293

Epoch 00014: val_loss did not improve from 0.81438
Epoch 15/60
 - 3s - loss: 0.7266 - acc: 0.7689 - val_loss: 0.7659 - val_acc: 0.7524

Epoch 00015: val_loss improved from 0.81438 to 0.76595, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 16/60
 - 3s - loss: 0.7033 - acc: 0.7763 - val_loss: 0.7630 - val_acc: 0.7520

Epoch 00016: val_loss improved from 0.76595 to 0.76302, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 17/60
 - 3s - loss: 0.6849 - acc: 0.7822 - val_loss: 0.7092 - val_acc: 0.7685

Epoch 00017: val_loss improved from 0.76302 to 0.70917, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 18/60
 - 3s - loss: 0.6678 - acc: 0.7870 - val_loss: 0.7341 - val_acc: 0.7660

Epoch 00018: val_loss did not improve from 0.70917
Epoch 19/60
 - 3s - loss: 0.6513 - acc: 0.7919 - val_loss: 0.7390 - val_acc: 0.7604

Epoch 00019: val_loss did not improve from 0.70917
Epoch 20/60
 - 3s - loss: 0.6390 - acc: 0.7956 - val_loss: 0.6909 - val_acc: 0.7711

Epoch 00020: val_loss improved from 0.70917 to 0.69086, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 21/60
 - 3s - loss: 0.6232 - acc: 0.8022 - val_loss: 0.7347 - val_acc: 0.7638

Epoch 00021: val_loss did not improve from 0.69086
Epoch 22/60
 - 3s - loss: 0.6129 - acc: 0.8035 - val_loss: 0.6724 - val_acc: 0.7826

Epoch 00022: val_loss improved from 0.69086 to 0.67242, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 23/60
 - 3s - loss: 0.5996 - acc: 0.8081 - val_loss: 0.6701 - val_acc: 0.7773

Epoch 00023: val_loss improved from 0.67242 to 0.67011, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 24/60
 - 3s - loss: 0.5927 - acc: 0.8099 - val_loss: 0.6517 - val_acc: 0.7882

Epoch 00024: val_loss improved from 0.67011 to 0.65171, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 25/60
 - 3s - loss: 0.5808 - acc: 0.8145 - val_loss: 0.6456 - val_acc: 0.7914

Epoch 00025: val_loss improved from 0.65171 to 0.64564, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 26/60
 - 3s - loss: 0.5706 - acc: 0.8158 - val_loss: 0.6635 - val_acc: 0.7902

Epoch 00026: val_loss did not improve from 0.64564
Epoch 27/60
 - 3s - loss: 0.5659 - acc: 0.8189 - val_loss: 0.7118 - val_acc: 0.7780

Epoch 00027: val_loss did not improve from 0.64564
Epoch 28/60
 - 3s - loss: 0.5533 - acc: 0.8240 - val_loss: 0.6311 - val_acc: 0.7919

Epoch 00028: val_loss improved from 0.64564 to 0.63107, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 29/60
 - 3s - loss: 0.5463 - acc: 0.8247 - val_loss: 0.6400 - val_acc: 0.7905

Epoch 00029: val_loss did not improve from 0.63107
Epoch 30/60
 - 3s - loss: 0.5408 - acc: 0.8277 - val_loss: 0.6856 - val_acc: 0.7714

Epoch 00030: val_loss did not improve from 0.63107
Epoch 31/60
 - 3s - loss: 0.5311 - acc: 0.8293 - val_loss: 0.7002 - val_acc: 0.7690

Epoch 00031: val_loss did not improve from 0.63107
Epoch 32/60
 - 3s - loss: 0.5301 - acc: 0.8309 - val_loss: 0.7070 - val_acc: 0.7792

Epoch 00032: val_loss did not improve from 0.63107
Epoch 33/60
 - 3s - loss: 0.5230 - acc: 0.8331 - val_loss: 0.7033 - val_acc: 0.7639

Epoch 00033: val_loss did not improve from 0.63107
Epoch 34/60
 - 3s - loss: 0.5163 - acc: 0.8355 - val_loss: 0.6197 - val_acc: 0.8071

Epoch 00034: val_loss improved from 0.63107 to 0.61971, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 35/60
 - 3s - loss: 0.5125 - acc: 0.8369 - val_loss: 0.6574 - val_acc: 0.7924

Epoch 00035: val_loss did not improve from 0.61971
Epoch 36/60
 - 3s - loss: 0.5074 - acc: 0.8387 - val_loss: 0.6551 - val_acc: 0.7929

Epoch 00036: val_loss did not improve from 0.61971
Epoch 37/60
 - 3s - loss: 0.5013 - acc: 0.8406 - val_loss: 0.6243 - val_acc: 0.7999

Epoch 00037: val_loss did not improve from 0.61971
Epoch 38/60
 - 3s - loss: 0.4996 - acc: 0.8412 - val_loss: 0.5791 - val_acc: 0.8164

Epoch 00038: val_loss improved from 0.61971 to 0.57909, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 39/60
 - 3s - loss: 0.4947 - acc: 0.8433 - val_loss: 0.6268 - val_acc: 0.8017

Epoch 00039: val_loss did not improve from 0.57909
Epoch 40/60
 - 3s - loss: 0.4879 - acc: 0.8435 - val_loss: 0.5908 - val_acc: 0.8192

Epoch 00040: val_loss did not improve from 0.57909
Epoch 41/60
 - 3s - loss: 0.4842 - acc: 0.8452 - val_loss: 0.6230 - val_acc: 0.8086

Epoch 00041: val_loss did not improve from 0.57909
Epoch 42/60
 - 3s - loss: 0.4816 - acc: 0.8468 - val_loss: 0.6173 - val_acc: 0.7986

Epoch 00042: val_loss did not improve from 0.57909
Epoch 43/60
 - 3s - loss: 0.4782 - acc: 0.8471 - val_loss: 0.5863 - val_acc: 0.8166

Epoch 00043: val_loss did not improve from 0.57909
Epoch 44/60
 - 3s - loss: 0.4752 - acc: 0.8471 - val_loss: 0.5902 - val_acc: 0.8155

Epoch 00044: val_loss did not improve from 0.57909
Epoch 45/60
 - 3s - loss: 0.4720 - acc: 0.8493 - val_loss: 0.6160 - val_acc: 0.8104

Epoch 00045: val_loss did not improve from 0.57909
Epoch 46/60
 - 3s - loss: 0.4670 - acc: 0.8519 - val_loss: 0.5781 - val_acc: 0.8099

Epoch 00046: val_loss improved from 0.57909 to 0.57808, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 47/60
 - 3s - loss: 0.4657 - acc: 0.8521 - val_loss: 0.6277 - val_acc: 0.7917

Epoch 00047: val_loss did not improve from 0.57808
Epoch 48/60
 - 3s - loss: 0.4622 - acc: 0.8527 - val_loss: 0.6159 - val_acc: 0.8089

Epoch 00048: val_loss did not improve from 0.57808
Epoch 49/60
 - 3s - loss: 0.4552 - acc: 0.8548 - val_loss: 0.6148 - val_acc: 0.8020

Epoch 00049: val_loss did not improve from 0.57808
Epoch 50/60
 - 3s - loss: 0.4558 - acc: 0.8557 - val_loss: 0.5789 - val_acc: 0.8099

Epoch 00050: val_loss did not improve from 0.57808
Epoch 51/60
 - 3s - loss: 0.4535 - acc: 0.8558 - val_loss: 0.6113 - val_acc: 0.8113

Epoch 00051: val_loss did not improve from 0.57808
Epoch 52/60
 - 3s - loss: 0.4501 - acc: 0.8562 - val_loss: 0.5794 - val_acc: 0.8158

Epoch 00052: val_loss did not improve from 0.57808
Epoch 53/60
 - 3s - loss: 0.4479 - acc: 0.8569 - val_loss: 0.5579 - val_acc: 0.8285

Epoch 00053: val_loss improved from 0.57808 to 0.55788, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 54/60
 - 3s - loss: 0.4434 - acc: 0.8597 - val_loss: 0.6010 - val_acc: 0.8069

Epoch 00054: val_loss did not improve from 0.55788
Epoch 55/60
 - 3s - loss: 0.4423 - acc: 0.8584 - val_loss: 0.6910 - val_acc: 0.7742

Epoch 00055: val_loss did not improve from 0.55788
Epoch 56/60
 - 3s - loss: 0.4392 - acc: 0.8601 - val_loss: 0.5600 - val_acc: 0.8191

Epoch 00056: val_loss did not improve from 0.55788
Epoch 57/60
 - 3s - loss: 0.4346 - acc: 0.8612 - val_loss: 0.5820 - val_acc: 0.8180

Epoch 00057: val_loss did not improve from 0.55788
Epoch 58/60
 - 3s - loss: 0.4328 - acc: 0.8614 - val_loss: 0.5488 - val_acc: 0.8298

Epoch 00058: val_loss improved from 0.55788 to 0.54877, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 59/60
 - 3s - loss: 0.4335 - acc: 0.8612 - val_loss: 0.5323 - val_acc: 0.8322

Epoch 00059: val_loss improved from 0.54877 to 0.53228, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Epoch 60/60
 - 3s - loss: 0.4314 - acc: 0.8633 - val_loss: 0.5313 - val_acc: 0.8269

Epoch 00060: val_loss improved from 0.53228 to 0.53132, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 6s - loss: 1.4551 - acc: 0.6228 - val_loss: 1.2357 - val_acc: 0.6334

Epoch 00001: val_loss improved from inf to 1.23566, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra0.hdf5
Epoch 2/60
 - 5s - loss: 1.1157 - acc: 0.6683 - val_loss: 1.2048 - val_acc: 0.6586

Epoch 00002: val_loss improved from 1.23566 to 1.20484, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra0.hdf5
Epoch 3/60
 - 5s - loss: 0.9959 - acc: 0.6921 - val_loss: 1.0057 - val_acc: 0.6773

Epoch 00003: val_loss improved from 1.20484 to 1.00573, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra0.hdf5
Epoch 4/60
 - 4s - loss: 0.9015 - acc: 0.7146 - val_loss: 0.9973 - val_acc: 0.6684

Epoch 00004: val_loss improved from 1.00573 to 0.99731, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra0.hdf5
Epoch 5/60
 - 5s - loss: 0.8188 - acc: 0.7378 - val_loss: 0.8170 - val_acc: 0.7326

Epoch 00005: val_loss improved from 0.99731 to 0.81700, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra0.hdf5
Epoch 6/60
 - 4s - loss: 0.7435 - acc: 0.7584 - val_loss: 0.7876 - val_acc: 0.7390

Epoch 00006: val_loss improved from 0.81700 to 0.78764, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra0.hdf5
Epoch 7/60
 - 4s - loss: 0.6829 - acc: 0.7769 - val_loss: 0.7130 - val_acc: 0.7640

Epoch 00007: val_loss improved from 0.78764 to 0.71296, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra0.hdf5
Epoch 8/60
 - 5s - loss: 0.6361 - acc: 0.7912 - val_loss: 0.6754 - val_acc: 0.7791

Epoch 00008: val_loss improved from 0.71296 to 0.67542, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra0.hdf5
Epoch 9/60
 - 4s - loss: 0.5901 - acc: 0.8063 - val_loss: 0.6936 - val_acc: 0.7730

Epoch 00009: val_loss did not improve from 0.67542
Epoch 10/60
 - 4s - loss: 0.5571 - acc: 0.8162 - val_loss: 0.6372 - val_acc: 0.7904

Epoch 00010: val_loss improved from 0.67542 to 0.63715, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra0.hdf5
Epoch 11/60
 - 5s - loss: 0.5284 - acc: 0.8257 - val_loss: 0.6681 - val_acc: 0.7841

Epoch 00011: val_loss did not improve from 0.63715
Epoch 12/60
 - 4s - loss: 0.5020 - acc: 0.8340 - val_loss: 0.5779 - val_acc: 0.8117

Epoch 00012: val_loss improved from 0.63715 to 0.57789, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra0.hdf5
Epoch 13/60
 - 4s - loss: 0.4836 - acc: 0.8417 - val_loss: 0.5647 - val_acc: 0.8199

Epoch 00013: val_loss improved from 0.57789 to 0.56466, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra0.hdf5
Epoch 14/60
 - 5s - loss: 0.4639 - acc: 0.8471 - val_loss: 0.5848 - val_acc: 0.8157

Epoch 00014: val_loss did not improve from 0.56466
Epoch 15/60
 - 5s - loss: 0.4471 - acc: 0.8517 - val_loss: 0.6494 - val_acc: 0.8020

Epoch 00015: val_loss did not improve from 0.56466
Epoch 16/60
 - 5s - loss: 0.4291 - acc: 0.8592 - val_loss: 0.5812 - val_acc: 0.8173

Epoch 00016: val_loss did not improve from 0.56466
Epoch 17/60
 - 5s - loss: 0.4150 - acc: 0.8634 - val_loss: 0.6446 - val_acc: 0.8069

Epoch 00017: val_loss did not improve from 0.56466
Epoch 18/60
 - 5s - loss: 0.3970 - acc: 0.8689 - val_loss: 0.5876 - val_acc: 0.8136

Epoch 00018: val_loss did not improve from 0.56466
Epoch 19/60
 - 5s - loss: 0.3866 - acc: 0.8724 - val_loss: 0.5458 - val_acc: 0.8305

Epoch 00019: val_loss improved from 0.56466 to 0.54579, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra0.hdf5
Epoch 20/60
 - 5s - loss: 0.3703 - acc: 0.8783 - val_loss: 0.5482 - val_acc: 0.8345

Epoch 00020: val_loss did not improve from 0.54579
Epoch 21/60
 - 4s - loss: 0.3634 - acc: 0.8794 - val_loss: 0.6088 - val_acc: 0.8202

Epoch 00021: val_loss did not improve from 0.54579
Epoch 22/60
 - 5s - loss: 0.3534 - acc: 0.8813 - val_loss: 0.5643 - val_acc: 0.8236

Epoch 00022: val_loss did not improve from 0.54579
Epoch 23/60
 - 4s - loss: 0.3410 - acc: 0.8864 - val_loss: 0.6063 - val_acc: 0.8198

Epoch 00023: val_loss did not improve from 0.54579
Epoch 24/60
 - 5s - loss: 0.3341 - acc: 0.8868 - val_loss: 0.6058 - val_acc: 0.8223

Epoch 00024: val_loss did not improve from 0.54579
Epoch 25/60
 - 5s - loss: 0.3257 - acc: 0.8910 - val_loss: 0.6383 - val_acc: 0.8239

Epoch 00025: val_loss did not improve from 0.54579
Epoch 26/60
 - 5s - loss: 0.3118 - acc: 0.8959 - val_loss: 0.6938 - val_acc: 0.8074

Epoch 00026: val_loss did not improve from 0.54579
Epoch 27/60
 - 5s - loss: 0.3100 - acc: 0.8957 - val_loss: 0.6851 - val_acc: 0.8094

Epoch 00027: val_loss did not improve from 0.54579
Epoch 28/60
 - 5s - loss: 0.2993 - acc: 0.8993 - val_loss: 0.6537 - val_acc: 0.8195

Epoch 00028: val_loss did not improve from 0.54579
Epoch 29/60
 - 5s - loss: 0.2919 - acc: 0.9024 - val_loss: 0.6304 - val_acc: 0.8101

Epoch 00029: val_loss did not improve from 0.54579
Epoch 00029: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 6s - loss: 3.5153 - acc: 0.5792 - val_loss: 1.3428 - val_acc: 0.5863

Epoch 00001: val_loss improved from inf to 1.34284, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 2/60
 - 4s - loss: 1.0676 - acc: 0.6831 - val_loss: 0.9586 - val_acc: 0.6954

Epoch 00002: val_loss improved from 1.34284 to 0.95856, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 3/60
 - 5s - loss: 0.7737 - acc: 0.7589 - val_loss: 0.8773 - val_acc: 0.7371

Epoch 00003: val_loss improved from 0.95856 to 0.87735, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 4/60
 - 4s - loss: 0.6287 - acc: 0.8009 - val_loss: 0.6814 - val_acc: 0.7826

Epoch 00004: val_loss improved from 0.87735 to 0.68139, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 5/60
 - 4s - loss: 0.5338 - acc: 0.8323 - val_loss: 0.6184 - val_acc: 0.8095

Epoch 00005: val_loss improved from 0.68139 to 0.61836, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 6/60
 - 4s - loss: 0.4790 - acc: 0.8476 - val_loss: 0.6449 - val_acc: 0.8085

Epoch 00006: val_loss did not improve from 0.61836
Epoch 7/60
 - 4s - loss: 0.4259 - acc: 0.8621 - val_loss: 0.5479 - val_acc: 0.8286

Epoch 00007: val_loss improved from 0.61836 to 0.54792, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 8/60
 - 4s - loss: 0.3939 - acc: 0.8732 - val_loss: 0.5597 - val_acc: 0.8291

Epoch 00008: val_loss did not improve from 0.54792
Epoch 9/60
 - 5s - loss: 0.3561 - acc: 0.8851 - val_loss: 0.5607 - val_acc: 0.8392

Epoch 00009: val_loss did not improve from 0.54792
Epoch 10/60
 - 5s - loss: 0.3311 - acc: 0.8934 - val_loss: 0.6960 - val_acc: 0.8060

Epoch 00010: val_loss did not improve from 0.54792
Epoch 11/60
 - 5s - loss: 0.3053 - acc: 0.8998 - val_loss: 0.6454 - val_acc: 0.8116

Epoch 00011: val_loss did not improve from 0.54792
Epoch 12/60
 - 5s - loss: 0.2842 - acc: 0.9070 - val_loss: 0.5946 - val_acc: 0.8286

Epoch 00012: val_loss did not improve from 0.54792
Epoch 13/60
 - 5s - loss: 0.2637 - acc: 0.9142 - val_loss: 0.5493 - val_acc: 0.8377

Epoch 00013: val_loss did not improve from 0.54792
Epoch 14/60
 - 5s - loss: 0.2474 - acc: 0.9204 - val_loss: 0.5369 - val_acc: 0.8538

Epoch 00014: val_loss improved from 0.54792 to 0.53685, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 15/60
 - 5s - loss: 0.2253 - acc: 0.9267 - val_loss: 0.5756 - val_acc: 0.8427

Epoch 00015: val_loss did not improve from 0.53685
Epoch 16/60
 - 5s - loss: 0.2166 - acc: 0.9280 - val_loss: 0.5027 - val_acc: 0.8569

Epoch 00016: val_loss improved from 0.53685 to 0.50265, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 17/60
 - 5s - loss: 0.1963 - acc: 0.9367 - val_loss: 0.5270 - val_acc: 0.8554

Epoch 00017: val_loss did not improve from 0.50265
Epoch 18/60
 - 4s - loss: 0.1958 - acc: 0.9345 - val_loss: 0.5362 - val_acc: 0.8573

Epoch 00018: val_loss did not improve from 0.50265
Epoch 19/60
 - 4s - loss: 0.1736 - acc: 0.9433 - val_loss: 0.5200 - val_acc: 0.8682

Epoch 00019: val_loss did not improve from 0.50265
Epoch 20/60
 - 4s - loss: 0.1644 - acc: 0.9451 - val_loss: 0.5764 - val_acc: 0.8561

Epoch 00020: val_loss did not improve from 0.50265
Epoch 21/60
 - 4s - loss: 0.1511 - acc: 0.9505 - val_loss: 0.6172 - val_acc: 0.8420

Epoch 00021: val_loss did not improve from 0.50265
Epoch 22/60
 - 4s - loss: 0.1448 - acc: 0.9526 - val_loss: 0.5550 - val_acc: 0.8626

Epoch 00022: val_loss did not improve from 0.50265
Epoch 23/60
 - 4s - loss: 0.1331 - acc: 0.9563 - val_loss: 0.5979 - val_acc: 0.8541

Epoch 00023: val_loss did not improve from 0.50265
Epoch 24/60
 - 4s - loss: 0.1254 - acc: 0.9601 - val_loss: 0.5686 - val_acc: 0.8560

Epoch 00024: val_loss did not improve from 0.50265
Epoch 25/60
 - 4s - loss: 0.1172 - acc: 0.9618 - val_loss: 0.6044 - val_acc: 0.8485

Epoch 00025: val_loss did not improve from 0.50265
Epoch 26/60
 - 4s - loss: 0.1128 - acc: 0.9636 - val_loss: 0.5978 - val_acc: 0.8657

Epoch 00026: val_loss did not improve from 0.50265
Epoch 00026: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 4s - loss: 1.6007 - acc: 0.6223 - val_loss: 1.4548 - val_acc: 0.6269

Epoch 00001: val_loss improved from inf to 1.45476, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 2/60
 - 3s - loss: 1.3015 - acc: 0.6519 - val_loss: 1.2933 - val_acc: 0.6496

Epoch 00002: val_loss improved from 1.45476 to 1.29330, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 3/60
 - 3s - loss: 1.1786 - acc: 0.6636 - val_loss: 1.1707 - val_acc: 0.6570

Epoch 00003: val_loss improved from 1.29330 to 1.17067, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 4/60
 - 3s - loss: 1.0957 - acc: 0.6734 - val_loss: 1.0973 - val_acc: 0.6623

Epoch 00004: val_loss improved from 1.17067 to 1.09727, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 5/60
 - 3s - loss: 1.0351 - acc: 0.6819 - val_loss: 1.0727 - val_acc: 0.6653

Epoch 00005: val_loss improved from 1.09727 to 1.07272, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 6/60
 - 3s - loss: 0.9832 - acc: 0.6924 - val_loss: 1.0511 - val_acc: 0.6627

Epoch 00006: val_loss improved from 1.07272 to 1.05109, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 7/60
 - 3s - loss: 0.9343 - acc: 0.7023 - val_loss: 0.9515 - val_acc: 0.6889

Epoch 00007: val_loss improved from 1.05109 to 0.95152, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 8/60
 - 3s - loss: 0.8921 - acc: 0.7145 - val_loss: 0.9179 - val_acc: 0.7049

Epoch 00008: val_loss improved from 0.95152 to 0.91786, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 9/60
 - 3s - loss: 0.8531 - acc: 0.7252 - val_loss: 0.9082 - val_acc: 0.7105

Epoch 00009: val_loss improved from 0.91786 to 0.90818, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 10/60
 - 3s - loss: 0.8194 - acc: 0.7369 - val_loss: 0.8905 - val_acc: 0.7108

Epoch 00010: val_loss improved from 0.90818 to 0.89052, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 11/60
 - 3s - loss: 0.7909 - acc: 0.7449 - val_loss: 0.8439 - val_acc: 0.7220

Epoch 00011: val_loss improved from 0.89052 to 0.84389, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 12/60
 - 3s - loss: 0.7657 - acc: 0.7526 - val_loss: 0.8250 - val_acc: 0.7286

Epoch 00012: val_loss improved from 0.84389 to 0.82503, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 13/60
 - 3s - loss: 0.7415 - acc: 0.7598 - val_loss: 0.8136 - val_acc: 0.7379

Epoch 00013: val_loss improved from 0.82503 to 0.81361, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 14/60
 - 3s - loss: 0.7232 - acc: 0.7643 - val_loss: 0.7957 - val_acc: 0.7383

Epoch 00014: val_loss improved from 0.81361 to 0.79575, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 15/60
 - 3s - loss: 0.7067 - acc: 0.7704 - val_loss: 0.7775 - val_acc: 0.7490

Epoch 00015: val_loss improved from 0.79575 to 0.77750, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 16/60
 - 3s - loss: 0.6887 - acc: 0.7749 - val_loss: 0.7339 - val_acc: 0.7626

Epoch 00016: val_loss improved from 0.77750 to 0.73389, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 17/60
 - 3s - loss: 0.6741 - acc: 0.7806 - val_loss: 0.7260 - val_acc: 0.7652

Epoch 00017: val_loss improved from 0.73389 to 0.72605, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 18/60
 - 3s - loss: 0.6593 - acc: 0.7854 - val_loss: 0.7694 - val_acc: 0.7442

Epoch 00018: val_loss did not improve from 0.72605
Epoch 19/60
 - 3s - loss: 0.6454 - acc: 0.7898 - val_loss: 0.7132 - val_acc: 0.7665

Epoch 00019: val_loss improved from 0.72605 to 0.71316, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 20/60
 - 3s - loss: 0.6357 - acc: 0.7937 - val_loss: 0.7849 - val_acc: 0.7545

Epoch 00020: val_loss did not improve from 0.71316
Epoch 21/60
 - 3s - loss: 0.6251 - acc: 0.7968 - val_loss: 0.6858 - val_acc: 0.7780

Epoch 00021: val_loss improved from 0.71316 to 0.68578, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 22/60
 - 3s - loss: 0.6141 - acc: 0.8001 - val_loss: 0.7153 - val_acc: 0.7633

Epoch 00022: val_loss did not improve from 0.68578
Epoch 23/60
 - 3s - loss: 0.6036 - acc: 0.8044 - val_loss: 0.6751 - val_acc: 0.7851

Epoch 00023: val_loss improved from 0.68578 to 0.67513, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 24/60
 - 3s - loss: 0.5931 - acc: 0.8082 - val_loss: 0.6784 - val_acc: 0.7814

Epoch 00024: val_loss did not improve from 0.67513
Epoch 25/60
 - 3s - loss: 0.5845 - acc: 0.8104 - val_loss: 0.6876 - val_acc: 0.7748

Epoch 00025: val_loss did not improve from 0.67513
Epoch 26/60
 - 3s - loss: 0.5772 - acc: 0.8115 - val_loss: 0.7016 - val_acc: 0.7642

Epoch 00026: val_loss did not improve from 0.67513
Epoch 27/60
 - 3s - loss: 0.5664 - acc: 0.8159 - val_loss: 0.6815 - val_acc: 0.7729

Epoch 00027: val_loss did not improve from 0.67513
Epoch 28/60
 - 3s - loss: 0.5598 - acc: 0.8174 - val_loss: 0.6480 - val_acc: 0.7967

Epoch 00028: val_loss improved from 0.67513 to 0.64799, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 29/60
 - 3s - loss: 0.5530 - acc: 0.8198 - val_loss: 0.7167 - val_acc: 0.7817

Epoch 00029: val_loss did not improve from 0.64799
Epoch 30/60
 - 3s - loss: 0.5461 - acc: 0.8218 - val_loss: 0.6816 - val_acc: 0.7895

Epoch 00030: val_loss did not improve from 0.64799
Epoch 31/60
 - 3s - loss: 0.5394 - acc: 0.8250 - val_loss: 0.6334 - val_acc: 0.7930

Epoch 00031: val_loss improved from 0.64799 to 0.63345, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 32/60
 - 3s - loss: 0.5296 - acc: 0.8275 - val_loss: 0.6419 - val_acc: 0.7889

Epoch 00032: val_loss did not improve from 0.63345
Epoch 33/60
 - 3s - loss: 0.5246 - acc: 0.8286 - val_loss: 0.6413 - val_acc: 0.7905

Epoch 00033: val_loss did not improve from 0.63345
Epoch 34/60
 - 3s - loss: 0.5200 - acc: 0.8304 - val_loss: 0.6342 - val_acc: 0.7951

Epoch 00034: val_loss did not improve from 0.63345
Epoch 35/60
 - 3s - loss: 0.5094 - acc: 0.8349 - val_loss: 0.6540 - val_acc: 0.7942

Epoch 00035: val_loss did not improve from 0.63345
Epoch 36/60
 - 3s - loss: 0.5082 - acc: 0.8341 - val_loss: 0.6242 - val_acc: 0.7973

Epoch 00036: val_loss improved from 0.63345 to 0.62421, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 37/60
 - 3s - loss: 0.5030 - acc: 0.8368 - val_loss: 0.6069 - val_acc: 0.8094

Epoch 00037: val_loss improved from 0.62421 to 0.60691, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 38/60
 - 3s - loss: 0.4991 - acc: 0.8381 - val_loss: 0.6512 - val_acc: 0.7988

Epoch 00038: val_loss did not improve from 0.60691
Epoch 39/60
 - 3s - loss: 0.4921 - acc: 0.8413 - val_loss: 0.6014 - val_acc: 0.8076

Epoch 00039: val_loss improved from 0.60691 to 0.60138, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 40/60
 - 3s - loss: 0.4883 - acc: 0.8415 - val_loss: 0.6296 - val_acc: 0.8052

Epoch 00040: val_loss did not improve from 0.60138
Epoch 41/60
 - 3s - loss: 0.4856 - acc: 0.8423 - val_loss: 0.5971 - val_acc: 0.8054

Epoch 00041: val_loss improved from 0.60138 to 0.59713, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 42/60
 - 3s - loss: 0.4798 - acc: 0.8452 - val_loss: 0.7172 - val_acc: 0.7824

Epoch 00042: val_loss did not improve from 0.59713
Epoch 43/60
 - 3s - loss: 0.4791 - acc: 0.8454 - val_loss: 0.6701 - val_acc: 0.7763

Epoch 00043: val_loss did not improve from 0.59713
Epoch 44/60
 - 3s - loss: 0.4734 - acc: 0.8467 - val_loss: 0.6117 - val_acc: 0.8122

Epoch 00044: val_loss did not improve from 0.59713
Epoch 45/60
 - 3s - loss: 0.4699 - acc: 0.8472 - val_loss: 0.6451 - val_acc: 0.7866

Epoch 00045: val_loss did not improve from 0.59713
Epoch 46/60
 - 3s - loss: 0.4669 - acc: 0.8476 - val_loss: 0.5763 - val_acc: 0.8154

Epoch 00046: val_loss improved from 0.59713 to 0.57631, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 47/60
 - 3s - loss: 0.4608 - acc: 0.8500 - val_loss: 0.5746 - val_acc: 0.8191

Epoch 00047: val_loss improved from 0.57631 to 0.57464, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 48/60
 - 3s - loss: 0.4614 - acc: 0.8506 - val_loss: 0.6703 - val_acc: 0.7892

Epoch 00048: val_loss did not improve from 0.57464
Epoch 49/60
 - 3s - loss: 0.4574 - acc: 0.8528 - val_loss: 0.5725 - val_acc: 0.8204

Epoch 00049: val_loss improved from 0.57464 to 0.57246, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 50/60
 - 3s - loss: 0.4530 - acc: 0.8538 - val_loss: 0.6238 - val_acc: 0.8019

Epoch 00050: val_loss did not improve from 0.57246
Epoch 51/60
 - 3s - loss: 0.4496 - acc: 0.8551 - val_loss: 0.6503 - val_acc: 0.7870

Epoch 00051: val_loss did not improve from 0.57246
Epoch 52/60
 - 3s - loss: 0.4452 - acc: 0.8560 - val_loss: 0.5822 - val_acc: 0.8133

Epoch 00052: val_loss did not improve from 0.57246
Epoch 53/60
 - 3s - loss: 0.4443 - acc: 0.8569 - val_loss: 0.5678 - val_acc: 0.8166

Epoch 00053: val_loss improved from 0.57246 to 0.56782, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 54/60
 - 3s - loss: 0.4421 - acc: 0.8577 - val_loss: 0.5608 - val_acc: 0.8230

Epoch 00054: val_loss improved from 0.56782 to 0.56080, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 55/60
 - 3s - loss: 0.4404 - acc: 0.8586 - val_loss: 0.6445 - val_acc: 0.7883

Epoch 00055: val_loss did not improve from 0.56080
Epoch 56/60
 - 3s - loss: 0.4340 - acc: 0.8599 - val_loss: 0.5649 - val_acc: 0.8220

Epoch 00056: val_loss did not improve from 0.56080
Epoch 57/60
 - 3s - loss: 0.4328 - acc: 0.8614 - val_loss: 0.5673 - val_acc: 0.8208

Epoch 00057: val_loss did not improve from 0.56080
Epoch 58/60
 - 3s - loss: 0.4281 - acc: 0.8622 - val_loss: 0.5543 - val_acc: 0.8255

Epoch 00058: val_loss improved from 0.56080 to 0.55434, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 59/60
 - 3s - loss: 0.4274 - acc: 0.8628 - val_loss: 0.5923 - val_acc: 0.8198

Epoch 00059: val_loss did not improve from 0.55434
Epoch 60/60
 - 3s - loss: 0.4280 - acc: 0.8627 - val_loss: 0.5639 - val_acc: 0.8310

Epoch 00060: val_loss did not improve from 0.55434
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 5s - loss: 1.4717 - acc: 0.6165 - val_loss: 1.2879 - val_acc: 0.6091

Epoch 00001: val_loss improved from inf to 1.28790, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 2/60
 - 4s - loss: 1.1040 - acc: 0.6694 - val_loss: 1.0678 - val_acc: 0.6618

Epoch 00002: val_loss improved from 1.28790 to 1.06783, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 3/60
 - 4s - loss: 0.9368 - acc: 0.7040 - val_loss: 1.0458 - val_acc: 0.6784

Epoch 00003: val_loss improved from 1.06783 to 1.04577, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 4/60
 - 4s - loss: 0.8233 - acc: 0.7341 - val_loss: 0.7876 - val_acc: 0.7399

Epoch 00004: val_loss improved from 1.04577 to 0.78757, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 5/60
 - 4s - loss: 0.7427 - acc: 0.7588 - val_loss: 0.8068 - val_acc: 0.7339

Epoch 00005: val_loss did not improve from 0.78757
Epoch 6/60
 - 4s - loss: 0.6788 - acc: 0.7765 - val_loss: 0.7881 - val_acc: 0.7360

Epoch 00006: val_loss did not improve from 0.78757
Epoch 7/60
 - 4s - loss: 0.6320 - acc: 0.7936 - val_loss: 0.7608 - val_acc: 0.7501

Epoch 00007: val_loss improved from 0.78757 to 0.76084, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 8/60
 - 4s - loss: 0.5935 - acc: 0.8069 - val_loss: 0.6571 - val_acc: 0.7835

Epoch 00008: val_loss improved from 0.76084 to 0.65711, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 9/60
 - 4s - loss: 0.5550 - acc: 0.8177 - val_loss: 0.6338 - val_acc: 0.7901

Epoch 00009: val_loss improved from 0.65711 to 0.63384, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 10/60
 - 4s - loss: 0.5268 - acc: 0.8262 - val_loss: 0.6799 - val_acc: 0.7785

Epoch 00010: val_loss did not improve from 0.63384
Epoch 11/60
 - 4s - loss: 0.5025 - acc: 0.8355 - val_loss: 0.6208 - val_acc: 0.7905

Epoch 00011: val_loss improved from 0.63384 to 0.62079, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 12/60
 - 4s - loss: 0.4774 - acc: 0.8420 - val_loss: 0.6088 - val_acc: 0.8004

Epoch 00012: val_loss improved from 0.62079 to 0.60877, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 13/60
 - 4s - loss: 0.4583 - acc: 0.8497 - val_loss: 0.6664 - val_acc: 0.7938

Epoch 00013: val_loss did not improve from 0.60877
Epoch 14/60
 - 4s - loss: 0.4407 - acc: 0.8533 - val_loss: 0.6187 - val_acc: 0.7989

Epoch 00014: val_loss did not improve from 0.60877
Epoch 15/60
 - 4s - loss: 0.4217 - acc: 0.8595 - val_loss: 0.5970 - val_acc: 0.8020

Epoch 00015: val_loss improved from 0.60877 to 0.59696, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 16/60
 - 4s - loss: 0.4070 - acc: 0.8645 - val_loss: 0.6690 - val_acc: 0.7964

Epoch 00016: val_loss did not improve from 0.59696
Epoch 17/60
 - 4s - loss: 0.3948 - acc: 0.8680 - val_loss: 0.5567 - val_acc: 0.8186

Epoch 00017: val_loss improved from 0.59696 to 0.55670, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 18/60
 - 4s - loss: 0.3774 - acc: 0.8748 - val_loss: 0.6056 - val_acc: 0.8071

Epoch 00018: val_loss did not improve from 0.55670
Epoch 19/60
 - 4s - loss: 0.3684 - acc: 0.8773 - val_loss: 0.5765 - val_acc: 0.8205

Epoch 00019: val_loss did not improve from 0.55670
Epoch 20/60
 - 4s - loss: 0.3564 - acc: 0.8823 - val_loss: 0.7325 - val_acc: 0.7685

Epoch 00020: val_loss did not improve from 0.55670
Epoch 21/60
 - 4s - loss: 0.3492 - acc: 0.8838 - val_loss: 0.5786 - val_acc: 0.8254

Epoch 00021: val_loss did not improve from 0.55670
Epoch 22/60
 - 4s - loss: 0.3349 - acc: 0.8881 - val_loss: 0.5506 - val_acc: 0.8188

Epoch 00022: val_loss improved from 0.55670 to 0.55061, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 23/60
 - 4s - loss: 0.3268 - acc: 0.8902 - val_loss: 0.5823 - val_acc: 0.8227

Epoch 00023: val_loss did not improve from 0.55061
Epoch 24/60
 - 4s - loss: 0.3170 - acc: 0.8944 - val_loss: 0.5862 - val_acc: 0.8123

Epoch 00024: val_loss did not improve from 0.55061
Epoch 25/60
 - 4s - loss: 0.3085 - acc: 0.8973 - val_loss: 0.5587 - val_acc: 0.8305

Epoch 00025: val_loss did not improve from 0.55061
Epoch 26/60
 - 4s - loss: 0.2990 - acc: 0.8986 - val_loss: 0.5565 - val_acc: 0.8317

Epoch 00026: val_loss did not improve from 0.55061
Epoch 27/60
 - 4s - loss: 0.2905 - acc: 0.9025 - val_loss: 0.5715 - val_acc: 0.8241

Epoch 00027: val_loss did not improve from 0.55061
Epoch 28/60
 - 4s - loss: 0.2838 - acc: 0.9058 - val_loss: 0.6405 - val_acc: 0.8004

Epoch 00028: val_loss did not improve from 0.55061
Epoch 29/60
 - 4s - loss: 0.2774 - acc: 0.9077 - val_loss: 0.5308 - val_acc: 0.8413

Epoch 00029: val_loss improved from 0.55061 to 0.53077, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.1.hdf5
Epoch 30/60
 - 4s - loss: 0.2701 - acc: 0.9098 - val_loss: 0.5507 - val_acc: 0.8388

Epoch 00030: val_loss did not improve from 0.53077
Epoch 31/60
 - 4s - loss: 0.2630 - acc: 0.9114 - val_loss: 0.6331 - val_acc: 0.8183

Epoch 00031: val_loss did not improve from 0.53077
Epoch 32/60
 - 4s - loss: 0.2544 - acc: 0.9146 - val_loss: 0.5897 - val_acc: 0.8351

Epoch 00032: val_loss did not improve from 0.53077
Epoch 33/60
 - 4s - loss: 0.2513 - acc: 0.9162 - val_loss: 0.6547 - val_acc: 0.8242

Epoch 00033: val_loss did not improve from 0.53077
Epoch 34/60
 - 4s - loss: 0.2443 - acc: 0.9179 - val_loss: 0.5775 - val_acc: 0.8369

Epoch 00034: val_loss did not improve from 0.53077
Epoch 35/60
 - 4s - loss: 0.2377 - acc: 0.9207 - val_loss: 0.5980 - val_acc: 0.8232

Epoch 00035: val_loss did not improve from 0.53077
Epoch 36/60
 - 4s - loss: 0.2351 - acc: 0.9201 - val_loss: 0.6145 - val_acc: 0.8354

Epoch 00036: val_loss did not improve from 0.53077
Epoch 37/60
 - 4s - loss: 0.2273 - acc: 0.9243 - val_loss: 0.6208 - val_acc: 0.8291

Epoch 00037: val_loss did not improve from 0.53077
Epoch 38/60
 - 4s - loss: 0.2178 - acc: 0.9266 - val_loss: 0.6068 - val_acc: 0.8404

Epoch 00038: val_loss did not improve from 0.53077
Epoch 39/60
 - 4s - loss: 0.2136 - acc: 0.9272 - val_loss: 0.6681 - val_acc: 0.8151

Epoch 00039: val_loss did not improve from 0.53077
Epoch 00039: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 5s - loss: 3.0002 - acc: 0.5794 - val_loss: 1.9123 - val_acc: 0.3457

Epoch 00001: val_loss improved from inf to 1.91233, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 2/60
 - 4s - loss: 1.0898 - acc: 0.6750 - val_loss: 0.9666 - val_acc: 0.6786

Epoch 00002: val_loss improved from 1.91233 to 0.96663, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 3/60
 - 4s - loss: 0.7971 - acc: 0.7494 - val_loss: 0.7645 - val_acc: 0.7592

Epoch 00003: val_loss improved from 0.96663 to 0.76453, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 4/60
 - 4s - loss: 0.6478 - acc: 0.7950 - val_loss: 0.6798 - val_acc: 0.7841

Epoch 00004: val_loss improved from 0.76453 to 0.67984, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 5/60
 - 4s - loss: 0.5559 - acc: 0.8247 - val_loss: 0.6589 - val_acc: 0.7939

Epoch 00005: val_loss improved from 0.67984 to 0.65889, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 6/60
 - 4s - loss: 0.4886 - acc: 0.8425 - val_loss: 0.6428 - val_acc: 0.7969

Epoch 00006: val_loss improved from 0.65889 to 0.64281, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 7/60
 - 4s - loss: 0.4415 - acc: 0.8592 - val_loss: 0.6879 - val_acc: 0.8016

Epoch 00007: val_loss did not improve from 0.64281
Epoch 8/60
 - 4s - loss: 0.4017 - acc: 0.8703 - val_loss: 0.5886 - val_acc: 0.8280

Epoch 00008: val_loss improved from 0.64281 to 0.58859, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 9/60
 - 4s - loss: 0.3751 - acc: 0.8783 - val_loss: 0.5316 - val_acc: 0.8370

Epoch 00009: val_loss improved from 0.58859 to 0.53163, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 10/60
 - 4s - loss: 0.3329 - acc: 0.8930 - val_loss: 0.5553 - val_acc: 0.8369

Epoch 00010: val_loss did not improve from 0.53163
Epoch 11/60
 - 4s - loss: 0.3131 - acc: 0.8992 - val_loss: 0.4860 - val_acc: 0.8525

Epoch 00011: val_loss improved from 0.53163 to 0.48604, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 12/60
 - 4s - loss: 0.2860 - acc: 0.9070 - val_loss: 0.5504 - val_acc: 0.8448

Epoch 00012: val_loss did not improve from 0.48604
Epoch 13/60
 - 4s - loss: 0.2705 - acc: 0.9101 - val_loss: 0.5998 - val_acc: 0.8232

Epoch 00013: val_loss did not improve from 0.48604
Epoch 14/60
 - 4s - loss: 0.2421 - acc: 0.9223 - val_loss: 0.6965 - val_acc: 0.7960

Epoch 00014: val_loss did not improve from 0.48604
Epoch 15/60
 - 4s - loss: 0.2334 - acc: 0.9244 - val_loss: 0.5441 - val_acc: 0.8489

Epoch 00015: val_loss did not improve from 0.48604
Epoch 16/60
 - 4s - loss: 0.2162 - acc: 0.9293 - val_loss: 0.5230 - val_acc: 0.8576

Epoch 00016: val_loss did not improve from 0.48604
Epoch 17/60
 - 4s - loss: 0.2046 - acc: 0.9337 - val_loss: 0.5429 - val_acc: 0.8489

Epoch 00017: val_loss did not improve from 0.48604
Epoch 18/60
 - 4s - loss: 0.1877 - acc: 0.9380 - val_loss: 0.4993 - val_acc: 0.8651

Epoch 00018: val_loss did not improve from 0.48604
Epoch 19/60
 - 4s - loss: 0.1776 - acc: 0.9413 - val_loss: 0.5432 - val_acc: 0.8494

Epoch 00019: val_loss did not improve from 0.48604
Epoch 20/60
 - 4s - loss: 0.1627 - acc: 0.9472 - val_loss: 0.6211 - val_acc: 0.8441

Epoch 00020: val_loss did not improve from 0.48604
Epoch 21/60
 - 4s - loss: 0.1526 - acc: 0.9498 - val_loss: 0.5695 - val_acc: 0.8561

Epoch 00021: val_loss did not improve from 0.48604
Epoch 00021: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 4s - loss: 1.6051 - acc: 0.6158 - val_loss: 1.4614 - val_acc: 0.6194

Epoch 00001: val_loss improved from inf to 1.46142, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 2/60
 - 3s - loss: 1.3405 - acc: 0.6398 - val_loss: 1.2898 - val_acc: 0.6289

Epoch 00002: val_loss improved from 1.46142 to 1.28977, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 3/60
 - 3s - loss: 1.2049 - acc: 0.6515 - val_loss: 1.1680 - val_acc: 0.6474

Epoch 00003: val_loss improved from 1.28977 to 1.16795, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 4/60
 - 3s - loss: 1.1123 - acc: 0.6676 - val_loss: 1.1017 - val_acc: 0.6603

Epoch 00004: val_loss improved from 1.16795 to 1.10168, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 5/60
 - 3s - loss: 1.0449 - acc: 0.6810 - val_loss: 1.1117 - val_acc: 0.6550

Epoch 00005: val_loss did not improve from 1.10168
Epoch 6/60
 - 3s - loss: 0.9940 - acc: 0.6941 - val_loss: 1.0011 - val_acc: 0.6849

Epoch 00006: val_loss improved from 1.10168 to 1.00115, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 7/60
 - 3s - loss: 0.9455 - acc: 0.7063 - val_loss: 1.0239 - val_acc: 0.6728

Epoch 00007: val_loss did not improve from 1.00115
Epoch 8/60
 - 3s - loss: 0.9032 - acc: 0.7175 - val_loss: 0.9587 - val_acc: 0.6924

Epoch 00008: val_loss improved from 1.00115 to 0.95872, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 9/60
 - 3s - loss: 0.8643 - acc: 0.7280 - val_loss: 0.8707 - val_acc: 0.7192

Epoch 00009: val_loss improved from 0.95872 to 0.87075, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 10/60
 - 3s - loss: 0.8317 - acc: 0.7368 - val_loss: 0.9222 - val_acc: 0.7027

Epoch 00010: val_loss did not improve from 0.87075
Epoch 11/60
 - 3s - loss: 0.8066 - acc: 0.7434 - val_loss: 0.8317 - val_acc: 0.7289

Epoch 00011: val_loss improved from 0.87075 to 0.83168, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 12/60
 - 3s - loss: 0.7797 - acc: 0.7519 - val_loss: 0.8554 - val_acc: 0.7189

Epoch 00012: val_loss did not improve from 0.83168
Epoch 13/60
 - 3s - loss: 0.7554 - acc: 0.7592 - val_loss: 0.8859 - val_acc: 0.7146

Epoch 00013: val_loss did not improve from 0.83168
Epoch 14/60
 - 3s - loss: 0.7357 - acc: 0.7645 - val_loss: 0.7917 - val_acc: 0.7455

Epoch 00014: val_loss improved from 0.83168 to 0.79172, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 15/60
 - 3s - loss: 0.7195 - acc: 0.7676 - val_loss: 0.7906 - val_acc: 0.7427

Epoch 00015: val_loss improved from 0.79172 to 0.79065, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 16/60
 - 3s - loss: 0.7018 - acc: 0.7745 - val_loss: 0.7437 - val_acc: 0.7542

Epoch 00016: val_loss improved from 0.79065 to 0.74370, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 17/60
 - 3s - loss: 0.6816 - acc: 0.7808 - val_loss: 0.7438 - val_acc: 0.7536

Epoch 00017: val_loss did not improve from 0.74370
Epoch 18/60
 - 3s - loss: 0.6728 - acc: 0.7836 - val_loss: 0.7558 - val_acc: 0.7546

Epoch 00018: val_loss did not improve from 0.74370
Epoch 19/60
 - 3s - loss: 0.6555 - acc: 0.7888 - val_loss: 0.7130 - val_acc: 0.7655

Epoch 00019: val_loss improved from 0.74370 to 0.71304, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 20/60
 - 3s - loss: 0.6450 - acc: 0.7918 - val_loss: 0.6982 - val_acc: 0.7730

Epoch 00020: val_loss improved from 0.71304 to 0.69822, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 21/60
 - 3s - loss: 0.6301 - acc: 0.7965 - val_loss: 0.7890 - val_acc: 0.7368

Epoch 00021: val_loss did not improve from 0.69822
Epoch 22/60
 - 3s - loss: 0.6255 - acc: 0.7978 - val_loss: 0.7225 - val_acc: 0.7657

Epoch 00022: val_loss did not improve from 0.69822
Epoch 23/60
 - 3s - loss: 0.6132 - acc: 0.8017 - val_loss: 0.7250 - val_acc: 0.7657

Epoch 00023: val_loss did not improve from 0.69822
Epoch 24/60
 - 3s - loss: 0.6044 - acc: 0.8038 - val_loss: 0.6981 - val_acc: 0.7713

Epoch 00024: val_loss improved from 0.69822 to 0.69807, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 25/60
 - 3s - loss: 0.5962 - acc: 0.8078 - val_loss: 0.7027 - val_acc: 0.7668

Epoch 00025: val_loss did not improve from 0.69807
Epoch 26/60
 - 3s - loss: 0.5849 - acc: 0.8110 - val_loss: 0.7243 - val_acc: 0.7582

Epoch 00026: val_loss did not improve from 0.69807
Epoch 27/60
 - 3s - loss: 0.5783 - acc: 0.8128 - val_loss: 0.7448 - val_acc: 0.7595

Epoch 00027: val_loss did not improve from 0.69807
Epoch 28/60
 - 3s - loss: 0.5685 - acc: 0.8172 - val_loss: 0.7899 - val_acc: 0.7321

Epoch 00028: val_loss did not improve from 0.69807
Epoch 29/60
 - 3s - loss: 0.5615 - acc: 0.8198 - val_loss: 0.6825 - val_acc: 0.7833

Epoch 00029: val_loss improved from 0.69807 to 0.68247, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 30/60
 - 3s - loss: 0.5544 - acc: 0.8206 - val_loss: 0.6499 - val_acc: 0.7893

Epoch 00030: val_loss improved from 0.68247 to 0.64990, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 31/60
 - 3s - loss: 0.5513 - acc: 0.8221 - val_loss: 0.6384 - val_acc: 0.7933

Epoch 00031: val_loss improved from 0.64990 to 0.63844, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 32/60
 - 3s - loss: 0.5399 - acc: 0.8258 - val_loss: 0.6371 - val_acc: 0.7948

Epoch 00032: val_loss improved from 0.63844 to 0.63708, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 33/60
 - 3s - loss: 0.5393 - acc: 0.8271 - val_loss: 0.6223 - val_acc: 0.7939

Epoch 00033: val_loss improved from 0.63708 to 0.62234, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 34/60
 - 3s - loss: 0.5258 - acc: 0.8310 - val_loss: 0.6818 - val_acc: 0.7820

Epoch 00034: val_loss did not improve from 0.62234
Epoch 35/60
 - 3s - loss: 0.5255 - acc: 0.8306 - val_loss: 0.6619 - val_acc: 0.7870

Epoch 00035: val_loss did not improve from 0.62234
Epoch 36/60
 - 3s - loss: 0.5204 - acc: 0.8315 - val_loss: 0.6790 - val_acc: 0.7896

Epoch 00036: val_loss did not improve from 0.62234
Epoch 37/60
 - 3s - loss: 0.5158 - acc: 0.8340 - val_loss: 0.6861 - val_acc: 0.7748

Epoch 00037: val_loss did not improve from 0.62234
Epoch 38/60
 - 3s - loss: 0.5102 - acc: 0.8345 - val_loss: 0.6044 - val_acc: 0.8088

Epoch 00038: val_loss improved from 0.62234 to 0.60441, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 39/60
 - 3s - loss: 0.5062 - acc: 0.8364 - val_loss: 0.6381 - val_acc: 0.7944

Epoch 00039: val_loss did not improve from 0.60441
Epoch 40/60
 - 3s - loss: 0.5007 - acc: 0.8384 - val_loss: 0.6337 - val_acc: 0.7966

Epoch 00040: val_loss did not improve from 0.60441
Epoch 41/60
 - 3s - loss: 0.4971 - acc: 0.8399 - val_loss: 0.7040 - val_acc: 0.7640

Epoch 00041: val_loss did not improve from 0.60441
Epoch 42/60
 - 3s - loss: 0.4947 - acc: 0.8405 - val_loss: 0.6427 - val_acc: 0.7883

Epoch 00042: val_loss did not improve from 0.60441
Epoch 43/60
 - 3s - loss: 0.4863 - acc: 0.8422 - val_loss: 0.6417 - val_acc: 0.7917

Epoch 00043: val_loss did not improve from 0.60441
Epoch 44/60
 - 3s - loss: 0.4831 - acc: 0.8429 - val_loss: 0.6720 - val_acc: 0.7945

Epoch 00044: val_loss did not improve from 0.60441
Epoch 45/60
 - 3s - loss: 0.4789 - acc: 0.8462 - val_loss: 0.5971 - val_acc: 0.8061

Epoch 00045: val_loss improved from 0.60441 to 0.59707, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 46/60
 - 3s - loss: 0.4767 - acc: 0.8467 - val_loss: 0.5960 - val_acc: 0.8102

Epoch 00046: val_loss improved from 0.59707 to 0.59595, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 47/60
 - 3s - loss: 0.4716 - acc: 0.8479 - val_loss: 0.6095 - val_acc: 0.8054

Epoch 00047: val_loss did not improve from 0.59595
Epoch 48/60
 - 3s - loss: 0.4691 - acc: 0.8496 - val_loss: 0.6841 - val_acc: 0.7771

Epoch 00048: val_loss did not improve from 0.59595
Epoch 49/60
 - 3s - loss: 0.4676 - acc: 0.8502 - val_loss: 0.6079 - val_acc: 0.8044

Epoch 00049: val_loss did not improve from 0.59595
Epoch 50/60
 - 3s - loss: 0.4620 - acc: 0.8523 - val_loss: 0.6588 - val_acc: 0.7964

Epoch 00050: val_loss did not improve from 0.59595
Epoch 51/60
 - 3s - loss: 0.4599 - acc: 0.8522 - val_loss: 0.6109 - val_acc: 0.8108

Epoch 00051: val_loss did not improve from 0.59595
Epoch 52/60
 - 3s - loss: 0.4597 - acc: 0.8516 - val_loss: 0.6203 - val_acc: 0.8102

Epoch 00052: val_loss did not improve from 0.59595
Epoch 53/60
 - 3s - loss: 0.4516 - acc: 0.8540 - val_loss: 0.6706 - val_acc: 0.7860

Epoch 00053: val_loss did not improve from 0.59595
Epoch 54/60
 - 3s - loss: 0.4539 - acc: 0.8521 - val_loss: 0.5763 - val_acc: 0.8144

Epoch 00054: val_loss improved from 0.59595 to 0.57631, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 55/60
 - 3s - loss: 0.4478 - acc: 0.8554 - val_loss: 0.5912 - val_acc: 0.8199

Epoch 00055: val_loss did not improve from 0.57631
Epoch 56/60
 - 3s - loss: 0.4457 - acc: 0.8564 - val_loss: 0.5720 - val_acc: 0.8147

Epoch 00056: val_loss improved from 0.57631 to 0.57204, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 57/60
 - 3s - loss: 0.4422 - acc: 0.8574 - val_loss: 0.5690 - val_acc: 0.8192

Epoch 00057: val_loss improved from 0.57204 to 0.56903, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 58/60
 - 3s - loss: 0.4411 - acc: 0.8580 - val_loss: 0.6008 - val_acc: 0.8073

Epoch 00058: val_loss did not improve from 0.56903
Epoch 59/60
 - 3s - loss: 0.4367 - acc: 0.8590 - val_loss: 0.6053 - val_acc: 0.8082

Epoch 00059: val_loss did not improve from 0.56903
Epoch 60/60
 - 3s - loss: 0.4359 - acc: 0.8593 - val_loss: 0.6084 - val_acc: 0.8033

Epoch 00060: val_loss did not improve from 0.56903
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 5s - loss: 1.5181 - acc: 0.6154 - val_loss: 1.2347 - val_acc: 0.6334

Epoch 00001: val_loss improved from inf to 1.23471, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 2/60
 - 4s - loss: 1.1243 - acc: 0.6662 - val_loss: 1.0290 - val_acc: 0.6711

Epoch 00002: val_loss improved from 1.23471 to 1.02901, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 3/60
 - 4s - loss: 0.9782 - acc: 0.6929 - val_loss: 0.9859 - val_acc: 0.6764

Epoch 00003: val_loss improved from 1.02901 to 0.98587, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 4/60
 - 4s - loss: 0.8631 - acc: 0.7221 - val_loss: 0.9115 - val_acc: 0.6976

Epoch 00004: val_loss improved from 0.98587 to 0.91149, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 5/60
 - 4s - loss: 0.7799 - acc: 0.7465 - val_loss: 0.8423 - val_acc: 0.7298

Epoch 00005: val_loss improved from 0.91149 to 0.84234, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 6/60
 - 4s - loss: 0.7079 - acc: 0.7684 - val_loss: 0.8584 - val_acc: 0.7259

Epoch 00006: val_loss did not improve from 0.84234
Epoch 7/60
 - 4s - loss: 0.6527 - acc: 0.7852 - val_loss: 0.7612 - val_acc: 0.7471

Epoch 00007: val_loss improved from 0.84234 to 0.76116, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 8/60
 - 4s - loss: 0.6121 - acc: 0.7976 - val_loss: 0.7854 - val_acc: 0.7390

Epoch 00008: val_loss did not improve from 0.76116
Epoch 9/60
 - 4s - loss: 0.5793 - acc: 0.8074 - val_loss: 0.7542 - val_acc: 0.7492

Epoch 00009: val_loss improved from 0.76116 to 0.75418, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 10/60
 - 4s - loss: 0.5460 - acc: 0.8203 - val_loss: 0.7525 - val_acc: 0.7771

Epoch 00010: val_loss improved from 0.75418 to 0.75248, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 11/60
 - 4s - loss: 0.5146 - acc: 0.8296 - val_loss: 0.6136 - val_acc: 0.7958

Epoch 00011: val_loss improved from 0.75248 to 0.61358, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 12/60
 - 4s - loss: 0.4902 - acc: 0.8370 - val_loss: 0.6371 - val_acc: 0.7952

Epoch 00012: val_loss did not improve from 0.61358
Epoch 13/60
 - 4s - loss: 0.4677 - acc: 0.8447 - val_loss: 0.6704 - val_acc: 0.7776

Epoch 00013: val_loss did not improve from 0.61358
Epoch 14/60
 - 4s - loss: 0.4471 - acc: 0.8510 - val_loss: 0.6574 - val_acc: 0.7871

Epoch 00014: val_loss did not improve from 0.61358
Epoch 15/60
 - 4s - loss: 0.4332 - acc: 0.8550 - val_loss: 0.6047 - val_acc: 0.8049

Epoch 00015: val_loss improved from 0.61358 to 0.60474, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 16/60
 - 4s - loss: 0.4115 - acc: 0.8625 - val_loss: 0.5921 - val_acc: 0.8107

Epoch 00016: val_loss improved from 0.60474 to 0.59207, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 17/60
 - 4s - loss: 0.3969 - acc: 0.8683 - val_loss: 0.7742 - val_acc: 0.7821

Epoch 00017: val_loss did not improve from 0.59207
Epoch 18/60
 - 4s - loss: 0.3880 - acc: 0.8706 - val_loss: 0.6564 - val_acc: 0.7970

Epoch 00018: val_loss did not improve from 0.59207
Epoch 19/60
 - 4s - loss: 0.3715 - acc: 0.8765 - val_loss: 0.5796 - val_acc: 0.8142

Epoch 00019: val_loss improved from 0.59207 to 0.57957, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 20/60
 - 4s - loss: 0.3663 - acc: 0.8773 - val_loss: 0.5801 - val_acc: 0.8133

Epoch 00020: val_loss did not improve from 0.57957
Epoch 21/60
 - 4s - loss: 0.3469 - acc: 0.8852 - val_loss: 0.5558 - val_acc: 0.8277

Epoch 00021: val_loss improved from 0.57957 to 0.55579, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.5.hdf5
Epoch 22/60
 - 4s - loss: 0.3376 - acc: 0.8871 - val_loss: 0.5928 - val_acc: 0.8169

Epoch 00022: val_loss did not improve from 0.55579
Epoch 23/60
 - 4s - loss: 0.3309 - acc: 0.8884 - val_loss: 0.6706 - val_acc: 0.7957

Epoch 00023: val_loss did not improve from 0.55579
Epoch 24/60
 - 4s - loss: 0.3220 - acc: 0.8911 - val_loss: 0.5709 - val_acc: 0.8267

Epoch 00024: val_loss did not improve from 0.55579
Epoch 25/60
 - 4s - loss: 0.3112 - acc: 0.8966 - val_loss: 0.5630 - val_acc: 0.8311

Epoch 00025: val_loss did not improve from 0.55579
Epoch 26/60
 - 4s - loss: 0.3027 - acc: 0.8971 - val_loss: 0.6393 - val_acc: 0.8214

Epoch 00026: val_loss did not improve from 0.55579
Epoch 27/60
 - 4s - loss: 0.2941 - acc: 0.9010 - val_loss: 0.5821 - val_acc: 0.8295

Epoch 00027: val_loss did not improve from 0.55579
Epoch 28/60
 - 4s - loss: 0.2870 - acc: 0.9024 - val_loss: 0.6154 - val_acc: 0.8173

Epoch 00028: val_loss did not improve from 0.55579
Epoch 29/60
 - 4s - loss: 0.2790 - acc: 0.9054 - val_loss: 0.6703 - val_acc: 0.8122

Epoch 00029: val_loss did not improve from 0.55579
Epoch 30/60
 - 4s - loss: 0.2722 - acc: 0.9070 - val_loss: 0.7389 - val_acc: 0.7913

Epoch 00030: val_loss did not improve from 0.55579
Epoch 31/60
 - 4s - loss: 0.2646 - acc: 0.9114 - val_loss: 0.6108 - val_acc: 0.8286

Epoch 00031: val_loss did not improve from 0.55579
Epoch 00031: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 5s - loss: 2.9740 - acc: 0.5407 - val_loss: 1.0167 - val_acc: 0.6858

Epoch 00001: val_loss improved from inf to 1.01668, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra0.hdf5
Epoch 2/60
 - 4s - loss: 0.9157 - acc: 0.7125 - val_loss: 0.8706 - val_acc: 0.7071

Epoch 00002: val_loss improved from 1.01668 to 0.87062, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra0.hdf5
Epoch 3/60
 - 4s - loss: 0.7151 - acc: 0.7708 - val_loss: 0.7446 - val_acc: 0.7664

Epoch 00003: val_loss improved from 0.87062 to 0.74462, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra0.hdf5
Epoch 4/60
 - 4s - loss: 0.5982 - acc: 0.8066 - val_loss: 0.6507 - val_acc: 0.7857

Epoch 00004: val_loss improved from 0.74462 to 0.65069, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra0.hdf5
Epoch 5/60
 - 4s - loss: 0.5198 - acc: 0.8325 - val_loss: 0.6195 - val_acc: 0.8051

Epoch 00005: val_loss improved from 0.65069 to 0.61948, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra0.hdf5
Epoch 6/60
 - 4s - loss: 0.4550 - acc: 0.8525 - val_loss: 0.7335 - val_acc: 0.7732

Epoch 00006: val_loss did not improve from 0.61948
Epoch 7/60
 - 4s - loss: 0.4147 - acc: 0.8659 - val_loss: 0.7169 - val_acc: 0.7746

Epoch 00007: val_loss did not improve from 0.61948
Epoch 8/60
 - 4s - loss: 0.3748 - acc: 0.8803 - val_loss: 0.5836 - val_acc: 0.8136

Epoch 00008: val_loss improved from 0.61948 to 0.58361, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra0.hdf5
Epoch 9/60
 - 4s - loss: 0.3412 - acc: 0.8901 - val_loss: 0.6222 - val_acc: 0.8263

Epoch 00009: val_loss did not improve from 0.58361
Epoch 10/60
 - 4s - loss: 0.3129 - acc: 0.8989 - val_loss: 0.5635 - val_acc: 0.8248

Epoch 00010: val_loss improved from 0.58361 to 0.56345, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra0.hdf5
Epoch 11/60
 - 5s - loss: 0.2903 - acc: 0.9035 - val_loss: 0.6302 - val_acc: 0.8135

Epoch 00011: val_loss did not improve from 0.56345
Epoch 12/60
 - 4s - loss: 0.2758 - acc: 0.9092 - val_loss: 0.5339 - val_acc: 0.8463

Epoch 00012: val_loss improved from 0.56345 to 0.53387, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra0.hdf5
Epoch 13/60
 - 4s - loss: 0.2486 - acc: 0.9195 - val_loss: 0.5439 - val_acc: 0.8457

Epoch 00013: val_loss did not improve from 0.53387
Epoch 14/60
 - 4s - loss: 0.2345 - acc: 0.9235 - val_loss: 0.6461 - val_acc: 0.8404

Epoch 00014: val_loss did not improve from 0.53387
Epoch 15/60
 - 4s - loss: 0.2191 - acc: 0.9281 - val_loss: 0.5224 - val_acc: 0.8514

Epoch 00015: val_loss improved from 0.53387 to 0.52242, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra0.hdf5
Epoch 16/60
 - 4s - loss: 0.2066 - acc: 0.9307 - val_loss: 0.5752 - val_acc: 0.8483

Epoch 00016: val_loss did not improve from 0.52242
Epoch 17/60
 - 4s - loss: 0.1896 - acc: 0.9375 - val_loss: 0.5865 - val_acc: 0.8282

Epoch 00017: val_loss did not improve from 0.52242
Epoch 18/60
 - 4s - loss: 0.1769 - acc: 0.9420 - val_loss: 0.5802 - val_acc: 0.8458

Epoch 00018: val_loss did not improve from 0.52242
Epoch 19/60
 - 4s - loss: 0.1712 - acc: 0.9426 - val_loss: 0.6047 - val_acc: 0.8503

Epoch 00019: val_loss did not improve from 0.52242
Epoch 20/60
 - 4s - loss: 0.1544 - acc: 0.9492 - val_loss: 0.6414 - val_acc: 0.8457

Epoch 00020: val_loss did not improve from 0.52242
Epoch 21/60
 - 4s - loss: 0.1446 - acc: 0.9543 - val_loss: 0.5552 - val_acc: 0.8578

Epoch 00021: val_loss did not improve from 0.52242
Epoch 22/60
 - 4s - loss: 0.1342 - acc: 0.9554 - val_loss: 0.5789 - val_acc: 0.8510

Epoch 00022: val_loss did not improve from 0.52242
Epoch 23/60
 - 4s - loss: 0.1269 - acc: 0.9588 - val_loss: 0.5614 - val_acc: 0.8580

Epoch 00023: val_loss did not improve from 0.52242
Epoch 24/60
 - 4s - loss: 0.1171 - acc: 0.9630 - val_loss: 0.6831 - val_acc: 0.8503

Epoch 00024: val_loss did not improve from 0.52242
Epoch 25/60
 - 4s - loss: 0.1128 - acc: 0.9632 - val_loss: 0.6916 - val_acc: 0.8539

Epoch 00025: val_loss did not improve from 0.52242
Epoch 00025: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 5s - loss: 1.6059 - acc: 0.6078 - val_loss: 1.4550 - val_acc: 0.6236

Epoch 00001: val_loss improved from inf to 1.45500, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 2/60
 - 3s - loss: 1.3400 - acc: 0.6470 - val_loss: 1.3184 - val_acc: 0.6392

Epoch 00002: val_loss improved from 1.45500 to 1.31843, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 3/60
 - 3s - loss: 1.2309 - acc: 0.6588 - val_loss: 1.2745 - val_acc: 0.6446

Epoch 00003: val_loss improved from 1.31843 to 1.27450, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 4/60
 - 3s - loss: 1.1485 - acc: 0.6689 - val_loss: 1.1433 - val_acc: 0.6583

Epoch 00004: val_loss improved from 1.27450 to 1.14330, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 5/60
 - 3s - loss: 1.0757 - acc: 0.6805 - val_loss: 1.1019 - val_acc: 0.6650

Epoch 00005: val_loss improved from 1.14330 to 1.10189, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 6/60
 - 3s - loss: 1.0133 - acc: 0.6939 - val_loss: 1.0632 - val_acc: 0.6724

Epoch 00006: val_loss improved from 1.10189 to 1.06316, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 7/60
 - 3s - loss: 0.9608 - acc: 0.7044 - val_loss: 0.9544 - val_acc: 0.6979

Epoch 00007: val_loss improved from 1.06316 to 0.95439, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 8/60
 - 3s - loss: 0.9125 - acc: 0.7163 - val_loss: 0.9885 - val_acc: 0.6962

Epoch 00008: val_loss did not improve from 0.95439
Epoch 9/60
 - 3s - loss: 0.8698 - acc: 0.7279 - val_loss: 1.0059 - val_acc: 0.6861

Epoch 00009: val_loss did not improve from 0.95439
Epoch 10/60
 - 3s - loss: 0.8324 - acc: 0.7381 - val_loss: 0.8803 - val_acc: 0.7240

Epoch 00010: val_loss improved from 0.95439 to 0.88032, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 11/60
 - 3s - loss: 0.8027 - acc: 0.7472 - val_loss: 0.8449 - val_acc: 0.7326

Epoch 00011: val_loss improved from 0.88032 to 0.84489, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 12/60
 - 3s - loss: 0.7741 - acc: 0.7558 - val_loss: 0.7869 - val_acc: 0.7549

Epoch 00012: val_loss improved from 0.84489 to 0.78694, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 13/60
 - 3s - loss: 0.7451 - acc: 0.7640 - val_loss: 0.8237 - val_acc: 0.7392

Epoch 00013: val_loss did not improve from 0.78694
Epoch 14/60
 - 3s - loss: 0.7238 - acc: 0.7704 - val_loss: 0.7750 - val_acc: 0.7515

Epoch 00014: val_loss improved from 0.78694 to 0.77497, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 15/60
 - 3s - loss: 0.7028 - acc: 0.7776 - val_loss: 0.7461 - val_acc: 0.7630

Epoch 00015: val_loss improved from 0.77497 to 0.74607, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 16/60
 - 3s - loss: 0.6847 - acc: 0.7822 - val_loss: 0.7466 - val_acc: 0.7546

Epoch 00016: val_loss did not improve from 0.74607
Epoch 17/60
 - 3s - loss: 0.6683 - acc: 0.7881 - val_loss: 0.7485 - val_acc: 0.7663

Epoch 00017: val_loss did not improve from 0.74607
Epoch 18/60
 - 3s - loss: 0.6532 - acc: 0.7921 - val_loss: 0.7594 - val_acc: 0.7533

Epoch 00018: val_loss did not improve from 0.74607
Epoch 19/60
 - 3s - loss: 0.6415 - acc: 0.7955 - val_loss: 0.7102 - val_acc: 0.7680

Epoch 00019: val_loss improved from 0.74607 to 0.71024, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 20/60
 - 3s - loss: 0.6247 - acc: 0.8017 - val_loss: 0.6791 - val_acc: 0.7817

Epoch 00020: val_loss improved from 0.71024 to 0.67908, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 21/60
 - 3s - loss: 0.6155 - acc: 0.8054 - val_loss: 0.6913 - val_acc: 0.7841

Epoch 00021: val_loss did not improve from 0.67908
Epoch 22/60
 - 3s - loss: 0.6066 - acc: 0.8077 - val_loss: 0.7372 - val_acc: 0.7717

Epoch 00022: val_loss did not improve from 0.67908
Epoch 23/60
 - 3s - loss: 0.5961 - acc: 0.8116 - val_loss: 0.6621 - val_acc: 0.7882

Epoch 00023: val_loss improved from 0.67908 to 0.66210, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 24/60
 - 3s - loss: 0.5852 - acc: 0.8145 - val_loss: 0.6528 - val_acc: 0.7895

Epoch 00024: val_loss improved from 0.66210 to 0.65282, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 25/60
 - 3s - loss: 0.5751 - acc: 0.8157 - val_loss: 0.6501 - val_acc: 0.7977

Epoch 00025: val_loss improved from 0.65282 to 0.65011, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 26/60
 - 3s - loss: 0.5721 - acc: 0.8177 - val_loss: 0.7004 - val_acc: 0.7757

Epoch 00026: val_loss did not improve from 0.65011
Epoch 27/60
 - 3s - loss: 0.5617 - acc: 0.8212 - val_loss: 0.7059 - val_acc: 0.7864

Epoch 00027: val_loss did not improve from 0.65011
Epoch 28/60
 - 3s - loss: 0.5545 - acc: 0.8244 - val_loss: 0.6120 - val_acc: 0.8079

Epoch 00028: val_loss improved from 0.65011 to 0.61202, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 29/60
 - 3s - loss: 0.5469 - acc: 0.8260 - val_loss: 0.6646 - val_acc: 0.7945

Epoch 00029: val_loss did not improve from 0.61202
Epoch 30/60
 - 3s - loss: 0.5412 - acc: 0.8277 - val_loss: 0.6531 - val_acc: 0.7889

Epoch 00030: val_loss did not improve from 0.61202
Epoch 31/60
 - 3s - loss: 0.5328 - acc: 0.8301 - val_loss: 0.6130 - val_acc: 0.8080

Epoch 00031: val_loss did not improve from 0.61202
Epoch 32/60
 - 3s - loss: 0.5254 - acc: 0.8334 - val_loss: 0.6532 - val_acc: 0.7969

Epoch 00032: val_loss did not improve from 0.61202
Epoch 33/60
 - 3s - loss: 0.5243 - acc: 0.8343 - val_loss: 0.6466 - val_acc: 0.8002

Epoch 00033: val_loss did not improve from 0.61202
Epoch 34/60
 - 3s - loss: 0.5155 - acc: 0.8365 - val_loss: 0.6570 - val_acc: 0.8017

Epoch 00034: val_loss did not improve from 0.61202
Epoch 35/60
 - 3s - loss: 0.5087 - acc: 0.8373 - val_loss: 0.6228 - val_acc: 0.8051

Epoch 00035: val_loss did not improve from 0.61202
Epoch 36/60
 - 3s - loss: 0.5074 - acc: 0.8375 - val_loss: 0.6022 - val_acc: 0.8107

Epoch 00036: val_loss improved from 0.61202 to 0.60220, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 37/60
 - 3s - loss: 0.5005 - acc: 0.8401 - val_loss: 0.6346 - val_acc: 0.8007

Epoch 00037: val_loss did not improve from 0.60220
Epoch 38/60
 - 3s - loss: 0.4970 - acc: 0.8399 - val_loss: 0.6195 - val_acc: 0.8077

Epoch 00038: val_loss did not improve from 0.60220
Epoch 39/60
 - 3s - loss: 0.4937 - acc: 0.8420 - val_loss: 0.6278 - val_acc: 0.7976

Epoch 00039: val_loss did not improve from 0.60220
Epoch 40/60
 - 3s - loss: 0.4858 - acc: 0.8441 - val_loss: 0.6165 - val_acc: 0.8073

Epoch 00040: val_loss did not improve from 0.60220
Epoch 41/60
 - 3s - loss: 0.4871 - acc: 0.8463 - val_loss: 0.6362 - val_acc: 0.8010

Epoch 00041: val_loss did not improve from 0.60220
Epoch 42/60
 - 3s - loss: 0.4822 - acc: 0.8466 - val_loss: 0.5969 - val_acc: 0.8092

Epoch 00042: val_loss improved from 0.60220 to 0.59695, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 43/60
 - 3s - loss: 0.4766 - acc: 0.8487 - val_loss: 0.6450 - val_acc: 0.8036

Epoch 00043: val_loss did not improve from 0.59695
Epoch 44/60
 - 3s - loss: 0.4747 - acc: 0.8494 - val_loss: 0.6194 - val_acc: 0.8135

Epoch 00044: val_loss did not improve from 0.59695
Epoch 45/60
 - 3s - loss: 0.4702 - acc: 0.8515 - val_loss: 0.6086 - val_acc: 0.8016

Epoch 00045: val_loss did not improve from 0.59695
Epoch 46/60
 - 3s - loss: 0.4678 - acc: 0.8520 - val_loss: 0.5684 - val_acc: 0.8197

Epoch 00046: val_loss improved from 0.59695 to 0.56837, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 47/60
 - 3s - loss: 0.4664 - acc: 0.8518 - val_loss: 0.5710 - val_acc: 0.8166

Epoch 00047: val_loss did not improve from 0.56837
Epoch 48/60
 - 3s - loss: 0.4579 - acc: 0.8549 - val_loss: 0.6112 - val_acc: 0.8049

Epoch 00048: val_loss did not improve from 0.56837
Epoch 49/60
 - 3s - loss: 0.4585 - acc: 0.8552 - val_loss: 0.5765 - val_acc: 0.8186

Epoch 00049: val_loss did not improve from 0.56837
Epoch 50/60
 - 3s - loss: 0.4519 - acc: 0.8583 - val_loss: 0.5850 - val_acc: 0.8207

Epoch 00050: val_loss did not improve from 0.56837
Epoch 51/60
 - 3s - loss: 0.4525 - acc: 0.8561 - val_loss: 0.5870 - val_acc: 0.8217

Epoch 00051: val_loss did not improve from 0.56837
Epoch 52/60
 - 3s - loss: 0.4463 - acc: 0.8595 - val_loss: 0.5931 - val_acc: 0.8177

Epoch 00052: val_loss did not improve from 0.56837
Epoch 53/60
 - 3s - loss: 0.4451 - acc: 0.8582 - val_loss: 0.5747 - val_acc: 0.8195

Epoch 00053: val_loss did not improve from 0.56837
Epoch 54/60
 - 3s - loss: 0.4430 - acc: 0.8592 - val_loss: 0.5533 - val_acc: 0.8280

Epoch 00054: val_loss improved from 0.56837 to 0.55331, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 55/60
 - 3s - loss: 0.4439 - acc: 0.8584 - val_loss: 0.5697 - val_acc: 0.8261

Epoch 00055: val_loss did not improve from 0.55331
Epoch 56/60
 - 3s - loss: 0.4379 - acc: 0.8618 - val_loss: 0.5341 - val_acc: 0.8311

Epoch 00056: val_loss improved from 0.55331 to 0.53411, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5
Epoch 57/60
 - 3s - loss: 0.4345 - acc: 0.8616 - val_loss: 0.6357 - val_acc: 0.8119

Epoch 00057: val_loss did not improve from 0.53411
Epoch 58/60
 - 3s - loss: 0.4324 - acc: 0.8620 - val_loss: 0.6434 - val_acc: 0.7929

Epoch 00058: val_loss did not improve from 0.53411
Epoch 59/60
 - 3s - loss: 0.4263 - acc: 0.8642 - val_loss: 0.5557 - val_acc: 0.8251

Epoch 00059: val_loss did not improve from 0.53411
Epoch 60/60
 - 3s - loss: 0.4310 - acc: 0.8626 - val_loss: 0.5426 - val_acc: 0.8326

Epoch 00060: val_loss did not improve from 0.53411
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 6s - loss: 1.3982 - acc: 0.6324 - val_loss: 1.1781 - val_acc: 0.6349

Epoch 00001: val_loss improved from inf to 1.17809, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra0.hdf5
Epoch 2/60
 - 4s - loss: 1.0734 - acc: 0.6747 - val_loss: 1.0454 - val_acc: 0.6781

Epoch 00002: val_loss improved from 1.17809 to 1.04545, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra0.hdf5
Epoch 3/60
 - 4s - loss: 0.9345 - acc: 0.7056 - val_loss: 0.9268 - val_acc: 0.7012

Epoch 00003: val_loss improved from 1.04545 to 0.92677, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra0.hdf5
Epoch 4/60
 - 4s - loss: 0.8188 - acc: 0.7370 - val_loss: 0.8534 - val_acc: 0.7184

Epoch 00004: val_loss improved from 0.92677 to 0.85343, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra0.hdf5
Epoch 5/60
 - 4s - loss: 0.7396 - acc: 0.7602 - val_loss: 0.8415 - val_acc: 0.7305

Epoch 00005: val_loss improved from 0.85343 to 0.84155, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra0.hdf5
Epoch 6/60
 - 4s - loss: 0.6718 - acc: 0.7807 - val_loss: 0.7755 - val_acc: 0.7461

Epoch 00006: val_loss improved from 0.84155 to 0.77550, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra0.hdf5
Epoch 7/60
 - 4s - loss: 0.6229 - acc: 0.7967 - val_loss: 0.6850 - val_acc: 0.7705

Epoch 00007: val_loss improved from 0.77550 to 0.68501, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra0.hdf5
Epoch 8/60
 - 4s - loss: 0.5777 - acc: 0.8085 - val_loss: 0.6867 - val_acc: 0.7761

Epoch 00008: val_loss did not improve from 0.68501
Epoch 9/60
 - 4s - loss: 0.5413 - acc: 0.8217 - val_loss: 0.7086 - val_acc: 0.7708

Epoch 00009: val_loss did not improve from 0.68501
Epoch 10/60
 - 4s - loss: 0.5167 - acc: 0.8286 - val_loss: 0.6911 - val_acc: 0.7788

Epoch 00010: val_loss did not improve from 0.68501
Epoch 11/60
 - 4s - loss: 0.4861 - acc: 0.8390 - val_loss: 0.6170 - val_acc: 0.8020

Epoch 00011: val_loss improved from 0.68501 to 0.61705, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra0.hdf5
Epoch 12/60
 - 4s - loss: 0.4615 - acc: 0.8468 - val_loss: 0.7317 - val_acc: 0.7665

Epoch 00012: val_loss did not improve from 0.61705
Epoch 13/60
 - 4s - loss: 0.4406 - acc: 0.8546 - val_loss: 0.7108 - val_acc: 0.7839

Epoch 00013: val_loss did not improve from 0.61705
Epoch 14/60
 - 4s - loss: 0.4200 - acc: 0.8607 - val_loss: 0.5999 - val_acc: 0.8155

Epoch 00014: val_loss improved from 0.61705 to 0.59992, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra0.hdf5
Epoch 15/60
 - 4s - loss: 0.4043 - acc: 0.8672 - val_loss: 0.6999 - val_acc: 0.7752

Epoch 00015: val_loss did not improve from 0.59992
Epoch 16/60
 - 4s - loss: 0.3865 - acc: 0.8713 - val_loss: 0.5853 - val_acc: 0.8210

Epoch 00016: val_loss improved from 0.59992 to 0.58529, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra0.hdf5
Epoch 17/60
 - 4s - loss: 0.3712 - acc: 0.8763 - val_loss: 0.5587 - val_acc: 0.8292

Epoch 00017: val_loss improved from 0.58529 to 0.55871, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra0.hdf5
Epoch 18/60
 - 4s - loss: 0.3580 - acc: 0.8811 - val_loss: 0.6004 - val_acc: 0.8205

Epoch 00018: val_loss did not improve from 0.55871
Epoch 19/60
 - 4s - loss: 0.3503 - acc: 0.8836 - val_loss: 0.5834 - val_acc: 0.8229

Epoch 00019: val_loss did not improve from 0.55871
Epoch 20/60
 - 4s - loss: 0.3371 - acc: 0.8881 - val_loss: 0.6360 - val_acc: 0.8016

Epoch 00020: val_loss did not improve from 0.55871
Epoch 21/60
 - 4s - loss: 0.3277 - acc: 0.8919 - val_loss: 0.5610 - val_acc: 0.8329

Epoch 00021: val_loss did not improve from 0.55871
Epoch 22/60
 - 4s - loss: 0.3151 - acc: 0.8943 - val_loss: 0.5922 - val_acc: 0.8295

Epoch 00022: val_loss did not improve from 0.55871
Epoch 23/60
 - 4s - loss: 0.3061 - acc: 0.8982 - val_loss: 0.6051 - val_acc: 0.8335

Epoch 00023: val_loss did not improve from 0.55871
Epoch 24/60
 - 4s - loss: 0.2961 - acc: 0.9002 - val_loss: 0.6639 - val_acc: 0.8255

Epoch 00024: val_loss did not improve from 0.55871
Epoch 25/60
 - 4s - loss: 0.2850 - acc: 0.9053 - val_loss: 0.6126 - val_acc: 0.8267

Epoch 00025: val_loss did not improve from 0.55871
Epoch 26/60
 - 4s - loss: 0.2814 - acc: 0.9049 - val_loss: 0.6143 - val_acc: 0.8091

Epoch 00026: val_loss did not improve from 0.55871
Epoch 27/60
 - 4s - loss: 0.2677 - acc: 0.9094 - val_loss: 0.6167 - val_acc: 0.8270

Epoch 00027: val_loss did not improve from 0.55871
Epoch 00027: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 6s - loss: 4.5342 - acc: 0.5840 - val_loss: 1.4711 - val_acc: 0.6294

Epoch 00001: val_loss improved from inf to 1.47112, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 2/60
 - 4s - loss: 1.1277 - acc: 0.6684 - val_loss: 0.9010 - val_acc: 0.7099

Epoch 00002: val_loss improved from 1.47112 to 0.90098, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 3/60
 - 4s - loss: 0.8202 - acc: 0.7403 - val_loss: 0.7626 - val_acc: 0.7485

Epoch 00003: val_loss improved from 0.90098 to 0.76261, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 4/60
 - 4s - loss: 0.6513 - acc: 0.7917 - val_loss: 0.9300 - val_acc: 0.7414

Epoch 00004: val_loss did not improve from 0.76261
Epoch 5/60
 - 4s - loss: 0.5630 - acc: 0.8208 - val_loss: 0.5934 - val_acc: 0.8135

Epoch 00005: val_loss improved from 0.76261 to 0.59337, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 6/60
 - 4s - loss: 0.4844 - acc: 0.8454 - val_loss: 0.6738 - val_acc: 0.7911

Epoch 00006: val_loss did not improve from 0.59337
Epoch 7/60
 - 4s - loss: 0.4368 - acc: 0.8587 - val_loss: 0.6220 - val_acc: 0.8145

Epoch 00007: val_loss did not improve from 0.59337
Epoch 8/60
 - 4s - loss: 0.3951 - acc: 0.8727 - val_loss: 0.5938 - val_acc: 0.8157

Epoch 00008: val_loss did not improve from 0.59337
Epoch 9/60
 - 4s - loss: 0.3584 - acc: 0.8842 - val_loss: 0.5995 - val_acc: 0.8160

Epoch 00009: val_loss did not improve from 0.59337
Epoch 10/60
 - 4s - loss: 0.3294 - acc: 0.8944 - val_loss: 0.5685 - val_acc: 0.8341

Epoch 00010: val_loss improved from 0.59337 to 0.56846, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 11/60
 - 4s - loss: 0.3004 - acc: 0.9025 - val_loss: 0.5348 - val_acc: 0.8379

Epoch 00011: val_loss improved from 0.56846 to 0.53476, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 12/60
 - 4s - loss: 0.2794 - acc: 0.9097 - val_loss: 0.5978 - val_acc: 0.8360

Epoch 00012: val_loss did not improve from 0.53476
Epoch 13/60
 - 4s - loss: 0.2616 - acc: 0.9149 - val_loss: 0.5527 - val_acc: 0.8420

Epoch 00013: val_loss did not improve from 0.53476
Epoch 14/60
 - 4s - loss: 0.2391 - acc: 0.9213 - val_loss: 0.5787 - val_acc: 0.8389

Epoch 00014: val_loss did not improve from 0.53476
Epoch 15/60
 - 4s - loss: 0.2221 - acc: 0.9266 - val_loss: 0.6637 - val_acc: 0.8154

Epoch 00015: val_loss did not improve from 0.53476
Epoch 16/60
 - 4s - loss: 0.2116 - acc: 0.9310 - val_loss: 0.5949 - val_acc: 0.8323

Epoch 00016: val_loss did not improve from 0.53476
Epoch 17/60
 - 4s - loss: 0.1916 - acc: 0.9380 - val_loss: 0.6082 - val_acc: 0.8233

Epoch 00017: val_loss did not improve from 0.53476
Epoch 18/60
 - 4s - loss: 0.1788 - acc: 0.9424 - val_loss: 0.5936 - val_acc: 0.8420

Epoch 00018: val_loss did not improve from 0.53476
Epoch 19/60
 - 4s - loss: 0.1660 - acc: 0.9454 - val_loss: 0.5673 - val_acc: 0.8445

Epoch 00019: val_loss did not improve from 0.53476
Epoch 20/60
 - 4s - loss: 0.1589 - acc: 0.9472 - val_loss: 0.5855 - val_acc: 0.8450

Epoch 00020: val_loss did not improve from 0.53476
Epoch 21/60
 - 4s - loss: 0.1424 - acc: 0.9532 - val_loss: 0.6512 - val_acc: 0.8420

Epoch 00021: val_loss did not improve from 0.53476
Epoch 00021: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 5s - loss: 1.8362 - acc: 0.5637 - val_loss: 1.4101 - val_acc: 0.6211

Epoch 00001: val_loss improved from inf to 1.41014, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 2/60
 - 3s - loss: 1.2686 - acc: 0.6474 - val_loss: 1.2325 - val_acc: 0.6440

Epoch 00002: val_loss improved from 1.41014 to 1.23245, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 3/60
 - 3s - loss: 1.1401 - acc: 0.6668 - val_loss: 1.1585 - val_acc: 0.6487

Epoch 00003: val_loss improved from 1.23245 to 1.15850, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 4/60
 - 3s - loss: 1.0583 - acc: 0.6814 - val_loss: 1.1013 - val_acc: 0.6734

Epoch 00004: val_loss improved from 1.15850 to 1.10127, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 5/60
 - 3s - loss: 0.9930 - acc: 0.6939 - val_loss: 0.9765 - val_acc: 0.6884

Epoch 00005: val_loss improved from 1.10127 to 0.97650, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 6/60
 - 3s - loss: 0.9350 - acc: 0.7073 - val_loss: 0.9854 - val_acc: 0.6868

Epoch 00006: val_loss did not improve from 0.97650
Epoch 7/60
 - 3s - loss: 0.8870 - acc: 0.7194 - val_loss: 0.9609 - val_acc: 0.6877

Epoch 00007: val_loss improved from 0.97650 to 0.96085, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 8/60
 - 3s - loss: 0.8508 - acc: 0.7286 - val_loss: 0.8742 - val_acc: 0.7148

Epoch 00008: val_loss improved from 0.96085 to 0.87420, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 9/60
 - 3s - loss: 0.8188 - acc: 0.7379 - val_loss: 0.8345 - val_acc: 0.7205

Epoch 00009: val_loss improved from 0.87420 to 0.83453, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 10/60
 - 3s - loss: 0.7893 - acc: 0.7452 - val_loss: 0.8195 - val_acc: 0.7307

Epoch 00010: val_loss improved from 0.83453 to 0.81948, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 11/60
 - 3s - loss: 0.7639 - acc: 0.7531 - val_loss: 0.7925 - val_acc: 0.7345

Epoch 00011: val_loss improved from 0.81948 to 0.79250, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 12/60
 - 3s - loss: 0.7433 - acc: 0.7585 - val_loss: 0.7967 - val_acc: 0.7420

Epoch 00012: val_loss did not improve from 0.79250
Epoch 13/60
 - 3s - loss: 0.7237 - acc: 0.7650 - val_loss: 0.8256 - val_acc: 0.7230

Epoch 00013: val_loss did not improve from 0.79250
Epoch 14/60
 - 3s - loss: 0.7087 - acc: 0.7702 - val_loss: 0.8473 - val_acc: 0.7345

Epoch 00014: val_loss did not improve from 0.79250
Epoch 15/60
 - 3s - loss: 0.6897 - acc: 0.7749 - val_loss: 0.8761 - val_acc: 0.7327

Epoch 00015: val_loss did not improve from 0.79250
Epoch 16/60
 - 3s - loss: 0.6784 - acc: 0.7806 - val_loss: 0.7215 - val_acc: 0.7627

Epoch 00016: val_loss improved from 0.79250 to 0.72155, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 17/60
 - 3s - loss: 0.6611 - acc: 0.7853 - val_loss: 0.7434 - val_acc: 0.7571

Epoch 00017: val_loss did not improve from 0.72155
Epoch 18/60
 - 3s - loss: 0.6511 - acc: 0.7892 - val_loss: 0.7021 - val_acc: 0.7693

Epoch 00018: val_loss improved from 0.72155 to 0.70209, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 19/60
 - 3s - loss: 0.6377 - acc: 0.7926 - val_loss: 0.7361 - val_acc: 0.7563

Epoch 00019: val_loss did not improve from 0.70209
Epoch 20/60
 - 3s - loss: 0.6277 - acc: 0.7959 - val_loss: 0.7891 - val_acc: 0.7336

Epoch 00020: val_loss did not improve from 0.70209
Epoch 21/60
 - 3s - loss: 0.6164 - acc: 0.8005 - val_loss: 0.7322 - val_acc: 0.7642

Epoch 00021: val_loss did not improve from 0.70209
Epoch 22/60
 - 3s - loss: 0.6078 - acc: 0.8037 - val_loss: 0.7473 - val_acc: 0.7670

Epoch 00022: val_loss did not improve from 0.70209
Epoch 23/60
 - 3s - loss: 0.5967 - acc: 0.8078 - val_loss: 0.7824 - val_acc: 0.7523

Epoch 00023: val_loss did not improve from 0.70209
Epoch 24/60
 - 3s - loss: 0.5883 - acc: 0.8086 - val_loss: 0.6935 - val_acc: 0.7791

Epoch 00024: val_loss improved from 0.70209 to 0.69348, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 25/60
 - 3s - loss: 0.5798 - acc: 0.8116 - val_loss: 0.6590 - val_acc: 0.7870

Epoch 00025: val_loss improved from 0.69348 to 0.65905, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 26/60
 - 3s - loss: 0.5764 - acc: 0.8136 - val_loss: 0.6721 - val_acc: 0.7773

Epoch 00026: val_loss did not improve from 0.65905
Epoch 27/60
 - 3s - loss: 0.5609 - acc: 0.8197 - val_loss: 0.6923 - val_acc: 0.7802

Epoch 00027: val_loss did not improve from 0.65905
Epoch 28/60
 - 3s - loss: 0.5612 - acc: 0.8187 - val_loss: 0.6193 - val_acc: 0.7966

Epoch 00028: val_loss improved from 0.65905 to 0.61926, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 29/60
 - 3s - loss: 0.5504 - acc: 0.8229 - val_loss: 0.6288 - val_acc: 0.7930

Epoch 00029: val_loss did not improve from 0.61926
Epoch 30/60
 - 3s - loss: 0.5454 - acc: 0.8242 - val_loss: 0.6748 - val_acc: 0.7795

Epoch 00030: val_loss did not improve from 0.61926
Epoch 31/60
 - 3s - loss: 0.5399 - acc: 0.8254 - val_loss: 0.6404 - val_acc: 0.7902

Epoch 00031: val_loss did not improve from 0.61926
Epoch 32/60
 - 3s - loss: 0.5306 - acc: 0.8285 - val_loss: 0.6564 - val_acc: 0.7826

Epoch 00032: val_loss did not improve from 0.61926
Epoch 33/60
 - 3s - loss: 0.5290 - acc: 0.8298 - val_loss: 0.6252 - val_acc: 0.7933

Epoch 00033: val_loss did not improve from 0.61926
Epoch 34/60
 - 3s - loss: 0.5246 - acc: 0.8311 - val_loss: 0.6638 - val_acc: 0.7917

Epoch 00034: val_loss did not improve from 0.61926
Epoch 35/60
 - 3s - loss: 0.5199 - acc: 0.8322 - val_loss: 0.7138 - val_acc: 0.7608

Epoch 00035: val_loss did not improve from 0.61926
Epoch 36/60
 - 3s - loss: 0.5108 - acc: 0.8350 - val_loss: 0.6088 - val_acc: 0.8054

Epoch 00036: val_loss improved from 0.61926 to 0.60884, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 37/60
 - 3s - loss: 0.5087 - acc: 0.8363 - val_loss: 0.6565 - val_acc: 0.7983

Epoch 00037: val_loss did not improve from 0.60884
Epoch 38/60
 - 3s - loss: 0.5041 - acc: 0.8373 - val_loss: 0.6946 - val_acc: 0.7702

Epoch 00038: val_loss did not improve from 0.60884
Epoch 39/60
 - 3s - loss: 0.4983 - acc: 0.8408 - val_loss: 0.6941 - val_acc: 0.7855

Epoch 00039: val_loss did not improve from 0.60884
Epoch 40/60
 - 3s - loss: 0.4964 - acc: 0.8410 - val_loss: 0.5997 - val_acc: 0.8036

Epoch 00040: val_loss improved from 0.60884 to 0.59968, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 41/60
 - 3s - loss: 0.4878 - acc: 0.8438 - val_loss: 0.6431 - val_acc: 0.7880

Epoch 00041: val_loss did not improve from 0.59968
Epoch 42/60
 - 3s - loss: 0.4865 - acc: 0.8449 - val_loss: 0.6774 - val_acc: 0.7983

Epoch 00042: val_loss did not improve from 0.59968
Epoch 43/60
 - 3s - loss: 0.4833 - acc: 0.8459 - val_loss: 0.6156 - val_acc: 0.8039

Epoch 00043: val_loss did not improve from 0.59968
Epoch 44/60
 - 3s - loss: 0.4779 - acc: 0.8465 - val_loss: 0.6221 - val_acc: 0.8033

Epoch 00044: val_loss did not improve from 0.59968
Epoch 45/60
 - 3s - loss: 0.4762 - acc: 0.8483 - val_loss: 0.6021 - val_acc: 0.8098

Epoch 00045: val_loss did not improve from 0.59968
Epoch 46/60
 - 3s - loss: 0.4706 - acc: 0.8494 - val_loss: 0.6243 - val_acc: 0.7924

Epoch 00046: val_loss did not improve from 0.59968
Epoch 47/60
 - 3s - loss: 0.4648 - acc: 0.8527 - val_loss: 0.6451 - val_acc: 0.7886

Epoch 00047: val_loss did not improve from 0.59968
Epoch 48/60
 - 3s - loss: 0.4619 - acc: 0.8518 - val_loss: 0.6302 - val_acc: 0.7992

Epoch 00048: val_loss did not improve from 0.59968
Epoch 49/60
 - 3s - loss: 0.4649 - acc: 0.8517 - val_loss: 0.5633 - val_acc: 0.8216

Epoch 00049: val_loss improved from 0.59968 to 0.56333, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 50/60
 - 3s - loss: 0.4566 - acc: 0.8536 - val_loss: 0.6169 - val_acc: 0.8077

Epoch 00050: val_loss did not improve from 0.56333
Epoch 51/60
 - 3s - loss: 0.4571 - acc: 0.8528 - val_loss: 0.6207 - val_acc: 0.8108

Epoch 00051: val_loss did not improve from 0.56333
Epoch 52/60
 - 3s - loss: 0.4517 - acc: 0.8554 - val_loss: 0.5620 - val_acc: 0.8176

Epoch 00052: val_loss improved from 0.56333 to 0.56203, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 53/60
 - 3s - loss: 0.4481 - acc: 0.8563 - val_loss: 0.5989 - val_acc: 0.8127

Epoch 00053: val_loss did not improve from 0.56203
Epoch 54/60
 - 3s - loss: 0.4449 - acc: 0.8589 - val_loss: 0.6063 - val_acc: 0.8110

Epoch 00054: val_loss did not improve from 0.56203
Epoch 55/60
 - 3s - loss: 0.4438 - acc: 0.8583 - val_loss: 0.5660 - val_acc: 0.8199

Epoch 00055: val_loss did not improve from 0.56203
Epoch 56/60
 - 3s - loss: 0.4393 - acc: 0.8593 - val_loss: 0.5632 - val_acc: 0.8177

Epoch 00056: val_loss did not improve from 0.56203
Epoch 57/60
 - 3s - loss: 0.4375 - acc: 0.8599 - val_loss: 0.6260 - val_acc: 0.7989

Epoch 00057: val_loss did not improve from 0.56203
Epoch 58/60
 - 3s - loss: 0.4353 - acc: 0.8609 - val_loss: 0.6068 - val_acc: 0.8044

Epoch 00058: val_loss did not improve from 0.56203
Epoch 59/60
 - 3s - loss: 0.4309 - acc: 0.8624 - val_loss: 0.5840 - val_acc: 0.8119

Epoch 00059: val_loss did not improve from 0.56203
Epoch 60/60
 - 3s - loss: 0.4312 - acc: 0.8621 - val_loss: 0.5488 - val_acc: 0.8251

Epoch 00060: val_loss improved from 0.56203 to 0.54877, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 6s - loss: 1.4768 - acc: 0.6209 - val_loss: 1.2675 - val_acc: 0.6437

Epoch 00001: val_loss improved from inf to 1.26747, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 2/60
 - 4s - loss: 1.0945 - acc: 0.6727 - val_loss: 1.0558 - val_acc: 0.6874

Epoch 00002: val_loss improved from 1.26747 to 1.05581, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 3/60
 - 4s - loss: 0.9367 - acc: 0.7071 - val_loss: 0.9226 - val_acc: 0.6939

Epoch 00003: val_loss improved from 1.05581 to 0.92256, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 4/60
 - 4s - loss: 0.8254 - acc: 0.7351 - val_loss: 0.9950 - val_acc: 0.7018

Epoch 00004: val_loss did not improve from 0.92256
Epoch 5/60
 - 4s - loss: 0.7497 - acc: 0.7577 - val_loss: 0.8129 - val_acc: 0.7276

Epoch 00005: val_loss improved from 0.92256 to 0.81295, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 6/60
 - 4s - loss: 0.6853 - acc: 0.7759 - val_loss: 0.8546 - val_acc: 0.6924

Epoch 00006: val_loss did not improve from 0.81295
Epoch 7/60
 - 4s - loss: 0.6375 - acc: 0.7927 - val_loss: 0.6929 - val_acc: 0.7749

Epoch 00007: val_loss improved from 0.81295 to 0.69288, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 8/60
 - 4s - loss: 0.5957 - acc: 0.8052 - val_loss: 0.7174 - val_acc: 0.7685

Epoch 00008: val_loss did not improve from 0.69288
Epoch 9/60
 - 4s - loss: 0.5591 - acc: 0.8157 - val_loss: 0.6796 - val_acc: 0.7646

Epoch 00009: val_loss improved from 0.69288 to 0.67960, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 10/60
 - 4s - loss: 0.5299 - acc: 0.8254 - val_loss: 0.6955 - val_acc: 0.7782

Epoch 00010: val_loss did not improve from 0.67960
Epoch 11/60
 - 4s - loss: 0.5077 - acc: 0.8326 - val_loss: 0.6561 - val_acc: 0.7836

Epoch 00011: val_loss improved from 0.67960 to 0.65614, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 12/60
 - 4s - loss: 0.4865 - acc: 0.8395 - val_loss: 0.5961 - val_acc: 0.8079

Epoch 00012: val_loss improved from 0.65614 to 0.59613, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 13/60
 - 4s - loss: 0.4632 - acc: 0.8469 - val_loss: 0.6039 - val_acc: 0.8049

Epoch 00013: val_loss did not improve from 0.59613
Epoch 14/60
 - 4s - loss: 0.4453 - acc: 0.8529 - val_loss: 0.6019 - val_acc: 0.8044

Epoch 00014: val_loss did not improve from 0.59613
Epoch 15/60
 - 4s - loss: 0.4318 - acc: 0.8567 - val_loss: 0.5879 - val_acc: 0.8044

Epoch 00015: val_loss improved from 0.59613 to 0.58795, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 16/60
 - 4s - loss: 0.4169 - acc: 0.8613 - val_loss: 0.6795 - val_acc: 0.7960

Epoch 00016: val_loss did not improve from 0.58795
Epoch 17/60
 - 4s - loss: 0.3988 - acc: 0.8687 - val_loss: 0.7092 - val_acc: 0.7867

Epoch 00017: val_loss did not improve from 0.58795
Epoch 18/60
 - 4s - loss: 0.3885 - acc: 0.8707 - val_loss: 0.6000 - val_acc: 0.8173

Epoch 00018: val_loss did not improve from 0.58795
Epoch 19/60
 - 4s - loss: 0.3747 - acc: 0.8749 - val_loss: 0.5966 - val_acc: 0.8120

Epoch 00019: val_loss did not improve from 0.58795
Epoch 20/60
 - 4s - loss: 0.3658 - acc: 0.8783 - val_loss: 0.5935 - val_acc: 0.8204

Epoch 00020: val_loss did not improve from 0.58795
Epoch 21/60
 - 4s - loss: 0.3556 - acc: 0.8811 - val_loss: 0.6247 - val_acc: 0.8207

Epoch 00021: val_loss did not improve from 0.58795
Epoch 22/60
 - 4s - loss: 0.3443 - acc: 0.8842 - val_loss: 0.5482 - val_acc: 0.8307

Epoch 00022: val_loss improved from 0.58795 to 0.54817, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.1.hdf5
Epoch 23/60
 - 4s - loss: 0.3347 - acc: 0.8876 - val_loss: 0.6272 - val_acc: 0.8144

Epoch 00023: val_loss did not improve from 0.54817
Epoch 24/60
 - 4s - loss: 0.3248 - acc: 0.8913 - val_loss: 0.6991 - val_acc: 0.8064

Epoch 00024: val_loss did not improve from 0.54817
Epoch 25/60
 - 4s - loss: 0.3172 - acc: 0.8948 - val_loss: 0.5769 - val_acc: 0.8257

Epoch 00025: val_loss did not improve from 0.54817
Epoch 26/60
 - 4s - loss: 0.3106 - acc: 0.8962 - val_loss: 0.6154 - val_acc: 0.8155

Epoch 00026: val_loss did not improve from 0.54817
Epoch 27/60
 - 4s - loss: 0.2999 - acc: 0.8991 - val_loss: 0.5774 - val_acc: 0.8291

Epoch 00027: val_loss did not improve from 0.54817
Epoch 28/60
 - 4s - loss: 0.2955 - acc: 0.9002 - val_loss: 0.5700 - val_acc: 0.8266

Epoch 00028: val_loss did not improve from 0.54817
Epoch 29/60
 - 4s - loss: 0.2855 - acc: 0.9031 - val_loss: 0.5704 - val_acc: 0.8404

Epoch 00029: val_loss did not improve from 0.54817
Epoch 30/60
 - 4s - loss: 0.2831 - acc: 0.9039 - val_loss: 0.5953 - val_acc: 0.8244

Epoch 00030: val_loss did not improve from 0.54817
Epoch 31/60
 - 4s - loss: 0.2712 - acc: 0.9086 - val_loss: 0.6021 - val_acc: 0.8360

Epoch 00031: val_loss did not improve from 0.54817
Epoch 32/60
 - 4s - loss: 0.2682 - acc: 0.9089 - val_loss: 0.6181 - val_acc: 0.8345

Epoch 00032: val_loss did not improve from 0.54817
Epoch 00032: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 6s - loss: 3.3552 - acc: 0.5485 - val_loss: 1.4171 - val_acc: 0.6503

Epoch 00001: val_loss improved from inf to 1.41711, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 2/60
 - 4s - loss: 1.0982 - acc: 0.6716 - val_loss: 0.9641 - val_acc: 0.7130

Epoch 00002: val_loss improved from 1.41711 to 0.96415, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 3/60
 - 4s - loss: 0.8013 - acc: 0.7463 - val_loss: 0.8166 - val_acc: 0.7229

Epoch 00003: val_loss improved from 0.96415 to 0.81663, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 4/60
 - 4s - loss: 0.6336 - acc: 0.7959 - val_loss: 0.7250 - val_acc: 0.7585

Epoch 00004: val_loss improved from 0.81663 to 0.72502, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 5/60
 - 4s - loss: 0.5447 - acc: 0.8252 - val_loss: 0.6492 - val_acc: 0.8030

Epoch 00005: val_loss improved from 0.72502 to 0.64923, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 6/60
 - 4s - loss: 0.4719 - acc: 0.8468 - val_loss: 0.6440 - val_acc: 0.8029

Epoch 00006: val_loss improved from 0.64923 to 0.64404, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 7/60
 - 4s - loss: 0.4232 - acc: 0.8619 - val_loss: 0.6064 - val_acc: 0.8214

Epoch 00007: val_loss improved from 0.64404 to 0.60641, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 8/60
 - 4s - loss: 0.3840 - acc: 0.8766 - val_loss: 0.5643 - val_acc: 0.8339

Epoch 00008: val_loss improved from 0.60641 to 0.56426, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 9/60
 - 4s - loss: 0.3454 - acc: 0.8885 - val_loss: 0.6289 - val_acc: 0.8051

Epoch 00009: val_loss did not improve from 0.56426
Epoch 10/60
 - 4s - loss: 0.3231 - acc: 0.8948 - val_loss: 0.5095 - val_acc: 0.8470

Epoch 00010: val_loss improved from 0.56426 to 0.50947, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 11/60
 - 4s - loss: 0.2954 - acc: 0.9044 - val_loss: 0.7556 - val_acc: 0.7701

Epoch 00011: val_loss did not improve from 0.50947
Epoch 12/60
 - 4s - loss: 0.2773 - acc: 0.9109 - val_loss: 0.5236 - val_acc: 0.8485

Epoch 00012: val_loss did not improve from 0.50947
Epoch 13/60
 - 4s - loss: 0.2562 - acc: 0.9167 - val_loss: 0.5097 - val_acc: 0.8525

Epoch 00013: val_loss did not improve from 0.50947
Epoch 14/60
 - 4s - loss: 0.2321 - acc: 0.9246 - val_loss: 0.6358 - val_acc: 0.8116

Epoch 00014: val_loss did not improve from 0.50947
Epoch 15/60
 - 4s - loss: 0.2162 - acc: 0.9298 - val_loss: 0.5230 - val_acc: 0.8528

Epoch 00015: val_loss did not improve from 0.50947
Epoch 16/60
 - 4s - loss: 0.2035 - acc: 0.9325 - val_loss: 0.5557 - val_acc: 0.8408

Epoch 00016: val_loss did not improve from 0.50947
Epoch 17/60
 - 4s - loss: 0.1896 - acc: 0.9370 - val_loss: 0.5640 - val_acc: 0.8536

Epoch 00017: val_loss did not improve from 0.50947
Epoch 18/60
 - 4s - loss: 0.1784 - acc: 0.9398 - val_loss: 0.5621 - val_acc: 0.8553

Epoch 00018: val_loss did not improve from 0.50947
Epoch 19/60
 - 4s - loss: 0.1577 - acc: 0.9482 - val_loss: 0.6111 - val_acc: 0.8467

Epoch 00019: val_loss did not improve from 0.50947
Epoch 20/60
 - 4s - loss: 0.1491 - acc: 0.9500 - val_loss: 0.5642 - val_acc: 0.8460

Epoch 00020: val_loss did not improve from 0.50947
Epoch 00020: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 5s - loss: 1.5262 - acc: 0.6308 - val_loss: 1.4150 - val_acc: 0.6212

Epoch 00001: val_loss improved from inf to 1.41496, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 2/60
 - 3s - loss: 1.3266 - acc: 0.6427 - val_loss: 1.3264 - val_acc: 0.6315

Epoch 00002: val_loss improved from 1.41496 to 1.32640, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 3/60
 - 3s - loss: 1.2275 - acc: 0.6556 - val_loss: 1.2081 - val_acc: 0.6475

Epoch 00003: val_loss improved from 1.32640 to 1.20814, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 4/60
 - 3s - loss: 1.1327 - acc: 0.6710 - val_loss: 1.1162 - val_acc: 0.6628

Epoch 00004: val_loss improved from 1.20814 to 1.11623, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 5/60
 - 3s - loss: 1.0577 - acc: 0.6851 - val_loss: 1.1011 - val_acc: 0.6681

Epoch 00005: val_loss improved from 1.11623 to 1.10113, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 6/60
 - 3s - loss: 1.0042 - acc: 0.6945 - val_loss: 1.0600 - val_acc: 0.6731

Epoch 00006: val_loss improved from 1.10113 to 1.06002, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 7/60
 - 3s - loss: 0.9520 - acc: 0.7071 - val_loss: 0.9828 - val_acc: 0.6965

Epoch 00007: val_loss improved from 1.06002 to 0.98280, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 8/60
 - 3s - loss: 0.9114 - acc: 0.7166 - val_loss: 0.9402 - val_acc: 0.7071

Epoch 00008: val_loss improved from 0.98280 to 0.94024, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 9/60
 - 3s - loss: 0.8752 - acc: 0.7255 - val_loss: 0.9299 - val_acc: 0.7036

Epoch 00009: val_loss improved from 0.94024 to 0.92992, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 10/60
 - 3s - loss: 0.8363 - acc: 0.7353 - val_loss: 0.8783 - val_acc: 0.7226

Epoch 00010: val_loss improved from 0.92992 to 0.87828, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 11/60
 - 3s - loss: 0.8046 - acc: 0.7438 - val_loss: 0.8465 - val_acc: 0.7343

Epoch 00011: val_loss improved from 0.87828 to 0.84652, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 12/60
 - 3s - loss: 0.7759 - acc: 0.7516 - val_loss: 0.8345 - val_acc: 0.7358

Epoch 00012: val_loss improved from 0.84652 to 0.83445, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 13/60
 - 3s - loss: 0.7524 - acc: 0.7593 - val_loss: 0.8223 - val_acc: 0.7377

Epoch 00013: val_loss improved from 0.83445 to 0.82228, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 14/60
 - 3s - loss: 0.7311 - acc: 0.7658 - val_loss: 0.7844 - val_acc: 0.7473

Epoch 00014: val_loss improved from 0.82228 to 0.78442, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 15/60
 - 3s - loss: 0.7081 - acc: 0.7722 - val_loss: 0.8088 - val_acc: 0.7360

Epoch 00015: val_loss did not improve from 0.78442
Epoch 16/60
 - 3s - loss: 0.6958 - acc: 0.7753 - val_loss: 0.7640 - val_acc: 0.7529

Epoch 00016: val_loss improved from 0.78442 to 0.76396, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 17/60
 - 3s - loss: 0.6776 - acc: 0.7815 - val_loss: 0.7984 - val_acc: 0.7361

Epoch 00017: val_loss did not improve from 0.76396
Epoch 18/60
 - 3s - loss: 0.6638 - acc: 0.7852 - val_loss: 0.7543 - val_acc: 0.7646

Epoch 00018: val_loss improved from 0.76396 to 0.75427, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 19/60
 - 3s - loss: 0.6529 - acc: 0.7912 - val_loss: 0.7247 - val_acc: 0.7567

Epoch 00019: val_loss improved from 0.75427 to 0.72467, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 20/60
 - 3s - loss: 0.6369 - acc: 0.7953 - val_loss: 0.7305 - val_acc: 0.7677

Epoch 00020: val_loss did not improve from 0.72467
Epoch 21/60
 - 3s - loss: 0.6285 - acc: 0.7969 - val_loss: 0.7758 - val_acc: 0.7417

Epoch 00021: val_loss did not improve from 0.72467
Epoch 22/60
 - 4s - loss: 0.6201 - acc: 0.8015 - val_loss: 0.7166 - val_acc: 0.7680

Epoch 00022: val_loss improved from 0.72467 to 0.71663, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 23/60
 - 4s - loss: 0.6098 - acc: 0.8031 - val_loss: 0.6847 - val_acc: 0.7823

Epoch 00023: val_loss improved from 0.71663 to 0.68469, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 24/60
 - 4s - loss: 0.5999 - acc: 0.8070 - val_loss: 0.7002 - val_acc: 0.7771

Epoch 00024: val_loss did not improve from 0.68469
Epoch 25/60
 - 3s - loss: 0.5909 - acc: 0.8092 - val_loss: 0.6768 - val_acc: 0.7830

Epoch 00025: val_loss improved from 0.68469 to 0.67680, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 26/60
 - 3s - loss: 0.5831 - acc: 0.8120 - val_loss: 0.6958 - val_acc: 0.7721

Epoch 00026: val_loss did not improve from 0.67680
Epoch 27/60
 - 4s - loss: 0.5762 - acc: 0.8139 - val_loss: 0.6997 - val_acc: 0.7732

Epoch 00027: val_loss did not improve from 0.67680
Epoch 28/60
 - 3s - loss: 0.5701 - acc: 0.8166 - val_loss: 0.6579 - val_acc: 0.7860

Epoch 00028: val_loss improved from 0.67680 to 0.65793, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 29/60
 - 3s - loss: 0.5597 - acc: 0.8194 - val_loss: 0.6577 - val_acc: 0.7889

Epoch 00029: val_loss improved from 0.65793 to 0.65773, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 30/60
 - 3s - loss: 0.5544 - acc: 0.8220 - val_loss: 0.6636 - val_acc: 0.7874

Epoch 00030: val_loss did not improve from 0.65773
Epoch 31/60
 - 3s - loss: 0.5472 - acc: 0.8249 - val_loss: 0.7110 - val_acc: 0.7776

Epoch 00031: val_loss did not improve from 0.65773
Epoch 32/60
 - 3s - loss: 0.5459 - acc: 0.8250 - val_loss: 0.6558 - val_acc: 0.7936

Epoch 00032: val_loss improved from 0.65773 to 0.65582, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 33/60
 - 3s - loss: 0.5342 - acc: 0.8295 - val_loss: 0.7184 - val_acc: 0.7674

Epoch 00033: val_loss did not improve from 0.65582
Epoch 34/60
 - 3s - loss: 0.5318 - acc: 0.8289 - val_loss: 0.6355 - val_acc: 0.8010

Epoch 00034: val_loss improved from 0.65582 to 0.63546, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 35/60
 - 3s - loss: 0.5245 - acc: 0.8316 - val_loss: 0.6394 - val_acc: 0.7955

Epoch 00035: val_loss did not improve from 0.63546
Epoch 36/60
 - 3s - loss: 0.5188 - acc: 0.8342 - val_loss: 0.7084 - val_acc: 0.7732

Epoch 00036: val_loss did not improve from 0.63546
Epoch 37/60
 - 3s - loss: 0.5165 - acc: 0.8327 - val_loss: 0.6734 - val_acc: 0.7848

Epoch 00037: val_loss did not improve from 0.63546
Epoch 38/60
 - 3s - loss: 0.5124 - acc: 0.8363 - val_loss: 0.6576 - val_acc: 0.7866

Epoch 00038: val_loss did not improve from 0.63546
Epoch 39/60
 - 3s - loss: 0.5048 - acc: 0.8375 - val_loss: 0.6506 - val_acc: 0.7970

Epoch 00039: val_loss did not improve from 0.63546
Epoch 40/60
 - 3s - loss: 0.5038 - acc: 0.8384 - val_loss: 0.6374 - val_acc: 0.8026

Epoch 00040: val_loss did not improve from 0.63546
Epoch 41/60
 - 3s - loss: 0.4982 - acc: 0.8391 - val_loss: 0.6402 - val_acc: 0.7967

Epoch 00041: val_loss did not improve from 0.63546
Epoch 42/60
 - 3s - loss: 0.4928 - acc: 0.8405 - val_loss: 0.6252 - val_acc: 0.7942

Epoch 00042: val_loss improved from 0.63546 to 0.62522, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 43/60
 - 3s - loss: 0.4879 - acc: 0.8425 - val_loss: 0.6810 - val_acc: 0.7892

Epoch 00043: val_loss did not improve from 0.62522
Epoch 44/60
 - 3s - loss: 0.4892 - acc: 0.8433 - val_loss: 0.5949 - val_acc: 0.8139

Epoch 00044: val_loss improved from 0.62522 to 0.59488, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 45/60
 - 3s - loss: 0.4818 - acc: 0.8459 - val_loss: 0.5992 - val_acc: 0.8045

Epoch 00045: val_loss did not improve from 0.59488
Epoch 46/60
 - 3s - loss: 0.4794 - acc: 0.8451 - val_loss: 0.7303 - val_acc: 0.7586

Epoch 00046: val_loss did not improve from 0.59488
Epoch 47/60
 - 3s - loss: 0.4771 - acc: 0.8470 - val_loss: 0.6242 - val_acc: 0.7944

Epoch 00047: val_loss did not improve from 0.59488
Epoch 48/60
 - 3s - loss: 0.4742 - acc: 0.8469 - val_loss: 0.5855 - val_acc: 0.8189

Epoch 00048: val_loss improved from 0.59488 to 0.58555, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 49/60
 - 3s - loss: 0.4694 - acc: 0.8490 - val_loss: 0.6137 - val_acc: 0.8147

Epoch 00049: val_loss did not improve from 0.58555
Epoch 50/60
 - 3s - loss: 0.4658 - acc: 0.8499 - val_loss: 0.5891 - val_acc: 0.8070

Epoch 00050: val_loss did not improve from 0.58555
Epoch 51/60
 - 3s - loss: 0.4625 - acc: 0.8509 - val_loss: 0.6004 - val_acc: 0.8076

Epoch 00051: val_loss did not improve from 0.58555
Epoch 52/60
 - 3s - loss: 0.4624 - acc: 0.8514 - val_loss: 0.5796 - val_acc: 0.8141

Epoch 00052: val_loss improved from 0.58555 to 0.57963, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 53/60
 - 3s - loss: 0.4583 - acc: 0.8529 - val_loss: 0.6242 - val_acc: 0.7996

Epoch 00053: val_loss did not improve from 0.57963
Epoch 54/60
 - 3s - loss: 0.4550 - acc: 0.8534 - val_loss: 0.6634 - val_acc: 0.7857

Epoch 00054: val_loss did not improve from 0.57963
Epoch 55/60
 - 3s - loss: 0.4536 - acc: 0.8547 - val_loss: 0.5790 - val_acc: 0.8173

Epoch 00055: val_loss improved from 0.57963 to 0.57904, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 56/60
 - 3s - loss: 0.4518 - acc: 0.8551 - val_loss: 0.5901 - val_acc: 0.8064

Epoch 00056: val_loss did not improve from 0.57904
Epoch 57/60
 - 3s - loss: 0.4466 - acc: 0.8561 - val_loss: 0.5717 - val_acc: 0.8216

Epoch 00057: val_loss improved from 0.57904 to 0.57167, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 58/60
 - 3s - loss: 0.4443 - acc: 0.8573 - val_loss: 0.6013 - val_acc: 0.8033

Epoch 00058: val_loss did not improve from 0.57167
Epoch 59/60
 - 3s - loss: 0.4427 - acc: 0.8571 - val_loss: 0.5690 - val_acc: 0.8236

Epoch 00059: val_loss improved from 0.57167 to 0.56902, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 60/60
 - 3s - loss: 0.4400 - acc: 0.8582 - val_loss: 0.5835 - val_acc: 0.8194

Epoch 00060: val_loss did not improve from 0.56902
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 6s - loss: 1.5395 - acc: 0.6139 - val_loss: 1.3339 - val_acc: 0.6174

Epoch 00001: val_loss improved from inf to 1.33389, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 2/60
 - 4s - loss: 1.1825 - acc: 0.6565 - val_loss: 1.1505 - val_acc: 0.6368

Epoch 00002: val_loss improved from 1.33389 to 1.15052, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 3/60
 - 4s - loss: 1.0062 - acc: 0.6883 - val_loss: 1.0216 - val_acc: 0.6614

Epoch 00003: val_loss improved from 1.15052 to 1.02164, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 4/60
 - 4s - loss: 0.8856 - acc: 0.7177 - val_loss: 0.9234 - val_acc: 0.6926

Epoch 00004: val_loss improved from 1.02164 to 0.92338, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 5/60
 - 4s - loss: 0.8038 - acc: 0.7415 - val_loss: 0.8607 - val_acc: 0.7132

Epoch 00005: val_loss improved from 0.92338 to 0.86070, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 6/60
 - 4s - loss: 0.7413 - acc: 0.7600 - val_loss: 0.7866 - val_acc: 0.7423

Epoch 00006: val_loss improved from 0.86070 to 0.78660, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 7/60
 - 4s - loss: 0.6854 - acc: 0.7772 - val_loss: 0.8362 - val_acc: 0.7329

Epoch 00007: val_loss did not improve from 0.78660
Epoch 8/60
 - 4s - loss: 0.6452 - acc: 0.7887 - val_loss: 0.7150 - val_acc: 0.7674

Epoch 00008: val_loss improved from 0.78660 to 0.71505, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 9/60
 - 4s - loss: 0.6072 - acc: 0.7992 - val_loss: 0.7720 - val_acc: 0.7558

Epoch 00009: val_loss did not improve from 0.71505
Epoch 10/60
 - 4s - loss: 0.5729 - acc: 0.8110 - val_loss: 0.7732 - val_acc: 0.7580

Epoch 00010: val_loss did not improve from 0.71505
Epoch 11/60
 - 4s - loss: 0.5434 - acc: 0.8219 - val_loss: 0.7632 - val_acc: 0.7677

Epoch 00011: val_loss did not improve from 0.71505
Epoch 12/60
 - 4s - loss: 0.5184 - acc: 0.8269 - val_loss: 0.6339 - val_acc: 0.7971

Epoch 00012: val_loss improved from 0.71505 to 0.63386, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 13/60
 - 4s - loss: 0.4938 - acc: 0.8365 - val_loss: 0.6022 - val_acc: 0.8024

Epoch 00013: val_loss improved from 0.63386 to 0.60220, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 14/60
 - 4s - loss: 0.4725 - acc: 0.8431 - val_loss: 0.5869 - val_acc: 0.8117

Epoch 00014: val_loss improved from 0.60220 to 0.58694, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 15/60
 - 4s - loss: 0.4466 - acc: 0.8538 - val_loss: 0.6706 - val_acc: 0.7945

Epoch 00015: val_loss did not improve from 0.58694
Epoch 16/60
 - 4s - loss: 0.4380 - acc: 0.8561 - val_loss: 0.5938 - val_acc: 0.8139

Epoch 00016: val_loss did not improve from 0.58694
Epoch 17/60
 - 4s - loss: 0.4164 - acc: 0.8617 - val_loss: 0.5739 - val_acc: 0.8116

Epoch 00017: val_loss improved from 0.58694 to 0.57394, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 18/60
 - 4s - loss: 0.4001 - acc: 0.8669 - val_loss: 0.6506 - val_acc: 0.8076

Epoch 00018: val_loss did not improve from 0.57394
Epoch 19/60
 - 4s - loss: 0.3862 - acc: 0.8708 - val_loss: 0.5696 - val_acc: 0.8245

Epoch 00019: val_loss improved from 0.57394 to 0.56957, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 20/60
 - 4s - loss: 0.3717 - acc: 0.8763 - val_loss: 0.5963 - val_acc: 0.8219

Epoch 00020: val_loss did not improve from 0.56957
Epoch 21/60
 - 4s - loss: 0.3642 - acc: 0.8782 - val_loss: 0.6331 - val_acc: 0.8158

Epoch 00021: val_loss did not improve from 0.56957
Epoch 22/60
 - 4s - loss: 0.3505 - acc: 0.8837 - val_loss: 0.5770 - val_acc: 0.8238

Epoch 00022: val_loss did not improve from 0.56957
Epoch 23/60
 - 4s - loss: 0.3420 - acc: 0.8876 - val_loss: 0.5438 - val_acc: 0.8342

Epoch 00023: val_loss improved from 0.56957 to 0.54380, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 24/60
 - 4s - loss: 0.3310 - acc: 0.8894 - val_loss: 0.5409 - val_acc: 0.8402

Epoch 00024: val_loss improved from 0.54380 to 0.54094, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 25/60
 - 4s - loss: 0.3216 - acc: 0.8935 - val_loss: 0.5351 - val_acc: 0.8308

Epoch 00025: val_loss improved from 0.54094 to 0.53514, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 26/60
 - 4s - loss: 0.3124 - acc: 0.8948 - val_loss: 0.5270 - val_acc: 0.8483

Epoch 00026: val_loss improved from 0.53514 to 0.52699, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 27/60
 - 4s - loss: 0.3042 - acc: 0.8976 - val_loss: 0.5234 - val_acc: 0.8422

Epoch 00027: val_loss improved from 0.52699 to 0.52342, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 28/60
 - 4s - loss: 0.2908 - acc: 0.9038 - val_loss: 0.6538 - val_acc: 0.8135

Epoch 00028: val_loss did not improve from 0.52342
Epoch 29/60
 - 4s - loss: 0.2895 - acc: 0.9030 - val_loss: 0.5138 - val_acc: 0.8452

Epoch 00029: val_loss improved from 0.52342 to 0.51381, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5
Epoch 30/60
 - 4s - loss: 0.2761 - acc: 0.9079 - val_loss: 0.6015 - val_acc: 0.8274

Epoch 00030: val_loss did not improve from 0.51381
Epoch 31/60
 - 4s - loss: 0.2689 - acc: 0.9093 - val_loss: 0.6774 - val_acc: 0.8120

Epoch 00031: val_loss did not improve from 0.51381
Epoch 32/60
 - 4s - loss: 0.2690 - acc: 0.9093 - val_loss: 0.5535 - val_acc: 0.8282

Epoch 00032: val_loss did not improve from 0.51381
Epoch 33/60
 - 4s - loss: 0.2599 - acc: 0.9115 - val_loss: 0.5628 - val_acc: 0.8298

Epoch 00033: val_loss did not improve from 0.51381
Epoch 34/60
 - 4s - loss: 0.2518 - acc: 0.9150 - val_loss: 0.5983 - val_acc: 0.8298

Epoch 00034: val_loss did not improve from 0.51381
Epoch 35/60
 - 4s - loss: 0.2462 - acc: 0.9173 - val_loss: 0.6259 - val_acc: 0.8126

Epoch 00035: val_loss did not improve from 0.51381
Epoch 36/60
 - 4s - loss: 0.2403 - acc: 0.9189 - val_loss: 0.5308 - val_acc: 0.8476

Epoch 00036: val_loss did not improve from 0.51381
Epoch 37/60
 - 4s - loss: 0.2332 - acc: 0.9203 - val_loss: 0.5820 - val_acc: 0.8495

Epoch 00037: val_loss did not improve from 0.51381
Epoch 38/60
 - 4s - loss: 0.2297 - acc: 0.9214 - val_loss: 0.6004 - val_acc: 0.8326

Epoch 00038: val_loss did not improve from 0.51381
Epoch 39/60
 - 4s - loss: 0.2191 - acc: 0.9256 - val_loss: 0.6124 - val_acc: 0.8442

Epoch 00039: val_loss did not improve from 0.51381
Epoch 00039: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 7s - loss: 3.0810 - acc: 0.5682 - val_loss: 1.2537 - val_acc: 0.6389

Epoch 00001: val_loss improved from inf to 1.25374, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 2/60
 - 5s - loss: 1.1945 - acc: 0.6515 - val_loss: 0.9392 - val_acc: 0.6948

Epoch 00002: val_loss improved from 1.25374 to 0.93924, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 3/60
 - 5s - loss: 0.9641 - acc: 0.7003 - val_loss: 0.7985 - val_acc: 0.7448

Epoch 00003: val_loss improved from 0.93924 to 0.79846, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 4/60
 - 5s - loss: 0.8232 - acc: 0.7390 - val_loss: 0.7829 - val_acc: 0.7383

Epoch 00004: val_loss improved from 0.79846 to 0.78293, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 5/60
 - 5s - loss: 0.7428 - acc: 0.7619 - val_loss: 0.6305 - val_acc: 0.7960

Epoch 00005: val_loss improved from 0.78293 to 0.63050, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 6/60
 - 5s - loss: 0.6766 - acc: 0.7838 - val_loss: 0.5572 - val_acc: 0.8182

Epoch 00006: val_loss improved from 0.63050 to 0.55723, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 7/60
 - 5s - loss: 0.6310 - acc: 0.7983 - val_loss: 0.5504 - val_acc: 0.8177

Epoch 00007: val_loss improved from 0.55723 to 0.55039, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 8/60
 - 5s - loss: 0.5896 - acc: 0.8122 - val_loss: 0.5313 - val_acc: 0.8314

Epoch 00008: val_loss improved from 0.55039 to 0.53128, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 9/60
 - 5s - loss: 0.5583 - acc: 0.8205 - val_loss: 0.5236 - val_acc: 0.8347

Epoch 00009: val_loss improved from 0.53128 to 0.52364, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 10/60
 - 5s - loss: 0.5388 - acc: 0.8254 - val_loss: 0.5007 - val_acc: 0.8448

Epoch 00010: val_loss improved from 0.52364 to 0.50069, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 11/60
 - 5s - loss: 0.5174 - acc: 0.8334 - val_loss: 0.5094 - val_acc: 0.8339

Epoch 00011: val_loss did not improve from 0.50069
Epoch 12/60
 - 5s - loss: 0.5003 - acc: 0.8378 - val_loss: 0.4616 - val_acc: 0.8589

Epoch 00012: val_loss improved from 0.50069 to 0.46157, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 13/60
 - 5s - loss: 0.4856 - acc: 0.8427 - val_loss: 0.4340 - val_acc: 0.8632

Epoch 00013: val_loss improved from 0.46157 to 0.43400, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 14/60
 - 5s - loss: 0.4698 - acc: 0.8481 - val_loss: 0.4424 - val_acc: 0.8626

Epoch 00014: val_loss did not improve from 0.43400
Epoch 15/60
 - 5s - loss: 0.4601 - acc: 0.8510 - val_loss: 0.4353 - val_acc: 0.8600

Epoch 00015: val_loss did not improve from 0.43400
Epoch 16/60
 - 5s - loss: 0.4447 - acc: 0.8550 - val_loss: 0.4257 - val_acc: 0.8680

Epoch 00016: val_loss improved from 0.43400 to 0.42570, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 17/60
 - 5s - loss: 0.4364 - acc: 0.8606 - val_loss: 0.4213 - val_acc: 0.8645

Epoch 00017: val_loss improved from 0.42570 to 0.42132, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 18/60
 - 5s - loss: 0.4300 - acc: 0.8604 - val_loss: 0.4530 - val_acc: 0.8604

Epoch 00018: val_loss did not improve from 0.42132
Epoch 19/60
 - 5s - loss: 0.4224 - acc: 0.8626 - val_loss: 0.4482 - val_acc: 0.8614

Epoch 00019: val_loss did not improve from 0.42132
Epoch 20/60
 - 5s - loss: 0.4179 - acc: 0.8649 - val_loss: 0.4126 - val_acc: 0.8719

Epoch 00020: val_loss improved from 0.42132 to 0.41258, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 21/60
 - 5s - loss: 0.4094 - acc: 0.8664 - val_loss: 0.4155 - val_acc: 0.8663

Epoch 00021: val_loss did not improve from 0.41258
Epoch 22/60
 - 5s - loss: 0.3983 - acc: 0.8711 - val_loss: 0.4151 - val_acc: 0.8692

Epoch 00022: val_loss did not improve from 0.41258
Epoch 23/60
 - 5s - loss: 0.3987 - acc: 0.8705 - val_loss: 0.4060 - val_acc: 0.8761

Epoch 00023: val_loss improved from 0.41258 to 0.40602, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 24/60
 - 5s - loss: 0.3913 - acc: 0.8729 - val_loss: 0.4065 - val_acc: 0.8719

Epoch 00024: val_loss did not improve from 0.40602
Epoch 25/60
 - 5s - loss: 0.3805 - acc: 0.8758 - val_loss: 0.3943 - val_acc: 0.8735

Epoch 00025: val_loss improved from 0.40602 to 0.39426, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 26/60
 - 5s - loss: 0.3811 - acc: 0.8745 - val_loss: 0.3962 - val_acc: 0.8781

Epoch 00026: val_loss did not improve from 0.39426
Epoch 27/60
 - 5s - loss: 0.3736 - acc: 0.8783 - val_loss: 0.3968 - val_acc: 0.8763

Epoch 00027: val_loss did not improve from 0.39426
Epoch 28/60
 - 5s - loss: 0.3706 - acc: 0.8780 - val_loss: 0.3785 - val_acc: 0.8832

Epoch 00028: val_loss improved from 0.39426 to 0.37853, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 29/60
 - 5s - loss: 0.3693 - acc: 0.8793 - val_loss: 0.4263 - val_acc: 0.8664

Epoch 00029: val_loss did not improve from 0.37853
Epoch 30/60
 - 5s - loss: 0.3600 - acc: 0.8815 - val_loss: 0.4139 - val_acc: 0.8736

Epoch 00030: val_loss did not improve from 0.37853
Epoch 31/60
 - 5s - loss: 0.3619 - acc: 0.8829 - val_loss: 0.3962 - val_acc: 0.8769

Epoch 00031: val_loss did not improve from 0.37853
Epoch 32/60
 - 5s - loss: 0.3538 - acc: 0.8844 - val_loss: 0.3942 - val_acc: 0.8753

Epoch 00032: val_loss did not improve from 0.37853
Epoch 33/60
 - 5s - loss: 0.3567 - acc: 0.8836 - val_loss: 0.3815 - val_acc: 0.8785

Epoch 00033: val_loss did not improve from 0.37853
Epoch 34/60
 - 5s - loss: 0.3522 - acc: 0.8854 - val_loss: 0.3945 - val_acc: 0.8783

Epoch 00034: val_loss did not improve from 0.37853
Epoch 35/60
 - 5s - loss: 0.3421 - acc: 0.8880 - val_loss: 0.4192 - val_acc: 0.8708

Epoch 00035: val_loss did not improve from 0.37853
Epoch 36/60
 - 5s - loss: 0.3435 - acc: 0.8869 - val_loss: 0.3897 - val_acc: 0.8785

Epoch 00036: val_loss did not improve from 0.37853
Epoch 37/60
 - 5s - loss: 0.3441 - acc: 0.8869 - val_loss: 0.4246 - val_acc: 0.8679

Epoch 00037: val_loss did not improve from 0.37853
Epoch 38/60
 - 5s - loss: 0.3388 - acc: 0.8908 - val_loss: 0.3764 - val_acc: 0.8810

Epoch 00038: val_loss improved from 0.37853 to 0.37641, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 39/60
 - 5s - loss: 0.3330 - acc: 0.8899 - val_loss: 0.3891 - val_acc: 0.8803

Epoch 00039: val_loss did not improve from 0.37641
Epoch 40/60
 - 5s - loss: 0.3365 - acc: 0.8880 - val_loss: 0.3903 - val_acc: 0.8763

Epoch 00040: val_loss did not improve from 0.37641
Epoch 41/60
 - 5s - loss: 0.3333 - acc: 0.8914 - val_loss: 0.3801 - val_acc: 0.8798

Epoch 00041: val_loss did not improve from 0.37641
Epoch 42/60
 - 5s - loss: 0.3288 - acc: 0.8904 - val_loss: 0.3744 - val_acc: 0.8822

Epoch 00042: val_loss improved from 0.37641 to 0.37436, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 43/60
 - 5s - loss: 0.3305 - acc: 0.8912 - val_loss: 0.3809 - val_acc: 0.8828

Epoch 00043: val_loss did not improve from 0.37436
Epoch 44/60
 - 5s - loss: 0.3293 - acc: 0.8916 - val_loss: 0.3969 - val_acc: 0.8741

Epoch 00044: val_loss did not improve from 0.37436
Epoch 45/60
 - 5s - loss: 0.3263 - acc: 0.8930 - val_loss: 0.3899 - val_acc: 0.8795

Epoch 00045: val_loss did not improve from 0.37436
Epoch 46/60
 - 5s - loss: 0.3247 - acc: 0.8923 - val_loss: 0.3770 - val_acc: 0.8817

Epoch 00046: val_loss did not improve from 0.37436
Epoch 47/60
 - 5s - loss: 0.3237 - acc: 0.8930 - val_loss: 0.3628 - val_acc: 0.8829

Epoch 00047: val_loss improved from 0.37436 to 0.36278, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 48/60
 - 5s - loss: 0.3210 - acc: 0.8942 - val_loss: 0.3847 - val_acc: 0.8804

Epoch 00048: val_loss did not improve from 0.36278
Epoch 49/60
 - 5s - loss: 0.3171 - acc: 0.8943 - val_loss: 0.3727 - val_acc: 0.8863

Epoch 00049: val_loss did not improve from 0.36278
Epoch 50/60
 - 5s - loss: 0.3181 - acc: 0.8946 - val_loss: 0.3890 - val_acc: 0.8820

Epoch 00050: val_loss did not improve from 0.36278
Epoch 51/60
 - 5s - loss: 0.3221 - acc: 0.8935 - val_loss: 0.3702 - val_acc: 0.8870

Epoch 00051: val_loss did not improve from 0.36278
Epoch 52/60
 - 5s - loss: 0.3079 - acc: 0.8975 - val_loss: 0.4062 - val_acc: 0.8756

Epoch 00052: val_loss did not improve from 0.36278
Epoch 53/60
 - 5s - loss: 0.3141 - acc: 0.8967 - val_loss: 0.3634 - val_acc: 0.8897

Epoch 00053: val_loss did not improve from 0.36278
Epoch 54/60
 - 5s - loss: 0.3107 - acc: 0.8985 - val_loss: 0.3715 - val_acc: 0.8847

Epoch 00054: val_loss did not improve from 0.36278
Epoch 55/60
 - 5s - loss: 0.3071 - acc: 0.8979 - val_loss: 0.3775 - val_acc: 0.8863

Epoch 00055: val_loss did not improve from 0.36278
Epoch 56/60
 - 5s - loss: 0.3130 - acc: 0.8961 - val_loss: 0.3653 - val_acc: 0.8894

Epoch 00056: val_loss did not improve from 0.36278
Epoch 57/60
 - 5s - loss: 0.3070 - acc: 0.8992 - val_loss: 0.3618 - val_acc: 0.8901

Epoch 00057: val_loss improved from 0.36278 to 0.36178, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5
Epoch 58/60
 - 5s - loss: 0.3075 - acc: 0.8997 - val_loss: 0.3662 - val_acc: 0.8866

Epoch 00058: val_loss did not improve from 0.36178
Epoch 59/60
 - 5s - loss: 0.3026 - acc: 0.9001 - val_loss: 0.3624 - val_acc: 0.8889

Epoch 00059: val_loss did not improve from 0.36178
Epoch 60/60
 - 5s - loss: 0.3061 - acc: 0.8989 - val_loss: 0.4033 - val_acc: 0.8776

Epoch 00060: val_loss did not improve from 0.36178
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 7s - loss: 2.3135 - acc: 0.5049 - val_loss: 1.8079 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 1.80791, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 2/60
 - 4s - loss: 1.6166 - acc: 0.6312 - val_loss: 1.5794 - val_acc: 0.6209

Epoch 00002: val_loss improved from 1.80791 to 1.57940, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 3/60
 - 4s - loss: 1.5197 - acc: 0.6367 - val_loss: 1.5020 - val_acc: 0.6209

Epoch 00003: val_loss improved from 1.57940 to 1.50200, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 4/60
 - 4s - loss: 1.4793 - acc: 0.6370 - val_loss: 1.4460 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.50200 to 1.44604, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 5/60
 - 4s - loss: 1.4546 - acc: 0.6371 - val_loss: 1.4399 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.44604 to 1.43993, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 6/60
 - 4s - loss: 1.4310 - acc: 0.6371 - val_loss: 1.4102 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.43993 to 1.41025, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 7/60
 - 4s - loss: 1.4120 - acc: 0.6370 - val_loss: 1.4056 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.41025 to 1.40558, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 8/60
 - 4s - loss: 1.3917 - acc: 0.6371 - val_loss: 1.3624 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.40558 to 1.36241, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 9/60
 - 4s - loss: 1.3595 - acc: 0.6379 - val_loss: 1.3086 - val_acc: 0.6234

Epoch 00009: val_loss improved from 1.36241 to 1.30860, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 10/60
 - 4s - loss: 1.3282 - acc: 0.6391 - val_loss: 1.2493 - val_acc: 0.6296

Epoch 00010: val_loss improved from 1.30860 to 1.24926, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 11/60
 - 4s - loss: 1.2966 - acc: 0.6420 - val_loss: 1.2280 - val_acc: 0.6371

Epoch 00011: val_loss improved from 1.24926 to 1.22798, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 12/60
 - 4s - loss: 1.2678 - acc: 0.6428 - val_loss: 1.1901 - val_acc: 0.6405

Epoch 00012: val_loss improved from 1.22798 to 1.19010, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 13/60
 - 4s - loss: 1.2422 - acc: 0.6454 - val_loss: 1.1798 - val_acc: 0.6356

Epoch 00013: val_loss improved from 1.19010 to 1.17978, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 14/60
 - 4s - loss: 1.2282 - acc: 0.6466 - val_loss: 1.1752 - val_acc: 0.6434

Epoch 00014: val_loss improved from 1.17978 to 1.17523, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 15/60
 - 4s - loss: 1.2126 - acc: 0.6478 - val_loss: 1.1233 - val_acc: 0.6468

Epoch 00015: val_loss improved from 1.17523 to 1.12331, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 16/60
 - 4s - loss: 1.1983 - acc: 0.6504 - val_loss: 1.1507 - val_acc: 0.6447

Epoch 00016: val_loss did not improve from 1.12331
Epoch 17/60
 - 4s - loss: 1.1871 - acc: 0.6520 - val_loss: 1.1243 - val_acc: 0.6461

Epoch 00017: val_loss did not improve from 1.12331
Epoch 18/60
 - 4s - loss: 1.1732 - acc: 0.6525 - val_loss: 1.0878 - val_acc: 0.6496

Epoch 00018: val_loss improved from 1.12331 to 1.08780, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 19/60
 - 4s - loss: 1.1574 - acc: 0.6548 - val_loss: 1.0927 - val_acc: 0.6515

Epoch 00019: val_loss did not improve from 1.08780
Epoch 20/60
 - 4s - loss: 1.1538 - acc: 0.6551 - val_loss: 1.0741 - val_acc: 0.6577

Epoch 00020: val_loss improved from 1.08780 to 1.07406, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 21/60
 - 4s - loss: 1.1471 - acc: 0.6540 - val_loss: 1.0584 - val_acc: 0.6552

Epoch 00021: val_loss improved from 1.07406 to 1.05840, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 22/60
 - 4s - loss: 1.1357 - acc: 0.6567 - val_loss: 1.0570 - val_acc: 0.6531

Epoch 00022: val_loss improved from 1.05840 to 1.05705, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 23/60
 - 4s - loss: 1.1281 - acc: 0.6566 - val_loss: 1.0350 - val_acc: 0.6539

Epoch 00023: val_loss improved from 1.05705 to 1.03499, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 24/60
 - 4s - loss: 1.1210 - acc: 0.6574 - val_loss: 1.0297 - val_acc: 0.6530

Epoch 00024: val_loss improved from 1.03499 to 1.02975, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 25/60
 - 4s - loss: 1.1091 - acc: 0.6611 - val_loss: 1.0279 - val_acc: 0.6623

Epoch 00025: val_loss improved from 1.02975 to 1.02792, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 26/60
 - 4s - loss: 1.1050 - acc: 0.6623 - val_loss: 0.9978 - val_acc: 0.6711

Epoch 00026: val_loss improved from 1.02792 to 0.99785, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 27/60
 - 4s - loss: 1.0985 - acc: 0.6643 - val_loss: 1.0038 - val_acc: 0.6712

Epoch 00027: val_loss did not improve from 0.99785
Epoch 28/60
 - 4s - loss: 1.0902 - acc: 0.6632 - val_loss: 0.9902 - val_acc: 0.6650

Epoch 00028: val_loss improved from 0.99785 to 0.99020, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 29/60
 - 4s - loss: 1.0841 - acc: 0.6629 - val_loss: 0.9898 - val_acc: 0.6589

Epoch 00029: val_loss improved from 0.99020 to 0.98985, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 30/60
 - 4s - loss: 1.0765 - acc: 0.6654 - val_loss: 0.9758 - val_acc: 0.6656

Epoch 00030: val_loss improved from 0.98985 to 0.97581, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 31/60
 - 4s - loss: 1.0700 - acc: 0.6683 - val_loss: 0.9660 - val_acc: 0.6784

Epoch 00031: val_loss improved from 0.97581 to 0.96603, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 32/60
 - 4s - loss: 1.0665 - acc: 0.6673 - val_loss: 0.9807 - val_acc: 0.6773

Epoch 00032: val_loss did not improve from 0.96603
Epoch 33/60
 - 4s - loss: 1.0595 - acc: 0.6687 - val_loss: 0.9302 - val_acc: 0.6828

Epoch 00033: val_loss improved from 0.96603 to 0.93025, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 34/60
 - 4s - loss: 1.0525 - acc: 0.6692 - val_loss: 0.9387 - val_acc: 0.6745

Epoch 00034: val_loss did not improve from 0.93025
Epoch 35/60
 - 4s - loss: 1.0435 - acc: 0.6716 - val_loss: 0.9252 - val_acc: 0.6814

Epoch 00035: val_loss improved from 0.93025 to 0.92516, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 36/60
 - 4s - loss: 1.0429 - acc: 0.6723 - val_loss: 0.9053 - val_acc: 0.6826

Epoch 00036: val_loss improved from 0.92516 to 0.90526, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 37/60
 - 4s - loss: 1.0333 - acc: 0.6739 - val_loss: 0.9104 - val_acc: 0.6848

Epoch 00037: val_loss did not improve from 0.90526
Epoch 38/60
 - 4s - loss: 1.0289 - acc: 0.6750 - val_loss: 0.9113 - val_acc: 0.6918

Epoch 00038: val_loss did not improve from 0.90526
Epoch 39/60
 - 4s - loss: 1.0268 - acc: 0.6757 - val_loss: 0.8983 - val_acc: 0.6858

Epoch 00039: val_loss improved from 0.90526 to 0.89827, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 40/60
 - 4s - loss: 1.0236 - acc: 0.6774 - val_loss: 0.8873 - val_acc: 0.6883

Epoch 00040: val_loss improved from 0.89827 to 0.88725, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 41/60
 - 5s - loss: 1.0180 - acc: 0.6755 - val_loss: 0.8833 - val_acc: 0.6946

Epoch 00041: val_loss improved from 0.88725 to 0.88332, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 42/60
 - 4s - loss: 1.0139 - acc: 0.6799 - val_loss: 0.8687 - val_acc: 0.6868

Epoch 00042: val_loss improved from 0.88332 to 0.86870, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 43/60
 - 4s - loss: 1.0108 - acc: 0.6794 - val_loss: 0.8757 - val_acc: 0.6949

Epoch 00043: val_loss did not improve from 0.86870
Epoch 44/60
 - 4s - loss: 1.0048 - acc: 0.6802 - val_loss: 0.8536 - val_acc: 0.6971

Epoch 00044: val_loss improved from 0.86870 to 0.85356, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 45/60
 - 4s - loss: 1.0059 - acc: 0.6804 - val_loss: 0.8518 - val_acc: 0.7014

Epoch 00045: val_loss improved from 0.85356 to 0.85183, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 46/60
 - 4s - loss: 1.0007 - acc: 0.6814 - val_loss: 0.8546 - val_acc: 0.6976

Epoch 00046: val_loss did not improve from 0.85183
Epoch 47/60
 - 4s - loss: 0.9983 - acc: 0.6822 - val_loss: 0.8358 - val_acc: 0.7030

Epoch 00047: val_loss improved from 0.85183 to 0.83579, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 48/60
 - 4s - loss: 0.9939 - acc: 0.6842 - val_loss: 0.8509 - val_acc: 0.6977

Epoch 00048: val_loss did not improve from 0.83579
Epoch 49/60
 - 4s - loss: 0.9825 - acc: 0.6850 - val_loss: 0.8439 - val_acc: 0.7121

Epoch 00049: val_loss did not improve from 0.83579
Epoch 50/60
 - 4s - loss: 0.9864 - acc: 0.6843 - val_loss: 0.8237 - val_acc: 0.7105

Epoch 00050: val_loss improved from 0.83579 to 0.82365, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 51/60
 - 4s - loss: 0.9824 - acc: 0.6856 - val_loss: 0.8354 - val_acc: 0.7162

Epoch 00051: val_loss did not improve from 0.82365
Epoch 52/60
 - 4s - loss: 0.9721 - acc: 0.6888 - val_loss: 0.8142 - val_acc: 0.7092

Epoch 00052: val_loss improved from 0.82365 to 0.81422, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 53/60
 - 4s - loss: 0.9716 - acc: 0.6868 - val_loss: 0.8038 - val_acc: 0.7164

Epoch 00053: val_loss improved from 0.81422 to 0.80376, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 54/60
 - 4s - loss: 0.9711 - acc: 0.6883 - val_loss: 0.8083 - val_acc: 0.7159

Epoch 00054: val_loss did not improve from 0.80376
Epoch 55/60
 - 4s - loss: 0.9606 - acc: 0.6901 - val_loss: 0.7987 - val_acc: 0.7209

Epoch 00055: val_loss improved from 0.80376 to 0.79869, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 56/60
 - 4s - loss: 0.9660 - acc: 0.6886 - val_loss: 0.8093 - val_acc: 0.7173

Epoch 00056: val_loss did not improve from 0.79869
Epoch 57/60
 - 4s - loss: 0.9596 - acc: 0.6909 - val_loss: 0.7962 - val_acc: 0.7209

Epoch 00057: val_loss improved from 0.79869 to 0.79619, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5
Epoch 58/60
 - 4s - loss: 0.9609 - acc: 0.6908 - val_loss: 0.8128 - val_acc: 0.7254

Epoch 00058: val_loss did not improve from 0.79619
Epoch 59/60
 - 4s - loss: 0.9550 - acc: 0.6920 - val_loss: 0.7983 - val_acc: 0.7229

Epoch 00059: val_loss did not improve from 0.79619
Epoch 60/60
 - 4s - loss: 0.9540 - acc: 0.6917 - val_loss: 0.8071 - val_acc: 0.7258

Epoch 00060: val_loss did not improve from 0.79619
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 1.8402 - acc: 0.5889 - val_loss: 1.6504 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 1.65037, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 2/60
 - 5s - loss: 1.4329 - acc: 0.6361 - val_loss: 1.4090 - val_acc: 0.6255

Epoch 00002: val_loss improved from 1.65037 to 1.40901, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 3/60
 - 5s - loss: 1.3235 - acc: 0.6412 - val_loss: 1.2583 - val_acc: 0.6483

Epoch 00003: val_loss improved from 1.40901 to 1.25830, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 4/60
 - 5s - loss: 1.2442 - acc: 0.6485 - val_loss: 1.2235 - val_acc: 0.6612

Epoch 00004: val_loss improved from 1.25830 to 1.22350, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 5/60
 - 5s - loss: 1.1927 - acc: 0.6549 - val_loss: 1.1617 - val_acc: 0.6650

Epoch 00005: val_loss improved from 1.22350 to 1.16170, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 6/60
 - 5s - loss: 1.1546 - acc: 0.6616 - val_loss: 1.0600 - val_acc: 0.6671

Epoch 00006: val_loss improved from 1.16170 to 1.05996, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 7/60
 - 6s - loss: 1.1149 - acc: 0.6668 - val_loss: 1.0287 - val_acc: 0.6781

Epoch 00007: val_loss improved from 1.05996 to 1.02873, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 8/60
 - 5s - loss: 1.0807 - acc: 0.6716 - val_loss: 1.0090 - val_acc: 0.6843

Epoch 00008: val_loss improved from 1.02873 to 1.00903, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 9/60
 - 5s - loss: 1.0564 - acc: 0.6748 - val_loss: 0.9858 - val_acc: 0.6876

Epoch 00009: val_loss improved from 1.00903 to 0.98578, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 10/60
 - 5s - loss: 1.0321 - acc: 0.6782 - val_loss: 0.9166 - val_acc: 0.6887

Epoch 00010: val_loss improved from 0.98578 to 0.91665, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 11/60
 - 5s - loss: 1.0081 - acc: 0.6825 - val_loss: 0.8755 - val_acc: 0.7023

Epoch 00011: val_loss improved from 0.91665 to 0.87549, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 12/60
 - 6s - loss: 0.9822 - acc: 0.6880 - val_loss: 0.8313 - val_acc: 0.7073

Epoch 00012: val_loss improved from 0.87549 to 0.83132, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 13/60
 - 5s - loss: 0.9595 - acc: 0.6922 - val_loss: 0.8595 - val_acc: 0.7183

Epoch 00013: val_loss did not improve from 0.83132
Epoch 14/60
 - 5s - loss: 0.9452 - acc: 0.6966 - val_loss: 0.8301 - val_acc: 0.7246

Epoch 00014: val_loss improved from 0.83132 to 0.83010, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 15/60
 - 5s - loss: 0.9267 - acc: 0.7029 - val_loss: 0.7677 - val_acc: 0.7317

Epoch 00015: val_loss improved from 0.83010 to 0.76773, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 16/60
 - 5s - loss: 0.9010 - acc: 0.7072 - val_loss: 0.7556 - val_acc: 0.7501

Epoch 00016: val_loss improved from 0.76773 to 0.75556, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 17/60
 - 5s - loss: 0.8882 - acc: 0.7131 - val_loss: 0.7396 - val_acc: 0.7567

Epoch 00017: val_loss improved from 0.75556 to 0.73956, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 18/60
 - 5s - loss: 0.8685 - acc: 0.7171 - val_loss: 0.7402 - val_acc: 0.7571

Epoch 00018: val_loss did not improve from 0.73956
Epoch 19/60
 - 6s - loss: 0.8554 - acc: 0.7201 - val_loss: 0.7128 - val_acc: 0.7692

Epoch 00019: val_loss improved from 0.73956 to 0.71280, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 20/60
 - 5s - loss: 0.8406 - acc: 0.7244 - val_loss: 0.6911 - val_acc: 0.7711

Epoch 00020: val_loss improved from 0.71280 to 0.69108, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 21/60
 - 5s - loss: 0.8276 - acc: 0.7284 - val_loss: 0.6570 - val_acc: 0.7767

Epoch 00021: val_loss improved from 0.69108 to 0.65696, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 22/60
 - 5s - loss: 0.8146 - acc: 0.7361 - val_loss: 0.6569 - val_acc: 0.7855

Epoch 00022: val_loss improved from 0.65696 to 0.65686, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 23/60
 - 5s - loss: 0.8082 - acc: 0.7372 - val_loss: 0.6419 - val_acc: 0.7771

Epoch 00023: val_loss improved from 0.65686 to 0.64188, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 24/60
 - 6s - loss: 0.7953 - acc: 0.7410 - val_loss: 0.6360 - val_acc: 0.7920

Epoch 00024: val_loss improved from 0.64188 to 0.63597, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 25/60
 - 5s - loss: 0.7869 - acc: 0.7440 - val_loss: 0.6187 - val_acc: 0.7967

Epoch 00025: val_loss improved from 0.63597 to 0.61874, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 26/60
 - 5s - loss: 0.7799 - acc: 0.7460 - val_loss: 0.6086 - val_acc: 0.7963

Epoch 00026: val_loss improved from 0.61874 to 0.60861, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 27/60
 - 5s - loss: 0.7661 - acc: 0.7484 - val_loss: 0.5987 - val_acc: 0.8004

Epoch 00027: val_loss improved from 0.60861 to 0.59868, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 28/60
 - 6s - loss: 0.7609 - acc: 0.7504 - val_loss: 0.6068 - val_acc: 0.7960

Epoch 00028: val_loss did not improve from 0.59868
Epoch 29/60
 - 5s - loss: 0.7546 - acc: 0.7534 - val_loss: 0.6076 - val_acc: 0.8013

Epoch 00029: val_loss did not improve from 0.59868
Epoch 30/60
 - 5s - loss: 0.7451 - acc: 0.7560 - val_loss: 0.5879 - val_acc: 0.8026

Epoch 00030: val_loss improved from 0.59868 to 0.58791, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 31/60
 - 5s - loss: 0.7417 - acc: 0.7551 - val_loss: 0.5823 - val_acc: 0.8008

Epoch 00031: val_loss improved from 0.58791 to 0.58234, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 32/60
 - 5s - loss: 0.7376 - acc: 0.7598 - val_loss: 0.5581 - val_acc: 0.8172

Epoch 00032: val_loss improved from 0.58234 to 0.55814, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 33/60
 - 5s - loss: 0.7295 - acc: 0.7610 - val_loss: 0.5634 - val_acc: 0.8124

Epoch 00033: val_loss did not improve from 0.55814
Epoch 34/60
 - 5s - loss: 0.7235 - acc: 0.7646 - val_loss: 0.5565 - val_acc: 0.8130

Epoch 00034: val_loss improved from 0.55814 to 0.55646, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 35/60
 - 5s - loss: 0.7177 - acc: 0.7630 - val_loss: 0.5597 - val_acc: 0.8099

Epoch 00035: val_loss did not improve from 0.55646
Epoch 36/60
 - 5s - loss: 0.7139 - acc: 0.7682 - val_loss: 0.5602 - val_acc: 0.8073

Epoch 00036: val_loss did not improve from 0.55646
Epoch 37/60
 - 5s - loss: 0.7111 - acc: 0.7680 - val_loss: 0.5433 - val_acc: 0.8173

Epoch 00037: val_loss improved from 0.55646 to 0.54330, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 38/60
 - 6s - loss: 0.7069 - acc: 0.7683 - val_loss: 0.5502 - val_acc: 0.8197

Epoch 00038: val_loss did not improve from 0.54330
Epoch 39/60
 - 5s - loss: 0.6998 - acc: 0.7705 - val_loss: 0.5463 - val_acc: 0.8202

Epoch 00039: val_loss did not improve from 0.54330
Epoch 40/60
 - 5s - loss: 0.7008 - acc: 0.7710 - val_loss: 0.5487 - val_acc: 0.8199

Epoch 00040: val_loss did not improve from 0.54330
Epoch 41/60
 - 5s - loss: 0.6986 - acc: 0.7725 - val_loss: 0.5370 - val_acc: 0.8238

Epoch 00041: val_loss improved from 0.54330 to 0.53697, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 42/60
 - 5s - loss: 0.6901 - acc: 0.7739 - val_loss: 0.5292 - val_acc: 0.8244

Epoch 00042: val_loss improved from 0.53697 to 0.52920, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 43/60
 - 5s - loss: 0.6882 - acc: 0.7756 - val_loss: 0.5307 - val_acc: 0.8204

Epoch 00043: val_loss did not improve from 0.52920
Epoch 44/60
 - 5s - loss: 0.6867 - acc: 0.7752 - val_loss: 0.5169 - val_acc: 0.8280

Epoch 00044: val_loss improved from 0.52920 to 0.51685, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 45/60
 - 5s - loss: 0.6828 - acc: 0.7779 - val_loss: 0.5186 - val_acc: 0.8270

Epoch 00045: val_loss did not improve from 0.51685
Epoch 46/60
 - 5s - loss: 0.6830 - acc: 0.7756 - val_loss: 0.5361 - val_acc: 0.8280

Epoch 00046: val_loss did not improve from 0.51685
Epoch 47/60
 - 5s - loss: 0.6742 - acc: 0.7786 - val_loss: 0.5184 - val_acc: 0.8345

Epoch 00047: val_loss did not improve from 0.51685
Epoch 48/60
 - 5s - loss: 0.6730 - acc: 0.7803 - val_loss: 0.5587 - val_acc: 0.8151

Epoch 00048: val_loss did not improve from 0.51685
Epoch 49/60
 - 5s - loss: 0.6690 - acc: 0.7801 - val_loss: 0.5031 - val_acc: 0.8354

Epoch 00049: val_loss improved from 0.51685 to 0.50310, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 50/60
 - 5s - loss: 0.6680 - acc: 0.7809 - val_loss: 0.5316 - val_acc: 0.8308

Epoch 00050: val_loss did not improve from 0.50310
Epoch 51/60
 - 5s - loss: 0.6634 - acc: 0.7818 - val_loss: 0.5210 - val_acc: 0.8329

Epoch 00051: val_loss did not improve from 0.50310
Epoch 52/60
 - 5s - loss: 0.6635 - acc: 0.7822 - val_loss: 0.5069 - val_acc: 0.8329

Epoch 00052: val_loss did not improve from 0.50310
Epoch 53/60
 - 5s - loss: 0.6613 - acc: 0.7848 - val_loss: 0.5002 - val_acc: 0.8395

Epoch 00053: val_loss improved from 0.50310 to 0.50020, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 54/60
 - 5s - loss: 0.6597 - acc: 0.7862 - val_loss: 0.4916 - val_acc: 0.8342

Epoch 00054: val_loss improved from 0.50020 to 0.49158, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 55/60
 - 5s - loss: 0.6557 - acc: 0.7861 - val_loss: 0.4984 - val_acc: 0.8370

Epoch 00055: val_loss did not improve from 0.49158
Epoch 56/60
 - 5s - loss: 0.6601 - acc: 0.7841 - val_loss: 0.4992 - val_acc: 0.8345

Epoch 00056: val_loss did not improve from 0.49158
Epoch 57/60
 - 5s - loss: 0.6544 - acc: 0.7884 - val_loss: 0.4929 - val_acc: 0.8364

Epoch 00057: val_loss did not improve from 0.49158
Epoch 58/60
 - 5s - loss: 0.6531 - acc: 0.7885 - val_loss: 0.4903 - val_acc: 0.8385

Epoch 00058: val_loss improved from 0.49158 to 0.49028, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 59/60
 - 6s - loss: 0.6450 - acc: 0.7911 - val_loss: 0.4796 - val_acc: 0.8397

Epoch 00059: val_loss improved from 0.49028 to 0.47963, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5
Epoch 60/60
 - 5s - loss: 0.6522 - acc: 0.7878 - val_loss: 0.4852 - val_acc: 0.8395

Epoch 00060: val_loss did not improve from 0.47963
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 7s - loss: 1.9986 - acc: 0.5823 - val_loss: 1.2149 - val_acc: 0.6478

Epoch 00001: val_loss improved from inf to 1.21487, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 2/60
 - 5s - loss: 1.0952 - acc: 0.6712 - val_loss: 0.8947 - val_acc: 0.7039

Epoch 00002: val_loss improved from 1.21487 to 0.89474, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 3/60
 - 5s - loss: 0.9084 - acc: 0.7165 - val_loss: 0.7540 - val_acc: 0.7470

Epoch 00003: val_loss improved from 0.89474 to 0.75398, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 4/60
 - 5s - loss: 0.7924 - acc: 0.7496 - val_loss: 0.6610 - val_acc: 0.7905

Epoch 00004: val_loss improved from 0.75398 to 0.66100, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 5/60
 - 5s - loss: 0.7136 - acc: 0.7731 - val_loss: 0.5747 - val_acc: 0.8186

Epoch 00005: val_loss improved from 0.66100 to 0.57473, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 6/60
 - 5s - loss: 0.6511 - acc: 0.7907 - val_loss: 0.5651 - val_acc: 0.8220

Epoch 00006: val_loss improved from 0.57473 to 0.56512, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 7/60
 - 5s - loss: 0.6094 - acc: 0.8056 - val_loss: 0.5365 - val_acc: 0.8260

Epoch 00007: val_loss improved from 0.56512 to 0.53655, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 8/60
 - 5s - loss: 0.5694 - acc: 0.8160 - val_loss: 0.5621 - val_acc: 0.8182

Epoch 00008: val_loss did not improve from 0.53655
Epoch 9/60
 - 5s - loss: 0.5471 - acc: 0.8261 - val_loss: 0.5378 - val_acc: 0.8229

Epoch 00009: val_loss did not improve from 0.53655
Epoch 10/60
 - 5s - loss: 0.5289 - acc: 0.8300 - val_loss: 0.4967 - val_acc: 0.8447

Epoch 00010: val_loss improved from 0.53655 to 0.49671, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 11/60
 - 5s - loss: 0.5059 - acc: 0.8384 - val_loss: 0.4800 - val_acc: 0.8501

Epoch 00011: val_loss improved from 0.49671 to 0.47997, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 12/60
 - 5s - loss: 0.4825 - acc: 0.8450 - val_loss: 0.4496 - val_acc: 0.8576

Epoch 00012: val_loss improved from 0.47997 to 0.44959, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 13/60
 - 5s - loss: 0.4735 - acc: 0.8489 - val_loss: 0.4460 - val_acc: 0.8589

Epoch 00013: val_loss improved from 0.44959 to 0.44602, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 14/60
 - 5s - loss: 0.4683 - acc: 0.8498 - val_loss: 0.4520 - val_acc: 0.8594

Epoch 00014: val_loss did not improve from 0.44602
Epoch 15/60
 - 5s - loss: 0.4465 - acc: 0.8564 - val_loss: 0.4384 - val_acc: 0.8632

Epoch 00015: val_loss improved from 0.44602 to 0.43838, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 16/60
 - 5s - loss: 0.4349 - acc: 0.8602 - val_loss: 0.4256 - val_acc: 0.8679

Epoch 00016: val_loss improved from 0.43838 to 0.42560, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 17/60
 - 5s - loss: 0.4239 - acc: 0.8623 - val_loss: 0.4081 - val_acc: 0.8736

Epoch 00017: val_loss improved from 0.42560 to 0.40812, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 18/60
 - 5s - loss: 0.4168 - acc: 0.8661 - val_loss: 0.4328 - val_acc: 0.8655

Epoch 00018: val_loss did not improve from 0.40812
Epoch 19/60
 - 5s - loss: 0.4130 - acc: 0.8677 - val_loss: 0.4086 - val_acc: 0.8745

Epoch 00019: val_loss did not improve from 0.40812
Epoch 20/60
 - 5s - loss: 0.3973 - acc: 0.8709 - val_loss: 0.4121 - val_acc: 0.8723

Epoch 00020: val_loss did not improve from 0.40812
Epoch 21/60
 - 5s - loss: 0.4005 - acc: 0.8708 - val_loss: 0.4006 - val_acc: 0.8760

Epoch 00021: val_loss improved from 0.40812 to 0.40058, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 22/60
 - 5s - loss: 0.3897 - acc: 0.8736 - val_loss: 0.3843 - val_acc: 0.8785

Epoch 00022: val_loss improved from 0.40058 to 0.38427, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 23/60
 - 5s - loss: 0.3861 - acc: 0.8743 - val_loss: 0.3949 - val_acc: 0.8778

Epoch 00023: val_loss did not improve from 0.38427
Epoch 24/60
 - 5s - loss: 0.3785 - acc: 0.8775 - val_loss: 0.4389 - val_acc: 0.8620

Epoch 00024: val_loss did not improve from 0.38427
Epoch 25/60
 - 5s - loss: 0.3820 - acc: 0.8754 - val_loss: 0.3718 - val_acc: 0.8845

Epoch 00025: val_loss improved from 0.38427 to 0.37178, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 26/60
 - 5s - loss: 0.3698 - acc: 0.8792 - val_loss: 0.3838 - val_acc: 0.8816

Epoch 00026: val_loss did not improve from 0.37178
Epoch 27/60
 - 5s - loss: 0.3691 - acc: 0.8788 - val_loss: 0.3816 - val_acc: 0.8820

Epoch 00027: val_loss did not improve from 0.37178
Epoch 28/60
 - 5s - loss: 0.3601 - acc: 0.8822 - val_loss: 0.3831 - val_acc: 0.8842

Epoch 00028: val_loss did not improve from 0.37178
Epoch 29/60
 - 5s - loss: 0.3609 - acc: 0.8822 - val_loss: 0.3645 - val_acc: 0.8879

Epoch 00029: val_loss improved from 0.37178 to 0.36447, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 30/60
 - 5s - loss: 0.3503 - acc: 0.8840 - val_loss: 0.4017 - val_acc: 0.8726

Epoch 00030: val_loss did not improve from 0.36447
Epoch 31/60
 - 5s - loss: 0.3535 - acc: 0.8854 - val_loss: 0.3844 - val_acc: 0.8847

Epoch 00031: val_loss did not improve from 0.36447
Epoch 32/60
 - 5s - loss: 0.3553 - acc: 0.8838 - val_loss: 0.3878 - val_acc: 0.8800

Epoch 00032: val_loss did not improve from 0.36447
Epoch 33/60
 - 5s - loss: 0.3473 - acc: 0.8865 - val_loss: 0.3684 - val_acc: 0.8870

Epoch 00033: val_loss did not improve from 0.36447
Epoch 34/60
 - 5s - loss: 0.3470 - acc: 0.8869 - val_loss: 0.3850 - val_acc: 0.8810

Epoch 00034: val_loss did not improve from 0.36447
Epoch 35/60
 - 5s - loss: 0.3430 - acc: 0.8876 - val_loss: 0.3856 - val_acc: 0.8814

Epoch 00035: val_loss did not improve from 0.36447
Epoch 36/60
 - 5s - loss: 0.3402 - acc: 0.8885 - val_loss: 0.3663 - val_acc: 0.8911

Epoch 00036: val_loss did not improve from 0.36447
Epoch 37/60
 - 5s - loss: 0.3388 - acc: 0.8884 - val_loss: 0.3867 - val_acc: 0.8817

Epoch 00037: val_loss did not improve from 0.36447
Epoch 38/60
 - 5s - loss: 0.3349 - acc: 0.8898 - val_loss: 0.3627 - val_acc: 0.8903

Epoch 00038: val_loss improved from 0.36447 to 0.36271, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 39/60
 - 5s - loss: 0.3324 - acc: 0.8910 - val_loss: 0.3672 - val_acc: 0.8897

Epoch 00039: val_loss did not improve from 0.36271
Epoch 40/60
 - 5s - loss: 0.3290 - acc: 0.8918 - val_loss: 0.3784 - val_acc: 0.8836

Epoch 00040: val_loss did not improve from 0.36271
Epoch 41/60
 - 5s - loss: 0.3264 - acc: 0.8933 - val_loss: 0.3894 - val_acc: 0.8823

Epoch 00041: val_loss did not improve from 0.36271
Epoch 42/60
 - 5s - loss: 0.3234 - acc: 0.8939 - val_loss: 0.3973 - val_acc: 0.8800

Epoch 00042: val_loss did not improve from 0.36271
Epoch 43/60
 - 5s - loss: 0.3260 - acc: 0.8935 - val_loss: 0.3565 - val_acc: 0.8913

Epoch 00043: val_loss improved from 0.36271 to 0.35647, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 44/60
 - 5s - loss: 0.3228 - acc: 0.8948 - val_loss: 0.3589 - val_acc: 0.8913

Epoch 00044: val_loss did not improve from 0.35647
Epoch 45/60
 - 5s - loss: 0.3261 - acc: 0.8929 - val_loss: 0.3669 - val_acc: 0.8900

Epoch 00045: val_loss did not improve from 0.35647
Epoch 46/60
 - 5s - loss: 0.3198 - acc: 0.8938 - val_loss: 0.3676 - val_acc: 0.8895

Epoch 00046: val_loss did not improve from 0.35647
Epoch 47/60
 - 5s - loss: 0.3155 - acc: 0.8954 - val_loss: 0.3525 - val_acc: 0.8913

Epoch 00047: val_loss improved from 0.35647 to 0.35253, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 48/60
 - 5s - loss: 0.3165 - acc: 0.8959 - val_loss: 0.3628 - val_acc: 0.8873

Epoch 00048: val_loss did not improve from 0.35253
Epoch 49/60
 - 5s - loss: 0.3146 - acc: 0.8961 - val_loss: 0.3579 - val_acc: 0.8916

Epoch 00049: val_loss did not improve from 0.35253
Epoch 50/60
 - 5s - loss: 0.3139 - acc: 0.8981 - val_loss: 0.3759 - val_acc: 0.8876

Epoch 00050: val_loss did not improve from 0.35253
Epoch 51/60
 - 5s - loss: 0.3137 - acc: 0.8967 - val_loss: 0.3596 - val_acc: 0.8886

Epoch 00051: val_loss did not improve from 0.35253
Epoch 52/60
 - 5s - loss: 0.3121 - acc: 0.8991 - val_loss: 0.3562 - val_acc: 0.8900

Epoch 00052: val_loss did not improve from 0.35253
Epoch 53/60
 - 5s - loss: 0.3061 - acc: 0.8986 - val_loss: 0.3854 - val_acc: 0.8825

Epoch 00053: val_loss did not improve from 0.35253
Epoch 54/60
 - 5s - loss: 0.3079 - acc: 0.8992 - val_loss: 0.3689 - val_acc: 0.8910

Epoch 00054: val_loss did not improve from 0.35253
Epoch 55/60
 - 5s - loss: 0.3086 - acc: 0.8980 - val_loss: 0.3559 - val_acc: 0.8934

Epoch 00055: val_loss did not improve from 0.35253
Epoch 56/60
 - 5s - loss: 0.3058 - acc: 0.8991 - val_loss: 0.3600 - val_acc: 0.8901

Epoch 00056: val_loss did not improve from 0.35253
Epoch 57/60
 - 5s - loss: 0.3073 - acc: 0.8983 - val_loss: 0.3621 - val_acc: 0.8900

Epoch 00057: val_loss did not improve from 0.35253
Epoch 00057: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 6s - loss: 2.7084 - acc: 0.3882 - val_loss: 1.7203 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 1.72028, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 2/60
 - 4s - loss: 1.6570 - acc: 0.6242 - val_loss: 1.5991 - val_acc: 0.6209

Epoch 00002: val_loss improved from 1.72028 to 1.59910, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 3/60
 - 4s - loss: 1.5462 - acc: 0.6366 - val_loss: 1.5263 - val_acc: 0.6209

Epoch 00003: val_loss improved from 1.59910 to 1.52632, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 4/60
 - 4s - loss: 1.5019 - acc: 0.6371 - val_loss: 1.5559 - val_acc: 0.6209

Epoch 00004: val_loss did not improve from 1.52632
Epoch 5/60
 - 4s - loss: 1.4694 - acc: 0.6372 - val_loss: 1.5022 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.52632 to 1.50222, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 6/60
 - 4s - loss: 1.4490 - acc: 0.6371 - val_loss: 1.4464 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.50222 to 1.44641, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 7/60
 - 4s - loss: 1.4258 - acc: 0.6371 - val_loss: 1.4094 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.44641 to 1.40936, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 8/60
 - 4s - loss: 1.3886 - acc: 0.6365 - val_loss: 1.3663 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.40936 to 1.36631, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 9/60
 - 4s - loss: 1.3485 - acc: 0.6360 - val_loss: 1.3132 - val_acc: 0.6230

Epoch 00009: val_loss improved from 1.36631 to 1.31319, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 10/60
 - 4s - loss: 1.3079 - acc: 0.6375 - val_loss: 1.2566 - val_acc: 0.6286

Epoch 00010: val_loss improved from 1.31319 to 1.25658, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 11/60
 - 4s - loss: 1.2789 - acc: 0.6397 - val_loss: 1.2236 - val_acc: 0.6340

Epoch 00011: val_loss improved from 1.25658 to 1.22356, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 12/60
 - 4s - loss: 1.2564 - acc: 0.6415 - val_loss: 1.1864 - val_acc: 0.6396

Epoch 00012: val_loss improved from 1.22356 to 1.18637, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 13/60
 - 4s - loss: 1.2374 - acc: 0.6437 - val_loss: 1.1677 - val_acc: 0.6397

Epoch 00013: val_loss improved from 1.18637 to 1.16772, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 14/60
 - 4s - loss: 1.2241 - acc: 0.6452 - val_loss: 1.1674 - val_acc: 0.6412

Epoch 00014: val_loss improved from 1.16772 to 1.16745, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 15/60
 - 4s - loss: 1.2077 - acc: 0.6469 - val_loss: 1.1406 - val_acc: 0.6418

Epoch 00015: val_loss improved from 1.16745 to 1.14059, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 16/60
 - 4s - loss: 1.1946 - acc: 0.6491 - val_loss: 1.1494 - val_acc: 0.6475

Epoch 00016: val_loss did not improve from 1.14059
Epoch 17/60
 - 4s - loss: 1.1836 - acc: 0.6502 - val_loss: 1.1079 - val_acc: 0.6462

Epoch 00017: val_loss improved from 1.14059 to 1.10785, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 18/60
 - 4s - loss: 1.1724 - acc: 0.6539 - val_loss: 1.0909 - val_acc: 0.6509

Epoch 00018: val_loss improved from 1.10785 to 1.09093, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 19/60
 - 4s - loss: 1.1576 - acc: 0.6534 - val_loss: 1.0802 - val_acc: 0.6565

Epoch 00019: val_loss improved from 1.09093 to 1.08023, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 20/60
 - 4s - loss: 1.1481 - acc: 0.6541 - val_loss: 1.0621 - val_acc: 0.6562

Epoch 00020: val_loss improved from 1.08023 to 1.06211, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 21/60
 - 4s - loss: 1.1388 - acc: 0.6565 - val_loss: 1.0688 - val_acc: 0.6590

Epoch 00021: val_loss did not improve from 1.06211
Epoch 22/60
 - 4s - loss: 1.1323 - acc: 0.6584 - val_loss: 1.0572 - val_acc: 0.6595

Epoch 00022: val_loss improved from 1.06211 to 1.05722, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 23/60
 - 4s - loss: 1.1259 - acc: 0.6585 - val_loss: 1.0330 - val_acc: 0.6615

Epoch 00023: val_loss improved from 1.05722 to 1.03300, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 24/60
 - 4s - loss: 1.1153 - acc: 0.6611 - val_loss: 1.0584 - val_acc: 0.6593

Epoch 00024: val_loss did not improve from 1.03300
Epoch 25/60
 - 4s - loss: 1.1073 - acc: 0.6622 - val_loss: 1.0187 - val_acc: 0.6633

Epoch 00025: val_loss improved from 1.03300 to 1.01873, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 26/60
 - 4s - loss: 1.1064 - acc: 0.6622 - val_loss: 1.0288 - val_acc: 0.6665

Epoch 00026: val_loss did not improve from 1.01873
Epoch 27/60
 - 4s - loss: 1.0965 - acc: 0.6637 - val_loss: 1.0154 - val_acc: 0.6665

Epoch 00027: val_loss improved from 1.01873 to 1.01535, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 28/60
 - 4s - loss: 1.0857 - acc: 0.6653 - val_loss: 1.0037 - val_acc: 0.6717

Epoch 00028: val_loss improved from 1.01535 to 1.00370, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 29/60
 - 4s - loss: 1.0819 - acc: 0.6657 - val_loss: 0.9780 - val_acc: 0.6689

Epoch 00029: val_loss improved from 1.00370 to 0.97804, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 30/60
 - 4s - loss: 1.0849 - acc: 0.6671 - val_loss: 0.9918 - val_acc: 0.6696

Epoch 00030: val_loss did not improve from 0.97804
Epoch 31/60
 - 4s - loss: 1.0743 - acc: 0.6669 - val_loss: 0.9960 - val_acc: 0.6742

Epoch 00031: val_loss did not improve from 0.97804
Epoch 32/60
 - 4s - loss: 1.0687 - acc: 0.6680 - val_loss: 0.9776 - val_acc: 0.6795

Epoch 00032: val_loss improved from 0.97804 to 0.97760, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 33/60
 - 4s - loss: 1.0638 - acc: 0.6684 - val_loss: 0.9616 - val_acc: 0.6733

Epoch 00033: val_loss improved from 0.97760 to 0.96158, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 34/60
 - 4s - loss: 1.0646 - acc: 0.6688 - val_loss: 0.9926 - val_acc: 0.6764

Epoch 00034: val_loss did not improve from 0.96158
Epoch 35/60
 - 4s - loss: 1.0556 - acc: 0.6701 - val_loss: 0.9539 - val_acc: 0.6808

Epoch 00035: val_loss improved from 0.96158 to 0.95390, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 36/60
 - 4s - loss: 1.0513 - acc: 0.6703 - val_loss: 0.9374 - val_acc: 0.6792

Epoch 00036: val_loss improved from 0.95390 to 0.93738, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 37/60
 - 4s - loss: 1.0494 - acc: 0.6705 - val_loss: 0.9530 - val_acc: 0.6748

Epoch 00037: val_loss did not improve from 0.93738
Epoch 38/60
 - 4s - loss: 1.0411 - acc: 0.6720 - val_loss: 0.9396 - val_acc: 0.6823

Epoch 00038: val_loss did not improve from 0.93738
Epoch 39/60
 - 4s - loss: 1.0358 - acc: 0.6733 - val_loss: 0.9220 - val_acc: 0.6831

Epoch 00039: val_loss improved from 0.93738 to 0.92204, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 40/60
 - 4s - loss: 1.0304 - acc: 0.6748 - val_loss: 0.9349 - val_acc: 0.6793

Epoch 00040: val_loss did not improve from 0.92204
Epoch 41/60
 - 5s - loss: 1.0263 - acc: 0.6746 - val_loss: 0.8948 - val_acc: 0.6848

Epoch 00041: val_loss improved from 0.92204 to 0.89485, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 42/60
 - 4s - loss: 1.0216 - acc: 0.6771 - val_loss: 0.9015 - val_acc: 0.6834

Epoch 00042: val_loss did not improve from 0.89485
Epoch 43/60
 - 4s - loss: 1.0188 - acc: 0.6749 - val_loss: 0.9022 - val_acc: 0.6836

Epoch 00043: val_loss did not improve from 0.89485
Epoch 44/60
 - 4s - loss: 1.0151 - acc: 0.6776 - val_loss: 0.9115 - val_acc: 0.6876

Epoch 00044: val_loss did not improve from 0.89485
Epoch 45/60
 - 4s - loss: 1.0124 - acc: 0.6774 - val_loss: 0.8648 - val_acc: 0.6936

Epoch 00045: val_loss improved from 0.89485 to 0.86481, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 46/60
 - 4s - loss: 1.0048 - acc: 0.6774 - val_loss: 0.8966 - val_acc: 0.6890

Epoch 00046: val_loss did not improve from 0.86481
Epoch 47/60
 - 4s - loss: 1.0041 - acc: 0.6775 - val_loss: 0.8715 - val_acc: 0.6940

Epoch 00047: val_loss did not improve from 0.86481
Epoch 48/60
 - 4s - loss: 1.0027 - acc: 0.6780 - val_loss: 0.8651 - val_acc: 0.6886

Epoch 00048: val_loss did not improve from 0.86481
Epoch 49/60
 - 4s - loss: 1.0021 - acc: 0.6784 - val_loss: 0.8462 - val_acc: 0.6937

Epoch 00049: val_loss improved from 0.86481 to 0.84622, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 50/60
 - 4s - loss: 0.9935 - acc: 0.6824 - val_loss: 0.8317 - val_acc: 0.6999

Epoch 00050: val_loss improved from 0.84622 to 0.83167, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 51/60
 - 4s - loss: 0.9865 - acc: 0.6803 - val_loss: 0.8601 - val_acc: 0.6990

Epoch 00051: val_loss did not improve from 0.83167
Epoch 52/60
 - 4s - loss: 0.9823 - acc: 0.6821 - val_loss: 0.8407 - val_acc: 0.6945

Epoch 00052: val_loss did not improve from 0.83167
Epoch 53/60
 - 4s - loss: 0.9856 - acc: 0.6822 - val_loss: 0.8137 - val_acc: 0.7037

Epoch 00053: val_loss improved from 0.83167 to 0.81371, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 54/60
 - 4s - loss: 0.9770 - acc: 0.6837 - val_loss: 0.8199 - val_acc: 0.6973

Epoch 00054: val_loss did not improve from 0.81371
Epoch 55/60
 - 4s - loss: 0.9777 - acc: 0.6846 - val_loss: 0.8274 - val_acc: 0.7015

Epoch 00055: val_loss did not improve from 0.81371
Epoch 56/60
 - 4s - loss: 0.9744 - acc: 0.6850 - val_loss: 0.8284 - val_acc: 0.7026

Epoch 00056: val_loss did not improve from 0.81371
Epoch 57/60
 - 4s - loss: 0.9709 - acc: 0.6857 - val_loss: 0.8503 - val_acc: 0.6987

Epoch 00057: val_loss did not improve from 0.81371
Epoch 58/60
 - 4s - loss: 0.9709 - acc: 0.6870 - val_loss: 0.8116 - val_acc: 0.6995

Epoch 00058: val_loss improved from 0.81371 to 0.81163, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 59/60
 - 4s - loss: 0.9628 - acc: 0.6869 - val_loss: 0.7865 - val_acc: 0.7099

Epoch 00059: val_loss improved from 0.81163 to 0.78651, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 60/60
 - 4s - loss: 0.9589 - acc: 0.6883 - val_loss: 0.8151 - val_acc: 0.7059

Epoch 00060: val_loss did not improve from 0.78651
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 1.8942 - acc: 0.5824 - val_loss: 1.6045 - val_acc: 0.6219

Epoch 00001: val_loss improved from inf to 1.60449, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 2/60
 - 5s - loss: 1.4381 - acc: 0.6361 - val_loss: 1.3066 - val_acc: 0.6277

Epoch 00002: val_loss improved from 1.60449 to 1.30658, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 3/60
 - 5s - loss: 1.3386 - acc: 0.6388 - val_loss: 1.2573 - val_acc: 0.6431

Epoch 00003: val_loss improved from 1.30658 to 1.25734, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 4/60
 - 5s - loss: 1.2703 - acc: 0.6464 - val_loss: 1.2397 - val_acc: 0.6570

Epoch 00004: val_loss improved from 1.25734 to 1.23974, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 5/60
 - 6s - loss: 1.2134 - acc: 0.6524 - val_loss: 1.1307 - val_acc: 0.6667

Epoch 00005: val_loss improved from 1.23974 to 1.13066, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 6/60
 - 6s - loss: 1.1675 - acc: 0.6587 - val_loss: 1.0884 - val_acc: 0.6698

Epoch 00006: val_loss improved from 1.13066 to 1.08842, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 7/60
 - 5s - loss: 1.1299 - acc: 0.6657 - val_loss: 1.0553 - val_acc: 0.6784

Epoch 00007: val_loss improved from 1.08842 to 1.05531, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 8/60
 - 5s - loss: 1.0987 - acc: 0.6681 - val_loss: 1.0450 - val_acc: 0.6803

Epoch 00008: val_loss improved from 1.05531 to 1.04503, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 9/60
 - 5s - loss: 1.0748 - acc: 0.6720 - val_loss: 0.9997 - val_acc: 0.6859

Epoch 00009: val_loss improved from 1.04503 to 0.99970, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 10/60
 - 5s - loss: 1.0559 - acc: 0.6742 - val_loss: 0.9537 - val_acc: 0.6871

Epoch 00010: val_loss improved from 0.99970 to 0.95373, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 11/60
 - 5s - loss: 1.0300 - acc: 0.6790 - val_loss: 0.9192 - val_acc: 0.6892

Epoch 00011: val_loss improved from 0.95373 to 0.91916, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 12/60
 - 5s - loss: 1.0120 - acc: 0.6809 - val_loss: 0.9136 - val_acc: 0.6904

Epoch 00012: val_loss improved from 0.91916 to 0.91365, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 13/60
 - 5s - loss: 0.9957 - acc: 0.6838 - val_loss: 0.8948 - val_acc: 0.6924

Epoch 00013: val_loss improved from 0.91365 to 0.89482, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 14/60
 - 5s - loss: 0.9872 - acc: 0.6860 - val_loss: 0.8744 - val_acc: 0.6987

Epoch 00014: val_loss improved from 0.89482 to 0.87443, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 15/60
 - 5s - loss: 0.9665 - acc: 0.6903 - val_loss: 0.8571 - val_acc: 0.7092

Epoch 00015: val_loss improved from 0.87443 to 0.85713, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 16/60
 - 6s - loss: 0.9536 - acc: 0.6916 - val_loss: 0.8314 - val_acc: 0.7148

Epoch 00016: val_loss improved from 0.85713 to 0.83139, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 17/60
 - 6s - loss: 0.9363 - acc: 0.6989 - val_loss: 0.8148 - val_acc: 0.7212

Epoch 00017: val_loss improved from 0.83139 to 0.81476, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 18/60
 - 5s - loss: 0.9261 - acc: 0.7006 - val_loss: 0.7965 - val_acc: 0.7273

Epoch 00018: val_loss improved from 0.81476 to 0.79655, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 19/60
 - 6s - loss: 0.9120 - acc: 0.7051 - val_loss: 0.7832 - val_acc: 0.7396

Epoch 00019: val_loss improved from 0.79655 to 0.78319, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 20/60
 - 5s - loss: 0.8951 - acc: 0.7086 - val_loss: 0.7734 - val_acc: 0.7415

Epoch 00020: val_loss improved from 0.78319 to 0.77343, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 21/60
 - 5s - loss: 0.8774 - acc: 0.7142 - val_loss: 0.7586 - val_acc: 0.7563

Epoch 00021: val_loss improved from 0.77343 to 0.75862, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 22/60
 - 6s - loss: 0.8731 - acc: 0.7172 - val_loss: 0.7312 - val_acc: 0.7545

Epoch 00022: val_loss improved from 0.75862 to 0.73122, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 23/60
 - 6s - loss: 0.8643 - acc: 0.7176 - val_loss: 0.7145 - val_acc: 0.7636

Epoch 00023: val_loss improved from 0.73122 to 0.71453, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 24/60
 - 6s - loss: 0.8486 - acc: 0.7239 - val_loss: 0.6997 - val_acc: 0.7617

Epoch 00024: val_loss improved from 0.71453 to 0.69968, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 25/60
 - 5s - loss: 0.8399 - acc: 0.7272 - val_loss: 0.6919 - val_acc: 0.7664

Epoch 00025: val_loss improved from 0.69968 to 0.69186, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 26/60
 - 5s - loss: 0.8298 - acc: 0.7284 - val_loss: 0.6707 - val_acc: 0.7788

Epoch 00026: val_loss improved from 0.69186 to 0.67069, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 27/60
 - 5s - loss: 0.8197 - acc: 0.7312 - val_loss: 0.6570 - val_acc: 0.7723

Epoch 00027: val_loss improved from 0.67069 to 0.65700, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 28/60
 - 5s - loss: 0.8104 - acc: 0.7348 - val_loss: 0.6494 - val_acc: 0.7785

Epoch 00028: val_loss improved from 0.65700 to 0.64937, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 29/60
 - 5s - loss: 0.7992 - acc: 0.7356 - val_loss: 0.6436 - val_acc: 0.7839

Epoch 00029: val_loss improved from 0.64937 to 0.64355, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 30/60
 - 5s - loss: 0.7936 - acc: 0.7422 - val_loss: 0.6445 - val_acc: 0.7798

Epoch 00030: val_loss did not improve from 0.64355
Epoch 31/60
 - 5s - loss: 0.7764 - acc: 0.7461 - val_loss: 0.6212 - val_acc: 0.7924

Epoch 00031: val_loss improved from 0.64355 to 0.62121, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 32/60
 - 5s - loss: 0.7760 - acc: 0.7450 - val_loss: 0.6152 - val_acc: 0.7920

Epoch 00032: val_loss improved from 0.62121 to 0.61516, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 33/60
 - 5s - loss: 0.7696 - acc: 0.7503 - val_loss: 0.6210 - val_acc: 0.7935

Epoch 00033: val_loss did not improve from 0.61516
Epoch 34/60
 - 5s - loss: 0.7618 - acc: 0.7491 - val_loss: 0.6043 - val_acc: 0.7952

Epoch 00034: val_loss improved from 0.61516 to 0.60434, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 35/60
 - 5s - loss: 0.7560 - acc: 0.7539 - val_loss: 0.5904 - val_acc: 0.8048

Epoch 00035: val_loss improved from 0.60434 to 0.59043, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 36/60
 - 6s - loss: 0.7524 - acc: 0.7527 - val_loss: 0.5819 - val_acc: 0.8071

Epoch 00036: val_loss improved from 0.59043 to 0.58193, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 37/60
 - 5s - loss: 0.7483 - acc: 0.7543 - val_loss: 0.5914 - val_acc: 0.8035

Epoch 00037: val_loss did not improve from 0.58193
Epoch 38/60
 - 5s - loss: 0.7460 - acc: 0.7555 - val_loss: 0.5780 - val_acc: 0.8021

Epoch 00038: val_loss improved from 0.58193 to 0.57804, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 39/60
 - 5s - loss: 0.7351 - acc: 0.7595 - val_loss: 0.5738 - val_acc: 0.8158

Epoch 00039: val_loss improved from 0.57804 to 0.57378, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 40/60
 - 5s - loss: 0.7275 - acc: 0.7620 - val_loss: 0.5705 - val_acc: 0.8119

Epoch 00040: val_loss improved from 0.57378 to 0.57051, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 41/60
 - 5s - loss: 0.7235 - acc: 0.7638 - val_loss: 0.5616 - val_acc: 0.8155

Epoch 00041: val_loss improved from 0.57051 to 0.56155, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 42/60
 - 5s - loss: 0.7215 - acc: 0.7642 - val_loss: 0.5667 - val_acc: 0.8149

Epoch 00042: val_loss did not improve from 0.56155
Epoch 43/60
 - 5s - loss: 0.7153 - acc: 0.7644 - val_loss: 0.5530 - val_acc: 0.8160

Epoch 00043: val_loss improved from 0.56155 to 0.55300, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 44/60
 - 5s - loss: 0.7132 - acc: 0.7673 - val_loss: 0.5537 - val_acc: 0.8185

Epoch 00044: val_loss did not improve from 0.55300
Epoch 45/60
 - 5s - loss: 0.7104 - acc: 0.7684 - val_loss: 0.5468 - val_acc: 0.8152

Epoch 00045: val_loss improved from 0.55300 to 0.54684, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 46/60
 - 5s - loss: 0.7095 - acc: 0.7675 - val_loss: 0.5454 - val_acc: 0.8198

Epoch 00046: val_loss improved from 0.54684 to 0.54537, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 47/60
 - 5s - loss: 0.7033 - acc: 0.7707 - val_loss: 0.5441 - val_acc: 0.8170

Epoch 00047: val_loss improved from 0.54537 to 0.54409, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 48/60
 - 5s - loss: 0.6980 - acc: 0.7716 - val_loss: 0.5542 - val_acc: 0.8205

Epoch 00048: val_loss did not improve from 0.54409
Epoch 49/60
 - 5s - loss: 0.6968 - acc: 0.7722 - val_loss: 0.5353 - val_acc: 0.8286

Epoch 00049: val_loss improved from 0.54409 to 0.53527, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 50/60
 - 5s - loss: 0.6941 - acc: 0.7741 - val_loss: 0.5253 - val_acc: 0.8276

Epoch 00050: val_loss improved from 0.53527 to 0.52531, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 51/60
 - 5s - loss: 0.6913 - acc: 0.7749 - val_loss: 0.5242 - val_acc: 0.8252

Epoch 00051: val_loss improved from 0.52531 to 0.52418, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 52/60
 - 5s - loss: 0.6888 - acc: 0.7755 - val_loss: 0.5353 - val_acc: 0.8244

Epoch 00052: val_loss did not improve from 0.52418
Epoch 53/60
 - 5s - loss: 0.6896 - acc: 0.7749 - val_loss: 0.5114 - val_acc: 0.8280

Epoch 00053: val_loss improved from 0.52418 to 0.51141, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 54/60
 - 5s - loss: 0.6781 - acc: 0.7787 - val_loss: 0.5184 - val_acc: 0.8304

Epoch 00054: val_loss did not improve from 0.51141
Epoch 55/60
 - 5s - loss: 0.6802 - acc: 0.7772 - val_loss: 0.5094 - val_acc: 0.8339

Epoch 00055: val_loss improved from 0.51141 to 0.50935, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Epoch 56/60
 - 5s - loss: 0.6816 - acc: 0.7786 - val_loss: 0.5133 - val_acc: 0.8310

Epoch 00056: val_loss did not improve from 0.50935
Epoch 57/60
 - 5s - loss: 0.6798 - acc: 0.7785 - val_loss: 0.5099 - val_acc: 0.8307

Epoch 00057: val_loss did not improve from 0.50935
Epoch 58/60
 - 5s - loss: 0.6677 - acc: 0.7824 - val_loss: 0.5210 - val_acc: 0.8252

Epoch 00058: val_loss did not improve from 0.50935
Epoch 59/60
 - 5s - loss: 0.6713 - acc: 0.7795 - val_loss: 0.5123 - val_acc: 0.8313

Epoch 00059: val_loss did not improve from 0.50935
Epoch 60/60
 - 5s - loss: 0.6642 - acc: 0.7844 - val_loss: 0.4966 - val_acc: 0.8361

Epoch 00060: val_loss improved from 0.50935 to 0.49662, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 7s - loss: 2.4885 - acc: 0.5668 - val_loss: 1.1723 - val_acc: 0.6589

Epoch 00001: val_loss improved from inf to 1.17233, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 2/60
 - 5s - loss: 1.1420 - acc: 0.6637 - val_loss: 0.8900 - val_acc: 0.7157

Epoch 00002: val_loss improved from 1.17233 to 0.89002, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 3/60
 - 5s - loss: 0.9163 - acc: 0.7156 - val_loss: 0.7315 - val_acc: 0.7610

Epoch 00003: val_loss improved from 0.89002 to 0.73148, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 4/60
 - 5s - loss: 0.7828 - acc: 0.7532 - val_loss: 0.6820 - val_acc: 0.7786

Epoch 00004: val_loss improved from 0.73148 to 0.68201, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 5/60
 - 5s - loss: 0.7032 - acc: 0.7766 - val_loss: 0.6303 - val_acc: 0.7991

Epoch 00005: val_loss improved from 0.68201 to 0.63034, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 6/60
 - 5s - loss: 0.6546 - acc: 0.7914 - val_loss: 0.5584 - val_acc: 0.8247

Epoch 00006: val_loss improved from 0.63034 to 0.55839, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 7/60
 - 5s - loss: 0.6060 - acc: 0.8051 - val_loss: 0.5588 - val_acc: 0.8272

Epoch 00007: val_loss did not improve from 0.55839
Epoch 8/60
 - 5s - loss: 0.5746 - acc: 0.8157 - val_loss: 0.5360 - val_acc: 0.8273

Epoch 00008: val_loss improved from 0.55839 to 0.53600, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 9/60
 - 5s - loss: 0.5480 - acc: 0.8242 - val_loss: 0.4963 - val_acc: 0.8457

Epoch 00009: val_loss improved from 0.53600 to 0.49627, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 10/60
 - 5s - loss: 0.5329 - acc: 0.8284 - val_loss: 0.4971 - val_acc: 0.8455

Epoch 00010: val_loss did not improve from 0.49627
Epoch 11/60
 - 5s - loss: 0.5018 - acc: 0.8390 - val_loss: 0.4708 - val_acc: 0.8547

Epoch 00011: val_loss improved from 0.49627 to 0.47076, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 12/60
 - 5s - loss: 0.4896 - acc: 0.8429 - val_loss: 0.4905 - val_acc: 0.8469

Epoch 00012: val_loss did not improve from 0.47076
Epoch 13/60
 - 5s - loss: 0.4743 - acc: 0.8458 - val_loss: 0.4454 - val_acc: 0.8610

Epoch 00013: val_loss improved from 0.47076 to 0.44538, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 14/60
 - 5s - loss: 0.4571 - acc: 0.8512 - val_loss: 0.4553 - val_acc: 0.8586

Epoch 00014: val_loss did not improve from 0.44538
Epoch 15/60
 - 5s - loss: 0.4478 - acc: 0.8559 - val_loss: 0.4545 - val_acc: 0.8553

Epoch 00015: val_loss did not improve from 0.44538
Epoch 16/60
 - 5s - loss: 0.4438 - acc: 0.8560 - val_loss: 0.4333 - val_acc: 0.8628

Epoch 00016: val_loss improved from 0.44538 to 0.43329, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 17/60
 - 5s - loss: 0.4318 - acc: 0.8591 - val_loss: 0.4294 - val_acc: 0.8654

Epoch 00017: val_loss improved from 0.43329 to 0.42937, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 18/60
 - 5s - loss: 0.4199 - acc: 0.8641 - val_loss: 0.4239 - val_acc: 0.8667

Epoch 00018: val_loss improved from 0.42937 to 0.42392, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 19/60
 - 5s - loss: 0.4119 - acc: 0.8661 - val_loss: 0.4335 - val_acc: 0.8630

Epoch 00019: val_loss did not improve from 0.42392
Epoch 20/60
 - 5s - loss: 0.4112 - acc: 0.8651 - val_loss: 0.3970 - val_acc: 0.8801

Epoch 00020: val_loss improved from 0.42392 to 0.39698, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 21/60
 - 5s - loss: 0.4003 - acc: 0.8697 - val_loss: 0.4148 - val_acc: 0.8714

Epoch 00021: val_loss did not improve from 0.39698
Epoch 22/60
 - 5s - loss: 0.3949 - acc: 0.8726 - val_loss: 0.4074 - val_acc: 0.8728

Epoch 00022: val_loss did not improve from 0.39698
Epoch 23/60
 - 5s - loss: 0.3864 - acc: 0.8742 - val_loss: 0.4244 - val_acc: 0.8655

Epoch 00023: val_loss did not improve from 0.39698
Epoch 24/60
 - 5s - loss: 0.3847 - acc: 0.8728 - val_loss: 0.4071 - val_acc: 0.8713

Epoch 00024: val_loss did not improve from 0.39698
Epoch 25/60
 - 5s - loss: 0.3822 - acc: 0.8750 - val_loss: 0.4291 - val_acc: 0.8664

Epoch 00025: val_loss did not improve from 0.39698
Epoch 26/60
 - 5s - loss: 0.3736 - acc: 0.8773 - val_loss: 0.4030 - val_acc: 0.8758

Epoch 00026: val_loss did not improve from 0.39698
Epoch 27/60
 - 5s - loss: 0.3706 - acc: 0.8794 - val_loss: 0.4047 - val_acc: 0.8757

Epoch 00027: val_loss did not improve from 0.39698
Epoch 28/60
 - 5s - loss: 0.3677 - acc: 0.8809 - val_loss: 0.3932 - val_acc: 0.8791

Epoch 00028: val_loss improved from 0.39698 to 0.39323, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 29/60
 - 5s - loss: 0.3623 - acc: 0.8806 - val_loss: 0.3967 - val_acc: 0.8806

Epoch 00029: val_loss did not improve from 0.39323
Epoch 30/60
 - 5s - loss: 0.3635 - acc: 0.8817 - val_loss: 0.4029 - val_acc: 0.8764

Epoch 00030: val_loss did not improve from 0.39323
Epoch 31/60
 - 5s - loss: 0.3536 - acc: 0.8829 - val_loss: 0.4131 - val_acc: 0.8738

Epoch 00031: val_loss did not improve from 0.39323
Epoch 32/60
 - 5s - loss: 0.3524 - acc: 0.8838 - val_loss: 0.3937 - val_acc: 0.8825

Epoch 00032: val_loss did not improve from 0.39323
Epoch 33/60
 - 5s - loss: 0.3536 - acc: 0.8845 - val_loss: 0.3840 - val_acc: 0.8841

Epoch 00033: val_loss improved from 0.39323 to 0.38398, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 34/60
 - 5s - loss: 0.3505 - acc: 0.8839 - val_loss: 0.3930 - val_acc: 0.8760

Epoch 00034: val_loss did not improve from 0.38398
Epoch 35/60
 - 5s - loss: 0.3466 - acc: 0.8864 - val_loss: 0.4071 - val_acc: 0.8782

Epoch 00035: val_loss did not improve from 0.38398
Epoch 36/60
 - 5s - loss: 0.3416 - acc: 0.8881 - val_loss: 0.3871 - val_acc: 0.8782

Epoch 00036: val_loss did not improve from 0.38398
Epoch 37/60
 - 5s - loss: 0.3416 - acc: 0.8891 - val_loss: 0.3777 - val_acc: 0.8836

Epoch 00037: val_loss improved from 0.38398 to 0.37767, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 38/60
 - 5s - loss: 0.3346 - acc: 0.8905 - val_loss: 0.4072 - val_acc: 0.8764

Epoch 00038: val_loss did not improve from 0.37767
Epoch 39/60
 - 5s - loss: 0.3374 - acc: 0.8893 - val_loss: 0.3841 - val_acc: 0.8841

Epoch 00039: val_loss did not improve from 0.37767
Epoch 40/60
 - 5s - loss: 0.3356 - acc: 0.8906 - val_loss: 0.3923 - val_acc: 0.8785

Epoch 00040: val_loss did not improve from 0.37767
Epoch 41/60
 - 5s - loss: 0.3330 - acc: 0.8899 - val_loss: 0.3874 - val_acc: 0.8826

Epoch 00041: val_loss did not improve from 0.37767
Epoch 42/60
 - 5s - loss: 0.3234 - acc: 0.8929 - val_loss: 0.3982 - val_acc: 0.8767

Epoch 00042: val_loss did not improve from 0.37767
Epoch 43/60
 - 5s - loss: 0.3285 - acc: 0.8921 - val_loss: 0.3766 - val_acc: 0.8835

Epoch 00043: val_loss improved from 0.37767 to 0.37656, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 44/60
 - 5s - loss: 0.3243 - acc: 0.8916 - val_loss: 0.4135 - val_acc: 0.8754

Epoch 00044: val_loss did not improve from 0.37656
Epoch 45/60
 - 5s - loss: 0.3243 - acc: 0.8932 - val_loss: 0.3810 - val_acc: 0.8816

Epoch 00045: val_loss did not improve from 0.37656
Epoch 46/60
 - 5s - loss: 0.3190 - acc: 0.8949 - val_loss: 0.3677 - val_acc: 0.8879

Epoch 00046: val_loss improved from 0.37656 to 0.36771, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 47/60
 - 5s - loss: 0.3202 - acc: 0.8945 - val_loss: 0.3953 - val_acc: 0.8813

Epoch 00047: val_loss did not improve from 0.36771
Epoch 48/60
 - 5s - loss: 0.3171 - acc: 0.8955 - val_loss: 0.3949 - val_acc: 0.8804

Epoch 00048: val_loss did not improve from 0.36771
Epoch 49/60
 - 5s - loss: 0.3211 - acc: 0.8937 - val_loss: 0.3754 - val_acc: 0.8836

Epoch 00049: val_loss did not improve from 0.36771
Epoch 50/60
 - 5s - loss: 0.3150 - acc: 0.8957 - val_loss: 0.3862 - val_acc: 0.8804

Epoch 00050: val_loss did not improve from 0.36771
Epoch 51/60
 - 5s - loss: 0.3202 - acc: 0.8943 - val_loss: 0.3672 - val_acc: 0.8888

Epoch 00051: val_loss improved from 0.36771 to 0.36716, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 52/60
 - 5s - loss: 0.3127 - acc: 0.8976 - val_loss: 0.4366 - val_acc: 0.8703

Epoch 00052: val_loss did not improve from 0.36716
Epoch 53/60
 - 5s - loss: 0.3115 - acc: 0.8962 - val_loss: 0.3952 - val_acc: 0.8814

Epoch 00053: val_loss did not improve from 0.36716
Epoch 54/60
 - 5s - loss: 0.3133 - acc: 0.8958 - val_loss: 0.3993 - val_acc: 0.8803

Epoch 00054: val_loss did not improve from 0.36716
Epoch 55/60
 - 5s - loss: 0.3063 - acc: 0.8974 - val_loss: 0.3740 - val_acc: 0.8870

Epoch 00055: val_loss did not improve from 0.36716
Epoch 56/60
 - 5s - loss: 0.3092 - acc: 0.8970 - val_loss: 0.3808 - val_acc: 0.8797

Epoch 00056: val_loss did not improve from 0.36716
Epoch 57/60
 - 5s - loss: 0.3106 - acc: 0.8970 - val_loss: 0.3839 - val_acc: 0.8836

Epoch 00057: val_loss did not improve from 0.36716
Epoch 58/60
 - 5s - loss: 0.3039 - acc: 0.8999 - val_loss: 0.3784 - val_acc: 0.8863

Epoch 00058: val_loss did not improve from 0.36716
Epoch 59/60
 - 5s - loss: 0.3045 - acc: 0.8999 - val_loss: 0.3689 - val_acc: 0.8873

Epoch 00059: val_loss did not improve from 0.36716
Epoch 60/60
 - 5s - loss: 0.3048 - acc: 0.8983 - val_loss: 0.3937 - val_acc: 0.8808

Epoch 00060: val_loss did not improve from 0.36716
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 7s - loss: 2.5086 - acc: 0.3192 - val_loss: 1.7544 - val_acc: 0.6211

Epoch 00001: val_loss improved from inf to 1.75444, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 2/60
 - 4s - loss: 1.6889 - acc: 0.6096 - val_loss: 1.6666 - val_acc: 0.6209

Epoch 00002: val_loss improved from 1.75444 to 1.66660, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 3/60
 - 4s - loss: 1.5613 - acc: 0.6330 - val_loss: 1.4852 - val_acc: 0.6209

Epoch 00003: val_loss improved from 1.66660 to 1.48518, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 4/60
 - 4s - loss: 1.4966 - acc: 0.6356 - val_loss: 1.4044 - val_acc: 0.6221

Epoch 00004: val_loss improved from 1.48518 to 1.40440, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 5/60
 - 4s - loss: 1.4415 - acc: 0.6363 - val_loss: 1.3790 - val_acc: 0.6224

Epoch 00005: val_loss improved from 1.40440 to 1.37896, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 6/60
 - 4s - loss: 1.4024 - acc: 0.6368 - val_loss: 1.3446 - val_acc: 0.6249

Epoch 00006: val_loss improved from 1.37896 to 1.34464, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 7/60
 - 4s - loss: 1.3671 - acc: 0.6382 - val_loss: 1.3452 - val_acc: 0.6318

Epoch 00007: val_loss did not improve from 1.34464
Epoch 8/60
 - 4s - loss: 1.3408 - acc: 0.6401 - val_loss: 1.2927 - val_acc: 0.6324

Epoch 00008: val_loss improved from 1.34464 to 1.29274, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 9/60
 - 4s - loss: 1.3157 - acc: 0.6419 - val_loss: 1.2614 - val_acc: 0.6337

Epoch 00009: val_loss improved from 1.29274 to 1.26141, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 10/60
 - 4s - loss: 1.2949 - acc: 0.6422 - val_loss: 1.2163 - val_acc: 0.6328

Epoch 00010: val_loss improved from 1.26141 to 1.21633, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 11/60
 - 4s - loss: 1.2726 - acc: 0.6437 - val_loss: 1.2248 - val_acc: 0.6397

Epoch 00011: val_loss did not improve from 1.21633
Epoch 12/60
 - 4s - loss: 1.2524 - acc: 0.6450 - val_loss: 1.1664 - val_acc: 0.6409

Epoch 00012: val_loss improved from 1.21633 to 1.16638, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 13/60
 - 4s - loss: 1.2350 - acc: 0.6466 - val_loss: 1.1671 - val_acc: 0.6442

Epoch 00013: val_loss did not improve from 1.16638
Epoch 14/60
 - 4s - loss: 1.2152 - acc: 0.6483 - val_loss: 1.1540 - val_acc: 0.6456

Epoch 00014: val_loss improved from 1.16638 to 1.15397, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 15/60
 - 4s - loss: 1.1995 - acc: 0.6503 - val_loss: 1.1172 - val_acc: 0.6505

Epoch 00015: val_loss improved from 1.15397 to 1.11715, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 16/60
 - 4s - loss: 1.1875 - acc: 0.6509 - val_loss: 1.0968 - val_acc: 0.6508

Epoch 00016: val_loss improved from 1.11715 to 1.09681, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 17/60
 - 4s - loss: 1.1754 - acc: 0.6546 - val_loss: 1.0899 - val_acc: 0.6511

Epoch 00017: val_loss improved from 1.09681 to 1.08986, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 18/60
 - 4s - loss: 1.1665 - acc: 0.6543 - val_loss: 1.0983 - val_acc: 0.6605

Epoch 00018: val_loss did not improve from 1.08986
Epoch 19/60
 - 4s - loss: 1.1572 - acc: 0.6554 - val_loss: 1.0600 - val_acc: 0.6552

Epoch 00019: val_loss improved from 1.08986 to 1.06001, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 20/60
 - 4s - loss: 1.1486 - acc: 0.6561 - val_loss: 1.0523 - val_acc: 0.6599

Epoch 00020: val_loss improved from 1.06001 to 1.05227, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 21/60
 - 4s - loss: 1.1385 - acc: 0.6575 - val_loss: 1.0432 - val_acc: 0.6612

Epoch 00021: val_loss improved from 1.05227 to 1.04317, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 22/60
 - 5s - loss: 1.1316 - acc: 0.6579 - val_loss: 1.0533 - val_acc: 0.6580

Epoch 00022: val_loss did not improve from 1.04317
Epoch 23/60
 - 4s - loss: 1.1240 - acc: 0.6605 - val_loss: 1.0505 - val_acc: 0.6702

Epoch 00023: val_loss did not improve from 1.04317
Epoch 24/60
 - 4s - loss: 1.1179 - acc: 0.6591 - val_loss: 1.0283 - val_acc: 0.6720

Epoch 00024: val_loss improved from 1.04317 to 1.02826, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 25/60
 - 4s - loss: 1.1107 - acc: 0.6598 - val_loss: 1.0023 - val_acc: 0.6717

Epoch 00025: val_loss improved from 1.02826 to 1.00230, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 26/60
 - 4s - loss: 1.1028 - acc: 0.6632 - val_loss: 1.0237 - val_acc: 0.6759

Epoch 00026: val_loss did not improve from 1.00230
Epoch 27/60
 - 4s - loss: 1.0901 - acc: 0.6648 - val_loss: 0.9957 - val_acc: 0.6798

Epoch 00027: val_loss improved from 1.00230 to 0.99572, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 28/60
 - 4s - loss: 1.0897 - acc: 0.6646 - val_loss: 0.9900 - val_acc: 0.6755

Epoch 00028: val_loss improved from 0.99572 to 0.98996, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 29/60
 - 4s - loss: 1.0807 - acc: 0.6666 - val_loss: 0.9543 - val_acc: 0.6767

Epoch 00029: val_loss improved from 0.98996 to 0.95431, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 30/60
 - 4s - loss: 1.0726 - acc: 0.6668 - val_loss: 0.9509 - val_acc: 0.6793

Epoch 00030: val_loss improved from 0.95431 to 0.95093, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 31/60
 - 4s - loss: 1.0627 - acc: 0.6694 - val_loss: 0.9440 - val_acc: 0.6737

Epoch 00031: val_loss improved from 0.95093 to 0.94403, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 32/60
 - 4s - loss: 1.0617 - acc: 0.6687 - val_loss: 0.9297 - val_acc: 0.6771

Epoch 00032: val_loss improved from 0.94403 to 0.92969, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 33/60
 - 4s - loss: 1.0543 - acc: 0.6695 - val_loss: 0.9330 - val_acc: 0.6768

Epoch 00033: val_loss did not improve from 0.92969
Epoch 34/60
 - 4s - loss: 1.0458 - acc: 0.6708 - val_loss: 0.9268 - val_acc: 0.6799

Epoch 00034: val_loss improved from 0.92969 to 0.92677, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 35/60
 - 4s - loss: 1.0440 - acc: 0.6696 - val_loss: 0.9102 - val_acc: 0.6853

Epoch 00035: val_loss improved from 0.92677 to 0.91017, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 36/60
 - 4s - loss: 1.0352 - acc: 0.6719 - val_loss: 0.9206 - val_acc: 0.6849

Epoch 00036: val_loss did not improve from 0.91017
Epoch 37/60
 - 4s - loss: 1.0315 - acc: 0.6717 - val_loss: 0.8890 - val_acc: 0.6870

Epoch 00037: val_loss improved from 0.91017 to 0.88899, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 38/60
 - 4s - loss: 1.0235 - acc: 0.6739 - val_loss: 0.8771 - val_acc: 0.6865

Epoch 00038: val_loss improved from 0.88899 to 0.87712, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 39/60
 - 4s - loss: 1.0219 - acc: 0.6736 - val_loss: 0.8742 - val_acc: 0.6878

Epoch 00039: val_loss improved from 0.87712 to 0.87418, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 40/60
 - 4s - loss: 1.0180 - acc: 0.6739 - val_loss: 0.8702 - val_acc: 0.6839

Epoch 00040: val_loss improved from 0.87418 to 0.87021, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 41/60
 - 4s - loss: 1.0107 - acc: 0.6754 - val_loss: 0.8696 - val_acc: 0.6876

Epoch 00041: val_loss improved from 0.87021 to 0.86957, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 42/60
 - 4s - loss: 1.0065 - acc: 0.6773 - val_loss: 0.8517 - val_acc: 0.6942

Epoch 00042: val_loss improved from 0.86957 to 0.85170, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 43/60
 - 4s - loss: 1.0014 - acc: 0.6787 - val_loss: 0.8461 - val_acc: 0.6983

Epoch 00043: val_loss improved from 0.85170 to 0.84610, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 44/60
 - 4s - loss: 0.9920 - acc: 0.6798 - val_loss: 0.8429 - val_acc: 0.7001

Epoch 00044: val_loss improved from 0.84610 to 0.84286, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 45/60
 - 4s - loss: 0.9839 - acc: 0.6833 - val_loss: 0.8231 - val_acc: 0.6995

Epoch 00045: val_loss improved from 0.84286 to 0.82313, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 46/60
 - 4s - loss: 0.9909 - acc: 0.6809 - val_loss: 0.8256 - val_acc: 0.7036

Epoch 00046: val_loss did not improve from 0.82313
Epoch 47/60
 - 4s - loss: 0.9770 - acc: 0.6835 - val_loss: 0.8191 - val_acc: 0.6999

Epoch 00047: val_loss improved from 0.82313 to 0.81910, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 48/60
 - 4s - loss: 0.9757 - acc: 0.6847 - val_loss: 0.8090 - val_acc: 0.7095

Epoch 00048: val_loss improved from 0.81910 to 0.80900, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 49/60
 - 4s - loss: 0.9778 - acc: 0.6848 - val_loss: 0.8175 - val_acc: 0.7045

Epoch 00049: val_loss did not improve from 0.80900
Epoch 50/60
 - 4s - loss: 0.9687 - acc: 0.6851 - val_loss: 0.8042 - val_acc: 0.7042

Epoch 00050: val_loss improved from 0.80900 to 0.80417, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 51/60
 - 4s - loss: 0.9654 - acc: 0.6884 - val_loss: 0.8082 - val_acc: 0.7121

Epoch 00051: val_loss did not improve from 0.80417
Epoch 52/60
 - 4s - loss: 0.9635 - acc: 0.6878 - val_loss: 0.7824 - val_acc: 0.7089

Epoch 00052: val_loss improved from 0.80417 to 0.78236, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 53/60
 - 4s - loss: 0.9605 - acc: 0.6876 - val_loss: 0.7910 - val_acc: 0.7187

Epoch 00053: val_loss did not improve from 0.78236
Epoch 54/60
 - 4s - loss: 0.9519 - acc: 0.6904 - val_loss: 0.7842 - val_acc: 0.7077

Epoch 00054: val_loss did not improve from 0.78236
Epoch 55/60
 - 4s - loss: 0.9527 - acc: 0.6907 - val_loss: 0.7632 - val_acc: 0.7255

Epoch 00055: val_loss improved from 0.78236 to 0.76318, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 56/60
 - 4s - loss: 0.9509 - acc: 0.6912 - val_loss: 0.7888 - val_acc: 0.7227

Epoch 00056: val_loss did not improve from 0.76318
Epoch 57/60
 - 4s - loss: 0.9459 - acc: 0.6909 - val_loss: 0.7744 - val_acc: 0.7252

Epoch 00057: val_loss did not improve from 0.76318
Epoch 58/60
 - 4s - loss: 0.9460 - acc: 0.6919 - val_loss: 0.7573 - val_acc: 0.7284

Epoch 00058: val_loss improved from 0.76318 to 0.75727, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 59/60
 - 4s - loss: 0.9381 - acc: 0.6954 - val_loss: 0.7725 - val_acc: 0.7237

Epoch 00059: val_loss did not improve from 0.75727
Epoch 60/60
 - 4s - loss: 0.9347 - acc: 0.6959 - val_loss: 0.7740 - val_acc: 0.7337

Epoch 00060: val_loss did not improve from 0.75727
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 2.3353 - acc: 0.5584 - val_loss: 1.7828 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 1.78276, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 2/60
 - 5s - loss: 1.5177 - acc: 0.6367 - val_loss: 1.5376 - val_acc: 0.6209

Epoch 00002: val_loss improved from 1.78276 to 1.53762, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 3/60
 - 5s - loss: 1.3805 - acc: 0.6370 - val_loss: 1.2459 - val_acc: 0.6446

Epoch 00003: val_loss improved from 1.53762 to 1.24594, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 4/60
 - 5s - loss: 1.2641 - acc: 0.6445 - val_loss: 1.2228 - val_acc: 0.6608

Epoch 00004: val_loss improved from 1.24594 to 1.22276, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 5/60
 - 5s - loss: 1.1901 - acc: 0.6524 - val_loss: 1.1411 - val_acc: 0.6631

Epoch 00005: val_loss improved from 1.22276 to 1.14115, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 6/60
 - 5s - loss: 1.1485 - acc: 0.6596 - val_loss: 1.0503 - val_acc: 0.6702

Epoch 00006: val_loss improved from 1.14115 to 1.05032, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 7/60
 - 5s - loss: 1.1109 - acc: 0.6653 - val_loss: 0.9993 - val_acc: 0.6843

Epoch 00007: val_loss improved from 1.05032 to 0.99927, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 8/60
 - 5s - loss: 1.0836 - acc: 0.6720 - val_loss: 1.0173 - val_acc: 0.6865

Epoch 00008: val_loss did not improve from 0.99927
Epoch 9/60
 - 5s - loss: 1.0528 - acc: 0.6759 - val_loss: 0.9323 - val_acc: 0.6912

Epoch 00009: val_loss improved from 0.99927 to 0.93232, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 10/60
 - 5s - loss: 1.0333 - acc: 0.6776 - val_loss: 0.9418 - val_acc: 0.6980

Epoch 00010: val_loss did not improve from 0.93232
Epoch 11/60
 - 5s - loss: 1.0075 - acc: 0.6826 - val_loss: 0.8791 - val_acc: 0.7014

Epoch 00011: val_loss improved from 0.93232 to 0.87911, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 12/60
 - 5s - loss: 0.9869 - acc: 0.6848 - val_loss: 0.8943 - val_acc: 0.7048

Epoch 00012: val_loss did not improve from 0.87911
Epoch 13/60
 - 5s - loss: 0.9702 - acc: 0.6881 - val_loss: 0.8256 - val_acc: 0.7139

Epoch 00013: val_loss improved from 0.87911 to 0.82559, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 14/60
 - 5s - loss: 0.9467 - acc: 0.6934 - val_loss: 0.8074 - val_acc: 0.7268

Epoch 00014: val_loss improved from 0.82559 to 0.80745, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 15/60
 - 5s - loss: 0.9332 - acc: 0.6952 - val_loss: 0.7745 - val_acc: 0.7343

Epoch 00015: val_loss improved from 0.80745 to 0.77451, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 16/60
 - 5s - loss: 0.9161 - acc: 0.7024 - val_loss: 0.8011 - val_acc: 0.7367

Epoch 00016: val_loss did not improve from 0.77451
Epoch 17/60
 - 5s - loss: 0.8993 - acc: 0.7067 - val_loss: 0.7335 - val_acc: 0.7526

Epoch 00017: val_loss improved from 0.77451 to 0.73354, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 18/60
 - 5s - loss: 0.8816 - acc: 0.7120 - val_loss: 0.7300 - val_acc: 0.7579

Epoch 00018: val_loss improved from 0.73354 to 0.73004, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 19/60
 - 5s - loss: 0.8656 - acc: 0.7158 - val_loss: 0.6976 - val_acc: 0.7563

Epoch 00019: val_loss improved from 0.73004 to 0.69763, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 20/60
 - 5s - loss: 0.8520 - acc: 0.7196 - val_loss: 0.6664 - val_acc: 0.7730

Epoch 00020: val_loss improved from 0.69763 to 0.66641, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 21/60
 - 5s - loss: 0.8360 - acc: 0.7243 - val_loss: 0.6706 - val_acc: 0.7726

Epoch 00021: val_loss did not improve from 0.66641
Epoch 22/60
 - 5s - loss: 0.8209 - acc: 0.7294 - val_loss: 0.6580 - val_acc: 0.7783

Epoch 00022: val_loss improved from 0.66641 to 0.65802, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 23/60
 - 5s - loss: 0.8116 - acc: 0.7330 - val_loss: 0.6321 - val_acc: 0.7879

Epoch 00023: val_loss improved from 0.65802 to 0.63215, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 24/60
 - 5s - loss: 0.8028 - acc: 0.7378 - val_loss: 0.6250 - val_acc: 0.7898

Epoch 00024: val_loss improved from 0.63215 to 0.62503, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 25/60
 - 5s - loss: 0.7923 - acc: 0.7403 - val_loss: 0.6217 - val_acc: 0.7848

Epoch 00025: val_loss improved from 0.62503 to 0.62171, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 26/60
 - 5s - loss: 0.7813 - acc: 0.7447 - val_loss: 0.6167 - val_acc: 0.7932

Epoch 00026: val_loss improved from 0.62171 to 0.61674, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 27/60
 - 5s - loss: 0.7756 - acc: 0.7448 - val_loss: 0.5977 - val_acc: 0.7954

Epoch 00027: val_loss improved from 0.61674 to 0.59771, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 28/60
 - 5s - loss: 0.7693 - acc: 0.7483 - val_loss: 0.6009 - val_acc: 0.7988

Epoch 00028: val_loss did not improve from 0.59771
Epoch 29/60
 - 5s - loss: 0.7613 - acc: 0.7493 - val_loss: 0.5957 - val_acc: 0.7983

Epoch 00029: val_loss improved from 0.59771 to 0.59572, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 30/60
 - 5s - loss: 0.7556 - acc: 0.7516 - val_loss: 0.5771 - val_acc: 0.8052

Epoch 00030: val_loss improved from 0.59572 to 0.57714, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 31/60
 - 5s - loss: 0.7498 - acc: 0.7518 - val_loss: 0.5784 - val_acc: 0.8089

Epoch 00031: val_loss did not improve from 0.57714
Epoch 32/60
 - 5s - loss: 0.7444 - acc: 0.7558 - val_loss: 0.5783 - val_acc: 0.7992

Epoch 00032: val_loss did not improve from 0.57714
Epoch 33/60
 - 5s - loss: 0.7389 - acc: 0.7578 - val_loss: 0.5772 - val_acc: 0.8060

Epoch 00033: val_loss did not improve from 0.57714
Epoch 34/60
 - 5s - loss: 0.7224 - acc: 0.7607 - val_loss: 0.5548 - val_acc: 0.8089

Epoch 00034: val_loss improved from 0.57714 to 0.55478, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 35/60
 - 5s - loss: 0.7234 - acc: 0.7625 - val_loss: 0.5777 - val_acc: 0.8099

Epoch 00035: val_loss did not improve from 0.55478
Epoch 36/60
 - 5s - loss: 0.7229 - acc: 0.7616 - val_loss: 0.5528 - val_acc: 0.8114

Epoch 00036: val_loss improved from 0.55478 to 0.55278, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 37/60
 - 5s - loss: 0.7215 - acc: 0.7634 - val_loss: 0.5600 - val_acc: 0.8085

Epoch 00037: val_loss did not improve from 0.55278
Epoch 38/60
 - 5s - loss: 0.7093 - acc: 0.7664 - val_loss: 0.5429 - val_acc: 0.8174

Epoch 00038: val_loss improved from 0.55278 to 0.54290, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 39/60
 - 5s - loss: 0.7065 - acc: 0.7705 - val_loss: 0.5406 - val_acc: 0.8173

Epoch 00039: val_loss improved from 0.54290 to 0.54059, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 40/60
 - 5s - loss: 0.7052 - acc: 0.7684 - val_loss: 0.5458 - val_acc: 0.8157

Epoch 00040: val_loss did not improve from 0.54059
Epoch 41/60
 - 5s - loss: 0.6957 - acc: 0.7713 - val_loss: 0.5345 - val_acc: 0.8217

Epoch 00041: val_loss improved from 0.54059 to 0.53450, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 42/60
 - 5s - loss: 0.7030 - acc: 0.7696 - val_loss: 0.5331 - val_acc: 0.8207

Epoch 00042: val_loss improved from 0.53450 to 0.53307, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 43/60
 - 5s - loss: 0.6968 - acc: 0.7708 - val_loss: 0.5460 - val_acc: 0.8202

Epoch 00043: val_loss did not improve from 0.53307
Epoch 44/60
 - 5s - loss: 0.6934 - acc: 0.7751 - val_loss: 0.5205 - val_acc: 0.8260

Epoch 00044: val_loss improved from 0.53307 to 0.52054, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 45/60
 - 5s - loss: 0.6843 - acc: 0.7760 - val_loss: 0.5238 - val_acc: 0.8297

Epoch 00045: val_loss did not improve from 0.52054
Epoch 46/60
 - 5s - loss: 0.6838 - acc: 0.7750 - val_loss: 0.5159 - val_acc: 0.8251

Epoch 00046: val_loss improved from 0.52054 to 0.51588, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 47/60
 - 5s - loss: 0.6754 - acc: 0.7788 - val_loss: 0.5135 - val_acc: 0.8285

Epoch 00047: val_loss improved from 0.51588 to 0.51354, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 48/60
 - 5s - loss: 0.6727 - acc: 0.7797 - val_loss: 0.5108 - val_acc: 0.8270

Epoch 00048: val_loss improved from 0.51354 to 0.51075, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 49/60
 - 5s - loss: 0.6721 - acc: 0.7799 - val_loss: 0.5089 - val_acc: 0.8326

Epoch 00049: val_loss improved from 0.51075 to 0.50887, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 50/60
 - 5s - loss: 0.6708 - acc: 0.7814 - val_loss: 0.5060 - val_acc: 0.8314

Epoch 00050: val_loss improved from 0.50887 to 0.50603, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 51/60
 - 5s - loss: 0.6706 - acc: 0.7822 - val_loss: 0.4995 - val_acc: 0.8336

Epoch 00051: val_loss improved from 0.50603 to 0.49948, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 52/60
 - 5s - loss: 0.6640 - acc: 0.7838 - val_loss: 0.5052 - val_acc: 0.8310

Epoch 00052: val_loss did not improve from 0.49948
Epoch 53/60
 - 5s - loss: 0.6641 - acc: 0.7828 - val_loss: 0.4997 - val_acc: 0.8326

Epoch 00053: val_loss did not improve from 0.49948
Epoch 54/60
 - 5s - loss: 0.6682 - acc: 0.7831 - val_loss: 0.5064 - val_acc: 0.8307

Epoch 00054: val_loss did not improve from 0.49948
Epoch 55/60
 - 5s - loss: 0.6648 - acc: 0.7854 - val_loss: 0.4916 - val_acc: 0.8358

Epoch 00055: val_loss improved from 0.49948 to 0.49162, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 56/60
 - 5s - loss: 0.6598 - acc: 0.7862 - val_loss: 0.4896 - val_acc: 0.8377

Epoch 00056: val_loss improved from 0.49162 to 0.48964, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 57/60
 - 5s - loss: 0.6553 - acc: 0.7863 - val_loss: 0.4890 - val_acc: 0.8329

Epoch 00057: val_loss improved from 0.48964 to 0.48898, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 58/60
 - 5s - loss: 0.6547 - acc: 0.7856 - val_loss: 0.4853 - val_acc: 0.8388

Epoch 00058: val_loss improved from 0.48898 to 0.48528, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5
Epoch 59/60
 - 5s - loss: 0.6538 - acc: 0.7884 - val_loss: 0.4934 - val_acc: 0.8357

Epoch 00059: val_loss did not improve from 0.48528
Epoch 60/60
 - 5s - loss: 0.6492 - acc: 0.7887 - val_loss: 0.4953 - val_acc: 0.8342

Epoch 00060: val_loss did not improve from 0.48528
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 7s - loss: 2.3276 - acc: 0.5698 - val_loss: 1.1301 - val_acc: 0.6549

Epoch 00001: val_loss improved from inf to 1.13014, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 2/60
 - 5s - loss: 1.1345 - acc: 0.6577 - val_loss: 0.8817 - val_acc: 0.7243

Epoch 00002: val_loss improved from 1.13014 to 0.88174, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 3/60
 - 5s - loss: 0.9169 - acc: 0.7118 - val_loss: 0.7286 - val_acc: 0.7580

Epoch 00003: val_loss improved from 0.88174 to 0.72858, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 4/60
 - 5s - loss: 0.7825 - acc: 0.7519 - val_loss: 0.6468 - val_acc: 0.7836

Epoch 00004: val_loss improved from 0.72858 to 0.64685, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 5/60
 - 5s - loss: 0.7096 - acc: 0.7749 - val_loss: 0.6013 - val_acc: 0.8026

Epoch 00005: val_loss improved from 0.64685 to 0.60132, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 6/60
 - 5s - loss: 0.6488 - acc: 0.7942 - val_loss: 0.5922 - val_acc: 0.8105

Epoch 00006: val_loss improved from 0.60132 to 0.59216, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 7/60
 - 5s - loss: 0.6058 - acc: 0.8086 - val_loss: 0.5184 - val_acc: 0.8366

Epoch 00007: val_loss improved from 0.59216 to 0.51841, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 8/60
 - 5s - loss: 0.5738 - acc: 0.8175 - val_loss: 0.5231 - val_acc: 0.8322

Epoch 00008: val_loss did not improve from 0.51841
Epoch 9/60
 - 5s - loss: 0.5465 - acc: 0.8253 - val_loss: 0.5088 - val_acc: 0.8427

Epoch 00009: val_loss improved from 0.51841 to 0.50877, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 10/60
 - 5s - loss: 0.5258 - acc: 0.8318 - val_loss: 0.4978 - val_acc: 0.8427

Epoch 00010: val_loss improved from 0.50877 to 0.49781, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 11/60
 - 5s - loss: 0.5012 - acc: 0.8412 - val_loss: 0.4796 - val_acc: 0.8504

Epoch 00011: val_loss improved from 0.49781 to 0.47961, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 12/60
 - 5s - loss: 0.4903 - acc: 0.8432 - val_loss: 0.4847 - val_acc: 0.8547

Epoch 00012: val_loss did not improve from 0.47961
Epoch 13/60
 - 5s - loss: 0.4778 - acc: 0.8472 - val_loss: 0.4610 - val_acc: 0.8608

Epoch 00013: val_loss improved from 0.47961 to 0.46104, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 14/60
 - 5s - loss: 0.4601 - acc: 0.8507 - val_loss: 0.4413 - val_acc: 0.8650

Epoch 00014: val_loss improved from 0.46104 to 0.44129, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 15/60
 - 5s - loss: 0.4533 - acc: 0.8533 - val_loss: 0.4901 - val_acc: 0.8551

Epoch 00015: val_loss did not improve from 0.44129
Epoch 16/60
 - 5s - loss: 0.4387 - acc: 0.8594 - val_loss: 0.4313 - val_acc: 0.8691

Epoch 00016: val_loss improved from 0.44129 to 0.43125, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 17/60
 - 5s - loss: 0.4289 - acc: 0.8619 - val_loss: 0.4153 - val_acc: 0.8758

Epoch 00017: val_loss improved from 0.43125 to 0.41528, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 18/60
 - 5s - loss: 0.4181 - acc: 0.8657 - val_loss: 0.4298 - val_acc: 0.8670

Epoch 00018: val_loss did not improve from 0.41528
Epoch 19/60
 - 5s - loss: 0.4138 - acc: 0.8656 - val_loss: 0.4224 - val_acc: 0.8679

Epoch 00019: val_loss did not improve from 0.41528
Epoch 20/60
 - 5s - loss: 0.4003 - acc: 0.8701 - val_loss: 0.4406 - val_acc: 0.8614

Epoch 00020: val_loss did not improve from 0.41528
Epoch 21/60
 - 5s - loss: 0.3982 - acc: 0.8707 - val_loss: 0.4023 - val_acc: 0.8726

Epoch 00021: val_loss improved from 0.41528 to 0.40230, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 22/60
 - 5s - loss: 0.3912 - acc: 0.8743 - val_loss: 0.4087 - val_acc: 0.8711

Epoch 00022: val_loss did not improve from 0.40230
Epoch 23/60
 - 5s - loss: 0.3863 - acc: 0.8745 - val_loss: 0.3888 - val_acc: 0.8810

Epoch 00023: val_loss improved from 0.40230 to 0.38875, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 24/60
 - 5s - loss: 0.3804 - acc: 0.8773 - val_loss: 0.3890 - val_acc: 0.8781

Epoch 00024: val_loss did not improve from 0.38875
Epoch 25/60
 - 5s - loss: 0.3695 - acc: 0.8805 - val_loss: 0.3802 - val_acc: 0.8847

Epoch 00025: val_loss improved from 0.38875 to 0.38024, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 26/60
 - 5s - loss: 0.3759 - acc: 0.8787 - val_loss: 0.4004 - val_acc: 0.8800

Epoch 00026: val_loss did not improve from 0.38024
Epoch 27/60
 - 5s - loss: 0.3732 - acc: 0.8789 - val_loss: 0.4338 - val_acc: 0.8725

Epoch 00027: val_loss did not improve from 0.38024
Epoch 28/60
 - 5s - loss: 0.3645 - acc: 0.8821 - val_loss: 0.3847 - val_acc: 0.8817

Epoch 00028: val_loss did not improve from 0.38024
Epoch 29/60
 - 5s - loss: 0.3640 - acc: 0.8828 - val_loss: 0.3842 - val_acc: 0.8813

Epoch 00029: val_loss did not improve from 0.38024
Epoch 30/60
 - 5s - loss: 0.3629 - acc: 0.8828 - val_loss: 0.3788 - val_acc: 0.8806

Epoch 00030: val_loss improved from 0.38024 to 0.37876, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 31/60
 - 5s - loss: 0.3504 - acc: 0.8866 - val_loss: 0.4211 - val_acc: 0.8745

Epoch 00031: val_loss did not improve from 0.37876
Epoch 32/60
 - 5s - loss: 0.3480 - acc: 0.8866 - val_loss: 0.3891 - val_acc: 0.8820

Epoch 00032: val_loss did not improve from 0.37876
Epoch 33/60
 - 5s - loss: 0.3428 - acc: 0.8875 - val_loss: 0.3849 - val_acc: 0.8810

Epoch 00033: val_loss did not improve from 0.37876
Epoch 34/60
 - 5s - loss: 0.3395 - acc: 0.8896 - val_loss: 0.3782 - val_acc: 0.8878

Epoch 00034: val_loss improved from 0.37876 to 0.37815, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 35/60
 - 5s - loss: 0.3372 - acc: 0.8906 - val_loss: 0.3930 - val_acc: 0.8817

Epoch 00035: val_loss did not improve from 0.37815
Epoch 36/60
 - 5s - loss: 0.3408 - acc: 0.8912 - val_loss: 0.3768 - val_acc: 0.8825

Epoch 00036: val_loss improved from 0.37815 to 0.37677, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 37/60
 - 5s - loss: 0.3380 - acc: 0.8887 - val_loss: 0.3878 - val_acc: 0.8851

Epoch 00037: val_loss did not improve from 0.37677
Epoch 38/60
 - 5s - loss: 0.3340 - acc: 0.8916 - val_loss: 0.3826 - val_acc: 0.8847

Epoch 00038: val_loss did not improve from 0.37677
Epoch 39/60
 - 5s - loss: 0.3328 - acc: 0.8929 - val_loss: 0.3687 - val_acc: 0.8867

Epoch 00039: val_loss improved from 0.37677 to 0.36871, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 40/60
 - 5s - loss: 0.3254 - acc: 0.8940 - val_loss: 0.3796 - val_acc: 0.8860

Epoch 00040: val_loss did not improve from 0.36871
Epoch 41/60
 - 5s - loss: 0.3290 - acc: 0.8919 - val_loss: 0.3917 - val_acc: 0.8835

Epoch 00041: val_loss did not improve from 0.36871
Epoch 42/60
 - 5s - loss: 0.3245 - acc: 0.8939 - val_loss: 0.3679 - val_acc: 0.8878

Epoch 00042: val_loss improved from 0.36871 to 0.36792, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 43/60
 - 5s - loss: 0.3234 - acc: 0.8939 - val_loss: 0.3670 - val_acc: 0.8863

Epoch 00043: val_loss improved from 0.36792 to 0.36704, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 44/60
 - 5s - loss: 0.3193 - acc: 0.8955 - val_loss: 0.3661 - val_acc: 0.8869

Epoch 00044: val_loss improved from 0.36704 to 0.36615, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 45/60
 - 5s - loss: 0.3228 - acc: 0.8944 - val_loss: 0.3738 - val_acc: 0.8881

Epoch 00045: val_loss did not improve from 0.36615
Epoch 46/60
 - 5s - loss: 0.3153 - acc: 0.8961 - val_loss: 0.3720 - val_acc: 0.8906

Epoch 00046: val_loss did not improve from 0.36615
Epoch 47/60
 - 5s - loss: 0.3153 - acc: 0.8973 - val_loss: 0.3863 - val_acc: 0.8833

Epoch 00047: val_loss did not improve from 0.36615
Epoch 48/60
 - 5s - loss: 0.3124 - acc: 0.8967 - val_loss: 0.3679 - val_acc: 0.8910

Epoch 00048: val_loss did not improve from 0.36615
Epoch 49/60
 - 5s - loss: 0.3064 - acc: 0.8992 - val_loss: 0.3578 - val_acc: 0.8891

Epoch 00049: val_loss improved from 0.36615 to 0.35783, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5
Epoch 50/60
 - 5s - loss: 0.3103 - acc: 0.8991 - val_loss: 0.3858 - val_acc: 0.8842

Epoch 00050: val_loss did not improve from 0.35783
Epoch 51/60
 - 5s - loss: 0.3119 - acc: 0.8981 - val_loss: 0.3806 - val_acc: 0.8875

Epoch 00051: val_loss did not improve from 0.35783
Epoch 52/60
 - 5s - loss: 0.3073 - acc: 0.8988 - val_loss: 0.3795 - val_acc: 0.8825

Epoch 00052: val_loss did not improve from 0.35783
Epoch 53/60
 - 5s - loss: 0.3065 - acc: 0.9006 - val_loss: 0.3824 - val_acc: 0.8813

Epoch 00053: val_loss did not improve from 0.35783
Epoch 54/60
 - 5s - loss: 0.3047 - acc: 0.8999 - val_loss: 0.3949 - val_acc: 0.8833

Epoch 00054: val_loss did not improve from 0.35783
Epoch 55/60
 - 5s - loss: 0.3080 - acc: 0.8997 - val_loss: 0.3689 - val_acc: 0.8894

Epoch 00055: val_loss did not improve from 0.35783
Epoch 56/60
 - 5s - loss: 0.3073 - acc: 0.8992 - val_loss: 0.3653 - val_acc: 0.8878

Epoch 00056: val_loss did not improve from 0.35783
Epoch 57/60
 - 5s - loss: 0.3023 - acc: 0.9001 - val_loss: 0.3701 - val_acc: 0.8832

Epoch 00057: val_loss did not improve from 0.35783
Epoch 58/60
 - 5s - loss: 0.3012 - acc: 0.9016 - val_loss: 0.3780 - val_acc: 0.8854

Epoch 00058: val_loss did not improve from 0.35783
Epoch 59/60
 - 5s - loss: 0.3009 - acc: 0.9002 - val_loss: 0.3851 - val_acc: 0.8847

Epoch 00059: val_loss did not improve from 0.35783
Epoch 00059: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 7s - loss: 3.0659 - acc: 0.3395 - val_loss: 1.8391 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 1.83905, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 2/60
 - 4s - loss: 1.7055 - acc: 0.6155 - val_loss: 1.6137 - val_acc: 0.6209

Epoch 00002: val_loss improved from 1.83905 to 1.61369, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 3/60
 - 4s - loss: 1.5799 - acc: 0.6350 - val_loss: 1.4933 - val_acc: 0.6209

Epoch 00003: val_loss improved from 1.61369 to 1.49333, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 4/60
 - 4s - loss: 1.5230 - acc: 0.6369 - val_loss: 1.5348 - val_acc: 0.6209

Epoch 00004: val_loss did not improve from 1.49333
Epoch 5/60
 - 4s - loss: 1.4767 - acc: 0.6371 - val_loss: 1.4189 - val_acc: 0.6211

Epoch 00005: val_loss improved from 1.49333 to 1.41889, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 6/60
 - 4s - loss: 1.4281 - acc: 0.6379 - val_loss: 1.4012 - val_acc: 0.6222

Epoch 00006: val_loss improved from 1.41889 to 1.40117, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 7/60
 - 4s - loss: 1.3909 - acc: 0.6381 - val_loss: 1.3777 - val_acc: 0.6231

Epoch 00007: val_loss improved from 1.40117 to 1.37766, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 8/60
 - 4s - loss: 1.3695 - acc: 0.6384 - val_loss: 1.3579 - val_acc: 0.6269

Epoch 00008: val_loss improved from 1.37766 to 1.35790, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 9/60
 - 4s - loss: 1.3459 - acc: 0.6398 - val_loss: 1.2988 - val_acc: 0.6222

Epoch 00009: val_loss improved from 1.35790 to 1.29878, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 10/60
 - 4s - loss: 1.3291 - acc: 0.6402 - val_loss: 1.2794 - val_acc: 0.6268

Epoch 00010: val_loss improved from 1.29878 to 1.27941, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 11/60
 - 4s - loss: 1.3135 - acc: 0.6403 - val_loss: 1.2653 - val_acc: 0.6287

Epoch 00011: val_loss improved from 1.27941 to 1.26527, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 12/60
 - 4s - loss: 1.3007 - acc: 0.6422 - val_loss: 1.2735 - val_acc: 0.6256

Epoch 00012: val_loss did not improve from 1.26527
Epoch 13/60
 - 4s - loss: 1.2882 - acc: 0.6416 - val_loss: 1.2405 - val_acc: 0.6259

Epoch 00013: val_loss improved from 1.26527 to 1.24051, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 14/60
 - 4s - loss: 1.2720 - acc: 0.6421 - val_loss: 1.2243 - val_acc: 0.6315

Epoch 00014: val_loss improved from 1.24051 to 1.22433, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 15/60
 - 5s - loss: 1.2605 - acc: 0.6430 - val_loss: 1.2357 - val_acc: 0.6305

Epoch 00015: val_loss did not improve from 1.22433
Epoch 16/60
 - 4s - loss: 1.2484 - acc: 0.6429 - val_loss: 1.1979 - val_acc: 0.6262

Epoch 00016: val_loss improved from 1.22433 to 1.19794, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 17/60
 - 4s - loss: 1.2410 - acc: 0.6437 - val_loss: 1.2010 - val_acc: 0.6302

Epoch 00017: val_loss did not improve from 1.19794
Epoch 18/60
 - 4s - loss: 1.2306 - acc: 0.6445 - val_loss: 1.1999 - val_acc: 0.6343

Epoch 00018: val_loss did not improve from 1.19794
Epoch 19/60
 - 4s - loss: 1.2186 - acc: 0.6451 - val_loss: 1.1567 - val_acc: 0.6352

Epoch 00019: val_loss improved from 1.19794 to 1.15671, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 20/60
 - 4s - loss: 1.2118 - acc: 0.6450 - val_loss: 1.1691 - val_acc: 0.6343

Epoch 00020: val_loss did not improve from 1.15671
Epoch 21/60
 - 4s - loss: 1.2013 - acc: 0.6468 - val_loss: 1.1310 - val_acc: 0.6367

Epoch 00021: val_loss improved from 1.15671 to 1.13104, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 22/60
 - 4s - loss: 1.1932 - acc: 0.6476 - val_loss: 1.1227 - val_acc: 0.6380

Epoch 00022: val_loss improved from 1.13104 to 1.12266, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 23/60
 - 4s - loss: 1.1763 - acc: 0.6499 - val_loss: 1.1063 - val_acc: 0.6421

Epoch 00023: val_loss improved from 1.12266 to 1.10631, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 24/60
 - 4s - loss: 1.1739 - acc: 0.6496 - val_loss: 1.0977 - val_acc: 0.6465

Epoch 00024: val_loss improved from 1.10631 to 1.09774, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 25/60
 - 4s - loss: 1.1600 - acc: 0.6511 - val_loss: 1.0986 - val_acc: 0.6471

Epoch 00025: val_loss did not improve from 1.09774
Epoch 26/60
 - 4s - loss: 1.1538 - acc: 0.6511 - val_loss: 1.0964 - val_acc: 0.6531

Epoch 00026: val_loss improved from 1.09774 to 1.09638, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 27/60
 - 4s - loss: 1.1406 - acc: 0.6533 - val_loss: 1.0685 - val_acc: 0.6471

Epoch 00027: val_loss improved from 1.09638 to 1.06853, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 28/60
 - 4s - loss: 1.1314 - acc: 0.6550 - val_loss: 1.0497 - val_acc: 0.6512

Epoch 00028: val_loss improved from 1.06853 to 1.04969, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 29/60
 - 4s - loss: 1.1247 - acc: 0.6559 - val_loss: 1.0250 - val_acc: 0.6558

Epoch 00029: val_loss improved from 1.04969 to 1.02500, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 30/60
 - 4s - loss: 1.1156 - acc: 0.6575 - val_loss: 1.0187 - val_acc: 0.6600

Epoch 00030: val_loss improved from 1.02500 to 1.01874, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 31/60
 - 4s - loss: 1.1087 - acc: 0.6585 - val_loss: 0.9945 - val_acc: 0.6578

Epoch 00031: val_loss improved from 1.01874 to 0.99452, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 32/60
 - 4s - loss: 1.0960 - acc: 0.6605 - val_loss: 1.0178 - val_acc: 0.6608

Epoch 00032: val_loss did not improve from 0.99452
Epoch 33/60
 - 4s - loss: 1.0923 - acc: 0.6609 - val_loss: 0.9780 - val_acc: 0.6611

Epoch 00033: val_loss improved from 0.99452 to 0.97799, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 34/60
 - 4s - loss: 1.0816 - acc: 0.6628 - val_loss: 0.9493 - val_acc: 0.6687

Epoch 00034: val_loss improved from 0.97799 to 0.94925, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 35/60
 - 4s - loss: 1.0773 - acc: 0.6625 - val_loss: 0.9554 - val_acc: 0.6667

Epoch 00035: val_loss did not improve from 0.94925
Epoch 36/60
 - 4s - loss: 1.0675 - acc: 0.6645 - val_loss: 0.9325 - val_acc: 0.6749

Epoch 00036: val_loss improved from 0.94925 to 0.93246, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 37/60
 - 4s - loss: 1.0623 - acc: 0.6660 - val_loss: 0.9211 - val_acc: 0.6770

Epoch 00037: val_loss improved from 0.93246 to 0.92106, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 38/60
 - 4s - loss: 1.0497 - acc: 0.6687 - val_loss: 0.9261 - val_acc: 0.6715

Epoch 00038: val_loss did not improve from 0.92106
Epoch 39/60
 - 4s - loss: 1.0461 - acc: 0.6670 - val_loss: 0.9074 - val_acc: 0.6753

Epoch 00039: val_loss improved from 0.92106 to 0.90737, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 40/60
 - 4s - loss: 1.0369 - acc: 0.6700 - val_loss: 0.9084 - val_acc: 0.6728

Epoch 00040: val_loss did not improve from 0.90737
Epoch 41/60
 - 4s - loss: 1.0303 - acc: 0.6693 - val_loss: 0.9222 - val_acc: 0.6846

Epoch 00041: val_loss did not improve from 0.90737
Epoch 42/60
 - 4s - loss: 1.0223 - acc: 0.6721 - val_loss: 0.8789 - val_acc: 0.6846

Epoch 00042: val_loss improved from 0.90737 to 0.87885, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 43/60
 - 4s - loss: 1.0255 - acc: 0.6720 - val_loss: 0.8684 - val_acc: 0.6820

Epoch 00043: val_loss improved from 0.87885 to 0.86838, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 44/60
 - 4s - loss: 1.0135 - acc: 0.6739 - val_loss: 0.8707 - val_acc: 0.6946

Epoch 00044: val_loss did not improve from 0.86838
Epoch 45/60
 - 4s - loss: 1.0052 - acc: 0.6776 - val_loss: 0.8604 - val_acc: 0.6942

Epoch 00045: val_loss improved from 0.86838 to 0.86043, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 46/60
 - 4s - loss: 1.0041 - acc: 0.6754 - val_loss: 0.8519 - val_acc: 0.6952

Epoch 00046: val_loss improved from 0.86043 to 0.85192, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 47/60
 - 4s - loss: 0.9998 - acc: 0.6792 - val_loss: 0.8351 - val_acc: 0.6979

Epoch 00047: val_loss improved from 0.85192 to 0.83514, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 48/60
 - 4s - loss: 0.9949 - acc: 0.6812 - val_loss: 0.8280 - val_acc: 0.6970

Epoch 00048: val_loss improved from 0.83514 to 0.82801, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 49/60
 - 4s - loss: 0.9869 - acc: 0.6832 - val_loss: 0.8440 - val_acc: 0.6955

Epoch 00049: val_loss did not improve from 0.82801
Epoch 50/60
 - 4s - loss: 0.9851 - acc: 0.6843 - val_loss: 0.8286 - val_acc: 0.7049

Epoch 00050: val_loss did not improve from 0.82801
Epoch 51/60
 - 4s - loss: 0.9757 - acc: 0.6858 - val_loss: 0.8513 - val_acc: 0.7065

Epoch 00051: val_loss did not improve from 0.82801
Epoch 52/60
 - 4s - loss: 0.9797 - acc: 0.6848 - val_loss: 0.8659 - val_acc: 0.6977

Epoch 00052: val_loss did not improve from 0.82801
Epoch 53/60
 - 4s - loss: 0.9743 - acc: 0.6858 - val_loss: 0.8401 - val_acc: 0.6905

Epoch 00053: val_loss did not improve from 0.82801
Epoch 54/60
 - 4s - loss: 0.9667 - acc: 0.6872 - val_loss: 0.8117 - val_acc: 0.7161

Epoch 00054: val_loss improved from 0.82801 to 0.81166, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 55/60
 - 4s - loss: 0.9603 - acc: 0.6906 - val_loss: 0.7933 - val_acc: 0.7192

Epoch 00055: val_loss improved from 0.81166 to 0.79328, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 56/60
 - 4s - loss: 0.9610 - acc: 0.6894 - val_loss: 0.7734 - val_acc: 0.7254

Epoch 00056: val_loss improved from 0.79328 to 0.77336, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5
Epoch 57/60
 - 4s - loss: 0.9587 - acc: 0.6913 - val_loss: 0.7954 - val_acc: 0.7168

Epoch 00057: val_loss did not improve from 0.77336
Epoch 58/60
 - 4s - loss: 0.9509 - acc: 0.6915 - val_loss: 0.8338 - val_acc: 0.7084

Epoch 00058: val_loss did not improve from 0.77336
Epoch 59/60
 - 4s - loss: 0.9492 - acc: 0.6931 - val_loss: 0.7865 - val_acc: 0.7223

Epoch 00059: val_loss did not improve from 0.77336
Epoch 60/60
 - 4s - loss: 0.9451 - acc: 0.6944 - val_loss: 0.7871 - val_acc: 0.7212

Epoch 00060: val_loss did not improve from 0.77336
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 1.8566 - acc: 0.5879 - val_loss: 1.7237 - val_acc: 0.6214

Epoch 00001: val_loss improved from inf to 1.72375, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 2/60
 - 5s - loss: 1.4527 - acc: 0.6350 - val_loss: 1.4979 - val_acc: 0.6287

Epoch 00002: val_loss improved from 1.72375 to 1.49792, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 3/60
 - 5s - loss: 1.3451 - acc: 0.6374 - val_loss: 1.3677 - val_acc: 0.6392

Epoch 00003: val_loss improved from 1.49792 to 1.36771, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 4/60
 - 5s - loss: 1.2735 - acc: 0.6432 - val_loss: 1.2524 - val_acc: 0.6525

Epoch 00004: val_loss improved from 1.36771 to 1.25241, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 5/60
 - 5s - loss: 1.2148 - acc: 0.6510 - val_loss: 1.1594 - val_acc: 0.6659

Epoch 00005: val_loss improved from 1.25241 to 1.15941, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 6/60
 - 5s - loss: 1.1749 - acc: 0.6570 - val_loss: 1.0687 - val_acc: 0.6643

Epoch 00006: val_loss improved from 1.15941 to 1.06867, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 7/60
 - 5s - loss: 1.1355 - acc: 0.6632 - val_loss: 1.1065 - val_acc: 0.6720

Epoch 00007: val_loss did not improve from 1.06867
Epoch 8/60
 - 5s - loss: 1.1087 - acc: 0.6667 - val_loss: 1.0527 - val_acc: 0.6815

Epoch 00008: val_loss improved from 1.06867 to 1.05273, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 9/60
 - 5s - loss: 1.0845 - acc: 0.6694 - val_loss: 1.0017 - val_acc: 0.6818

Epoch 00009: val_loss improved from 1.05273 to 1.00173, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 10/60
 - 5s - loss: 1.0565 - acc: 0.6753 - val_loss: 0.9376 - val_acc: 0.6812

Epoch 00010: val_loss improved from 1.00173 to 0.93757, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 11/60
 - 5s - loss: 1.0363 - acc: 0.6757 - val_loss: 0.9281 - val_acc: 0.6878

Epoch 00011: val_loss improved from 0.93757 to 0.92812, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 12/60
 - 5s - loss: 1.0180 - acc: 0.6790 - val_loss: 0.9079 - val_acc: 0.6873

Epoch 00012: val_loss improved from 0.92812 to 0.90792, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 13/60
 - 5s - loss: 0.9994 - acc: 0.6824 - val_loss: 0.8638 - val_acc: 0.6967

Epoch 00013: val_loss improved from 0.90792 to 0.86382, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 14/60
 - 5s - loss: 0.9790 - acc: 0.6879 - val_loss: 0.8610 - val_acc: 0.7036

Epoch 00014: val_loss improved from 0.86382 to 0.86105, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 15/60
 - 5s - loss: 0.9624 - acc: 0.6907 - val_loss: 0.8507 - val_acc: 0.7212

Epoch 00015: val_loss improved from 0.86105 to 0.85065, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 16/60
 - 5s - loss: 0.9484 - acc: 0.6951 - val_loss: 0.8055 - val_acc: 0.7227

Epoch 00016: val_loss improved from 0.85065 to 0.80546, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 17/60
 - 5s - loss: 0.9264 - acc: 0.6989 - val_loss: 0.8581 - val_acc: 0.7308

Epoch 00017: val_loss did not improve from 0.80546
Epoch 18/60
 - 5s - loss: 0.9162 - acc: 0.7020 - val_loss: 0.7669 - val_acc: 0.7390

Epoch 00018: val_loss improved from 0.80546 to 0.76686, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 19/60
 - 5s - loss: 0.8950 - acc: 0.7081 - val_loss: 0.7772 - val_acc: 0.7449

Epoch 00019: val_loss did not improve from 0.76686
Epoch 20/60
 - 5s - loss: 0.8846 - acc: 0.7114 - val_loss: 0.7506 - val_acc: 0.7567

Epoch 00020: val_loss improved from 0.76686 to 0.75063, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 21/60
 - 5s - loss: 0.8708 - acc: 0.7140 - val_loss: 0.7231 - val_acc: 0.7627

Epoch 00021: val_loss improved from 0.75063 to 0.72314, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 22/60
 - 5s - loss: 0.8522 - acc: 0.7215 - val_loss: 0.7102 - val_acc: 0.7648

Epoch 00022: val_loss improved from 0.72314 to 0.71022, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 23/60
 - 5s - loss: 0.8475 - acc: 0.7230 - val_loss: 0.6844 - val_acc: 0.7668

Epoch 00023: val_loss improved from 0.71022 to 0.68438, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 24/60
 - 5s - loss: 0.8397 - acc: 0.7266 - val_loss: 0.6808 - val_acc: 0.7802

Epoch 00024: val_loss improved from 0.68438 to 0.68085, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 25/60
 - 5s - loss: 0.8228 - acc: 0.7297 - val_loss: 0.6796 - val_acc: 0.7779

Epoch 00025: val_loss improved from 0.68085 to 0.67961, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 26/60
 - 5s - loss: 0.8130 - acc: 0.7342 - val_loss: 0.6625 - val_acc: 0.7798

Epoch 00026: val_loss improved from 0.67961 to 0.66251, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 27/60
 - 5s - loss: 0.7989 - acc: 0.7368 - val_loss: 0.6499 - val_acc: 0.7857

Epoch 00027: val_loss improved from 0.66251 to 0.64995, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 28/60
 - 5s - loss: 0.7896 - acc: 0.7397 - val_loss: 0.6295 - val_acc: 0.7916

Epoch 00028: val_loss improved from 0.64995 to 0.62951, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 29/60
 - 5s - loss: 0.7850 - acc: 0.7426 - val_loss: 0.6305 - val_acc: 0.7913

Epoch 00029: val_loss did not improve from 0.62951
Epoch 30/60
 - 5s - loss: 0.7733 - acc: 0.7438 - val_loss: 0.6204 - val_acc: 0.7951

Epoch 00030: val_loss improved from 0.62951 to 0.62039, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 31/60
 - 5s - loss: 0.7653 - acc: 0.7471 - val_loss: 0.6285 - val_acc: 0.7891

Epoch 00031: val_loss did not improve from 0.62039
Epoch 32/60
 - 5s - loss: 0.7631 - acc: 0.7503 - val_loss: 0.6036 - val_acc: 0.7974

Epoch 00032: val_loss improved from 0.62039 to 0.60358, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 33/60
 - 5s - loss: 0.7588 - acc: 0.7509 - val_loss: 0.6013 - val_acc: 0.7951

Epoch 00033: val_loss improved from 0.60358 to 0.60132, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 34/60
 - 5s - loss: 0.7549 - acc: 0.7518 - val_loss: 0.5922 - val_acc: 0.7988

Epoch 00034: val_loss improved from 0.60132 to 0.59219, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 35/60
 - 5s - loss: 0.7433 - acc: 0.7553 - val_loss: 0.5927 - val_acc: 0.8035

Epoch 00035: val_loss did not improve from 0.59219
Epoch 36/60
 - 5s - loss: 0.7396 - acc: 0.7569 - val_loss: 0.5777 - val_acc: 0.8066

Epoch 00036: val_loss improved from 0.59219 to 0.57766, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 37/60
 - 5s - loss: 0.7295 - acc: 0.7597 - val_loss: 0.5753 - val_acc: 0.8061

Epoch 00037: val_loss improved from 0.57766 to 0.57534, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 38/60
 - 5s - loss: 0.7307 - acc: 0.7593 - val_loss: 0.5642 - val_acc: 0.8144

Epoch 00038: val_loss improved from 0.57534 to 0.56421, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 39/60
 - 5s - loss: 0.7247 - acc: 0.7617 - val_loss: 0.5663 - val_acc: 0.8141

Epoch 00039: val_loss did not improve from 0.56421
Epoch 40/60
 - 5s - loss: 0.7177 - acc: 0.7656 - val_loss: 0.5533 - val_acc: 0.8169

Epoch 00040: val_loss improved from 0.56421 to 0.55328, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 41/60
 - 5s - loss: 0.7134 - acc: 0.7666 - val_loss: 0.5685 - val_acc: 0.8176

Epoch 00041: val_loss did not improve from 0.55328
Epoch 42/60
 - 5s - loss: 0.7109 - acc: 0.7669 - val_loss: 0.5541 - val_acc: 0.8198

Epoch 00042: val_loss did not improve from 0.55328
Epoch 43/60
 - 5s - loss: 0.7079 - acc: 0.7674 - val_loss: 0.5515 - val_acc: 0.8242

Epoch 00043: val_loss improved from 0.55328 to 0.55153, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 44/60
 - 5s - loss: 0.7035 - acc: 0.7694 - val_loss: 0.5382 - val_acc: 0.8202

Epoch 00044: val_loss improved from 0.55153 to 0.53825, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 45/60
 - 5s - loss: 0.6983 - acc: 0.7732 - val_loss: 0.5302 - val_acc: 0.8272

Epoch 00045: val_loss improved from 0.53825 to 0.53019, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 46/60
 - 5s - loss: 0.6986 - acc: 0.7721 - val_loss: 0.5370 - val_acc: 0.8191

Epoch 00046: val_loss did not improve from 0.53019
Epoch 47/60
 - 5s - loss: 0.6903 - acc: 0.7735 - val_loss: 0.5258 - val_acc: 0.8238

Epoch 00047: val_loss improved from 0.53019 to 0.52583, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 48/60
 - 5s - loss: 0.6871 - acc: 0.7742 - val_loss: 0.5410 - val_acc: 0.8239

Epoch 00048: val_loss did not improve from 0.52583
Epoch 49/60
 - 5s - loss: 0.6882 - acc: 0.7743 - val_loss: 0.5249 - val_acc: 0.8261

Epoch 00049: val_loss improved from 0.52583 to 0.52495, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 50/60
 - 5s - loss: 0.6829 - acc: 0.7763 - val_loss: 0.5490 - val_acc: 0.8267

Epoch 00050: val_loss did not improve from 0.52495
Epoch 51/60
 - 5s - loss: 0.6807 - acc: 0.7758 - val_loss: 0.5226 - val_acc: 0.8295

Epoch 00051: val_loss improved from 0.52495 to 0.52256, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 52/60
 - 5s - loss: 0.6760 - acc: 0.7797 - val_loss: 0.5208 - val_acc: 0.8294

Epoch 00052: val_loss improved from 0.52256 to 0.52079, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 53/60
 - 5s - loss: 0.6785 - acc: 0.7807 - val_loss: 0.5127 - val_acc: 0.8319

Epoch 00053: val_loss improved from 0.52079 to 0.51270, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 54/60
 - 5s - loss: 0.6765 - acc: 0.7776 - val_loss: 0.5178 - val_acc: 0.8274

Epoch 00054: val_loss did not improve from 0.51270
Epoch 55/60
 - 5s - loss: 0.6767 - acc: 0.7788 - val_loss: 0.5108 - val_acc: 0.8291

Epoch 00055: val_loss improved from 0.51270 to 0.51081, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 56/60
 - 5s - loss: 0.6693 - acc: 0.7811 - val_loss: 0.5031 - val_acc: 0.8307

Epoch 00056: val_loss improved from 0.51081 to 0.50312, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 57/60
 - 5s - loss: 0.6693 - acc: 0.7801 - val_loss: 0.4986 - val_acc: 0.8350

Epoch 00057: val_loss improved from 0.50312 to 0.49857, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 58/60
 - 5s - loss: 0.6647 - acc: 0.7830 - val_loss: 0.5118 - val_acc: 0.8313

Epoch 00058: val_loss did not improve from 0.49857
Epoch 59/60
 - 5s - loss: 0.6578 - acc: 0.7843 - val_loss: 0.4965 - val_acc: 0.8364

Epoch 00059: val_loss improved from 0.49857 to 0.49649, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Epoch 60/60
 - 5s - loss: 0.6595 - acc: 0.7856 - val_loss: 0.4908 - val_acc: 0.8377

Epoch 00060: val_loss improved from 0.49649 to 0.49080, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 7s - loss: 3.0804 - acc: 0.5704 - val_loss: 1.2556 - val_acc: 0.6340

Epoch 00001: val_loss improved from inf to 1.25559, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 2/60
 - 5s - loss: 1.1942 - acc: 0.6535 - val_loss: 0.9885 - val_acc: 0.6896

Epoch 00002: val_loss improved from 1.25559 to 0.98846, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 3/60
 - 5s - loss: 0.9428 - acc: 0.7085 - val_loss: 0.7350 - val_acc: 0.7624

Epoch 00003: val_loss improved from 0.98846 to 0.73505, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 4/60
 - 5s - loss: 0.8018 - acc: 0.7475 - val_loss: 0.6426 - val_acc: 0.7973

Epoch 00004: val_loss improved from 0.73505 to 0.64258, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 5/60
 - 5s - loss: 0.7206 - acc: 0.7720 - val_loss: 0.6587 - val_acc: 0.7846

Epoch 00005: val_loss did not improve from 0.64258
Epoch 6/60
 - 5s - loss: 0.6573 - acc: 0.7918 - val_loss: 0.5998 - val_acc: 0.8124

Epoch 00006: val_loss improved from 0.64258 to 0.59976, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 7/60
 - 5s - loss: 0.6153 - acc: 0.8021 - val_loss: 0.5464 - val_acc: 0.8224

Epoch 00007: val_loss improved from 0.59976 to 0.54636, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 8/60
 - 5s - loss: 0.5804 - acc: 0.8150 - val_loss: 0.5072 - val_acc: 0.8380

Epoch 00008: val_loss improved from 0.54636 to 0.50721, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 9/60
 - 5s - loss: 0.5547 - acc: 0.8219 - val_loss: 0.4959 - val_acc: 0.8445

Epoch 00009: val_loss improved from 0.50721 to 0.49588, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 10/60
 - 5s - loss: 0.5365 - acc: 0.8287 - val_loss: 0.4985 - val_acc: 0.8438

Epoch 00010: val_loss did not improve from 0.49588
Epoch 11/60
 - 5s - loss: 0.5175 - acc: 0.8350 - val_loss: 0.4686 - val_acc: 0.8558

Epoch 00011: val_loss improved from 0.49588 to 0.46858, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 12/60
 - 5s - loss: 0.5014 - acc: 0.8387 - val_loss: 0.4602 - val_acc: 0.8554

Epoch 00012: val_loss improved from 0.46858 to 0.46018, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 13/60
 - 5s - loss: 0.4844 - acc: 0.8448 - val_loss: 0.4379 - val_acc: 0.8639

Epoch 00013: val_loss improved from 0.46018 to 0.43787, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 14/60
 - 5s - loss: 0.4709 - acc: 0.8497 - val_loss: 0.4563 - val_acc: 0.8604

Epoch 00014: val_loss did not improve from 0.43787
Epoch 15/60
 - 5s - loss: 0.4553 - acc: 0.8540 - val_loss: 0.4472 - val_acc: 0.8616

Epoch 00015: val_loss did not improve from 0.43787
Epoch 16/60
 - 5s - loss: 0.4477 - acc: 0.8537 - val_loss: 0.4300 - val_acc: 0.8604

Epoch 00016: val_loss improved from 0.43787 to 0.43003, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 17/60
 - 5s - loss: 0.4399 - acc: 0.8589 - val_loss: 0.4701 - val_acc: 0.8511

Epoch 00017: val_loss did not improve from 0.43003
Epoch 18/60
 - 5s - loss: 0.4273 - acc: 0.8605 - val_loss: 0.4676 - val_acc: 0.8516

Epoch 00018: val_loss did not improve from 0.43003
Epoch 19/60
 - 5s - loss: 0.4266 - acc: 0.8625 - val_loss: 0.4137 - val_acc: 0.8704

Epoch 00019: val_loss improved from 0.43003 to 0.41365, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 20/60
 - 5s - loss: 0.4109 - acc: 0.8667 - val_loss: 0.4457 - val_acc: 0.8628

Epoch 00020: val_loss did not improve from 0.41365
Epoch 21/60
 - 5s - loss: 0.4114 - acc: 0.8661 - val_loss: 0.4048 - val_acc: 0.8748

Epoch 00021: val_loss improved from 0.41365 to 0.40483, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 22/60
 - 5s - loss: 0.3953 - acc: 0.8715 - val_loss: 0.4207 - val_acc: 0.8688

Epoch 00022: val_loss did not improve from 0.40483
Epoch 23/60
 - 5s - loss: 0.3946 - acc: 0.8722 - val_loss: 0.4631 - val_acc: 0.8541

Epoch 00023: val_loss did not improve from 0.40483
Epoch 24/60
 - 5s - loss: 0.3891 - acc: 0.8733 - val_loss: 0.4000 - val_acc: 0.8731

Epoch 00024: val_loss improved from 0.40483 to 0.40002, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 25/60
 - 5s - loss: 0.3798 - acc: 0.8763 - val_loss: 0.4597 - val_acc: 0.8567

Epoch 00025: val_loss did not improve from 0.40002
Epoch 26/60
 - 5s - loss: 0.3849 - acc: 0.8765 - val_loss: 0.3971 - val_acc: 0.8798

Epoch 00026: val_loss improved from 0.40002 to 0.39711, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 27/60
 - 5s - loss: 0.3728 - acc: 0.8773 - val_loss: 0.4018 - val_acc: 0.8766

Epoch 00027: val_loss did not improve from 0.39711
Epoch 28/60
 - 5s - loss: 0.3727 - acc: 0.8779 - val_loss: 0.3907 - val_acc: 0.8785

Epoch 00028: val_loss improved from 0.39711 to 0.39066, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 29/60
 - 5s - loss: 0.3692 - acc: 0.8797 - val_loss: 0.3817 - val_acc: 0.8798

Epoch 00029: val_loss improved from 0.39066 to 0.38168, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 30/60
 - 5s - loss: 0.3639 - acc: 0.8804 - val_loss: 0.3745 - val_acc: 0.8833

Epoch 00030: val_loss improved from 0.38168 to 0.37448, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 31/60
 - 5s - loss: 0.3597 - acc: 0.8818 - val_loss: 0.4446 - val_acc: 0.8650

Epoch 00031: val_loss did not improve from 0.37448
Epoch 32/60
 - 5s - loss: 0.3564 - acc: 0.8829 - val_loss: 0.4043 - val_acc: 0.8751

Epoch 00032: val_loss did not improve from 0.37448
Epoch 33/60
 - 5s - loss: 0.3562 - acc: 0.8837 - val_loss: 0.3852 - val_acc: 0.8814

Epoch 00033: val_loss did not improve from 0.37448
Epoch 34/60
 - 5s - loss: 0.3544 - acc: 0.8840 - val_loss: 0.3857 - val_acc: 0.8816

Epoch 00034: val_loss did not improve from 0.37448
Epoch 35/60
 - 5s - loss: 0.3468 - acc: 0.8859 - val_loss: 0.3908 - val_acc: 0.8791

Epoch 00035: val_loss did not improve from 0.37448
Epoch 36/60
 - 5s - loss: 0.3493 - acc: 0.8855 - val_loss: 0.3895 - val_acc: 0.8808

Epoch 00036: val_loss did not improve from 0.37448
Epoch 37/60
 - 5s - loss: 0.3427 - acc: 0.8866 - val_loss: 0.3895 - val_acc: 0.8810

Epoch 00037: val_loss did not improve from 0.37448
Epoch 38/60
 - 5s - loss: 0.3427 - acc: 0.8874 - val_loss: 0.4081 - val_acc: 0.8738

Epoch 00038: val_loss did not improve from 0.37448
Epoch 39/60
 - 5s - loss: 0.3370 - acc: 0.8903 - val_loss: 0.3776 - val_acc: 0.8825

Epoch 00039: val_loss did not improve from 0.37448
Epoch 40/60
 - 5s - loss: 0.3407 - acc: 0.8892 - val_loss: 0.3816 - val_acc: 0.8826

Epoch 00040: val_loss did not improve from 0.37448
Epoch 00040: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 7s - loss: 2.1618 - acc: 0.4919 - val_loss: 1.6658 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 1.66578, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 2/60
 - 4s - loss: 1.6026 - acc: 0.6288 - val_loss: 1.5364 - val_acc: 0.6209

Epoch 00002: val_loss improved from 1.66578 to 1.53643, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 3/60
 - 4s - loss: 1.4998 - acc: 0.6362 - val_loss: 1.4621 - val_acc: 0.6227

Epoch 00003: val_loss improved from 1.53643 to 1.46212, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 4/60
 - 4s - loss: 1.4437 - acc: 0.6350 - val_loss: 1.4015 - val_acc: 0.6227

Epoch 00004: val_loss improved from 1.46212 to 1.40149, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 5/60
 - 4s - loss: 1.3993 - acc: 0.6356 - val_loss: 1.3271 - val_acc: 0.6243

Epoch 00005: val_loss improved from 1.40149 to 1.32714, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 6/60
 - 4s - loss: 1.3617 - acc: 0.6366 - val_loss: 1.2910 - val_acc: 0.6303

Epoch 00006: val_loss improved from 1.32714 to 1.29099, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 7/60
 - 4s - loss: 1.3281 - acc: 0.6381 - val_loss: 1.2416 - val_acc: 0.6336

Epoch 00007: val_loss improved from 1.29099 to 1.24164, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 8/60
 - 4s - loss: 1.2998 - acc: 0.6405 - val_loss: 1.2349 - val_acc: 0.6325

Epoch 00008: val_loss improved from 1.24164 to 1.23491, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 9/60
 - 4s - loss: 1.2739 - acc: 0.6424 - val_loss: 1.2116 - val_acc: 0.6378

Epoch 00009: val_loss improved from 1.23491 to 1.21165, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 10/60
 - 4s - loss: 1.2489 - acc: 0.6438 - val_loss: 1.1778 - val_acc: 0.6355

Epoch 00010: val_loss improved from 1.21165 to 1.17783, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 11/60
 - 4s - loss: 1.2304 - acc: 0.6450 - val_loss: 1.1629 - val_acc: 0.6408

Epoch 00011: val_loss improved from 1.17783 to 1.16293, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 12/60
 - 4s - loss: 1.2143 - acc: 0.6464 - val_loss: 1.1348 - val_acc: 0.6464

Epoch 00012: val_loss improved from 1.16293 to 1.13477, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 13/60
 - 4s - loss: 1.1987 - acc: 0.6491 - val_loss: 1.1488 - val_acc: 0.6508

Epoch 00013: val_loss did not improve from 1.13477
Epoch 14/60
 - 4s - loss: 1.1809 - acc: 0.6505 - val_loss: 1.0926 - val_acc: 0.6553

Epoch 00014: val_loss improved from 1.13477 to 1.09264, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 15/60
 - 4s - loss: 1.1728 - acc: 0.6508 - val_loss: 1.0949 - val_acc: 0.6575

Epoch 00015: val_loss did not improve from 1.09264
Epoch 16/60
 - 4s - loss: 1.1585 - acc: 0.6532 - val_loss: 1.0689 - val_acc: 0.6548

Epoch 00016: val_loss improved from 1.09264 to 1.06888, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 17/60
 - 4s - loss: 1.1514 - acc: 0.6557 - val_loss: 1.0670 - val_acc: 0.6603

Epoch 00017: val_loss improved from 1.06888 to 1.06703, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 18/60
 - 4s - loss: 1.1362 - acc: 0.6563 - val_loss: 1.0890 - val_acc: 0.6571

Epoch 00018: val_loss did not improve from 1.06703
Epoch 19/60
 - 4s - loss: 1.1281 - acc: 0.6586 - val_loss: 1.0330 - val_acc: 0.6662

Epoch 00019: val_loss improved from 1.06703 to 1.03301, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 20/60
 - 4s - loss: 1.1174 - acc: 0.6587 - val_loss: 1.0304 - val_acc: 0.6684

Epoch 00020: val_loss improved from 1.03301 to 1.03037, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 21/60
 - 4s - loss: 1.1094 - acc: 0.6612 - val_loss: 1.0114 - val_acc: 0.6643

Epoch 00021: val_loss improved from 1.03037 to 1.01137, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 22/60
 - 4s - loss: 1.1019 - acc: 0.6605 - val_loss: 1.0170 - val_acc: 0.6702

Epoch 00022: val_loss did not improve from 1.01137
Epoch 23/60
 - 4s - loss: 1.0935 - acc: 0.6627 - val_loss: 0.9762 - val_acc: 0.6698

Epoch 00023: val_loss improved from 1.01137 to 0.97616, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 24/60
 - 4s - loss: 1.0793 - acc: 0.6639 - val_loss: 0.9522 - val_acc: 0.6737

Epoch 00024: val_loss improved from 0.97616 to 0.95218, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 25/60
 - 4s - loss: 1.0686 - acc: 0.6645 - val_loss: 0.9474 - val_acc: 0.6742

Epoch 00025: val_loss improved from 0.95218 to 0.94742, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 26/60
 - 4s - loss: 1.0633 - acc: 0.6671 - val_loss: 0.9400 - val_acc: 0.6761

Epoch 00026: val_loss improved from 0.94742 to 0.93998, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 27/60
 - 4s - loss: 1.0562 - acc: 0.6666 - val_loss: 0.9359 - val_acc: 0.6758

Epoch 00027: val_loss improved from 0.93998 to 0.93594, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 28/60
 - 4s - loss: 1.0401 - acc: 0.6694 - val_loss: 0.9153 - val_acc: 0.6824

Epoch 00028: val_loss improved from 0.93594 to 0.91528, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 29/60
 - 4s - loss: 1.0413 - acc: 0.6693 - val_loss: 0.9082 - val_acc: 0.6853

Epoch 00029: val_loss improved from 0.91528 to 0.90816, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 30/60
 - 4s - loss: 1.0319 - acc: 0.6706 - val_loss: 0.9121 - val_acc: 0.6837

Epoch 00030: val_loss did not improve from 0.90816
Epoch 31/60
 - 4s - loss: 1.0270 - acc: 0.6712 - val_loss: 0.8779 - val_acc: 0.6859

Epoch 00031: val_loss improved from 0.90816 to 0.87785, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 32/60
 - 4s - loss: 1.0116 - acc: 0.6740 - val_loss: 0.8789 - val_acc: 0.6833

Epoch 00032: val_loss did not improve from 0.87785
Epoch 33/60
 - 4s - loss: 1.0110 - acc: 0.6767 - val_loss: 0.8624 - val_acc: 0.6918

Epoch 00033: val_loss improved from 0.87785 to 0.86240, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 34/60
 - 5s - loss: 0.9989 - acc: 0.6773 - val_loss: 0.8629 - val_acc: 0.6921

Epoch 00034: val_loss did not improve from 0.86240
Epoch 35/60
 - 4s - loss: 0.9955 - acc: 0.6780 - val_loss: 0.8480 - val_acc: 0.6871

Epoch 00035: val_loss improved from 0.86240 to 0.84798, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 36/60
 - 4s - loss: 0.9872 - acc: 0.6808 - val_loss: 0.8484 - val_acc: 0.6911

Epoch 00036: val_loss did not improve from 0.84798
Epoch 37/60
 - 4s - loss: 0.9879 - acc: 0.6813 - val_loss: 0.8255 - val_acc: 0.7064

Epoch 00037: val_loss improved from 0.84798 to 0.82553, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 38/60
 - 4s - loss: 0.9827 - acc: 0.6817 - val_loss: 0.8399 - val_acc: 0.7068

Epoch 00038: val_loss did not improve from 0.82553
Epoch 39/60
 - 4s - loss: 0.9760 - acc: 0.6829 - val_loss: 0.8188 - val_acc: 0.7108

Epoch 00039: val_loss improved from 0.82553 to 0.81884, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 40/60
 - 4s - loss: 0.9744 - acc: 0.6839 - val_loss: 0.8000 - val_acc: 0.7132

Epoch 00040: val_loss improved from 0.81884 to 0.79998, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 41/60
 - 4s - loss: 0.9696 - acc: 0.6862 - val_loss: 0.8100 - val_acc: 0.7132

Epoch 00041: val_loss did not improve from 0.79998
Epoch 42/60
 - 4s - loss: 0.9687 - acc: 0.6852 - val_loss: 0.8219 - val_acc: 0.7143

Epoch 00042: val_loss did not improve from 0.79998
Epoch 43/60
 - 4s - loss: 0.9625 - acc: 0.6866 - val_loss: 0.7948 - val_acc: 0.7151

Epoch 00043: val_loss improved from 0.79998 to 0.79483, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 44/60
 - 4s - loss: 0.9597 - acc: 0.6874 - val_loss: 0.8161 - val_acc: 0.7179

Epoch 00044: val_loss did not improve from 0.79483
Epoch 45/60
 - 4s - loss: 0.9503 - acc: 0.6911 - val_loss: 0.7767 - val_acc: 0.7283

Epoch 00045: val_loss improved from 0.79483 to 0.77668, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 46/60
 - 4s - loss: 0.9549 - acc: 0.6896 - val_loss: 0.7826 - val_acc: 0.7140

Epoch 00046: val_loss did not improve from 0.77668
Epoch 47/60
 - 4s - loss: 0.9458 - acc: 0.6902 - val_loss: 0.7789 - val_acc: 0.7165

Epoch 00047: val_loss did not improve from 0.77668
Epoch 48/60
 - 4s - loss: 0.9437 - acc: 0.6920 - val_loss: 0.7725 - val_acc: 0.7346

Epoch 00048: val_loss improved from 0.77668 to 0.77251, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 49/60
 - 4s - loss: 0.9366 - acc: 0.6923 - val_loss: 0.7594 - val_acc: 0.7348

Epoch 00049: val_loss improved from 0.77251 to 0.75945, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 50/60
 - 4s - loss: 0.9381 - acc: 0.6935 - val_loss: 0.7857 - val_acc: 0.7383

Epoch 00050: val_loss did not improve from 0.75945
Epoch 51/60
 - 4s - loss: 0.9362 - acc: 0.6936 - val_loss: 0.7533 - val_acc: 0.7364

Epoch 00051: val_loss improved from 0.75945 to 0.75331, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 52/60
 - 4s - loss: 0.9347 - acc: 0.6944 - val_loss: 0.7590 - val_acc: 0.7310

Epoch 00052: val_loss did not improve from 0.75331
Epoch 53/60
 - 4s - loss: 0.9261 - acc: 0.6948 - val_loss: 0.7549 - val_acc: 0.7367

Epoch 00053: val_loss did not improve from 0.75331
Epoch 54/60
 - 4s - loss: 0.9339 - acc: 0.6941 - val_loss: 0.7449 - val_acc: 0.7414

Epoch 00054: val_loss improved from 0.75331 to 0.74487, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 55/60
 - 4s - loss: 0.9315 - acc: 0.6949 - val_loss: 0.7411 - val_acc: 0.7358

Epoch 00055: val_loss improved from 0.74487 to 0.74110, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 56/60
 - 4s - loss: 0.9232 - acc: 0.6984 - val_loss: 0.7424 - val_acc: 0.7440

Epoch 00056: val_loss did not improve from 0.74110
Epoch 57/60
 - 4s - loss: 0.9223 - acc: 0.7006 - val_loss: 0.7374 - val_acc: 0.7462

Epoch 00057: val_loss improved from 0.74110 to 0.73741, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 58/60
 - 4s - loss: 0.9129 - acc: 0.7001 - val_loss: 0.7452 - val_acc: 0.7398

Epoch 00058: val_loss did not improve from 0.73741
Epoch 59/60
 - 4s - loss: 0.9155 - acc: 0.7008 - val_loss: 0.7309 - val_acc: 0.7511

Epoch 00059: val_loss improved from 0.73741 to 0.73086, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 60/60
 - 4s - loss: 0.9149 - acc: 0.7014 - val_loss: 0.7248 - val_acc: 0.7520

Epoch 00060: val_loss improved from 0.73086 to 0.72484, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 1.9485 - acc: 0.5895 - val_loss: 1.6608 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 1.66079, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 2/60
 - 5s - loss: 1.4532 - acc: 0.6364 - val_loss: 1.4186 - val_acc: 0.6289

Epoch 00002: val_loss improved from 1.66079 to 1.41856, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 3/60
 - 5s - loss: 1.3405 - acc: 0.6383 - val_loss: 1.2465 - val_acc: 0.6412

Epoch 00003: val_loss improved from 1.41856 to 1.24646, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 4/60
 - 5s - loss: 1.2571 - acc: 0.6463 - val_loss: 1.1676 - val_acc: 0.6617

Epoch 00004: val_loss improved from 1.24646 to 1.16759, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 5/60
 - 5s - loss: 1.1970 - acc: 0.6528 - val_loss: 1.1465 - val_acc: 0.6746

Epoch 00005: val_loss improved from 1.16759 to 1.14648, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 6/60
 - 5s - loss: 1.1517 - acc: 0.6588 - val_loss: 1.0742 - val_acc: 0.6743

Epoch 00006: val_loss improved from 1.14648 to 1.07416, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 7/60
 - 5s - loss: 1.1187 - acc: 0.6652 - val_loss: 1.0350 - val_acc: 0.6798

Epoch 00007: val_loss improved from 1.07416 to 1.03502, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 8/60
 - 5s - loss: 1.0819 - acc: 0.6691 - val_loss: 1.0115 - val_acc: 0.6849

Epoch 00008: val_loss improved from 1.03502 to 1.01154, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 9/60
 - 5s - loss: 1.0563 - acc: 0.6723 - val_loss: 0.9736 - val_acc: 0.6870

Epoch 00009: val_loss improved from 1.01154 to 0.97358, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 10/60
 - 5s - loss: 1.0325 - acc: 0.6778 - val_loss: 0.9113 - val_acc: 0.6873

Epoch 00010: val_loss improved from 0.97358 to 0.91133, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 11/60
 - 5s - loss: 1.0102 - acc: 0.6819 - val_loss: 0.9366 - val_acc: 0.6917

Epoch 00011: val_loss did not improve from 0.91133
Epoch 12/60
 - 5s - loss: 0.9888 - acc: 0.6836 - val_loss: 0.8935 - val_acc: 0.7001

Epoch 00012: val_loss improved from 0.91133 to 0.89354, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 13/60
 - 5s - loss: 0.9707 - acc: 0.6874 - val_loss: 0.8433 - val_acc: 0.7123

Epoch 00013: val_loss improved from 0.89354 to 0.84333, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 14/60
 - 5s - loss: 0.9478 - acc: 0.6929 - val_loss: 0.7987 - val_acc: 0.7245

Epoch 00014: val_loss improved from 0.84333 to 0.79874, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 15/60
 - 5s - loss: 0.9285 - acc: 0.6958 - val_loss: 0.8034 - val_acc: 0.7343

Epoch 00015: val_loss did not improve from 0.79874
Epoch 16/60
 - 5s - loss: 0.9055 - acc: 0.7058 - val_loss: 0.7673 - val_acc: 0.7427

Epoch 00016: val_loss improved from 0.79874 to 0.76730, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 17/60
 - 5s - loss: 0.8855 - acc: 0.7110 - val_loss: 0.7521 - val_acc: 0.7585

Epoch 00017: val_loss improved from 0.76730 to 0.75214, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 18/60
 - 5s - loss: 0.8723 - acc: 0.7133 - val_loss: 0.7154 - val_acc: 0.7642

Epoch 00018: val_loss improved from 0.75214 to 0.71539, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 19/60
 - 5s - loss: 0.8612 - acc: 0.7191 - val_loss: 0.6887 - val_acc: 0.7674

Epoch 00019: val_loss improved from 0.71539 to 0.68874, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 20/60
 - 5s - loss: 0.8431 - acc: 0.7237 - val_loss: 0.6901 - val_acc: 0.7752

Epoch 00020: val_loss did not improve from 0.68874
Epoch 21/60
 - 5s - loss: 0.8287 - acc: 0.7284 - val_loss: 0.7185 - val_acc: 0.7711

Epoch 00021: val_loss did not improve from 0.68874
Epoch 22/60
 - 5s - loss: 0.8227 - acc: 0.7304 - val_loss: 0.6827 - val_acc: 0.7899

Epoch 00022: val_loss improved from 0.68874 to 0.68269, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 23/60
 - 5s - loss: 0.8078 - acc: 0.7353 - val_loss: 0.6755 - val_acc: 0.7882

Epoch 00023: val_loss improved from 0.68269 to 0.67550, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 24/60
 - 5s - loss: 0.7986 - acc: 0.7367 - val_loss: 0.6476 - val_acc: 0.7866

Epoch 00024: val_loss improved from 0.67550 to 0.64761, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 25/60
 - 5s - loss: 0.7874 - acc: 0.7432 - val_loss: 0.6172 - val_acc: 0.7951

Epoch 00025: val_loss improved from 0.64761 to 0.61718, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 26/60
 - 5s - loss: 0.7769 - acc: 0.7448 - val_loss: 0.6014 - val_acc: 0.7973

Epoch 00026: val_loss improved from 0.61718 to 0.60140, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 27/60
 - 5s - loss: 0.7748 - acc: 0.7466 - val_loss: 0.6008 - val_acc: 0.7964

Epoch 00027: val_loss improved from 0.60140 to 0.60083, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 28/60
 - 5s - loss: 0.7675 - acc: 0.7458 - val_loss: 0.5909 - val_acc: 0.8023

Epoch 00028: val_loss improved from 0.60083 to 0.59087, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 29/60
 - 5s - loss: 0.7613 - acc: 0.7516 - val_loss: 0.5955 - val_acc: 0.8058

Epoch 00029: val_loss did not improve from 0.59087
Epoch 30/60
 - 5s - loss: 0.7495 - acc: 0.7533 - val_loss: 0.5768 - val_acc: 0.8054

Epoch 00030: val_loss improved from 0.59087 to 0.57682, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 31/60
 - 5s - loss: 0.7499 - acc: 0.7537 - val_loss: 0.5795 - val_acc: 0.8126

Epoch 00031: val_loss did not improve from 0.57682
Epoch 32/60
 - 6s - loss: 0.7380 - acc: 0.7584 - val_loss: 0.5753 - val_acc: 0.8119

Epoch 00032: val_loss improved from 0.57682 to 0.57526, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 33/60
 - 5s - loss: 0.7350 - acc: 0.7593 - val_loss: 0.5578 - val_acc: 0.8129

Epoch 00033: val_loss improved from 0.57526 to 0.55778, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 34/60
 - 5s - loss: 0.7310 - acc: 0.7598 - val_loss: 0.5727 - val_acc: 0.8189

Epoch 00034: val_loss did not improve from 0.55778
Epoch 35/60
 - 5s - loss: 0.7238 - acc: 0.7647 - val_loss: 0.5597 - val_acc: 0.8141

Epoch 00035: val_loss did not improve from 0.55778
Epoch 36/60
 - 5s - loss: 0.7263 - acc: 0.7631 - val_loss: 0.5738 - val_acc: 0.8183

Epoch 00036: val_loss did not improve from 0.55778
Epoch 37/60
 - 5s - loss: 0.7194 - acc: 0.7629 - val_loss: 0.5761 - val_acc: 0.8201

Epoch 00037: val_loss did not improve from 0.55778
Epoch 38/60
 - 5s - loss: 0.7146 - acc: 0.7642 - val_loss: 0.5498 - val_acc: 0.8210

Epoch 00038: val_loss improved from 0.55778 to 0.54980, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 39/60
 - 5s - loss: 0.7070 - acc: 0.7691 - val_loss: 0.5384 - val_acc: 0.8177

Epoch 00039: val_loss improved from 0.54980 to 0.53841, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 40/60
 - 5s - loss: 0.7051 - acc: 0.7689 - val_loss: 0.5390 - val_acc: 0.8223

Epoch 00040: val_loss did not improve from 0.53841
Epoch 41/60
 - 5s - loss: 0.7027 - acc: 0.7696 - val_loss: 0.5420 - val_acc: 0.8216

Epoch 00041: val_loss did not improve from 0.53841
Epoch 42/60
 - 5s - loss: 0.7012 - acc: 0.7711 - val_loss: 0.5366 - val_acc: 0.8220

Epoch 00042: val_loss improved from 0.53841 to 0.53662, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 43/60
 - 5s - loss: 0.6925 - acc: 0.7729 - val_loss: 0.5269 - val_acc: 0.8274

Epoch 00043: val_loss improved from 0.53662 to 0.52687, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 44/60
 - 5s - loss: 0.6877 - acc: 0.7730 - val_loss: 0.5429 - val_acc: 0.8197

Epoch 00044: val_loss did not improve from 0.52687
Epoch 45/60
 - 5s - loss: 0.6915 - acc: 0.7744 - val_loss: 0.5265 - val_acc: 0.8263

Epoch 00045: val_loss improved from 0.52687 to 0.52649, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 46/60
 - 5s - loss: 0.6827 - acc: 0.7761 - val_loss: 0.5156 - val_acc: 0.8307

Epoch 00046: val_loss improved from 0.52649 to 0.51559, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 47/60
 - 5s - loss: 0.6824 - acc: 0.7789 - val_loss: 0.5117 - val_acc: 0.8322

Epoch 00047: val_loss improved from 0.51559 to 0.51171, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 48/60
 - 5s - loss: 0.6827 - acc: 0.7766 - val_loss: 0.5052 - val_acc: 0.8339

Epoch 00048: val_loss improved from 0.51171 to 0.50517, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 49/60
 - 5s - loss: 0.6804 - acc: 0.7780 - val_loss: 0.5302 - val_acc: 0.8289

Epoch 00049: val_loss did not improve from 0.50517
Epoch 50/60
 - 5s - loss: 0.6736 - acc: 0.7800 - val_loss: 0.5155 - val_acc: 0.8351

Epoch 00050: val_loss did not improve from 0.50517
Epoch 51/60
 - 5s - loss: 0.6716 - acc: 0.7815 - val_loss: 0.5013 - val_acc: 0.8382

Epoch 00051: val_loss improved from 0.50517 to 0.50130, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 52/60
 - 5s - loss: 0.6723 - acc: 0.7821 - val_loss: 0.5209 - val_acc: 0.8289

Epoch 00052: val_loss did not improve from 0.50130
Epoch 53/60
 - 5s - loss: 0.6676 - acc: 0.7825 - val_loss: 0.5091 - val_acc: 0.8332

Epoch 00053: val_loss did not improve from 0.50130
Epoch 54/60
 - 5s - loss: 0.6656 - acc: 0.7813 - val_loss: 0.5028 - val_acc: 0.8389

Epoch 00054: val_loss did not improve from 0.50130
Epoch 55/60
 - 5s - loss: 0.6610 - acc: 0.7858 - val_loss: 0.5290 - val_acc: 0.8283

Epoch 00055: val_loss did not improve from 0.50130
Epoch 56/60
 - 5s - loss: 0.6615 - acc: 0.7846 - val_loss: 0.5017 - val_acc: 0.8364

Epoch 00056: val_loss did not improve from 0.50130
Epoch 57/60
 - 5s - loss: 0.6649 - acc: 0.7826 - val_loss: 0.4951 - val_acc: 0.8355

Epoch 00057: val_loss improved from 0.50130 to 0.49506, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 58/60
 - 5s - loss: 0.6554 - acc: 0.7854 - val_loss: 0.4975 - val_acc: 0.8380

Epoch 00058: val_loss did not improve from 0.49506
Epoch 59/60
 - 5s - loss: 0.6626 - acc: 0.7858 - val_loss: 0.4790 - val_acc: 0.8416

Epoch 00059: val_loss improved from 0.49506 to 0.47902, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5
Epoch 60/60
 - 5s - loss: 0.6510 - acc: 0.7881 - val_loss: 0.4910 - val_acc: 0.8375

Epoch 00060: val_loss did not improve from 0.47902
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 7s - loss: 1.8113 - acc: 0.5926 - val_loss: 1.1169 - val_acc: 0.6565

Epoch 00001: val_loss improved from inf to 1.11687, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 2/60
 - 5s - loss: 1.0933 - acc: 0.6730 - val_loss: 0.8806 - val_acc: 0.7102

Epoch 00002: val_loss improved from 1.11687 to 0.88064, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 3/60
 - 5s - loss: 0.9145 - acc: 0.7143 - val_loss: 0.7314 - val_acc: 0.7696

Epoch 00003: val_loss improved from 0.88064 to 0.73138, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 4/60
 - 5s - loss: 0.8025 - acc: 0.7463 - val_loss: 0.6949 - val_acc: 0.7698

Epoch 00004: val_loss improved from 0.73138 to 0.69485, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 5/60
 - 5s - loss: 0.7276 - acc: 0.7700 - val_loss: 0.5917 - val_acc: 0.8145

Epoch 00005: val_loss improved from 0.69485 to 0.59169, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 6/60
 - 5s - loss: 0.6724 - acc: 0.7878 - val_loss: 0.5984 - val_acc: 0.8201

Epoch 00006: val_loss did not improve from 0.59169
Epoch 7/60
 - 5s - loss: 0.6258 - acc: 0.8011 - val_loss: 0.5286 - val_acc: 0.8332

Epoch 00007: val_loss improved from 0.59169 to 0.52856, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 8/60
 - 5s - loss: 0.5931 - acc: 0.8110 - val_loss: 0.5486 - val_acc: 0.8211

Epoch 00008: val_loss did not improve from 0.52856
Epoch 9/60
 - 5s - loss: 0.5696 - acc: 0.8173 - val_loss: 0.5046 - val_acc: 0.8429

Epoch 00009: val_loss improved from 0.52856 to 0.50457, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 10/60
 - 5s - loss: 0.5389 - acc: 0.8287 - val_loss: 0.5719 - val_acc: 0.8183

Epoch 00010: val_loss did not improve from 0.50457
Epoch 11/60
 - 5s - loss: 0.5209 - acc: 0.8344 - val_loss: 0.4945 - val_acc: 0.8450

Epoch 00011: val_loss improved from 0.50457 to 0.49454, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 12/60
 - 5s - loss: 0.5116 - acc: 0.8355 - val_loss: 0.4487 - val_acc: 0.8572

Epoch 00012: val_loss improved from 0.49454 to 0.44871, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 13/60
 - 5s - loss: 0.4897 - acc: 0.8438 - val_loss: 0.4607 - val_acc: 0.8563

Epoch 00013: val_loss did not improve from 0.44871
Epoch 14/60
 - 5s - loss: 0.4735 - acc: 0.8476 - val_loss: 0.4706 - val_acc: 0.8539

Epoch 00014: val_loss did not improve from 0.44871
Epoch 15/60
 - 5s - loss: 0.4694 - acc: 0.8496 - val_loss: 0.4723 - val_acc: 0.8497

Epoch 00015: val_loss did not improve from 0.44871
Epoch 16/60
 - 5s - loss: 0.4523 - acc: 0.8560 - val_loss: 0.4327 - val_acc: 0.8626

Epoch 00016: val_loss improved from 0.44871 to 0.43270, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 17/60
 - 5s - loss: 0.4419 - acc: 0.8562 - val_loss: 0.4218 - val_acc: 0.8642

Epoch 00017: val_loss improved from 0.43270 to 0.42181, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 18/60
 - 5s - loss: 0.4322 - acc: 0.8601 - val_loss: 0.4407 - val_acc: 0.8620

Epoch 00018: val_loss did not improve from 0.42181
Epoch 19/60
 - 5s - loss: 0.4261 - acc: 0.8627 - val_loss: 0.4059 - val_acc: 0.8716

Epoch 00019: val_loss improved from 0.42181 to 0.40588, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 20/60
 - 5s - loss: 0.4154 - acc: 0.8650 - val_loss: 0.4297 - val_acc: 0.8636

Epoch 00020: val_loss did not improve from 0.40588
Epoch 21/60
 - 5s - loss: 0.4067 - acc: 0.8681 - val_loss: 0.4513 - val_acc: 0.8608

Epoch 00021: val_loss did not improve from 0.40588
Epoch 22/60
 - 5s - loss: 0.4054 - acc: 0.8676 - val_loss: 0.4177 - val_acc: 0.8713

Epoch 00022: val_loss did not improve from 0.40588
Epoch 23/60
 - 5s - loss: 0.4022 - acc: 0.8694 - val_loss: 0.3977 - val_acc: 0.8754

Epoch 00023: val_loss improved from 0.40588 to 0.39769, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 24/60
 - 5s - loss: 0.3956 - acc: 0.8728 - val_loss: 0.3992 - val_acc: 0.8745

Epoch 00024: val_loss did not improve from 0.39769
Epoch 25/60
 - 5s - loss: 0.3842 - acc: 0.8757 - val_loss: 0.3972 - val_acc: 0.8767

Epoch 00025: val_loss improved from 0.39769 to 0.39720, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 26/60
 - 5s - loss: 0.3836 - acc: 0.8748 - val_loss: 0.4194 - val_acc: 0.8675

Epoch 00026: val_loss did not improve from 0.39720
Epoch 27/60
 - 5s - loss: 0.3808 - acc: 0.8773 - val_loss: 0.4374 - val_acc: 0.8607

Epoch 00027: val_loss did not improve from 0.39720
Epoch 28/60
 - 5s - loss: 0.3767 - acc: 0.8771 - val_loss: 0.4211 - val_acc: 0.8733

Epoch 00028: val_loss did not improve from 0.39720
Epoch 29/60
 - 5s - loss: 0.3742 - acc: 0.8777 - val_loss: 0.3997 - val_acc: 0.8748

Epoch 00029: val_loss did not improve from 0.39720
Epoch 30/60
 - 5s - loss: 0.3685 - acc: 0.8807 - val_loss: 0.4052 - val_acc: 0.8733

Epoch 00030: val_loss did not improve from 0.39720
Epoch 31/60
 - 5s - loss: 0.3618 - acc: 0.8819 - val_loss: 0.3777 - val_acc: 0.8825

Epoch 00031: val_loss improved from 0.39720 to 0.37771, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 32/60
 - 5s - loss: 0.3579 - acc: 0.8809 - val_loss: 0.3712 - val_acc: 0.8854

Epoch 00032: val_loss improved from 0.37771 to 0.37117, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 33/60
 - 5s - loss: 0.3560 - acc: 0.8848 - val_loss: 0.3710 - val_acc: 0.8842

Epoch 00033: val_loss improved from 0.37117 to 0.37098, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 34/60
 - 5s - loss: 0.3472 - acc: 0.8850 - val_loss: 0.3830 - val_acc: 0.8847

Epoch 00034: val_loss did not improve from 0.37098
Epoch 35/60
 - 5s - loss: 0.3500 - acc: 0.8843 - val_loss: 0.3738 - val_acc: 0.8870

Epoch 00035: val_loss did not improve from 0.37098
Epoch 36/60
 - 5s - loss: 0.3452 - acc: 0.8885 - val_loss: 0.3860 - val_acc: 0.8867

Epoch 00036: val_loss did not improve from 0.37098
Epoch 37/60
 - 5s - loss: 0.3418 - acc: 0.8872 - val_loss: 0.3827 - val_acc: 0.8825

Epoch 00037: val_loss did not improve from 0.37098
Epoch 38/60
 - 5s - loss: 0.3391 - acc: 0.8898 - val_loss: 0.3737 - val_acc: 0.8854

Epoch 00038: val_loss did not improve from 0.37098
Epoch 39/60
 - 5s - loss: 0.3365 - acc: 0.8889 - val_loss: 0.3875 - val_acc: 0.8847

Epoch 00039: val_loss did not improve from 0.37098
Epoch 40/60
 - 5s - loss: 0.3378 - acc: 0.8897 - val_loss: 0.4032 - val_acc: 0.8795

Epoch 00040: val_loss did not improve from 0.37098
Epoch 41/60
 - 5s - loss: 0.3332 - acc: 0.8905 - val_loss: 0.3725 - val_acc: 0.8842

Epoch 00041: val_loss did not improve from 0.37098
Epoch 42/60
 - 5s - loss: 0.3305 - acc: 0.8915 - val_loss: 0.4012 - val_acc: 0.8773

Epoch 00042: val_loss did not improve from 0.37098
Epoch 43/60
 - 5s - loss: 0.3304 - acc: 0.8920 - val_loss: 0.3905 - val_acc: 0.8869

Epoch 00043: val_loss did not improve from 0.37098
Epoch 00043: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 7s - loss: 2.5068 - acc: 0.4208 - val_loss: 1.7535 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 1.75352, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 2/60
 - 4s - loss: 1.6470 - acc: 0.6209 - val_loss: 1.5826 - val_acc: 0.6209

Epoch 00002: val_loss improved from 1.75352 to 1.58256, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 3/60
 - 4s - loss: 1.5403 - acc: 0.6359 - val_loss: 1.5224 - val_acc: 0.6209

Epoch 00003: val_loss improved from 1.58256 to 1.52244, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 4/60
 - 4s - loss: 1.4947 - acc: 0.6370 - val_loss: 1.4823 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.52244 to 1.48231, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 5/60
 - 4s - loss: 1.4597 - acc: 0.6371 - val_loss: 1.4494 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.48231 to 1.44944, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 6/60
 - 4s - loss: 1.4335 - acc: 0.6371 - val_loss: 1.4222 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.44944 to 1.42217, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 7/60
 - 4s - loss: 1.4020 - acc: 0.6371 - val_loss: 1.4068 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.42217 to 1.40685, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 8/60
 - 4s - loss: 1.3748 - acc: 0.6371 - val_loss: 1.3699 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.40685 to 1.36992, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 9/60
 - 4s - loss: 1.3485 - acc: 0.6373 - val_loss: 1.2869 - val_acc: 0.6236

Epoch 00009: val_loss improved from 1.36992 to 1.28695, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 10/60
 - 4s - loss: 1.3146 - acc: 0.6395 - val_loss: 1.2474 - val_acc: 0.6333

Epoch 00010: val_loss improved from 1.28695 to 1.24735, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 11/60
 - 4s - loss: 1.2858 - acc: 0.6414 - val_loss: 1.2209 - val_acc: 0.6393

Epoch 00011: val_loss improved from 1.24735 to 1.22089, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 12/60
 - 4s - loss: 1.2658 - acc: 0.6446 - val_loss: 1.1996 - val_acc: 0.6374

Epoch 00012: val_loss improved from 1.22089 to 1.19965, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 13/60
 - 4s - loss: 1.2485 - acc: 0.6448 - val_loss: 1.1823 - val_acc: 0.6418

Epoch 00013: val_loss improved from 1.19965 to 1.18233, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 14/60
 - 4s - loss: 1.2315 - acc: 0.6460 - val_loss: 1.1805 - val_acc: 0.6462

Epoch 00014: val_loss improved from 1.18233 to 1.18053, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 15/60
 - 4s - loss: 1.2187 - acc: 0.6464 - val_loss: 1.1772 - val_acc: 0.6449

Epoch 00015: val_loss improved from 1.18053 to 1.17722, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 16/60
 - 4s - loss: 1.2026 - acc: 0.6481 - val_loss: 1.1243 - val_acc: 0.6496

Epoch 00016: val_loss improved from 1.17722 to 1.12425, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 17/60
 - 4s - loss: 1.1900 - acc: 0.6484 - val_loss: 1.1148 - val_acc: 0.6487

Epoch 00017: val_loss improved from 1.12425 to 1.11483, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 18/60
 - 4s - loss: 1.1779 - acc: 0.6501 - val_loss: 1.0949 - val_acc: 0.6471

Epoch 00018: val_loss improved from 1.11483 to 1.09494, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 19/60
 - 4s - loss: 1.1681 - acc: 0.6503 - val_loss: 1.0821 - val_acc: 0.6442

Epoch 00019: val_loss improved from 1.09494 to 1.08209, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 20/60
 - 4s - loss: 1.1525 - acc: 0.6521 - val_loss: 1.0605 - val_acc: 0.6556

Epoch 00020: val_loss improved from 1.08209 to 1.06051, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 21/60
 - 4s - loss: 1.1461 - acc: 0.6532 - val_loss: 1.0839 - val_acc: 0.6520

Epoch 00021: val_loss did not improve from 1.06051
Epoch 22/60
 - 4s - loss: 1.1370 - acc: 0.6543 - val_loss: 1.0384 - val_acc: 0.6587

Epoch 00022: val_loss improved from 1.06051 to 1.03835, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 23/60
 - 4s - loss: 1.1287 - acc: 0.6542 - val_loss: 1.0279 - val_acc: 0.6550

Epoch 00023: val_loss improved from 1.03835 to 1.02786, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 24/60
 - 4s - loss: 1.1152 - acc: 0.6570 - val_loss: 1.0166 - val_acc: 0.6584

Epoch 00024: val_loss improved from 1.02786 to 1.01661, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 25/60
 - 4s - loss: 1.1068 - acc: 0.6556 - val_loss: 1.0202 - val_acc: 0.6514

Epoch 00025: val_loss did not improve from 1.01661
Epoch 26/60
 - 4s - loss: 1.0994 - acc: 0.6570 - val_loss: 1.0060 - val_acc: 0.6633

Epoch 00026: val_loss improved from 1.01661 to 1.00602, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 27/60
 - 4s - loss: 1.0945 - acc: 0.6569 - val_loss: 1.0086 - val_acc: 0.6581

Epoch 00027: val_loss did not improve from 1.00602
Epoch 28/60
 - 4s - loss: 1.0834 - acc: 0.6593 - val_loss: 0.9654 - val_acc: 0.6611

Epoch 00028: val_loss improved from 1.00602 to 0.96540, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 29/60
 - 4s - loss: 1.0791 - acc: 0.6586 - val_loss: 0.9846 - val_acc: 0.6668

Epoch 00029: val_loss did not improve from 0.96540
Epoch 30/60
 - 4s - loss: 1.0695 - acc: 0.6603 - val_loss: 0.9456 - val_acc: 0.6662

Epoch 00030: val_loss improved from 0.96540 to 0.94558, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 31/60
 - 4s - loss: 1.0669 - acc: 0.6623 - val_loss: 0.9276 - val_acc: 0.6686

Epoch 00031: val_loss improved from 0.94558 to 0.92761, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 32/60
 - 4s - loss: 1.0576 - acc: 0.6632 - val_loss: 0.9279 - val_acc: 0.6687

Epoch 00032: val_loss did not improve from 0.92761
Epoch 33/60
 - 4s - loss: 1.0553 - acc: 0.6645 - val_loss: 0.9070 - val_acc: 0.6724

Epoch 00033: val_loss improved from 0.92761 to 0.90696, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 34/60
 - 4s - loss: 1.0457 - acc: 0.6656 - val_loss: 0.9070 - val_acc: 0.6696

Epoch 00034: val_loss did not improve from 0.90696
Epoch 35/60
 - 4s - loss: 1.0419 - acc: 0.6688 - val_loss: 0.9089 - val_acc: 0.6689

Epoch 00035: val_loss did not improve from 0.90696
Epoch 36/60
 - 4s - loss: 1.0374 - acc: 0.6670 - val_loss: 0.9102 - val_acc: 0.6731

Epoch 00036: val_loss did not improve from 0.90696
Epoch 37/60
 - 4s - loss: 1.0269 - acc: 0.6697 - val_loss: 0.8901 - val_acc: 0.6846

Epoch 00037: val_loss improved from 0.90696 to 0.89008, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 38/60
 - 4s - loss: 1.0261 - acc: 0.6696 - val_loss: 0.8740 - val_acc: 0.6827

Epoch 00038: val_loss improved from 0.89008 to 0.87399, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 39/60
 - 4s - loss: 1.0199 - acc: 0.6730 - val_loss: 0.8611 - val_acc: 0.6881

Epoch 00039: val_loss improved from 0.87399 to 0.86112, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 40/60
 - 4s - loss: 1.0150 - acc: 0.6722 - val_loss: 0.8664 - val_acc: 0.6877

Epoch 00040: val_loss did not improve from 0.86112
Epoch 41/60
 - 4s - loss: 1.0042 - acc: 0.6752 - val_loss: 0.8466 - val_acc: 0.6926

Epoch 00041: val_loss improved from 0.86112 to 0.84659, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 42/60
 - 4s - loss: 1.0024 - acc: 0.6754 - val_loss: 0.8518 - val_acc: 0.6868

Epoch 00042: val_loss did not improve from 0.84659
Epoch 43/60
 - 4s - loss: 1.0025 - acc: 0.6768 - val_loss: 0.8723 - val_acc: 0.6983

Epoch 00043: val_loss did not improve from 0.84659
Epoch 44/60
 - 4s - loss: 0.9969 - acc: 0.6766 - val_loss: 0.8516 - val_acc: 0.6895

Epoch 00044: val_loss did not improve from 0.84659
Epoch 45/60
 - 4s - loss: 0.9899 - acc: 0.6774 - val_loss: 0.8478 - val_acc: 0.6971

Epoch 00045: val_loss did not improve from 0.84659
Epoch 46/60
 - 4s - loss: 0.9858 - acc: 0.6794 - val_loss: 0.8265 - val_acc: 0.7055

Epoch 00046: val_loss improved from 0.84659 to 0.82654, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 47/60
 - 4s - loss: 0.9838 - acc: 0.6812 - val_loss: 0.8193 - val_acc: 0.7064

Epoch 00047: val_loss improved from 0.82654 to 0.81926, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 48/60
 - 4s - loss: 0.9794 - acc: 0.6811 - val_loss: 0.8274 - val_acc: 0.7058

Epoch 00048: val_loss did not improve from 0.81926
Epoch 49/60
 - 4s - loss: 0.9725 - acc: 0.6831 - val_loss: 0.7947 - val_acc: 0.7165

Epoch 00049: val_loss improved from 0.81926 to 0.79474, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 50/60
 - 4s - loss: 0.9735 - acc: 0.6842 - val_loss: 0.8102 - val_acc: 0.7142

Epoch 00050: val_loss did not improve from 0.79474
Epoch 51/60
 - 4s - loss: 0.9693 - acc: 0.6836 - val_loss: 0.8239 - val_acc: 0.7087

Epoch 00051: val_loss did not improve from 0.79474
Epoch 52/60
 - 4s - loss: 0.9648 - acc: 0.6856 - val_loss: 0.7900 - val_acc: 0.7195

Epoch 00052: val_loss improved from 0.79474 to 0.78996, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 53/60
 - 4s - loss: 0.9641 - acc: 0.6858 - val_loss: 0.8132 - val_acc: 0.7148

Epoch 00053: val_loss did not improve from 0.78996
Epoch 54/60
 - 4s - loss: 0.9567 - acc: 0.6870 - val_loss: 0.7811 - val_acc: 0.7201

Epoch 00054: val_loss improved from 0.78996 to 0.78115, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 55/60
 - 4s - loss: 0.9563 - acc: 0.6896 - val_loss: 0.7793 - val_acc: 0.7311

Epoch 00055: val_loss improved from 0.78115 to 0.77928, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 56/60
 - 4s - loss: 0.9531 - acc: 0.6889 - val_loss: 0.7817 - val_acc: 0.7295

Epoch 00056: val_loss did not improve from 0.77928
Epoch 57/60
 - 4s - loss: 0.9470 - acc: 0.6908 - val_loss: 0.7655 - val_acc: 0.7308

Epoch 00057: val_loss improved from 0.77928 to 0.76552, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 58/60
 - 4s - loss: 0.9415 - acc: 0.6929 - val_loss: 0.7611 - val_acc: 0.7237

Epoch 00058: val_loss improved from 0.76552 to 0.76110, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 59/60
 - 4s - loss: 0.9378 - acc: 0.6943 - val_loss: 0.7737 - val_acc: 0.7327

Epoch 00059: val_loss did not improve from 0.76110
Epoch 60/60
 - 4s - loss: 0.9412 - acc: 0.6949 - val_loss: 0.7488 - val_acc: 0.7386

Epoch 00060: val_loss improved from 0.76110 to 0.74882, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 1.8943 - acc: 0.5798 - val_loss: 1.6335 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 1.63355, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 2/60
 - 5s - loss: 1.4615 - acc: 0.6354 - val_loss: 1.3923 - val_acc: 0.6231

Epoch 00002: val_loss improved from 1.63355 to 1.39226, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 3/60
 - 5s - loss: 1.3618 - acc: 0.6375 - val_loss: 1.3654 - val_acc: 0.6425

Epoch 00003: val_loss improved from 1.39226 to 1.36544, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 4/60
 - 5s - loss: 1.2888 - acc: 0.6432 - val_loss: 1.1881 - val_acc: 0.6459

Epoch 00004: val_loss improved from 1.36544 to 1.18815, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 5/60
 - 5s - loss: 1.2293 - acc: 0.6495 - val_loss: 1.1328 - val_acc: 0.6620

Epoch 00005: val_loss improved from 1.18815 to 1.13284, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 6/60
 - 5s - loss: 1.1812 - acc: 0.6560 - val_loss: 1.0950 - val_acc: 0.6723

Epoch 00006: val_loss improved from 1.13284 to 1.09499, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 7/60
 - 5s - loss: 1.1413 - acc: 0.6628 - val_loss: 1.0662 - val_acc: 0.6767

Epoch 00007: val_loss improved from 1.09499 to 1.06620, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 8/60
 - 5s - loss: 1.1118 - acc: 0.6657 - val_loss: 1.0047 - val_acc: 0.6839

Epoch 00008: val_loss improved from 1.06620 to 1.00469, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 9/60
 - 5s - loss: 1.0832 - acc: 0.6699 - val_loss: 0.9591 - val_acc: 0.6831

Epoch 00009: val_loss improved from 1.00469 to 0.95915, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 10/60
 - 5s - loss: 1.0599 - acc: 0.6736 - val_loss: 0.9573 - val_acc: 0.6912

Epoch 00010: val_loss improved from 0.95915 to 0.95726, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 11/60
 - 5s - loss: 1.0376 - acc: 0.6777 - val_loss: 0.9013 - val_acc: 0.6940

Epoch 00011: val_loss improved from 0.95726 to 0.90132, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 12/60
 - 5s - loss: 1.0203 - acc: 0.6800 - val_loss: 0.8847 - val_acc: 0.6958

Epoch 00012: val_loss improved from 0.90132 to 0.88470, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 13/60
 - 5s - loss: 0.9978 - acc: 0.6835 - val_loss: 0.8835 - val_acc: 0.7039

Epoch 00013: val_loss improved from 0.88470 to 0.88355, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 14/60
 - 5s - loss: 0.9768 - acc: 0.6875 - val_loss: 0.8875 - val_acc: 0.7143

Epoch 00014: val_loss did not improve from 0.88355
Epoch 15/60
 - 5s - loss: 0.9575 - acc: 0.6938 - val_loss: 0.8161 - val_acc: 0.7205

Epoch 00015: val_loss improved from 0.88355 to 0.81613, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 16/60
 - 5s - loss: 0.9393 - acc: 0.6955 - val_loss: 0.8052 - val_acc: 0.7258

Epoch 00016: val_loss improved from 0.81613 to 0.80517, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 17/60
 - 5s - loss: 0.9248 - acc: 0.6990 - val_loss: 0.7601 - val_acc: 0.7412

Epoch 00017: val_loss improved from 0.80517 to 0.76008, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 18/60
 - 5s - loss: 0.9037 - acc: 0.7048 - val_loss: 0.7585 - val_acc: 0.7554

Epoch 00018: val_loss improved from 0.76008 to 0.75855, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 19/60
 - 5s - loss: 0.8878 - acc: 0.7100 - val_loss: 0.7468 - val_acc: 0.7543

Epoch 00019: val_loss improved from 0.75855 to 0.74680, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 20/60
 - 5s - loss: 0.8830 - acc: 0.7151 - val_loss: 0.7341 - val_acc: 0.7618

Epoch 00020: val_loss improved from 0.74680 to 0.73408, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 21/60
 - 5s - loss: 0.8616 - acc: 0.7188 - val_loss: 0.7133 - val_acc: 0.7633

Epoch 00021: val_loss improved from 0.73408 to 0.71333, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 22/60
 - 5s - loss: 0.8527 - acc: 0.7243 - val_loss: 0.6919 - val_acc: 0.7704

Epoch 00022: val_loss improved from 0.71333 to 0.69187, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 23/60
 - 5s - loss: 0.8380 - acc: 0.7249 - val_loss: 0.6775 - val_acc: 0.7710

Epoch 00023: val_loss improved from 0.69187 to 0.67755, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 24/60
 - 5s - loss: 0.8284 - acc: 0.7288 - val_loss: 0.6627 - val_acc: 0.7814

Epoch 00024: val_loss improved from 0.67755 to 0.66270, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 25/60
 - 5s - loss: 0.8172 - acc: 0.7324 - val_loss: 0.6663 - val_acc: 0.7736

Epoch 00025: val_loss did not improve from 0.66270
Epoch 26/60
 - 5s - loss: 0.8073 - acc: 0.7382 - val_loss: 0.6378 - val_acc: 0.7907

Epoch 00026: val_loss improved from 0.66270 to 0.63779, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 27/60
 - 5s - loss: 0.8043 - acc: 0.7367 - val_loss: 0.6422 - val_acc: 0.7799

Epoch 00027: val_loss did not improve from 0.63779
Epoch 28/60
 - 5s - loss: 0.7911 - acc: 0.7396 - val_loss: 0.6356 - val_acc: 0.7917

Epoch 00028: val_loss improved from 0.63779 to 0.63562, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 29/60
 - 5s - loss: 0.7845 - acc: 0.7429 - val_loss: 0.6209 - val_acc: 0.7942

Epoch 00029: val_loss improved from 0.63562 to 0.62091, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 30/60
 - 5s - loss: 0.7784 - acc: 0.7453 - val_loss: 0.6172 - val_acc: 0.7919

Epoch 00030: val_loss improved from 0.62091 to 0.61717, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 31/60
 - 5s - loss: 0.7671 - acc: 0.7487 - val_loss: 0.5953 - val_acc: 0.8002

Epoch 00031: val_loss improved from 0.61717 to 0.59532, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 32/60
 - 5s - loss: 0.7631 - acc: 0.7494 - val_loss: 0.6279 - val_acc: 0.8016

Epoch 00032: val_loss did not improve from 0.59532
Epoch 33/60
 - 5s - loss: 0.7549 - acc: 0.7548 - val_loss: 0.5878 - val_acc: 0.8057

Epoch 00033: val_loss improved from 0.59532 to 0.58780, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 34/60
 - 5s - loss: 0.7505 - acc: 0.7539 - val_loss: 0.5872 - val_acc: 0.8060

Epoch 00034: val_loss improved from 0.58780 to 0.58724, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 35/60
 - 5s - loss: 0.7458 - acc: 0.7543 - val_loss: 0.5801 - val_acc: 0.8076

Epoch 00035: val_loss improved from 0.58724 to 0.58006, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 36/60
 - 5s - loss: 0.7396 - acc: 0.7564 - val_loss: 0.5750 - val_acc: 0.8067

Epoch 00036: val_loss improved from 0.58006 to 0.57500, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 37/60
 - 5s - loss: 0.7346 - acc: 0.7602 - val_loss: 0.5704 - val_acc: 0.8139

Epoch 00037: val_loss improved from 0.57500 to 0.57041, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 38/60
 - 5s - loss: 0.7322 - acc: 0.7595 - val_loss: 0.5725 - val_acc: 0.8120

Epoch 00038: val_loss did not improve from 0.57041
Epoch 39/60
 - 5s - loss: 0.7251 - acc: 0.7627 - val_loss: 0.5544 - val_acc: 0.8083

Epoch 00039: val_loss improved from 0.57041 to 0.55440, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 40/60
 - 5s - loss: 0.7245 - acc: 0.7641 - val_loss: 0.5664 - val_acc: 0.8130

Epoch 00040: val_loss did not improve from 0.55440
Epoch 41/60
 - 5s - loss: 0.7177 - acc: 0.7654 - val_loss: 0.5479 - val_acc: 0.8179

Epoch 00041: val_loss improved from 0.55440 to 0.54788, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 42/60
 - 5s - loss: 0.7139 - acc: 0.7657 - val_loss: 0.5541 - val_acc: 0.8133

Epoch 00042: val_loss did not improve from 0.54788
Epoch 43/60
 - 5s - loss: 0.7046 - acc: 0.7714 - val_loss: 0.5528 - val_acc: 0.8141

Epoch 00043: val_loss did not improve from 0.54788
Epoch 44/60
 - 5s - loss: 0.7060 - acc: 0.7688 - val_loss: 0.5262 - val_acc: 0.8214

Epoch 00044: val_loss improved from 0.54788 to 0.52623, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 45/60
 - 5s - loss: 0.7010 - acc: 0.7714 - val_loss: 0.5296 - val_acc: 0.8239

Epoch 00045: val_loss did not improve from 0.52623
Epoch 46/60
 - 5s - loss: 0.7028 - acc: 0.7686 - val_loss: 0.5347 - val_acc: 0.8189

Epoch 00046: val_loss did not improve from 0.52623
Epoch 47/60
 - 5s - loss: 0.6989 - acc: 0.7718 - val_loss: 0.5421 - val_acc: 0.8255

Epoch 00047: val_loss did not improve from 0.52623
Epoch 48/60
 - 5s - loss: 0.6952 - acc: 0.7737 - val_loss: 0.5187 - val_acc: 0.8251

Epoch 00048: val_loss improved from 0.52623 to 0.51867, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 49/60
 - 5s - loss: 0.6912 - acc: 0.7750 - val_loss: 0.5215 - val_acc: 0.8205

Epoch 00049: val_loss did not improve from 0.51867
Epoch 50/60
 - 5s - loss: 0.6866 - acc: 0.7762 - val_loss: 0.5371 - val_acc: 0.8173

Epoch 00050: val_loss did not improve from 0.51867
Epoch 51/60
 - 5s - loss: 0.6855 - acc: 0.7741 - val_loss: 0.5184 - val_acc: 0.8248

Epoch 00051: val_loss improved from 0.51867 to 0.51844, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 52/60
 - 5s - loss: 0.6835 - acc: 0.7752 - val_loss: 0.5045 - val_acc: 0.8277

Epoch 00052: val_loss improved from 0.51844 to 0.50455, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 53/60
 - 5s - loss: 0.6799 - acc: 0.7797 - val_loss: 0.5258 - val_acc: 0.8297

Epoch 00053: val_loss did not improve from 0.50455
Epoch 54/60
 - 5s - loss: 0.6725 - acc: 0.7818 - val_loss: 0.5027 - val_acc: 0.8273

Epoch 00054: val_loss improved from 0.50455 to 0.50272, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 55/60
 - 5s - loss: 0.6743 - acc: 0.7802 - val_loss: 0.5020 - val_acc: 0.8294

Epoch 00055: val_loss improved from 0.50272 to 0.50196, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 56/60
 - 5s - loss: 0.6669 - acc: 0.7825 - val_loss: 0.5094 - val_acc: 0.8332

Epoch 00056: val_loss did not improve from 0.50196
Epoch 57/60
 - 5s - loss: 0.6699 - acc: 0.7811 - val_loss: 0.5154 - val_acc: 0.8336

Epoch 00057: val_loss did not improve from 0.50196
Epoch 58/60
 - 5s - loss: 0.6701 - acc: 0.7831 - val_loss: 0.4989 - val_acc: 0.8320

Epoch 00058: val_loss improved from 0.50196 to 0.49894, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 59/60
 - 5s - loss: 0.6628 - acc: 0.7843 - val_loss: 0.4962 - val_acc: 0.8325

Epoch 00059: val_loss improved from 0.49894 to 0.49619, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Epoch 60/60
 - 5s - loss: 0.6623 - acc: 0.7850 - val_loss: 0.4882 - val_acc: 0.8344

Epoch 00060: val_loss improved from 0.49619 to 0.48818, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 7s - loss: 2.1976 - acc: 0.5705 - val_loss: 1.1795 - val_acc: 0.6445

Epoch 00001: val_loss improved from inf to 1.17952, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 2/60
 - 5s - loss: 1.1331 - acc: 0.6617 - val_loss: 0.9732 - val_acc: 0.6955

Epoch 00002: val_loss improved from 1.17952 to 0.97319, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 3/60
 - 5s - loss: 0.9139 - acc: 0.7165 - val_loss: 0.7205 - val_acc: 0.7748

Epoch 00003: val_loss improved from 0.97319 to 0.72048, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 4/60
 - 5s - loss: 0.7829 - acc: 0.7523 - val_loss: 0.6269 - val_acc: 0.8014

Epoch 00004: val_loss improved from 0.72048 to 0.62692, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 5/60
 - 5s - loss: 0.7012 - acc: 0.7768 - val_loss: 0.6243 - val_acc: 0.8011

Epoch 00005: val_loss improved from 0.62692 to 0.62430, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 6/60
 - 5s - loss: 0.6483 - acc: 0.7935 - val_loss: 0.5533 - val_acc: 0.8220

Epoch 00006: val_loss improved from 0.62430 to 0.55335, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 7/60
 - 5s - loss: 0.6017 - acc: 0.8067 - val_loss: 0.5616 - val_acc: 0.8126

Epoch 00007: val_loss did not improve from 0.55335
Epoch 8/60
 - 5s - loss: 0.5802 - acc: 0.8136 - val_loss: 0.5193 - val_acc: 0.8366

Epoch 00008: val_loss improved from 0.55335 to 0.51929, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 9/60
 - 5s - loss: 0.5475 - acc: 0.8253 - val_loss: 0.4851 - val_acc: 0.8513

Epoch 00009: val_loss improved from 0.51929 to 0.48506, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 10/60
 - 5s - loss: 0.5196 - acc: 0.8308 - val_loss: 0.4775 - val_acc: 0.8526

Epoch 00010: val_loss improved from 0.48506 to 0.47750, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 11/60
 - 5s - loss: 0.4987 - acc: 0.8392 - val_loss: 0.4666 - val_acc: 0.8519

Epoch 00011: val_loss improved from 0.47750 to 0.46664, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 12/60
 - 5s - loss: 0.4876 - acc: 0.8436 - val_loss: 0.4666 - val_acc: 0.8541

Epoch 00012: val_loss improved from 0.46664 to 0.46661, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 13/60
 - 5s - loss: 0.4694 - acc: 0.8488 - val_loss: 0.4555 - val_acc: 0.8553

Epoch 00013: val_loss improved from 0.46661 to 0.45552, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 14/60
 - 5s - loss: 0.4602 - acc: 0.8514 - val_loss: 0.4496 - val_acc: 0.8638

Epoch 00014: val_loss improved from 0.45552 to 0.44959, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 15/60
 - 5s - loss: 0.4495 - acc: 0.8554 - val_loss: 0.4435 - val_acc: 0.8630

Epoch 00015: val_loss improved from 0.44959 to 0.44346, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 16/60
 - 5s - loss: 0.4401 - acc: 0.8579 - val_loss: 0.4674 - val_acc: 0.8522

Epoch 00016: val_loss did not improve from 0.44346
Epoch 17/60
 - 5s - loss: 0.4249 - acc: 0.8619 - val_loss: 0.4396 - val_acc: 0.8583

Epoch 00017: val_loss improved from 0.44346 to 0.43963, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 18/60
 - 5s - loss: 0.4229 - acc: 0.8630 - val_loss: 0.4326 - val_acc: 0.8663

Epoch 00018: val_loss improved from 0.43963 to 0.43258, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 19/60
 - 5s - loss: 0.4131 - acc: 0.8660 - val_loss: 0.4244 - val_acc: 0.8686

Epoch 00019: val_loss improved from 0.43258 to 0.42439, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 20/60
 - 5s - loss: 0.4061 - acc: 0.8680 - val_loss: 0.4234 - val_acc: 0.8698

Epoch 00020: val_loss improved from 0.42439 to 0.42338, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 21/60
 - 5s - loss: 0.3987 - acc: 0.8713 - val_loss: 0.4134 - val_acc: 0.8747

Epoch 00021: val_loss improved from 0.42338 to 0.41345, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 22/60
 - 5s - loss: 0.3945 - acc: 0.8709 - val_loss: 0.3967 - val_acc: 0.8782

Epoch 00022: val_loss improved from 0.41345 to 0.39673, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 23/60
 - 5s - loss: 0.3867 - acc: 0.8728 - val_loss: 0.4184 - val_acc: 0.8738

Epoch 00023: val_loss did not improve from 0.39673
Epoch 24/60
 - 5s - loss: 0.3813 - acc: 0.8751 - val_loss: 0.3937 - val_acc: 0.8783

Epoch 00024: val_loss improved from 0.39673 to 0.39365, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 25/60
 - 5s - loss: 0.3785 - acc: 0.8759 - val_loss: 0.4076 - val_acc: 0.8772

Epoch 00025: val_loss did not improve from 0.39365
Epoch 26/60
 - 5s - loss: 0.3756 - acc: 0.8768 - val_loss: 0.4164 - val_acc: 0.8738

Epoch 00026: val_loss did not improve from 0.39365
Epoch 27/60
 - 5s - loss: 0.3738 - acc: 0.8775 - val_loss: 0.3923 - val_acc: 0.8803

Epoch 00027: val_loss improved from 0.39365 to 0.39226, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 28/60
 - 5s - loss: 0.3648 - acc: 0.8808 - val_loss: 0.4019 - val_acc: 0.8764

Epoch 00028: val_loss did not improve from 0.39226
Epoch 29/60
 - 5s - loss: 0.3620 - acc: 0.8814 - val_loss: 0.3938 - val_acc: 0.8792

Epoch 00029: val_loss did not improve from 0.39226
Epoch 30/60
 - 5s - loss: 0.3549 - acc: 0.8831 - val_loss: 0.4512 - val_acc: 0.8636

Epoch 00030: val_loss did not improve from 0.39226
Epoch 31/60
 - 5s - loss: 0.3534 - acc: 0.8835 - val_loss: 0.3976 - val_acc: 0.8760

Epoch 00031: val_loss did not improve from 0.39226
Epoch 32/60
 - 5s - loss: 0.3542 - acc: 0.8822 - val_loss: 0.3870 - val_acc: 0.8829

Epoch 00032: val_loss improved from 0.39226 to 0.38698, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 33/60
 - 5s - loss: 0.3488 - acc: 0.8850 - val_loss: 0.4027 - val_acc: 0.8773

Epoch 00033: val_loss did not improve from 0.38698
Epoch 34/60
 - 5s - loss: 0.3452 - acc: 0.8855 - val_loss: 0.4026 - val_acc: 0.8735

Epoch 00034: val_loss did not improve from 0.38698
Epoch 35/60
 - 5s - loss: 0.3420 - acc: 0.8871 - val_loss: 0.3939 - val_acc: 0.8766

Epoch 00035: val_loss did not improve from 0.38698
Epoch 36/60
 - 5s - loss: 0.3398 - acc: 0.8870 - val_loss: 0.3801 - val_acc: 0.8878

Epoch 00036: val_loss improved from 0.38698 to 0.38009, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 37/60
 - 5s - loss: 0.3404 - acc: 0.8879 - val_loss: 0.3782 - val_acc: 0.8823

Epoch 00037: val_loss improved from 0.38009 to 0.37820, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 38/60
 - 5s - loss: 0.3338 - acc: 0.8899 - val_loss: 0.3755 - val_acc: 0.8835

Epoch 00038: val_loss improved from 0.37820 to 0.37553, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 39/60
 - 5s - loss: 0.3334 - acc: 0.8886 - val_loss: 0.3752 - val_acc: 0.8831

Epoch 00039: val_loss improved from 0.37553 to 0.37517, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 40/60
 - 5s - loss: 0.3289 - acc: 0.8924 - val_loss: 0.3869 - val_acc: 0.8832

Epoch 00040: val_loss did not improve from 0.37517
Epoch 41/60
 - 5s - loss: 0.3297 - acc: 0.8908 - val_loss: 0.3844 - val_acc: 0.8832

Epoch 00041: val_loss did not improve from 0.37517
Epoch 42/60
 - 5s - loss: 0.3297 - acc: 0.8912 - val_loss: 0.3827 - val_acc: 0.8806

Epoch 00042: val_loss did not improve from 0.37517
Epoch 43/60
 - 5s - loss: 0.3290 - acc: 0.8918 - val_loss: 0.4132 - val_acc: 0.8763

Epoch 00043: val_loss did not improve from 0.37517
Epoch 44/60
 - 5s - loss: 0.3242 - acc: 0.8931 - val_loss: 0.3822 - val_acc: 0.8864

Epoch 00044: val_loss did not improve from 0.37517
Epoch 45/60
 - 5s - loss: 0.3175 - acc: 0.8944 - val_loss: 0.3905 - val_acc: 0.8820

Epoch 00045: val_loss did not improve from 0.37517
Epoch 46/60
 - 5s - loss: 0.3174 - acc: 0.8950 - val_loss: 0.4035 - val_acc: 0.8832

Epoch 00046: val_loss did not improve from 0.37517
Epoch 47/60
 - 5s - loss: 0.3183 - acc: 0.8944 - val_loss: 0.3721 - val_acc: 0.8866

Epoch 00047: val_loss improved from 0.37517 to 0.37211, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 48/60
 - 5s - loss: 0.3137 - acc: 0.8966 - val_loss: 0.3648 - val_acc: 0.8892

Epoch 00048: val_loss improved from 0.37211 to 0.36476, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5
Epoch 49/60
 - 5s - loss: 0.3139 - acc: 0.8967 - val_loss: 0.3837 - val_acc: 0.8856

Epoch 00049: val_loss did not improve from 0.36476
Epoch 50/60
 - 5s - loss: 0.3177 - acc: 0.8958 - val_loss: 0.3685 - val_acc: 0.8888

Epoch 00050: val_loss did not improve from 0.36476
Epoch 51/60
 - 5s - loss: 0.3131 - acc: 0.8974 - val_loss: 0.4135 - val_acc: 0.8764

Epoch 00051: val_loss did not improve from 0.36476
Epoch 52/60
 - 5s - loss: 0.3159 - acc: 0.8948 - val_loss: 0.3772 - val_acc: 0.8889

Epoch 00052: val_loss did not improve from 0.36476
Epoch 53/60
 - 5s - loss: 0.3083 - acc: 0.8989 - val_loss: 0.3709 - val_acc: 0.8894

Epoch 00053: val_loss did not improve from 0.36476
Epoch 54/60
 - 5s - loss: 0.3088 - acc: 0.8984 - val_loss: 0.3865 - val_acc: 0.8807

Epoch 00054: val_loss did not improve from 0.36476
Epoch 55/60
 - 5s - loss: 0.3091 - acc: 0.8984 - val_loss: 0.3828 - val_acc: 0.8817

Epoch 00055: val_loss did not improve from 0.36476
Epoch 56/60
 - 5s - loss: 0.3016 - acc: 0.8997 - val_loss: 0.3669 - val_acc: 0.8904

Epoch 00056: val_loss did not improve from 0.36476
Epoch 57/60
 - 5s - loss: 0.3007 - acc: 0.9006 - val_loss: 0.3851 - val_acc: 0.8819

Epoch 00057: val_loss did not improve from 0.36476
Epoch 58/60
 - 5s - loss: 0.3046 - acc: 0.8982 - val_loss: 0.3799 - val_acc: 0.8850

Epoch 00058: val_loss did not improve from 0.36476
Epoch 00058: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 7s - loss: 2.1593 - acc: 0.4675 - val_loss: 1.8371 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 1.83707, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 2/60
 - 4s - loss: 1.6245 - acc: 0.6299 - val_loss: 1.6171 - val_acc: 0.6209

Epoch 00002: val_loss improved from 1.83707 to 1.61712, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 3/60
 - 4s - loss: 1.5298 - acc: 0.6369 - val_loss: 1.5619 - val_acc: 0.6209

Epoch 00003: val_loss improved from 1.61712 to 1.56187, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 4/60
 - 4s - loss: 1.4794 - acc: 0.6371 - val_loss: 1.4604 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.56187 to 1.46038, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 5/60
 - 4s - loss: 1.4456 - acc: 0.6371 - val_loss: 1.4062 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.46038 to 1.40615, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 6/60
 - 4s - loss: 1.4174 - acc: 0.6371 - val_loss: 1.3764 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.40615 to 1.37641, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 7/60
 - 4s - loss: 1.3860 - acc: 0.6372 - val_loss: 1.3311 - val_acc: 0.6233

Epoch 00007: val_loss improved from 1.37641 to 1.33110, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 8/60
 - 4s - loss: 1.3486 - acc: 0.6385 - val_loss: 1.2872 - val_acc: 0.6240

Epoch 00008: val_loss improved from 1.33110 to 1.28723, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 9/60
 - 4s - loss: 1.3207 - acc: 0.6400 - val_loss: 1.2833 - val_acc: 0.6265

Epoch 00009: val_loss improved from 1.28723 to 1.28327, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 10/60
 - 4s - loss: 1.2938 - acc: 0.6417 - val_loss: 1.2476 - val_acc: 0.6395

Epoch 00010: val_loss improved from 1.28327 to 1.24765, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 11/60
 - 4s - loss: 1.2691 - acc: 0.6444 - val_loss: 1.2050 - val_acc: 0.6409

Epoch 00011: val_loss improved from 1.24765 to 1.20499, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 12/60
 - 4s - loss: 1.2472 - acc: 0.6450 - val_loss: 1.1642 - val_acc: 0.6467

Epoch 00012: val_loss improved from 1.20499 to 1.16421, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 13/60
 - 4s - loss: 1.2334 - acc: 0.6472 - val_loss: 1.1438 - val_acc: 0.6472

Epoch 00013: val_loss improved from 1.16421 to 1.14380, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 14/60
 - 4s - loss: 1.2142 - acc: 0.6497 - val_loss: 1.1480 - val_acc: 0.6483

Epoch 00014: val_loss did not improve from 1.14380
Epoch 15/60
 - 4s - loss: 1.1945 - acc: 0.6531 - val_loss: 1.1121 - val_acc: 0.6505

Epoch 00015: val_loss improved from 1.14380 to 1.11209, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 16/60
 - 4s - loss: 1.1899 - acc: 0.6519 - val_loss: 1.1296 - val_acc: 0.6505

Epoch 00016: val_loss did not improve from 1.11209
Epoch 17/60
 - 4s - loss: 1.1755 - acc: 0.6546 - val_loss: 1.1130 - val_acc: 0.6583

Epoch 00017: val_loss did not improve from 1.11209
Epoch 18/60
 - 4s - loss: 1.1617 - acc: 0.6561 - val_loss: 1.1124 - val_acc: 0.6609

Epoch 00018: val_loss did not improve from 1.11209
Epoch 19/60
 - 4s - loss: 1.1517 - acc: 0.6592 - val_loss: 1.0704 - val_acc: 0.6653

Epoch 00019: val_loss improved from 1.11209 to 1.07040, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 20/60
 - 4s - loss: 1.1396 - acc: 0.6600 - val_loss: 1.0517 - val_acc: 0.6642

Epoch 00020: val_loss improved from 1.07040 to 1.05171, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 21/60
 - 4s - loss: 1.1380 - acc: 0.6598 - val_loss: 1.0446 - val_acc: 0.6687

Epoch 00021: val_loss improved from 1.05171 to 1.04462, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 22/60
 - 4s - loss: 1.1295 - acc: 0.6611 - val_loss: 1.0275 - val_acc: 0.6762

Epoch 00022: val_loss improved from 1.04462 to 1.02745, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 23/60
 - 4s - loss: 1.1201 - acc: 0.6632 - val_loss: 1.0373 - val_acc: 0.6714

Epoch 00023: val_loss did not improve from 1.02745
Epoch 24/60
 - 4s - loss: 1.1111 - acc: 0.6650 - val_loss: 1.0049 - val_acc: 0.6733

Epoch 00024: val_loss improved from 1.02745 to 1.00491, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 25/60
 - 4s - loss: 1.1012 - acc: 0.6663 - val_loss: 0.9963 - val_acc: 0.6771

Epoch 00025: val_loss improved from 1.00491 to 0.99628, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 26/60
 - 4s - loss: 1.0936 - acc: 0.6683 - val_loss: 0.9961 - val_acc: 0.6824

Epoch 00026: val_loss improved from 0.99628 to 0.99608, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 27/60
 - 4s - loss: 1.0860 - acc: 0.6716 - val_loss: 0.9892 - val_acc: 0.6809

Epoch 00027: val_loss improved from 0.99608 to 0.98923, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 28/60
 - 4s - loss: 1.0808 - acc: 0.6711 - val_loss: 0.9673 - val_acc: 0.6862

Epoch 00028: val_loss improved from 0.98923 to 0.96734, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 29/60
 - 4s - loss: 1.0755 - acc: 0.6729 - val_loss: 0.9681 - val_acc: 0.6809

Epoch 00029: val_loss did not improve from 0.96734
Epoch 30/60
 - 4s - loss: 1.0650 - acc: 0.6733 - val_loss: 0.9476 - val_acc: 0.6893

Epoch 00030: val_loss improved from 0.96734 to 0.94755, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 31/60
 - 4s - loss: 1.0613 - acc: 0.6743 - val_loss: 0.9507 - val_acc: 0.6889

Epoch 00031: val_loss did not improve from 0.94755
Epoch 32/60
 - 4s - loss: 1.0535 - acc: 0.6761 - val_loss: 0.9441 - val_acc: 0.6842

Epoch 00032: val_loss improved from 0.94755 to 0.94410, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 33/60
 - 4s - loss: 1.0467 - acc: 0.6768 - val_loss: 0.9419 - val_acc: 0.6934

Epoch 00033: val_loss improved from 0.94410 to 0.94190, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 34/60
 - 4s - loss: 1.0484 - acc: 0.6773 - val_loss: 0.9174 - val_acc: 0.6929

Epoch 00034: val_loss improved from 0.94190 to 0.91739, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 35/60
 - 4s - loss: 1.0377 - acc: 0.6788 - val_loss: 0.9317 - val_acc: 0.6920

Epoch 00035: val_loss did not improve from 0.91739
Epoch 36/60
 - 4s - loss: 1.0363 - acc: 0.6788 - val_loss: 0.9025 - val_acc: 0.6930

Epoch 00036: val_loss improved from 0.91739 to 0.90252, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 37/60
 - 4s - loss: 1.0263 - acc: 0.6778 - val_loss: 0.9242 - val_acc: 0.6971

Epoch 00037: val_loss did not improve from 0.90252
Epoch 38/60
 - 4s - loss: 1.0263 - acc: 0.6816 - val_loss: 0.9051 - val_acc: 0.6959

Epoch 00038: val_loss did not improve from 0.90252
Epoch 39/60
 - 4s - loss: 1.0224 - acc: 0.6815 - val_loss: 0.8797 - val_acc: 0.6931

Epoch 00039: val_loss improved from 0.90252 to 0.87971, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 40/60
 - 4s - loss: 1.0145 - acc: 0.6809 - val_loss: 0.9079 - val_acc: 0.6921

Epoch 00040: val_loss did not improve from 0.87971
Epoch 41/60
 - 4s - loss: 1.0101 - acc: 0.6817 - val_loss: 0.8730 - val_acc: 0.6942

Epoch 00041: val_loss improved from 0.87971 to 0.87297, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 42/60
 - 4s - loss: 1.0058 - acc: 0.6825 - val_loss: 0.8593 - val_acc: 0.7005

Epoch 00042: val_loss improved from 0.87297 to 0.85928, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 43/60
 - 4s - loss: 1.0043 - acc: 0.6814 - val_loss: 0.8840 - val_acc: 0.6977

Epoch 00043: val_loss did not improve from 0.85928
Epoch 44/60
 - 4s - loss: 1.0011 - acc: 0.6826 - val_loss: 0.8557 - val_acc: 0.6987

Epoch 00044: val_loss improved from 0.85928 to 0.85568, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 45/60
 - 4s - loss: 0.9916 - acc: 0.6837 - val_loss: 0.8476 - val_acc: 0.7026

Epoch 00045: val_loss improved from 0.85568 to 0.84756, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 46/60
 - 4s - loss: 0.9918 - acc: 0.6867 - val_loss: 0.8522 - val_acc: 0.7049

Epoch 00046: val_loss did not improve from 0.84756
Epoch 47/60
 - 4s - loss: 0.9851 - acc: 0.6870 - val_loss: 0.8515 - val_acc: 0.6964

Epoch 00047: val_loss did not improve from 0.84756
Epoch 48/60
 - 4s - loss: 0.9805 - acc: 0.6869 - val_loss: 0.8283 - val_acc: 0.7095

Epoch 00048: val_loss improved from 0.84756 to 0.82825, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 49/60
 - 4s - loss: 0.9833 - acc: 0.6866 - val_loss: 0.8278 - val_acc: 0.7114

Epoch 00049: val_loss improved from 0.82825 to 0.82778, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 50/60
 - 4s - loss: 0.9720 - acc: 0.6879 - val_loss: 0.8327 - val_acc: 0.7064

Epoch 00050: val_loss did not improve from 0.82778
Epoch 51/60
 - 4s - loss: 0.9721 - acc: 0.6871 - val_loss: 0.8218 - val_acc: 0.7098

Epoch 00051: val_loss improved from 0.82778 to 0.82175, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 52/60
 - 4s - loss: 0.9641 - acc: 0.6884 - val_loss: 0.7915 - val_acc: 0.7123

Epoch 00052: val_loss improved from 0.82175 to 0.79150, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 53/60
 - 4s - loss: 0.9588 - acc: 0.6915 - val_loss: 0.8022 - val_acc: 0.7149

Epoch 00053: val_loss did not improve from 0.79150
Epoch 54/60
 - 4s - loss: 0.9522 - acc: 0.6929 - val_loss: 0.7875 - val_acc: 0.7190

Epoch 00054: val_loss improved from 0.79150 to 0.78750, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 55/60
 - 4s - loss: 0.9548 - acc: 0.6921 - val_loss: 0.7741 - val_acc: 0.7164

Epoch 00055: val_loss improved from 0.78750 to 0.77406, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 56/60
 - 4s - loss: 0.9437 - acc: 0.6938 - val_loss: 0.7705 - val_acc: 0.7183

Epoch 00056: val_loss improved from 0.77406 to 0.77049, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 57/60
 - 4s - loss: 0.9426 - acc: 0.6944 - val_loss: 0.7675 - val_acc: 0.7201

Epoch 00057: val_loss improved from 0.77049 to 0.76751, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 58/60
 - 4s - loss: 0.9425 - acc: 0.6958 - val_loss: 0.7662 - val_acc: 0.7307

Epoch 00058: val_loss improved from 0.76751 to 0.76619, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 59/60
 - 4s - loss: 0.9460 - acc: 0.6968 - val_loss: 0.7618 - val_acc: 0.7251

Epoch 00059: val_loss improved from 0.76619 to 0.76180, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5
Epoch 60/60
 - 4s - loss: 0.9390 - acc: 0.6961 - val_loss: 0.7695 - val_acc: 0.7287

Epoch 00060: val_loss did not improve from 0.76180
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 2.0054 - acc: 0.5682 - val_loss: 1.6877 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 1.68766, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 2/60
 - 5s - loss: 1.4693 - acc: 0.6365 - val_loss: 1.4927 - val_acc: 0.6259

Epoch 00002: val_loss improved from 1.68766 to 1.49269, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 3/60
 - 5s - loss: 1.3424 - acc: 0.6402 - val_loss: 1.2367 - val_acc: 0.6486

Epoch 00003: val_loss improved from 1.49269 to 1.23670, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 4/60
 - 5s - loss: 1.2609 - acc: 0.6451 - val_loss: 1.2085 - val_acc: 0.6574

Epoch 00004: val_loss improved from 1.23670 to 1.20846, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 5/60
 - 5s - loss: 1.2101 - acc: 0.6519 - val_loss: 1.1386 - val_acc: 0.6596

Epoch 00005: val_loss improved from 1.20846 to 1.13863, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 6/60
 - 5s - loss: 1.1679 - acc: 0.6579 - val_loss: 1.1286 - val_acc: 0.6711

Epoch 00006: val_loss improved from 1.13863 to 1.12858, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 7/60
 - 5s - loss: 1.1319 - acc: 0.6630 - val_loss: 1.0472 - val_acc: 0.6734

Epoch 00007: val_loss improved from 1.12858 to 1.04717, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 8/60
 - 5s - loss: 1.1081 - acc: 0.6669 - val_loss: 1.0465 - val_acc: 0.6792

Epoch 00008: val_loss improved from 1.04717 to 1.04648, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 9/60
 - 5s - loss: 1.0795 - acc: 0.6707 - val_loss: 0.9885 - val_acc: 0.6858

Epoch 00009: val_loss improved from 1.04648 to 0.98848, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 10/60
 - 5s - loss: 1.0580 - acc: 0.6751 - val_loss: 1.0019 - val_acc: 0.6890

Epoch 00010: val_loss did not improve from 0.98848
Epoch 11/60
 - 5s - loss: 1.0339 - acc: 0.6772 - val_loss: 0.9296 - val_acc: 0.6908

Epoch 00011: val_loss improved from 0.98848 to 0.92964, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 12/60
 - 5s - loss: 1.0126 - acc: 0.6813 - val_loss: 0.9036 - val_acc: 0.6878

Epoch 00012: val_loss improved from 0.92964 to 0.90359, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 13/60
 - 5s - loss: 0.9977 - acc: 0.6859 - val_loss: 0.8822 - val_acc: 0.7055

Epoch 00013: val_loss improved from 0.90359 to 0.88220, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 14/60
 - 5s - loss: 0.9776 - acc: 0.6898 - val_loss: 0.8393 - val_acc: 0.7102

Epoch 00014: val_loss improved from 0.88220 to 0.83932, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 15/60
 - 5s - loss: 0.9572 - acc: 0.6944 - val_loss: 0.8095 - val_acc: 0.7198

Epoch 00015: val_loss improved from 0.83932 to 0.80947, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 16/60
 - 5s - loss: 0.9404 - acc: 0.6976 - val_loss: 0.7829 - val_acc: 0.7248

Epoch 00016: val_loss improved from 0.80947 to 0.78295, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 17/60
 - 5s - loss: 0.9264 - acc: 0.7013 - val_loss: 0.7787 - val_acc: 0.7289

Epoch 00017: val_loss improved from 0.78295 to 0.77873, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 18/60
 - 5s - loss: 0.9130 - acc: 0.7058 - val_loss: 0.7719 - val_acc: 0.7412

Epoch 00018: val_loss improved from 0.77873 to 0.77191, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 19/60
 - 5s - loss: 0.8967 - acc: 0.7097 - val_loss: 0.7464 - val_acc: 0.7440

Epoch 00019: val_loss improved from 0.77191 to 0.74641, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 20/60
 - 5s - loss: 0.8820 - acc: 0.7125 - val_loss: 0.7584 - val_acc: 0.7565

Epoch 00020: val_loss did not improve from 0.74641
Epoch 21/60
 - 5s - loss: 0.8677 - acc: 0.7172 - val_loss: 0.7000 - val_acc: 0.7595

Epoch 00021: val_loss improved from 0.74641 to 0.70004, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 22/60
 - 5s - loss: 0.8523 - acc: 0.7226 - val_loss: 0.6957 - val_acc: 0.7607

Epoch 00022: val_loss improved from 0.70004 to 0.69567, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 23/60
 - 5s - loss: 0.8445 - acc: 0.7242 - val_loss: 0.6915 - val_acc: 0.7689

Epoch 00023: val_loss improved from 0.69567 to 0.69145, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 24/60
 - 5s - loss: 0.8309 - acc: 0.7271 - val_loss: 0.6594 - val_acc: 0.7767

Epoch 00024: val_loss improved from 0.69145 to 0.65943, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 25/60
 - 5s - loss: 0.8254 - acc: 0.7301 - val_loss: 0.6540 - val_acc: 0.7792

Epoch 00025: val_loss improved from 0.65943 to 0.65403, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 26/60
 - 5s - loss: 0.8105 - acc: 0.7328 - val_loss: 0.6385 - val_acc: 0.7801

Epoch 00026: val_loss improved from 0.65403 to 0.63848, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 27/60
 - 5s - loss: 0.7994 - acc: 0.7373 - val_loss: 0.6374 - val_acc: 0.7820

Epoch 00027: val_loss improved from 0.63848 to 0.63742, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 28/60
 - 5s - loss: 0.7940 - acc: 0.7388 - val_loss: 0.6310 - val_acc: 0.7945

Epoch 00028: val_loss improved from 0.63742 to 0.63103, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 29/60
 - 5s - loss: 0.7840 - acc: 0.7413 - val_loss: 0.6374 - val_acc: 0.7945

Epoch 00029: val_loss did not improve from 0.63103
Epoch 30/60
 - 5s - loss: 0.7752 - acc: 0.7439 - val_loss: 0.6065 - val_acc: 0.7966

Epoch 00030: val_loss improved from 0.63103 to 0.60646, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 31/60
 - 5s - loss: 0.7702 - acc: 0.7462 - val_loss: 0.6117 - val_acc: 0.7921

Epoch 00031: val_loss did not improve from 0.60646
Epoch 32/60
 - 5s - loss: 0.7613 - acc: 0.7483 - val_loss: 0.6043 - val_acc: 0.7932

Epoch 00032: val_loss improved from 0.60646 to 0.60433, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 33/60
 - 5s - loss: 0.7588 - acc: 0.7490 - val_loss: 0.5813 - val_acc: 0.8004

Epoch 00033: val_loss improved from 0.60433 to 0.58131, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 34/60
 - 5s - loss: 0.7489 - acc: 0.7543 - val_loss: 0.5896 - val_acc: 0.7999

Epoch 00034: val_loss did not improve from 0.58131
Epoch 35/60
 - 5s - loss: 0.7415 - acc: 0.7567 - val_loss: 0.5735 - val_acc: 0.8038

Epoch 00035: val_loss improved from 0.58131 to 0.57347, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 36/60
 - 5s - loss: 0.7406 - acc: 0.7561 - val_loss: 0.5833 - val_acc: 0.8074

Epoch 00036: val_loss did not improve from 0.57347
Epoch 37/60
 - 5s - loss: 0.7360 - acc: 0.7582 - val_loss: 0.5623 - val_acc: 0.8077

Epoch 00037: val_loss improved from 0.57347 to 0.56225, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 38/60
 - 5s - loss: 0.7290 - acc: 0.7606 - val_loss: 0.5806 - val_acc: 0.8046

Epoch 00038: val_loss did not improve from 0.56225
Epoch 39/60
 - 5s - loss: 0.7286 - acc: 0.7600 - val_loss: 0.5586 - val_acc: 0.8096

Epoch 00039: val_loss improved from 0.56225 to 0.55856, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 40/60
 - 5s - loss: 0.7186 - acc: 0.7644 - val_loss: 0.5722 - val_acc: 0.8042

Epoch 00040: val_loss did not improve from 0.55856
Epoch 41/60
 - 5s - loss: 0.7180 - acc: 0.7630 - val_loss: 0.5822 - val_acc: 0.8076

Epoch 00041: val_loss did not improve from 0.55856
Epoch 42/60
 - 5s - loss: 0.7091 - acc: 0.7668 - val_loss: 0.5430 - val_acc: 0.8191

Epoch 00042: val_loss improved from 0.55856 to 0.54298, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 43/60
 - 6s - loss: 0.7071 - acc: 0.7681 - val_loss: 0.5393 - val_acc: 0.8195

Epoch 00043: val_loss improved from 0.54298 to 0.53927, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 44/60
 - 5s - loss: 0.7042 - acc: 0.7696 - val_loss: 0.5486 - val_acc: 0.8108

Epoch 00044: val_loss did not improve from 0.53927
Epoch 45/60
 - 5s - loss: 0.7042 - acc: 0.7693 - val_loss: 0.5412 - val_acc: 0.8149

Epoch 00045: val_loss did not improve from 0.53927
Epoch 46/60
 - 5s - loss: 0.6987 - acc: 0.7673 - val_loss: 0.5440 - val_acc: 0.8236

Epoch 00046: val_loss did not improve from 0.53927
Epoch 47/60
 - 5s - loss: 0.6939 - acc: 0.7720 - val_loss: 0.5346 - val_acc: 0.8204

Epoch 00047: val_loss improved from 0.53927 to 0.53455, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 48/60
 - 5s - loss: 0.6907 - acc: 0.7724 - val_loss: 0.5328 - val_acc: 0.8244

Epoch 00048: val_loss improved from 0.53455 to 0.53283, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 49/60
 - 5s - loss: 0.6897 - acc: 0.7737 - val_loss: 0.5360 - val_acc: 0.8210

Epoch 00049: val_loss did not improve from 0.53283
Epoch 50/60
 - 5s - loss: 0.6856 - acc: 0.7754 - val_loss: 0.5221 - val_acc: 0.8276

Epoch 00050: val_loss improved from 0.53283 to 0.52206, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 51/60
 - 5s - loss: 0.6795 - acc: 0.7767 - val_loss: 0.5260 - val_acc: 0.8251

Epoch 00051: val_loss did not improve from 0.52206
Epoch 52/60
 - 5s - loss: 0.6849 - acc: 0.7750 - val_loss: 0.5273 - val_acc: 0.8254

Epoch 00052: val_loss did not improve from 0.52206
Epoch 53/60
 - 5s - loss: 0.6796 - acc: 0.7786 - val_loss: 0.5204 - val_acc: 0.8241

Epoch 00053: val_loss improved from 0.52206 to 0.52044, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 54/60
 - 5s - loss: 0.6782 - acc: 0.7789 - val_loss: 0.5298 - val_acc: 0.8238

Epoch 00054: val_loss did not improve from 0.52044
Epoch 55/60
 - 5s - loss: 0.6780 - acc: 0.7782 - val_loss: 0.5105 - val_acc: 0.8302

Epoch 00055: val_loss improved from 0.52044 to 0.51054, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 56/60
 - 5s - loss: 0.6680 - acc: 0.7811 - val_loss: 0.5235 - val_acc: 0.8276

Epoch 00056: val_loss did not improve from 0.51054
Epoch 57/60
 - 5s - loss: 0.6661 - acc: 0.7815 - val_loss: 0.4994 - val_acc: 0.8327

Epoch 00057: val_loss improved from 0.51054 to 0.49936, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5
Epoch 58/60
 - 5s - loss: 0.6679 - acc: 0.7832 - val_loss: 0.5016 - val_acc: 0.8345

Epoch 00058: val_loss did not improve from 0.49936
Epoch 59/60
 - 5s - loss: 0.6676 - acc: 0.7821 - val_loss: 0.5081 - val_acc: 0.8339

Epoch 00059: val_loss did not improve from 0.49936
Epoch 60/60
 - 5s - loss: 0.6621 - acc: 0.7833 - val_loss: 0.5088 - val_acc: 0.8295

Epoch 00060: val_loss did not improve from 0.49936
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 7s - loss: 1.9088 - acc: 0.5799 - val_loss: 1.1599 - val_acc: 0.6536

Epoch 00001: val_loss improved from inf to 1.15986, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 2/60
 - 5s - loss: 1.1054 - acc: 0.6720 - val_loss: 0.8570 - val_acc: 0.7315

Epoch 00002: val_loss improved from 1.15986 to 0.85697, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 3/60
 - 5s - loss: 0.9147 - acc: 0.7147 - val_loss: 0.7526 - val_acc: 0.7543

Epoch 00003: val_loss improved from 0.85697 to 0.75263, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 4/60
 - 5s - loss: 0.7990 - acc: 0.7493 - val_loss: 0.6505 - val_acc: 0.7885

Epoch 00004: val_loss improved from 0.75263 to 0.65050, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 5/60
 - 5s - loss: 0.7157 - acc: 0.7727 - val_loss: 0.5905 - val_acc: 0.8148

Epoch 00005: val_loss improved from 0.65050 to 0.59050, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 6/60
 - 5s - loss: 0.6601 - acc: 0.7893 - val_loss: 0.5791 - val_acc: 0.8255

Epoch 00006: val_loss improved from 0.59050 to 0.57905, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 7/60
 - 5s - loss: 0.6187 - acc: 0.8030 - val_loss: 0.5295 - val_acc: 0.8329

Epoch 00007: val_loss improved from 0.57905 to 0.52951, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 8/60
 - 5s - loss: 0.5885 - acc: 0.8101 - val_loss: 0.5429 - val_acc: 0.8288

Epoch 00008: val_loss did not improve from 0.52951
Epoch 9/60
 - 5s - loss: 0.5590 - acc: 0.8202 - val_loss: 0.5030 - val_acc: 0.8404

Epoch 00009: val_loss improved from 0.52951 to 0.50303, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 10/60
 - 5s - loss: 0.5393 - acc: 0.8253 - val_loss: 0.4935 - val_acc: 0.8448

Epoch 00010: val_loss improved from 0.50303 to 0.49348, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 11/60
 - 5s - loss: 0.5117 - acc: 0.8353 - val_loss: 0.4888 - val_acc: 0.8472

Epoch 00011: val_loss improved from 0.49348 to 0.48878, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 12/60
 - 5s - loss: 0.4990 - acc: 0.8395 - val_loss: 0.4804 - val_acc: 0.8497

Epoch 00012: val_loss improved from 0.48878 to 0.48038, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 13/60
 - 5s - loss: 0.4847 - acc: 0.8452 - val_loss: 0.4844 - val_acc: 0.8473

Epoch 00013: val_loss did not improve from 0.48038
Epoch 14/60
 - 5s - loss: 0.4762 - acc: 0.8459 - val_loss: 0.4627 - val_acc: 0.8520

Epoch 00014: val_loss improved from 0.48038 to 0.46271, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 15/60
 - 5s - loss: 0.4609 - acc: 0.8510 - val_loss: 0.4462 - val_acc: 0.8600

Epoch 00015: val_loss improved from 0.46271 to 0.44623, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 16/60
 - 5s - loss: 0.4523 - acc: 0.8530 - val_loss: 0.4373 - val_acc: 0.8660

Epoch 00016: val_loss improved from 0.44623 to 0.43725, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 17/60
 - 5s - loss: 0.4418 - acc: 0.8584 - val_loss: 0.4263 - val_acc: 0.8676

Epoch 00017: val_loss improved from 0.43725 to 0.42628, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 18/60
 - 5s - loss: 0.4323 - acc: 0.8606 - val_loss: 0.4412 - val_acc: 0.8655

Epoch 00018: val_loss did not improve from 0.42628
Epoch 19/60
 - 5s - loss: 0.4261 - acc: 0.8619 - val_loss: 0.4218 - val_acc: 0.8689

Epoch 00019: val_loss improved from 0.42628 to 0.42184, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 20/60
 - 5s - loss: 0.4150 - acc: 0.8646 - val_loss: 0.4102 - val_acc: 0.8733

Epoch 00020: val_loss improved from 0.42184 to 0.41023, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 21/60
 - 5s - loss: 0.4104 - acc: 0.8681 - val_loss: 0.4350 - val_acc: 0.8641

Epoch 00021: val_loss did not improve from 0.41023
Epoch 22/60
 - 5s - loss: 0.4071 - acc: 0.8675 - val_loss: 0.3970 - val_acc: 0.8757

Epoch 00022: val_loss improved from 0.41023 to 0.39699, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 23/60
 - 5s - loss: 0.4029 - acc: 0.8685 - val_loss: 0.4174 - val_acc: 0.8710

Epoch 00023: val_loss did not improve from 0.39699
Epoch 24/60
 - 5s - loss: 0.3921 - acc: 0.8721 - val_loss: 0.4209 - val_acc: 0.8742

Epoch 00024: val_loss did not improve from 0.39699
Epoch 25/60
 - 5s - loss: 0.3876 - acc: 0.8751 - val_loss: 0.4018 - val_acc: 0.8773

Epoch 00025: val_loss did not improve from 0.39699
Epoch 26/60
 - 5s - loss: 0.3832 - acc: 0.8748 - val_loss: 0.4104 - val_acc: 0.8716

Epoch 00026: val_loss did not improve from 0.39699
Epoch 27/60
 - 5s - loss: 0.3777 - acc: 0.8764 - val_loss: 0.3991 - val_acc: 0.8758

Epoch 00027: val_loss did not improve from 0.39699
Epoch 28/60
 - 5s - loss: 0.3766 - acc: 0.8773 - val_loss: 0.3985 - val_acc: 0.8775

Epoch 00028: val_loss did not improve from 0.39699
Epoch 29/60
 - 5s - loss: 0.3659 - acc: 0.8805 - val_loss: 0.3992 - val_acc: 0.8769

Epoch 00029: val_loss did not improve from 0.39699
Epoch 30/60
 - 5s - loss: 0.3666 - acc: 0.8816 - val_loss: 0.3976 - val_acc: 0.8782

Epoch 00030: val_loss did not improve from 0.39699
Epoch 31/60
 - 5s - loss: 0.3571 - acc: 0.8837 - val_loss: 0.3943 - val_acc: 0.8783

Epoch 00031: val_loss improved from 0.39699 to 0.39431, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 32/60
 - 5s - loss: 0.3580 - acc: 0.8828 - val_loss: 0.4072 - val_acc: 0.8769

Epoch 00032: val_loss did not improve from 0.39431
Epoch 33/60
 - 5s - loss: 0.3559 - acc: 0.8828 - val_loss: 0.3910 - val_acc: 0.8844

Epoch 00033: val_loss improved from 0.39431 to 0.39095, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 34/60
 - 5s - loss: 0.3537 - acc: 0.8852 - val_loss: 0.3984 - val_acc: 0.8801

Epoch 00034: val_loss did not improve from 0.39095
Epoch 35/60
 - 5s - loss: 0.3481 - acc: 0.8868 - val_loss: 0.3917 - val_acc: 0.8838

Epoch 00035: val_loss did not improve from 0.39095
Epoch 36/60
 - 5s - loss: 0.3474 - acc: 0.8873 - val_loss: 0.4009 - val_acc: 0.8764

Epoch 00036: val_loss did not improve from 0.39095
Epoch 37/60
 - 5s - loss: 0.3472 - acc: 0.8869 - val_loss: 0.3999 - val_acc: 0.8800

Epoch 00037: val_loss did not improve from 0.39095
Epoch 38/60
 - 5s - loss: 0.3418 - acc: 0.8887 - val_loss: 0.3788 - val_acc: 0.8832

Epoch 00038: val_loss improved from 0.39095 to 0.37884, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 39/60
 - 5s - loss: 0.3392 - acc: 0.8892 - val_loss: 0.4128 - val_acc: 0.8773

Epoch 00039: val_loss did not improve from 0.37884
Epoch 40/60
 - 5s - loss: 0.3355 - acc: 0.8902 - val_loss: 0.3841 - val_acc: 0.8853

Epoch 00040: val_loss did not improve from 0.37884
Epoch 41/60
 - 5s - loss: 0.3382 - acc: 0.8887 - val_loss: 0.3920 - val_acc: 0.8820

Epoch 00041: val_loss did not improve from 0.37884
Epoch 42/60
 - 5s - loss: 0.3320 - acc: 0.8914 - val_loss: 0.3951 - val_acc: 0.8813

Epoch 00042: val_loss did not improve from 0.37884
Epoch 43/60
 - 5s - loss: 0.3286 - acc: 0.8916 - val_loss: 0.3914 - val_acc: 0.8883

Epoch 00043: val_loss did not improve from 0.37884
Epoch 44/60
 - 5s - loss: 0.3257 - acc: 0.8929 - val_loss: 0.4125 - val_acc: 0.8767

Epoch 00044: val_loss did not improve from 0.37884
Epoch 45/60
 - 5s - loss: 0.3248 - acc: 0.8930 - val_loss: 0.3836 - val_acc: 0.8858

Epoch 00045: val_loss did not improve from 0.37884
Epoch 46/60
 - 5s - loss: 0.3262 - acc: 0.8941 - val_loss: 0.3781 - val_acc: 0.8861

Epoch 00046: val_loss improved from 0.37884 to 0.37808, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 47/60
 - 5s - loss: 0.3263 - acc: 0.8926 - val_loss: 0.4139 - val_acc: 0.8810

Epoch 00047: val_loss did not improve from 0.37808
Epoch 48/60
 - 5s - loss: 0.3242 - acc: 0.8930 - val_loss: 0.4084 - val_acc: 0.8781

Epoch 00048: val_loss did not improve from 0.37808
Epoch 49/60
 - 5s - loss: 0.3163 - acc: 0.8971 - val_loss: 0.4109 - val_acc: 0.8798

Epoch 00049: val_loss did not improve from 0.37808
Epoch 50/60
 - 5s - loss: 0.3165 - acc: 0.8957 - val_loss: 0.3790 - val_acc: 0.8888

Epoch 00050: val_loss did not improve from 0.37808
Epoch 51/60
 - 5s - loss: 0.3171 - acc: 0.8950 - val_loss: 0.3809 - val_acc: 0.8876

Epoch 00051: val_loss did not improve from 0.37808
Epoch 52/60
 - 5s - loss: 0.3154 - acc: 0.8950 - val_loss: 0.3817 - val_acc: 0.8860

Epoch 00052: val_loss did not improve from 0.37808
Epoch 53/60
 - 5s - loss: 0.3154 - acc: 0.8962 - val_loss: 0.3807 - val_acc: 0.8879

Epoch 00053: val_loss did not improve from 0.37808
Epoch 54/60
 - 5s - loss: 0.3105 - acc: 0.8969 - val_loss: 0.3862 - val_acc: 0.8836

Epoch 00054: val_loss did not improve from 0.37808
Epoch 55/60
 - 5s - loss: 0.3077 - acc: 0.8981 - val_loss: 0.3950 - val_acc: 0.8832

Epoch 00055: val_loss did not improve from 0.37808
Epoch 56/60
 - 5s - loss: 0.3103 - acc: 0.8982 - val_loss: 0.3751 - val_acc: 0.8885

Epoch 00056: val_loss improved from 0.37808 to 0.37510, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 57/60
 - 5s - loss: 0.3071 - acc: 0.8987 - val_loss: 0.3834 - val_acc: 0.8869

Epoch 00057: val_loss did not improve from 0.37510
Epoch 58/60
 - 5s - loss: 0.3075 - acc: 0.8978 - val_loss: 0.3774 - val_acc: 0.8917

Epoch 00058: val_loss did not improve from 0.37510
Epoch 59/60
 - 5s - loss: 0.3017 - acc: 0.9013 - val_loss: 0.3918 - val_acc: 0.8848

Epoch 00059: val_loss did not improve from 0.37510
Epoch 60/60
 - 5s - loss: 0.3021 - acc: 0.9003 - val_loss: 0.3737 - val_acc: 0.8920

Epoch 00060: val_loss improved from 0.37510 to 0.37374, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 2.2286 - acc: 0.4003 - val_loss: 1.7014 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 1.70139, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 2/60
 - 4s - loss: 1.6239 - acc: 0.6270 - val_loss: 1.5623 - val_acc: 0.6209

Epoch 00002: val_loss improved from 1.70139 to 1.56228, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 3/60
 - 4s - loss: 1.5111 - acc: 0.6363 - val_loss: 1.4373 - val_acc: 0.6209

Epoch 00003: val_loss improved from 1.56228 to 1.43734, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 4/60
 - 4s - loss: 1.4626 - acc: 0.6370 - val_loss: 1.3997 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.43734 to 1.39966, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 5/60
 - 4s - loss: 1.4217 - acc: 0.6370 - val_loss: 1.3856 - val_acc: 0.6221

Epoch 00005: val_loss improved from 1.39966 to 1.38564, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 6/60
 - 4s - loss: 1.3829 - acc: 0.6388 - val_loss: 1.3036 - val_acc: 0.6281

Epoch 00006: val_loss improved from 1.38564 to 1.30361, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 7/60
 - 4s - loss: 1.3578 - acc: 0.6392 - val_loss: 1.2877 - val_acc: 0.6296

Epoch 00007: val_loss improved from 1.30361 to 1.28769, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 8/60
 - 4s - loss: 1.3332 - acc: 0.6395 - val_loss: 1.2488 - val_acc: 0.6337

Epoch 00008: val_loss improved from 1.28769 to 1.24884, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 9/60
 - 4s - loss: 1.3127 - acc: 0.6418 - val_loss: 1.2738 - val_acc: 0.6342

Epoch 00009: val_loss did not improve from 1.24884
Epoch 10/60
 - 4s - loss: 1.2938 - acc: 0.6429 - val_loss: 1.2284 - val_acc: 0.6392

Epoch 00010: val_loss improved from 1.24884 to 1.22839, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 11/60
 - 4s - loss: 1.2830 - acc: 0.6431 - val_loss: 1.2516 - val_acc: 0.6415

Epoch 00011: val_loss did not improve from 1.22839
Epoch 12/60
 - 4s - loss: 1.2682 - acc: 0.6443 - val_loss: 1.2116 - val_acc: 0.6439

Epoch 00012: val_loss improved from 1.22839 to 1.21163, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 13/60
 - 4s - loss: 1.2574 - acc: 0.6447 - val_loss: 1.1901 - val_acc: 0.6470

Epoch 00013: val_loss improved from 1.21163 to 1.19011, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 14/60
 - 4s - loss: 1.2418 - acc: 0.6472 - val_loss: 1.1736 - val_acc: 0.6370

Epoch 00014: val_loss improved from 1.19011 to 1.17364, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 15/60
 - 4s - loss: 1.2290 - acc: 0.6481 - val_loss: 1.1689 - val_acc: 0.6462

Epoch 00015: val_loss improved from 1.17364 to 1.16893, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 16/60
 - 4s - loss: 1.2198 - acc: 0.6495 - val_loss: 1.1593 - val_acc: 0.6486

Epoch 00016: val_loss improved from 1.16893 to 1.15933, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 17/60
 - 4s - loss: 1.2143 - acc: 0.6501 - val_loss: 1.1522 - val_acc: 0.6500

Epoch 00017: val_loss improved from 1.15933 to 1.15223, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 18/60
 - 4s - loss: 1.1954 - acc: 0.6523 - val_loss: 1.1430 - val_acc: 0.6447

Epoch 00018: val_loss improved from 1.15223 to 1.14302, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 19/60
 - 4s - loss: 1.1892 - acc: 0.6527 - val_loss: 1.1110 - val_acc: 0.6545

Epoch 00019: val_loss improved from 1.14302 to 1.11104, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 20/60
 - 4s - loss: 1.1815 - acc: 0.6533 - val_loss: 1.0967 - val_acc: 0.6555

Epoch 00020: val_loss improved from 1.11104 to 1.09671, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 21/60
 - 4s - loss: 1.1710 - acc: 0.6543 - val_loss: 1.0843 - val_acc: 0.6590

Epoch 00021: val_loss improved from 1.09671 to 1.08431, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 22/60
 - 4s - loss: 1.1604 - acc: 0.6563 - val_loss: 1.0894 - val_acc: 0.6608

Epoch 00022: val_loss did not improve from 1.08431
Epoch 23/60
 - 4s - loss: 1.1573 - acc: 0.6571 - val_loss: 1.0720 - val_acc: 0.6650

Epoch 00023: val_loss improved from 1.08431 to 1.07200, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 24/60
 - 4s - loss: 1.1490 - acc: 0.6595 - val_loss: 1.0760 - val_acc: 0.6639

Epoch 00024: val_loss did not improve from 1.07200
Epoch 25/60
 - 4s - loss: 1.1415 - acc: 0.6605 - val_loss: 1.0852 - val_acc: 0.6687

Epoch 00025: val_loss did not improve from 1.07200
Epoch 26/60
 - 4s - loss: 1.1339 - acc: 0.6612 - val_loss: 1.0569 - val_acc: 0.6667

Epoch 00026: val_loss improved from 1.07200 to 1.05693, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 27/60
 - 4s - loss: 1.1286 - acc: 0.6625 - val_loss: 1.0644 - val_acc: 0.6656

Epoch 00027: val_loss did not improve from 1.05693
Epoch 28/60
 - 4s - loss: 1.1279 - acc: 0.6623 - val_loss: 1.0429 - val_acc: 0.6689

Epoch 00028: val_loss improved from 1.05693 to 1.04288, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 29/60
 - 4s - loss: 1.1166 - acc: 0.6642 - val_loss: 1.0464 - val_acc: 0.6701

Epoch 00029: val_loss did not improve from 1.04288
Epoch 30/60
 - 4s - loss: 1.1081 - acc: 0.6654 - val_loss: 1.0241 - val_acc: 0.6701

Epoch 00030: val_loss improved from 1.04288 to 1.02408, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 31/60
 - 4s - loss: 1.1075 - acc: 0.6677 - val_loss: 1.0281 - val_acc: 0.6705

Epoch 00031: val_loss did not improve from 1.02408
Epoch 32/60
 - 4s - loss: 1.1039 - acc: 0.6651 - val_loss: 1.0054 - val_acc: 0.6745

Epoch 00032: val_loss improved from 1.02408 to 1.00536, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 33/60
 - 4s - loss: 1.0938 - acc: 0.6677 - val_loss: 1.0082 - val_acc: 0.6746

Epoch 00033: val_loss did not improve from 1.00536
Epoch 34/60
 - 4s - loss: 1.0874 - acc: 0.6693 - val_loss: 0.9946 - val_acc: 0.6742

Epoch 00034: val_loss improved from 1.00536 to 0.99459, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 35/60
 - 4s - loss: 1.0809 - acc: 0.6709 - val_loss: 0.9963 - val_acc: 0.6756

Epoch 00035: val_loss did not improve from 0.99459
Epoch 36/60
 - 4s - loss: 1.0776 - acc: 0.6715 - val_loss: 0.9903 - val_acc: 0.6865

Epoch 00036: val_loss improved from 0.99459 to 0.99025, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 37/60
 - 4s - loss: 1.0715 - acc: 0.6729 - val_loss: 0.9862 - val_acc: 0.6836

Epoch 00037: val_loss improved from 0.99025 to 0.98621, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 38/60
 - 4s - loss: 1.0688 - acc: 0.6723 - val_loss: 0.9511 - val_acc: 0.6864

Epoch 00038: val_loss improved from 0.98621 to 0.95113, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 39/60
 - 4s - loss: 1.0630 - acc: 0.6742 - val_loss: 0.9524 - val_acc: 0.6859

Epoch 00039: val_loss did not improve from 0.95113
Epoch 40/60
 - 4s - loss: 1.0538 - acc: 0.6746 - val_loss: 0.9476 - val_acc: 0.6812

Epoch 00040: val_loss improved from 0.95113 to 0.94759, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 41/60
 - 4s - loss: 1.0568 - acc: 0.6739 - val_loss: 0.9380 - val_acc: 0.6874

Epoch 00041: val_loss improved from 0.94759 to 0.93801, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 42/60
 - 4s - loss: 1.0451 - acc: 0.6763 - val_loss: 0.9392 - val_acc: 0.6862

Epoch 00042: val_loss did not improve from 0.93801
Epoch 43/60
 - 4s - loss: 1.0440 - acc: 0.6754 - val_loss: 0.9158 - val_acc: 0.6911

Epoch 00043: val_loss improved from 0.93801 to 0.91582, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 44/60
 - 5s - loss: 1.0360 - acc: 0.6770 - val_loss: 0.9128 - val_acc: 0.6880

Epoch 00044: val_loss improved from 0.91582 to 0.91275, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 45/60
 - 4s - loss: 1.0346 - acc: 0.6778 - val_loss: 0.9098 - val_acc: 0.6852

Epoch 00045: val_loss improved from 0.91275 to 0.90978, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 46/60
 - 4s - loss: 1.0269 - acc: 0.6782 - val_loss: 0.9109 - val_acc: 0.6868

Epoch 00046: val_loss did not improve from 0.90978
Epoch 47/60
 - 4s - loss: 1.0219 - acc: 0.6789 - val_loss: 0.8932 - val_acc: 0.6920

Epoch 00047: val_loss improved from 0.90978 to 0.89316, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 48/60
 - 4s - loss: 1.0151 - acc: 0.6808 - val_loss: 0.8918 - val_acc: 0.6945

Epoch 00048: val_loss improved from 0.89316 to 0.89184, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 49/60
 - 4s - loss: 1.0138 - acc: 0.6803 - val_loss: 0.9019 - val_acc: 0.6951

Epoch 00049: val_loss did not improve from 0.89184
Epoch 50/60
 - 4s - loss: 1.0076 - acc: 0.6828 - val_loss: 0.8859 - val_acc: 0.6934

Epoch 00050: val_loss improved from 0.89184 to 0.88592, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 51/60
 - 4s - loss: 1.0021 - acc: 0.6816 - val_loss: 0.8715 - val_acc: 0.6955

Epoch 00051: val_loss improved from 0.88592 to 0.87155, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 52/60
 - 4s - loss: 0.9989 - acc: 0.6842 - val_loss: 0.8700 - val_acc: 0.6924

Epoch 00052: val_loss improved from 0.87155 to 0.86997, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 53/60
 - 4s - loss: 0.9961 - acc: 0.6861 - val_loss: 0.8653 - val_acc: 0.6959

Epoch 00053: val_loss improved from 0.86997 to 0.86528, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 54/60
 - 4s - loss: 0.9925 - acc: 0.6839 - val_loss: 0.8707 - val_acc: 0.7012

Epoch 00054: val_loss did not improve from 0.86528
Epoch 55/60
 - 4s - loss: 0.9900 - acc: 0.6865 - val_loss: 0.8610 - val_acc: 0.6984

Epoch 00055: val_loss improved from 0.86528 to 0.86095, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 56/60
 - 4s - loss: 0.9873 - acc: 0.6864 - val_loss: 0.8629 - val_acc: 0.6964

Epoch 00056: val_loss did not improve from 0.86095
Epoch 57/60
 - 4s - loss: 0.9865 - acc: 0.6872 - val_loss: 0.8470 - val_acc: 0.7020

Epoch 00057: val_loss improved from 0.86095 to 0.84703, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 58/60
 - 4s - loss: 0.9839 - acc: 0.6860 - val_loss: 0.8468 - val_acc: 0.7001

Epoch 00058: val_loss improved from 0.84703 to 0.84681, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 59/60
 - 4s - loss: 0.9743 - acc: 0.6874 - val_loss: 0.8553 - val_acc: 0.7056

Epoch 00059: val_loss did not improve from 0.84681
Epoch 60/60
 - 4s - loss: 0.9787 - acc: 0.6881 - val_loss: 0.8586 - val_acc: 0.7071

Epoch 00060: val_loss did not improve from 0.84681
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 1.9679 - acc: 0.5697 - val_loss: 1.6618 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 1.66182, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 2/60
 - 5s - loss: 1.4731 - acc: 0.6361 - val_loss: 1.4052 - val_acc: 0.6267

Epoch 00002: val_loss improved from 1.66182 to 1.40522, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 3/60
 - 5s - loss: 1.3515 - acc: 0.6377 - val_loss: 1.2520 - val_acc: 0.6477

Epoch 00003: val_loss improved from 1.40522 to 1.25203, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 4/60
 - 5s - loss: 1.2761 - acc: 0.6463 - val_loss: 1.1689 - val_acc: 0.6599

Epoch 00004: val_loss improved from 1.25203 to 1.16887, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 5/60
 - 5s - loss: 1.2100 - acc: 0.6537 - val_loss: 1.1651 - val_acc: 0.6726

Epoch 00005: val_loss improved from 1.16887 to 1.16510, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 6/60
 - 5s - loss: 1.1593 - acc: 0.6602 - val_loss: 1.1186 - val_acc: 0.6734

Epoch 00006: val_loss improved from 1.16510 to 1.11861, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 7/60
 - 5s - loss: 1.1315 - acc: 0.6664 - val_loss: 1.0492 - val_acc: 0.6815

Epoch 00007: val_loss improved from 1.11861 to 1.04919, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 8/60
 - 5s - loss: 1.0967 - acc: 0.6697 - val_loss: 1.0038 - val_acc: 0.6796

Epoch 00008: val_loss improved from 1.04919 to 1.00382, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 9/60
 - 5s - loss: 1.0763 - acc: 0.6736 - val_loss: 1.0321 - val_acc: 0.6880

Epoch 00009: val_loss did not improve from 1.00382
Epoch 10/60
 - 5s - loss: 1.0511 - acc: 0.6785 - val_loss: 0.9785 - val_acc: 0.6898

Epoch 00010: val_loss improved from 1.00382 to 0.97849, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 11/60
 - 5s - loss: 1.0326 - acc: 0.6806 - val_loss: 0.9358 - val_acc: 0.6912

Epoch 00011: val_loss improved from 0.97849 to 0.93577, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 12/60
 - 5s - loss: 1.0133 - acc: 0.6844 - val_loss: 0.9335 - val_acc: 0.6979

Epoch 00012: val_loss improved from 0.93577 to 0.93345, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 13/60
 - 5s - loss: 0.9932 - acc: 0.6876 - val_loss: 0.8942 - val_acc: 0.7029

Epoch 00013: val_loss improved from 0.93345 to 0.89422, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 14/60
 - 5s - loss: 0.9757 - acc: 0.6912 - val_loss: 0.9170 - val_acc: 0.7140

Epoch 00014: val_loss did not improve from 0.89422
Epoch 15/60
 - 5s - loss: 0.9587 - acc: 0.6941 - val_loss: 0.8428 - val_acc: 0.7171

Epoch 00015: val_loss improved from 0.89422 to 0.84284, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 16/60
 - 5s - loss: 0.9445 - acc: 0.6975 - val_loss: 0.8049 - val_acc: 0.7211

Epoch 00016: val_loss improved from 0.84284 to 0.80493, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 17/60
 - 5s - loss: 0.9247 - acc: 0.7028 - val_loss: 0.8041 - val_acc: 0.7364

Epoch 00017: val_loss improved from 0.80493 to 0.80415, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 18/60
 - 5s - loss: 0.9055 - acc: 0.7071 - val_loss: 0.7603 - val_acc: 0.7330

Epoch 00018: val_loss improved from 0.80415 to 0.76028, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 19/60
 - 5s - loss: 0.8918 - acc: 0.7137 - val_loss: 0.7586 - val_acc: 0.7561

Epoch 00019: val_loss improved from 0.76028 to 0.75856, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 20/60
 - 5s - loss: 0.8771 - acc: 0.7150 - val_loss: 0.7475 - val_acc: 0.7489

Epoch 00020: val_loss improved from 0.75856 to 0.74750, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 21/60
 - 5s - loss: 0.8628 - acc: 0.7186 - val_loss: 0.7338 - val_acc: 0.7598

Epoch 00021: val_loss improved from 0.74750 to 0.73382, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 22/60
 - 5s - loss: 0.8540 - acc: 0.7229 - val_loss: 0.7077 - val_acc: 0.7727

Epoch 00022: val_loss improved from 0.73382 to 0.70766, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 23/60
 - 5s - loss: 0.8455 - acc: 0.7254 - val_loss: 0.6883 - val_acc: 0.7741

Epoch 00023: val_loss improved from 0.70766 to 0.68825, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 24/60
 - 5s - loss: 0.8274 - acc: 0.7298 - val_loss: 0.6700 - val_acc: 0.7699

Epoch 00024: val_loss improved from 0.68825 to 0.66999, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 25/60
 - 5s - loss: 0.8157 - acc: 0.7337 - val_loss: 0.6703 - val_acc: 0.7783

Epoch 00025: val_loss did not improve from 0.66999
Epoch 26/60
 - 5s - loss: 0.8089 - acc: 0.7359 - val_loss: 0.6536 - val_acc: 0.7777

Epoch 00026: val_loss improved from 0.66999 to 0.65361, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 27/60
 - 5s - loss: 0.7985 - acc: 0.7396 - val_loss: 0.6395 - val_acc: 0.7842

Epoch 00027: val_loss improved from 0.65361 to 0.63954, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 28/60
 - 5s - loss: 0.7891 - acc: 0.7413 - val_loss: 0.6344 - val_acc: 0.7891

Epoch 00028: val_loss improved from 0.63954 to 0.63440, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 29/60
 - 5s - loss: 0.7834 - acc: 0.7437 - val_loss: 0.6120 - val_acc: 0.7893

Epoch 00029: val_loss improved from 0.63440 to 0.61202, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 30/60
 - 5s - loss: 0.7753 - acc: 0.7480 - val_loss: 0.6154 - val_acc: 0.7924

Epoch 00030: val_loss did not improve from 0.61202
Epoch 31/60
 - 5s - loss: 0.7674 - acc: 0.7468 - val_loss: 0.6039 - val_acc: 0.7917

Epoch 00031: val_loss improved from 0.61202 to 0.60387, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 32/60
 - 5s - loss: 0.7601 - acc: 0.7508 - val_loss: 0.6048 - val_acc: 0.8005

Epoch 00032: val_loss did not improve from 0.60387
Epoch 33/60
 - 5s - loss: 0.7541 - acc: 0.7530 - val_loss: 0.5929 - val_acc: 0.7932

Epoch 00033: val_loss improved from 0.60387 to 0.59286, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 34/60
 - 5s - loss: 0.7544 - acc: 0.7515 - val_loss: 0.5977 - val_acc: 0.7967

Epoch 00034: val_loss did not improve from 0.59286
Epoch 35/60
 - 5s - loss: 0.7470 - acc: 0.7552 - val_loss: 0.5855 - val_acc: 0.8020

Epoch 00035: val_loss improved from 0.59286 to 0.58553, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 36/60
 - 5s - loss: 0.7387 - acc: 0.7548 - val_loss: 0.5756 - val_acc: 0.8114

Epoch 00036: val_loss improved from 0.58553 to 0.57562, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 37/60
 - 5s - loss: 0.7340 - acc: 0.7574 - val_loss: 0.5800 - val_acc: 0.8057

Epoch 00037: val_loss did not improve from 0.57562
Epoch 38/60
 - 5s - loss: 0.7287 - acc: 0.7596 - val_loss: 0.5701 - val_acc: 0.8122

Epoch 00038: val_loss improved from 0.57562 to 0.57007, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 39/60
 - 6s - loss: 0.7236 - acc: 0.7622 - val_loss: 0.5576 - val_acc: 0.8136

Epoch 00039: val_loss improved from 0.57007 to 0.55760, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 40/60
 - 5s - loss: 0.7227 - acc: 0.7629 - val_loss: 0.5565 - val_acc: 0.8226

Epoch 00040: val_loss improved from 0.55760 to 0.55651, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 41/60
 - 5s - loss: 0.7133 - acc: 0.7653 - val_loss: 0.5481 - val_acc: 0.8199

Epoch 00041: val_loss improved from 0.55651 to 0.54807, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 42/60
 - 5s - loss: 0.7103 - acc: 0.7678 - val_loss: 0.5495 - val_acc: 0.8207

Epoch 00042: val_loss did not improve from 0.54807
Epoch 43/60
 - 5s - loss: 0.7115 - acc: 0.7669 - val_loss: 0.5491 - val_acc: 0.8176

Epoch 00043: val_loss did not improve from 0.54807
Epoch 44/60
 - 5s - loss: 0.7048 - acc: 0.7700 - val_loss: 0.5493 - val_acc: 0.8161

Epoch 00044: val_loss did not improve from 0.54807
Epoch 45/60
 - 5s - loss: 0.6991 - acc: 0.7707 - val_loss: 0.5355 - val_acc: 0.8232

Epoch 00045: val_loss improved from 0.54807 to 0.53545, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 46/60
 - 5s - loss: 0.6992 - acc: 0.7721 - val_loss: 0.5429 - val_acc: 0.8154

Epoch 00046: val_loss did not improve from 0.53545
Epoch 47/60
 - 5s - loss: 0.6953 - acc: 0.7736 - val_loss: 0.5291 - val_acc: 0.8244

Epoch 00047: val_loss improved from 0.53545 to 0.52912, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 48/60
 - 5s - loss: 0.6887 - acc: 0.7758 - val_loss: 0.5379 - val_acc: 0.8261

Epoch 00048: val_loss did not improve from 0.52912
Epoch 49/60
 - 5s - loss: 0.6872 - acc: 0.7749 - val_loss: 0.5260 - val_acc: 0.8261

Epoch 00049: val_loss improved from 0.52912 to 0.52603, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 50/60
 - 5s - loss: 0.6850 - acc: 0.7745 - val_loss: 0.5377 - val_acc: 0.8274

Epoch 00050: val_loss did not improve from 0.52603
Epoch 51/60
 - 5s - loss: 0.6830 - acc: 0.7775 - val_loss: 0.5190 - val_acc: 0.8263

Epoch 00051: val_loss improved from 0.52603 to 0.51904, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 52/60
 - 5s - loss: 0.6858 - acc: 0.7747 - val_loss: 0.5101 - val_acc: 0.8305

Epoch 00052: val_loss improved from 0.51904 to 0.51014, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 53/60
 - 5s - loss: 0.6783 - acc: 0.7813 - val_loss: 0.5179 - val_acc: 0.8350

Epoch 00053: val_loss did not improve from 0.51014
Epoch 54/60
 - 5s - loss: 0.6743 - acc: 0.7801 - val_loss: 0.5145 - val_acc: 0.8311

Epoch 00054: val_loss did not improve from 0.51014
Epoch 55/60
 - 5s - loss: 0.6740 - acc: 0.7798 - val_loss: 0.5103 - val_acc: 0.8289

Epoch 00055: val_loss did not improve from 0.51014
Epoch 56/60
 - 5s - loss: 0.6739 - acc: 0.7804 - val_loss: 0.5271 - val_acc: 0.8204

Epoch 00056: val_loss did not improve from 0.51014
Epoch 57/60
 - 5s - loss: 0.6686 - acc: 0.7825 - val_loss: 0.5029 - val_acc: 0.8364

Epoch 00057: val_loss improved from 0.51014 to 0.50288, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5
Epoch 58/60
 - 5s - loss: 0.6656 - acc: 0.7813 - val_loss: 0.5040 - val_acc: 0.8388

Epoch 00058: val_loss did not improve from 0.50288
Epoch 59/60
 - 5s - loss: 0.6650 - acc: 0.7844 - val_loss: 0.5171 - val_acc: 0.8254

Epoch 00059: val_loss did not improve from 0.50288
Epoch 60/60
 - 5s - loss: 0.6627 - acc: 0.7830 - val_loss: 0.5033 - val_acc: 0.8389

Epoch 00060: val_loss did not improve from 0.50288
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 2.4182 - acc: 0.5773 - val_loss: 1.2009 - val_acc: 0.6371

Epoch 00001: val_loss improved from inf to 1.20087, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 2/60
 - 5s - loss: 1.1242 - acc: 0.6633 - val_loss: 0.8783 - val_acc: 0.7195

Epoch 00002: val_loss improved from 1.20087 to 0.87830, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 3/60
 - 5s - loss: 0.9140 - acc: 0.7122 - val_loss: 0.7520 - val_acc: 0.7521

Epoch 00003: val_loss improved from 0.87830 to 0.75198, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 4/60
 - 5s - loss: 0.7920 - acc: 0.7488 - val_loss: 0.6406 - val_acc: 0.7880

Epoch 00004: val_loss improved from 0.75198 to 0.64064, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 5/60
 - 5s - loss: 0.7112 - acc: 0.7747 - val_loss: 0.5881 - val_acc: 0.8099

Epoch 00005: val_loss improved from 0.64064 to 0.58806, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 6/60
 - 5s - loss: 0.6534 - acc: 0.7924 - val_loss: 0.5699 - val_acc: 0.8192

Epoch 00006: val_loss improved from 0.58806 to 0.56992, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 7/60
 - 5s - loss: 0.6159 - acc: 0.8039 - val_loss: 0.5292 - val_acc: 0.8285

Epoch 00007: val_loss improved from 0.56992 to 0.52924, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 8/60
 - 5s - loss: 0.5791 - acc: 0.8157 - val_loss: 0.5130 - val_acc: 0.8382

Epoch 00008: val_loss improved from 0.52924 to 0.51304, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 9/60
 - 5s - loss: 0.5551 - acc: 0.8217 - val_loss: 0.5029 - val_acc: 0.8405

Epoch 00009: val_loss improved from 0.51304 to 0.50291, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 10/60
 - 5s - loss: 0.5245 - acc: 0.8303 - val_loss: 0.4787 - val_acc: 0.8458

Epoch 00010: val_loss improved from 0.50291 to 0.47865, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 11/60
 - 5s - loss: 0.5104 - acc: 0.8364 - val_loss: 0.5013 - val_acc: 0.8398

Epoch 00011: val_loss did not improve from 0.47865
Epoch 12/60
 - 5s - loss: 0.4904 - acc: 0.8428 - val_loss: 0.4701 - val_acc: 0.8550

Epoch 00012: val_loss improved from 0.47865 to 0.47013, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 13/60
 - 5s - loss: 0.4798 - acc: 0.8453 - val_loss: 0.5085 - val_acc: 0.8420

Epoch 00013: val_loss did not improve from 0.47013
Epoch 14/60
 - 5s - loss: 0.4656 - acc: 0.8509 - val_loss: 0.4346 - val_acc: 0.8626

Epoch 00014: val_loss improved from 0.47013 to 0.43463, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 15/60
 - 5s - loss: 0.4544 - acc: 0.8545 - val_loss: 0.4560 - val_acc: 0.8588

Epoch 00015: val_loss did not improve from 0.43463
Epoch 16/60
 - 5s - loss: 0.4392 - acc: 0.8579 - val_loss: 0.4640 - val_acc: 0.8538

Epoch 00016: val_loss did not improve from 0.43463
Epoch 17/60
 - 5s - loss: 0.4288 - acc: 0.8611 - val_loss: 0.4025 - val_acc: 0.8763

Epoch 00017: val_loss improved from 0.43463 to 0.40249, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 18/60
 - 5s - loss: 0.4225 - acc: 0.8641 - val_loss: 0.4121 - val_acc: 0.8744

Epoch 00018: val_loss did not improve from 0.40249
Epoch 19/60
 - 5s - loss: 0.4163 - acc: 0.8649 - val_loss: 0.4043 - val_acc: 0.8733

Epoch 00019: val_loss did not improve from 0.40249
Epoch 20/60
 - 5s - loss: 0.4042 - acc: 0.8692 - val_loss: 0.4303 - val_acc: 0.8678

Epoch 00020: val_loss did not improve from 0.40249
Epoch 21/60
 - 5s - loss: 0.4025 - acc: 0.8693 - val_loss: 0.4140 - val_acc: 0.8723

Epoch 00021: val_loss did not improve from 0.40249
Epoch 22/60
 - 5s - loss: 0.3946 - acc: 0.8718 - val_loss: 0.4427 - val_acc: 0.8633

Epoch 00022: val_loss did not improve from 0.40249
Epoch 23/60
 - 5s - loss: 0.3876 - acc: 0.8738 - val_loss: 0.4028 - val_acc: 0.8791

Epoch 00023: val_loss did not improve from 0.40249
Epoch 24/60
 - 5s - loss: 0.3834 - acc: 0.8747 - val_loss: 0.4199 - val_acc: 0.8717

Epoch 00024: val_loss did not improve from 0.40249
Epoch 25/60
 - 5s - loss: 0.3812 - acc: 0.8783 - val_loss: 0.4244 - val_acc: 0.8758

Epoch 00025: val_loss did not improve from 0.40249
Epoch 26/60
 - 5s - loss: 0.3725 - acc: 0.8785 - val_loss: 0.4358 - val_acc: 0.8703

Epoch 00026: val_loss did not improve from 0.40249
Epoch 27/60
 - 5s - loss: 0.3701 - acc: 0.8799 - val_loss: 0.4053 - val_acc: 0.8735

Epoch 00027: val_loss did not improve from 0.40249
Epoch 00027: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 7s - loss: 2.1388 - acc: 0.4856 - val_loss: 1.8700 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 1.87003, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 2/60
 - 4s - loss: 1.6355 - acc: 0.6281 - val_loss: 1.6193 - val_acc: 0.6209

Epoch 00002: val_loss improved from 1.87003 to 1.61927, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 3/60
 - 4s - loss: 1.5332 - acc: 0.6364 - val_loss: 1.5164 - val_acc: 0.6209

Epoch 00003: val_loss improved from 1.61927 to 1.51640, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 4/60
 - 4s - loss: 1.4761 - acc: 0.6366 - val_loss: 1.4968 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.51640 to 1.49685, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 5/60
 - 4s - loss: 1.4278 - acc: 0.6354 - val_loss: 1.3601 - val_acc: 0.6214

Epoch 00005: val_loss improved from 1.49685 to 1.36006, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 6/60
 - 4s - loss: 1.3860 - acc: 0.6357 - val_loss: 1.3364 - val_acc: 0.6253

Epoch 00006: val_loss improved from 1.36006 to 1.33643, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 7/60
 - 4s - loss: 1.3567 - acc: 0.6375 - val_loss: 1.3199 - val_acc: 0.6249

Epoch 00007: val_loss improved from 1.33643 to 1.31989, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 8/60
 - 5s - loss: 1.3313 - acc: 0.6387 - val_loss: 1.2880 - val_acc: 0.6253

Epoch 00008: val_loss improved from 1.31989 to 1.28800, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 9/60
 - 4s - loss: 1.3050 - acc: 0.6401 - val_loss: 1.2345 - val_acc: 0.6303

Epoch 00009: val_loss improved from 1.28800 to 1.23446, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 10/60
 - 4s - loss: 1.2781 - acc: 0.6424 - val_loss: 1.2217 - val_acc: 0.6362

Epoch 00010: val_loss improved from 1.23446 to 1.22175, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 11/60
 - 4s - loss: 1.2512 - acc: 0.6449 - val_loss: 1.1707 - val_acc: 0.6427

Epoch 00011: val_loss improved from 1.22175 to 1.17067, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 12/60
 - 4s - loss: 1.2326 - acc: 0.6478 - val_loss: 1.1429 - val_acc: 0.6499

Epoch 00012: val_loss improved from 1.17067 to 1.14289, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 13/60
 - 4s - loss: 1.2144 - acc: 0.6480 - val_loss: 1.1396 - val_acc: 0.6508

Epoch 00013: val_loss improved from 1.14289 to 1.13959, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 14/60
 - 4s - loss: 1.1956 - acc: 0.6501 - val_loss: 1.1205 - val_acc: 0.6556

Epoch 00014: val_loss improved from 1.13959 to 1.12050, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 15/60
 - 4s - loss: 1.1856 - acc: 0.6530 - val_loss: 1.1156 - val_acc: 0.6562

Epoch 00015: val_loss improved from 1.12050 to 1.11562, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 16/60
 - 4s - loss: 1.1715 - acc: 0.6546 - val_loss: 1.0705 - val_acc: 0.6611

Epoch 00016: val_loss improved from 1.11562 to 1.07050, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 17/60
 - 4s - loss: 1.1517 - acc: 0.6569 - val_loss: 1.0859 - val_acc: 0.6548

Epoch 00017: val_loss did not improve from 1.07050
Epoch 18/60
 - 4s - loss: 1.1415 - acc: 0.6581 - val_loss: 1.0586 - val_acc: 0.6639

Epoch 00018: val_loss improved from 1.07050 to 1.05863, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 19/60
 - 4s - loss: 1.1309 - acc: 0.6604 - val_loss: 1.0320 - val_acc: 0.6733

Epoch 00019: val_loss improved from 1.05863 to 1.03195, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 20/60
 - 4s - loss: 1.1241 - acc: 0.6601 - val_loss: 1.0264 - val_acc: 0.6639

Epoch 00020: val_loss improved from 1.03195 to 1.02638, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 21/60
 - 4s - loss: 1.1124 - acc: 0.6621 - val_loss: 1.0355 - val_acc: 0.6731

Epoch 00021: val_loss did not improve from 1.02638
Epoch 22/60
 - 4s - loss: 1.1106 - acc: 0.6628 - val_loss: 1.0307 - val_acc: 0.6711

Epoch 00022: val_loss did not improve from 1.02638
Epoch 23/60
 - 4s - loss: 1.0997 - acc: 0.6643 - val_loss: 0.9990 - val_acc: 0.6752

Epoch 00023: val_loss improved from 1.02638 to 0.99900, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 24/60
 - 4s - loss: 1.0932 - acc: 0.6645 - val_loss: 0.9895 - val_acc: 0.6656

Epoch 00024: val_loss improved from 0.99900 to 0.98947, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 25/60
 - 4s - loss: 1.0840 - acc: 0.6661 - val_loss: 0.9978 - val_acc: 0.6786

Epoch 00025: val_loss did not improve from 0.98947
Epoch 26/60
 - 4s - loss: 1.0775 - acc: 0.6686 - val_loss: 0.9573 - val_acc: 0.6806

Epoch 00026: val_loss improved from 0.98947 to 0.95730, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 27/60
 - 4s - loss: 1.0683 - acc: 0.6677 - val_loss: 0.9725 - val_acc: 0.6828

Epoch 00027: val_loss did not improve from 0.95730
Epoch 28/60
 - 4s - loss: 1.0665 - acc: 0.6678 - val_loss: 0.9529 - val_acc: 0.6824

Epoch 00028: val_loss improved from 0.95730 to 0.95287, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 29/60
 - 4s - loss: 1.0579 - acc: 0.6720 - val_loss: 0.9455 - val_acc: 0.6796

Epoch 00029: val_loss improved from 0.95287 to 0.94552, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 30/60
 - 4s - loss: 1.0577 - acc: 0.6708 - val_loss: 0.9455 - val_acc: 0.6761

Epoch 00030: val_loss improved from 0.94552 to 0.94551, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 31/60
 - 4s - loss: 1.0508 - acc: 0.6713 - val_loss: 0.9457 - val_acc: 0.6839

Epoch 00031: val_loss did not improve from 0.94551
Epoch 32/60
 - 4s - loss: 1.0425 - acc: 0.6745 - val_loss: 0.9389 - val_acc: 0.6865

Epoch 00032: val_loss improved from 0.94551 to 0.93892, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 33/60
 - 4s - loss: 1.0413 - acc: 0.6715 - val_loss: 0.9195 - val_acc: 0.6858

Epoch 00033: val_loss improved from 0.93892 to 0.91948, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 34/60
 - 4s - loss: 1.0309 - acc: 0.6741 - val_loss: 0.9088 - val_acc: 0.6861

Epoch 00034: val_loss improved from 0.91948 to 0.90881, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 35/60
 - 4s - loss: 1.0261 - acc: 0.6744 - val_loss: 0.9007 - val_acc: 0.6878

Epoch 00035: val_loss improved from 0.90881 to 0.90067, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 36/60
 - 4s - loss: 1.0220 - acc: 0.6769 - val_loss: 0.9131 - val_acc: 0.6870

Epoch 00036: val_loss did not improve from 0.90067
Epoch 37/60
 - 4s - loss: 1.0138 - acc: 0.6763 - val_loss: 0.8764 - val_acc: 0.6906

Epoch 00037: val_loss improved from 0.90067 to 0.87637, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 38/60
 - 4s - loss: 1.0130 - acc: 0.6779 - val_loss: 0.8761 - val_acc: 0.6942

Epoch 00038: val_loss improved from 0.87637 to 0.87606, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 39/60
 - 4s - loss: 1.0063 - acc: 0.6783 - val_loss: 0.8584 - val_acc: 0.6906

Epoch 00039: val_loss improved from 0.87606 to 0.85841, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 40/60
 - 4s - loss: 1.0023 - acc: 0.6789 - val_loss: 0.8779 - val_acc: 0.6887

Epoch 00040: val_loss did not improve from 0.85841
Epoch 41/60
 - 4s - loss: 0.9937 - acc: 0.6802 - val_loss: 0.8755 - val_acc: 0.6901

Epoch 00041: val_loss did not improve from 0.85841
Epoch 42/60
 - 4s - loss: 0.9905 - acc: 0.6818 - val_loss: 0.8255 - val_acc: 0.6970

Epoch 00042: val_loss improved from 0.85841 to 0.82546, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 43/60
 - 4s - loss: 0.9806 - acc: 0.6832 - val_loss: 0.8214 - val_acc: 0.6989

Epoch 00043: val_loss improved from 0.82546 to 0.82142, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 44/60
 - 4s - loss: 0.9821 - acc: 0.6824 - val_loss: 0.8229 - val_acc: 0.7064

Epoch 00044: val_loss did not improve from 0.82142
Epoch 45/60
 - 4s - loss: 0.9736 - acc: 0.6856 - val_loss: 0.8297 - val_acc: 0.7148

Epoch 00045: val_loss did not improve from 0.82142
Epoch 46/60
 - 4s - loss: 0.9696 - acc: 0.6858 - val_loss: 0.8128 - val_acc: 0.7133

Epoch 00046: val_loss improved from 0.82142 to 0.81283, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 47/60
 - 4s - loss: 0.9646 - acc: 0.6875 - val_loss: 0.8357 - val_acc: 0.7081

Epoch 00047: val_loss did not improve from 0.81283
Epoch 48/60
 - 4s - loss: 0.9626 - acc: 0.6881 - val_loss: 0.8020 - val_acc: 0.7245

Epoch 00048: val_loss improved from 0.81283 to 0.80203, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 49/60
 - 4s - loss: 0.9572 - acc: 0.6883 - val_loss: 0.7872 - val_acc: 0.7246

Epoch 00049: val_loss improved from 0.80203 to 0.78722, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 50/60
 - 4s - loss: 0.9486 - acc: 0.6930 - val_loss: 0.7734 - val_acc: 0.7320

Epoch 00050: val_loss improved from 0.78722 to 0.77339, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 51/60
 - 4s - loss: 0.9475 - acc: 0.6935 - val_loss: 0.7648 - val_acc: 0.7290

Epoch 00051: val_loss improved from 0.77339 to 0.76476, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 52/60
 - 4s - loss: 0.9435 - acc: 0.6933 - val_loss: 0.7786 - val_acc: 0.7292

Epoch 00052: val_loss did not improve from 0.76476
Epoch 53/60
 - 4s - loss: 0.9375 - acc: 0.6948 - val_loss: 0.7649 - val_acc: 0.7298

Epoch 00053: val_loss did not improve from 0.76476
Epoch 54/60
 - 4s - loss: 0.9328 - acc: 0.6985 - val_loss: 0.7620 - val_acc: 0.7365

Epoch 00054: val_loss improved from 0.76476 to 0.76198, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 55/60
 - 4s - loss: 0.9321 - acc: 0.6948 - val_loss: 0.7624 - val_acc: 0.7376

Epoch 00055: val_loss did not improve from 0.76198
Epoch 56/60
 - 4s - loss: 0.9311 - acc: 0.6982 - val_loss: 0.7503 - val_acc: 0.7361

Epoch 00056: val_loss improved from 0.76198 to 0.75025, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 57/60
 - 4s - loss: 0.9255 - acc: 0.7006 - val_loss: 0.7492 - val_acc: 0.7415

Epoch 00057: val_loss improved from 0.75025 to 0.74916, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 58/60
 - 4s - loss: 0.9202 - acc: 0.7007 - val_loss: 0.7491 - val_acc: 0.7457

Epoch 00058: val_loss improved from 0.74916 to 0.74913, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 59/60
 - 4s - loss: 0.9202 - acc: 0.7008 - val_loss: 0.7490 - val_acc: 0.7465

Epoch 00059: val_loss improved from 0.74913 to 0.74901, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 60/60
 - 4s - loss: 0.9142 - acc: 0.7018 - val_loss: 0.7214 - val_acc: 0.7529

Epoch 00060: val_loss improved from 0.74901 to 0.72144, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 2.2442 - acc: 0.5764 - val_loss: 1.7311 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 1.73112, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 2/60
 - 5s - loss: 1.4729 - acc: 0.6368 - val_loss: 1.4873 - val_acc: 0.6209

Epoch 00002: val_loss improved from 1.73112 to 1.48731, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 3/60
 - 5s - loss: 1.3545 - acc: 0.6374 - val_loss: 1.2645 - val_acc: 0.6370

Epoch 00003: val_loss improved from 1.48731 to 1.26451, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 4/60
 - 5s - loss: 1.2655 - acc: 0.6432 - val_loss: 1.1944 - val_acc: 0.6556

Epoch 00004: val_loss improved from 1.26451 to 1.19444, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 5/60
 - 5s - loss: 1.2050 - acc: 0.6518 - val_loss: 1.1599 - val_acc: 0.6559

Epoch 00005: val_loss improved from 1.19444 to 1.15989, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 6/60
 - 5s - loss: 1.1575 - acc: 0.6580 - val_loss: 1.1811 - val_acc: 0.6723

Epoch 00006: val_loss did not improve from 1.15989
Epoch 7/60
 - 5s - loss: 1.1323 - acc: 0.6617 - val_loss: 1.0517 - val_acc: 0.6780

Epoch 00007: val_loss improved from 1.15989 to 1.05168, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 8/60
 - 5s - loss: 1.0955 - acc: 0.6662 - val_loss: 1.0551 - val_acc: 0.6771

Epoch 00008: val_loss did not improve from 1.05168
Epoch 9/60
 - 5s - loss: 1.0703 - acc: 0.6699 - val_loss: 0.9698 - val_acc: 0.6836

Epoch 00009: val_loss improved from 1.05168 to 0.96983, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 10/60
 - 5s - loss: 1.0441 - acc: 0.6745 - val_loss: 0.9635 - val_acc: 0.6870

Epoch 00010: val_loss improved from 0.96983 to 0.96348, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 11/60
 - 6s - loss: 1.0237 - acc: 0.6770 - val_loss: 0.9235 - val_acc: 0.6914

Epoch 00011: val_loss improved from 0.96348 to 0.92350, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 12/60
 - 5s - loss: 1.0047 - acc: 0.6805 - val_loss: 0.8957 - val_acc: 0.6931

Epoch 00012: val_loss improved from 0.92350 to 0.89574, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 13/60
 - 5s - loss: 0.9860 - acc: 0.6842 - val_loss: 0.8532 - val_acc: 0.6970

Epoch 00013: val_loss improved from 0.89574 to 0.85320, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 14/60
 - 5s - loss: 0.9628 - acc: 0.6900 - val_loss: 0.8213 - val_acc: 0.7133

Epoch 00014: val_loss improved from 0.85320 to 0.82130, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 15/60
 - 5s - loss: 0.9458 - acc: 0.6922 - val_loss: 0.8240 - val_acc: 0.7292

Epoch 00015: val_loss did not improve from 0.82130
Epoch 16/60
 - 5s - loss: 0.9294 - acc: 0.6977 - val_loss: 0.8116 - val_acc: 0.7342

Epoch 00016: val_loss improved from 0.82130 to 0.81164, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 17/60
 - 5s - loss: 0.9074 - acc: 0.7035 - val_loss: 0.7516 - val_acc: 0.7333

Epoch 00017: val_loss improved from 0.81164 to 0.75156, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 18/60
 - 5s - loss: 0.8979 - acc: 0.7064 - val_loss: 0.7648 - val_acc: 0.7571

Epoch 00018: val_loss did not improve from 0.75156
Epoch 19/60
 - 5s - loss: 0.8830 - acc: 0.7093 - val_loss: 0.7190 - val_acc: 0.7476

Epoch 00019: val_loss improved from 0.75156 to 0.71900, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 20/60
 - 5s - loss: 0.8643 - acc: 0.7156 - val_loss: 0.7102 - val_acc: 0.7604

Epoch 00020: val_loss improved from 0.71900 to 0.71025, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 21/60
 - 5s - loss: 0.8516 - acc: 0.7192 - val_loss: 0.6964 - val_acc: 0.7601

Epoch 00021: val_loss improved from 0.71025 to 0.69645, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 22/60
 - 5s - loss: 0.8418 - acc: 0.7241 - val_loss: 0.6742 - val_acc: 0.7692

Epoch 00022: val_loss improved from 0.69645 to 0.67423, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 23/60
 - 5s - loss: 0.8305 - acc: 0.7257 - val_loss: 0.6688 - val_acc: 0.7863

Epoch 00023: val_loss improved from 0.67423 to 0.66877, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 24/60
 - 5s - loss: 0.8195 - acc: 0.7314 - val_loss: 0.6550 - val_acc: 0.7733

Epoch 00024: val_loss improved from 0.66877 to 0.65499, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 25/60
 - 5s - loss: 0.8089 - acc: 0.7343 - val_loss: 0.6456 - val_acc: 0.7846

Epoch 00025: val_loss improved from 0.65499 to 0.64555, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 26/60
 - 5s - loss: 0.7958 - acc: 0.7385 - val_loss: 0.6260 - val_acc: 0.7874

Epoch 00026: val_loss improved from 0.64555 to 0.62602, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 27/60
 - 5s - loss: 0.7909 - acc: 0.7394 - val_loss: 0.6546 - val_acc: 0.7858

Epoch 00027: val_loss did not improve from 0.62602
Epoch 28/60
 - 5s - loss: 0.7802 - acc: 0.7419 - val_loss: 0.6086 - val_acc: 0.7898

Epoch 00028: val_loss improved from 0.62602 to 0.60859, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 29/60
 - 5s - loss: 0.7777 - acc: 0.7456 - val_loss: 0.6127 - val_acc: 0.8027

Epoch 00029: val_loss did not improve from 0.60859
Epoch 30/60
 - 5s - loss: 0.7669 - acc: 0.7472 - val_loss: 0.6033 - val_acc: 0.7992

Epoch 00030: val_loss improved from 0.60859 to 0.60329, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 31/60
 - 5s - loss: 0.7618 - acc: 0.7481 - val_loss: 0.5950 - val_acc: 0.7991

Epoch 00031: val_loss improved from 0.60329 to 0.59501, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 32/60
 - 5s - loss: 0.7537 - acc: 0.7509 - val_loss: 0.5788 - val_acc: 0.8048

Epoch 00032: val_loss improved from 0.59501 to 0.57883, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 33/60
 - 5s - loss: 0.7498 - acc: 0.7541 - val_loss: 0.5751 - val_acc: 0.8039

Epoch 00033: val_loss improved from 0.57883 to 0.57509, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 34/60
 - 5s - loss: 0.7438 - acc: 0.7545 - val_loss: 0.5749 - val_acc: 0.8046

Epoch 00034: val_loss improved from 0.57509 to 0.57490, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 35/60
 - 5s - loss: 0.7370 - acc: 0.7581 - val_loss: 0.5868 - val_acc: 0.8085

Epoch 00035: val_loss did not improve from 0.57490
Epoch 36/60
 - 6s - loss: 0.7318 - acc: 0.7585 - val_loss: 0.5610 - val_acc: 0.8098

Epoch 00036: val_loss improved from 0.57490 to 0.56102, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 37/60
 - 5s - loss: 0.7259 - acc: 0.7618 - val_loss: 0.5591 - val_acc: 0.8126

Epoch 00037: val_loss improved from 0.56102 to 0.55912, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 38/60
 - 5s - loss: 0.7205 - acc: 0.7656 - val_loss: 0.5439 - val_acc: 0.8188

Epoch 00038: val_loss improved from 0.55912 to 0.54389, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 39/60
 - 5s - loss: 0.7191 - acc: 0.7647 - val_loss: 0.5419 - val_acc: 0.8173

Epoch 00039: val_loss improved from 0.54389 to 0.54189, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 40/60
 - 5s - loss: 0.7141 - acc: 0.7653 - val_loss: 0.5410 - val_acc: 0.8216

Epoch 00040: val_loss improved from 0.54189 to 0.54097, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 41/60
 - 5s - loss: 0.7093 - acc: 0.7652 - val_loss: 0.5400 - val_acc: 0.8185

Epoch 00041: val_loss improved from 0.54097 to 0.53998, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 42/60
 - 5s - loss: 0.7027 - acc: 0.7710 - val_loss: 0.5360 - val_acc: 0.8163

Epoch 00042: val_loss improved from 0.53998 to 0.53598, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 43/60
 - 5s - loss: 0.7041 - acc: 0.7696 - val_loss: 0.5326 - val_acc: 0.8232

Epoch 00043: val_loss improved from 0.53598 to 0.53259, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 44/60
 - 5s - loss: 0.6963 - acc: 0.7732 - val_loss: 0.5234 - val_acc: 0.8269

Epoch 00044: val_loss improved from 0.53259 to 0.52337, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 45/60
 - 5s - loss: 0.6972 - acc: 0.7697 - val_loss: 0.5484 - val_acc: 0.8226

Epoch 00045: val_loss did not improve from 0.52337
Epoch 46/60
 - 5s - loss: 0.6881 - acc: 0.7737 - val_loss: 0.5228 - val_acc: 0.8279

Epoch 00046: val_loss improved from 0.52337 to 0.52280, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 47/60
 - 5s - loss: 0.6928 - acc: 0.7722 - val_loss: 0.5275 - val_acc: 0.8230

Epoch 00047: val_loss did not improve from 0.52280
Epoch 48/60
 - 5s - loss: 0.6861 - acc: 0.7761 - val_loss: 0.5163 - val_acc: 0.8314

Epoch 00048: val_loss improved from 0.52280 to 0.51627, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 49/60
 - 5s - loss: 0.6796 - acc: 0.7778 - val_loss: 0.4998 - val_acc: 0.8280

Epoch 00049: val_loss improved from 0.51627 to 0.49976, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 50/60
 - 5s - loss: 0.6776 - acc: 0.7767 - val_loss: 0.5315 - val_acc: 0.8295

Epoch 00050: val_loss did not improve from 0.49976
Epoch 51/60
 - 5s - loss: 0.6755 - acc: 0.7793 - val_loss: 0.5114 - val_acc: 0.8338

Epoch 00051: val_loss did not improve from 0.49976
Epoch 52/60
 - 5s - loss: 0.6708 - acc: 0.7801 - val_loss: 0.5033 - val_acc: 0.8347

Epoch 00052: val_loss did not improve from 0.49976
Epoch 53/60
 - 5s - loss: 0.6769 - acc: 0.7806 - val_loss: 0.5084 - val_acc: 0.8351

Epoch 00053: val_loss did not improve from 0.49976
Epoch 54/60
 - 5s - loss: 0.6701 - acc: 0.7835 - val_loss: 0.4975 - val_acc: 0.8361

Epoch 00054: val_loss improved from 0.49976 to 0.49746, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 55/60
 - 5s - loss: 0.6649 - acc: 0.7815 - val_loss: 0.4982 - val_acc: 0.8383

Epoch 00055: val_loss did not improve from 0.49746
Epoch 56/60
 - 5s - loss: 0.6639 - acc: 0.7822 - val_loss: 0.4862 - val_acc: 0.8357

Epoch 00056: val_loss improved from 0.49746 to 0.48625, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 57/60
 - 5s - loss: 0.6647 - acc: 0.7823 - val_loss: 0.4848 - val_acc: 0.8408

Epoch 00057: val_loss improved from 0.48625 to 0.48482, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 58/60
 - 5s - loss: 0.6641 - acc: 0.7839 - val_loss: 0.4825 - val_acc: 0.8401

Epoch 00058: val_loss improved from 0.48482 to 0.48246, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5
Epoch 59/60
 - 5s - loss: 0.6565 - acc: 0.7867 - val_loss: 0.4856 - val_acc: 0.8392

Epoch 00059: val_loss did not improve from 0.48246
Epoch 60/60
 - 5s - loss: 0.6561 - acc: 0.7859 - val_loss: 0.4906 - val_acc: 0.8373

Epoch 00060: val_loss did not improve from 0.48246
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 3.2642 - acc: 0.5614 - val_loss: 1.4651 - val_acc: 0.6277

Epoch 00001: val_loss improved from inf to 1.46514, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 2/60
 - 5s - loss: 1.4228 - acc: 0.6278 - val_loss: 1.1531 - val_acc: 0.6503

Epoch 00002: val_loss improved from 1.46514 to 1.15312, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 3/60
 - 5s - loss: 1.2563 - acc: 0.6459 - val_loss: 1.0719 - val_acc: 0.6799

Epoch 00003: val_loss improved from 1.15312 to 1.07192, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 4/60
 - 5s - loss: 1.1374 - acc: 0.6635 - val_loss: 0.9254 - val_acc: 0.6940

Epoch 00004: val_loss improved from 1.07192 to 0.92538, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 5/60
 - 5s - loss: 1.0601 - acc: 0.6784 - val_loss: 0.8429 - val_acc: 0.7234

Epoch 00005: val_loss improved from 0.92538 to 0.84294, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 6/60
 - 5s - loss: 0.9909 - acc: 0.6922 - val_loss: 0.7535 - val_acc: 0.7565

Epoch 00006: val_loss improved from 0.84294 to 0.75349, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 7/60
 - 5s - loss: 0.9370 - acc: 0.7070 - val_loss: 0.7342 - val_acc: 0.7771

Epoch 00007: val_loss improved from 0.75349 to 0.73418, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 8/60
 - 5s - loss: 0.8978 - acc: 0.7165 - val_loss: 0.6947 - val_acc: 0.7820

Epoch 00008: val_loss improved from 0.73418 to 0.69474, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 9/60
 - 5s - loss: 0.8606 - acc: 0.7270 - val_loss: 0.6709 - val_acc: 0.7991

Epoch 00009: val_loss improved from 0.69474 to 0.67090, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 10/60
 - 5s - loss: 0.8313 - acc: 0.7349 - val_loss: 0.6576 - val_acc: 0.7751

Epoch 00010: val_loss improved from 0.67090 to 0.65757, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 11/60
 - 5s - loss: 0.8129 - acc: 0.7419 - val_loss: 0.5975 - val_acc: 0.8161

Epoch 00011: val_loss improved from 0.65757 to 0.59755, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 12/60
 - 5s - loss: 0.7866 - acc: 0.7502 - val_loss: 0.5975 - val_acc: 0.8197

Epoch 00012: val_loss improved from 0.59755 to 0.59750, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 13/60
 - 5s - loss: 0.7674 - acc: 0.7554 - val_loss: 0.6171 - val_acc: 0.7914

Epoch 00013: val_loss did not improve from 0.59750
Epoch 14/60
 - 5s - loss: 0.7632 - acc: 0.7562 - val_loss: 0.5731 - val_acc: 0.8330

Epoch 00014: val_loss improved from 0.59750 to 0.57314, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 15/60
 - 5s - loss: 0.7476 - acc: 0.7626 - val_loss: 0.5420 - val_acc: 0.8342

Epoch 00015: val_loss improved from 0.57314 to 0.54197, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 16/60
 - 5s - loss: 0.7254 - acc: 0.7664 - val_loss: 0.5336 - val_acc: 0.8405

Epoch 00016: val_loss improved from 0.54197 to 0.53358, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 17/60
 - 5s - loss: 0.7197 - acc: 0.7696 - val_loss: 0.5278 - val_acc: 0.8427

Epoch 00017: val_loss improved from 0.53358 to 0.52776, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 18/60
 - 5s - loss: 0.7101 - acc: 0.7712 - val_loss: 0.5287 - val_acc: 0.8276

Epoch 00018: val_loss did not improve from 0.52776
Epoch 19/60
 - 5s - loss: 0.7026 - acc: 0.7756 - val_loss: 0.5170 - val_acc: 0.8397

Epoch 00019: val_loss improved from 0.52776 to 0.51700, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 20/60
 - 5s - loss: 0.6949 - acc: 0.7767 - val_loss: 0.5078 - val_acc: 0.8413

Epoch 00020: val_loss improved from 0.51700 to 0.50777, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 21/60
 - 5s - loss: 0.6835 - acc: 0.7811 - val_loss: 0.5177 - val_acc: 0.8533

Epoch 00021: val_loss did not improve from 0.50777
Epoch 22/60
 - 5s - loss: 0.6780 - acc: 0.7839 - val_loss: 0.5114 - val_acc: 0.8497

Epoch 00022: val_loss did not improve from 0.50777
Epoch 23/60
 - 5s - loss: 0.6685 - acc: 0.7872 - val_loss: 0.5008 - val_acc: 0.8394

Epoch 00023: val_loss improved from 0.50777 to 0.50075, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 24/60
 - 5s - loss: 0.6713 - acc: 0.7850 - val_loss: 0.5049 - val_acc: 0.8386

Epoch 00024: val_loss did not improve from 0.50075
Epoch 25/60
 - 5s - loss: 0.6614 - acc: 0.7875 - val_loss: 0.5040 - val_acc: 0.8480

Epoch 00025: val_loss did not improve from 0.50075
Epoch 26/60
 - 5s - loss: 0.6573 - acc: 0.7881 - val_loss: 0.5008 - val_acc: 0.8480

Epoch 00026: val_loss did not improve from 0.50075
Epoch 27/60
 - 5s - loss: 0.6514 - acc: 0.7926 - val_loss: 0.5053 - val_acc: 0.8522

Epoch 00027: val_loss did not improve from 0.50075
Epoch 28/60
 - 5s - loss: 0.6449 - acc: 0.7941 - val_loss: 0.4782 - val_acc: 0.8550

Epoch 00028: val_loss improved from 0.50075 to 0.47819, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 29/60
 - 5s - loss: 0.6436 - acc: 0.7943 - val_loss: 0.4972 - val_acc: 0.8483

Epoch 00029: val_loss did not improve from 0.47819
Epoch 30/60
 - 5s - loss: 0.6436 - acc: 0.7929 - val_loss: 0.4755 - val_acc: 0.8507

Epoch 00030: val_loss improved from 0.47819 to 0.47554, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 31/60
 - 5s - loss: 0.6288 - acc: 0.7973 - val_loss: 0.4680 - val_acc: 0.8542

Epoch 00031: val_loss improved from 0.47554 to 0.46796, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 32/60
 - 5s - loss: 0.6358 - acc: 0.7967 - val_loss: 0.4713 - val_acc: 0.8585

Epoch 00032: val_loss did not improve from 0.46796
Epoch 33/60
 - 5s - loss: 0.6347 - acc: 0.7959 - val_loss: 0.4801 - val_acc: 0.8638

Epoch 00033: val_loss did not improve from 0.46796
Epoch 34/60
 - 5s - loss: 0.6283 - acc: 0.7986 - val_loss: 0.4585 - val_acc: 0.8566

Epoch 00034: val_loss improved from 0.46796 to 0.45854, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 35/60
 - 5s - loss: 0.6227 - acc: 0.8001 - val_loss: 0.4871 - val_acc: 0.8386

Epoch 00035: val_loss did not improve from 0.45854
Epoch 36/60
 - 5s - loss: 0.6270 - acc: 0.7973 - val_loss: 0.4581 - val_acc: 0.8520

Epoch 00036: val_loss improved from 0.45854 to 0.45810, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 37/60
 - 5s - loss: 0.6198 - acc: 0.8022 - val_loss: 0.4558 - val_acc: 0.8600

Epoch 00037: val_loss improved from 0.45810 to 0.45575, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 38/60
 - 5s - loss: 0.6154 - acc: 0.8011 - val_loss: 0.4579 - val_acc: 0.8561

Epoch 00038: val_loss did not improve from 0.45575
Epoch 39/60
 - 5s - loss: 0.6128 - acc: 0.8051 - val_loss: 0.4515 - val_acc: 0.8539

Epoch 00039: val_loss improved from 0.45575 to 0.45148, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 40/60
 - 5s - loss: 0.6094 - acc: 0.8029 - val_loss: 0.4916 - val_acc: 0.8330

Epoch 00040: val_loss did not improve from 0.45148
Epoch 41/60
 - 5s - loss: 0.6105 - acc: 0.8034 - val_loss: 0.4556 - val_acc: 0.8570

Epoch 00041: val_loss did not improve from 0.45148
Epoch 42/60
 - 5s - loss: 0.6097 - acc: 0.8052 - val_loss: 0.4639 - val_acc: 0.8507

Epoch 00042: val_loss did not improve from 0.45148
Epoch 43/60
 - 5s - loss: 0.6071 - acc: 0.8048 - val_loss: 0.4395 - val_acc: 0.8642

Epoch 00043: val_loss improved from 0.45148 to 0.43953, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 44/60
 - 5s - loss: 0.6023 - acc: 0.8052 - val_loss: 0.4472 - val_acc: 0.8635

Epoch 00044: val_loss did not improve from 0.43953
Epoch 45/60
 - 5s - loss: 0.6043 - acc: 0.8059 - val_loss: 0.4578 - val_acc: 0.8535

Epoch 00045: val_loss did not improve from 0.43953
Epoch 46/60
 - 5s - loss: 0.6030 - acc: 0.8081 - val_loss: 0.4479 - val_acc: 0.8601

Epoch 00046: val_loss did not improve from 0.43953
Epoch 47/60
 - 5s - loss: 0.6001 - acc: 0.8086 - val_loss: 0.4559 - val_acc: 0.8542

Epoch 00047: val_loss did not improve from 0.43953
Epoch 48/60
 - 5s - loss: 0.5994 - acc: 0.8063 - val_loss: 0.4419 - val_acc: 0.8692

Epoch 00048: val_loss did not improve from 0.43953
Epoch 49/60
 - 5s - loss: 0.5997 - acc: 0.8082 - val_loss: 0.4337 - val_acc: 0.8600

Epoch 00049: val_loss improved from 0.43953 to 0.43373, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 50/60
 - 5s - loss: 0.5948 - acc: 0.8081 - val_loss: 0.4664 - val_acc: 0.8551

Epoch 00050: val_loss did not improve from 0.43373
Epoch 51/60
 - 5s - loss: 0.5921 - acc: 0.8099 - val_loss: 0.4420 - val_acc: 0.8630

Epoch 00051: val_loss did not improve from 0.43373
Epoch 52/60
 - 5s - loss: 0.5907 - acc: 0.8082 - val_loss: 0.4369 - val_acc: 0.8654

Epoch 00052: val_loss did not improve from 0.43373
Epoch 53/60
 - 5s - loss: 0.5888 - acc: 0.8126 - val_loss: 0.4598 - val_acc: 0.8638

Epoch 00053: val_loss did not improve from 0.43373
Epoch 54/60
 - 5s - loss: 0.5881 - acc: 0.8097 - val_loss: 0.4463 - val_acc: 0.8594

Epoch 00054: val_loss did not improve from 0.43373
Epoch 55/60
 - 5s - loss: 0.5853 - acc: 0.8121 - val_loss: 0.4482 - val_acc: 0.8570

Epoch 00055: val_loss did not improve from 0.43373
Epoch 56/60
 - 5s - loss: 0.5904 - acc: 0.8096 - val_loss: 0.4285 - val_acc: 0.8667

Epoch 00056: val_loss improved from 0.43373 to 0.42852, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 57/60
 - 5s - loss: 0.5884 - acc: 0.8113 - val_loss: 0.4513 - val_acc: 0.8505

Epoch 00057: val_loss did not improve from 0.42852
Epoch 58/60
 - 5s - loss: 0.5806 - acc: 0.8109 - val_loss: 0.4268 - val_acc: 0.8638

Epoch 00058: val_loss improved from 0.42852 to 0.42682, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5
Epoch 59/60
 - 5s - loss: 0.5883 - acc: 0.8140 - val_loss: 0.4358 - val_acc: 0.8657

Epoch 00059: val_loss did not improve from 0.42682
Epoch 60/60
 - 5s - loss: 0.5791 - acc: 0.8147 - val_loss: 0.4357 - val_acc: 0.8641

Epoch 00060: val_loss did not improve from 0.42682
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 5.2802 - acc: 0.3029 - val_loss: 2.2054 - val_acc: 0.6208

Epoch 00001: val_loss improved from inf to 2.20541, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 2/60
 - 4s - loss: 1.9827 - acc: 0.5444 - val_loss: 2.0637 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.20541 to 2.06370, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 3/60
 - 5s - loss: 1.7723 - acc: 0.6232 - val_loss: 1.8889 - val_acc: 0.6209

Epoch 00003: val_loss improved from 2.06370 to 1.88893, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 4/60
 - 4s - loss: 1.6749 - acc: 0.6351 - val_loss: 1.7203 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.88893 to 1.72028, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 5/60
 - 4s - loss: 1.6178 - acc: 0.6368 - val_loss: 1.6353 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.72028 to 1.63526, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 6/60
 - 4s - loss: 1.5808 - acc: 0.6371 - val_loss: 1.5989 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.63526 to 1.59886, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 7/60
 - 4s - loss: 1.5497 - acc: 0.6371 - val_loss: 1.5600 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.59886 to 1.56004, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 8/60
 - 4s - loss: 1.5332 - acc: 0.6371 - val_loss: 1.5307 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.56004 to 1.53067, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 9/60
 - 4s - loss: 1.5162 - acc: 0.6371 - val_loss: 1.5289 - val_acc: 0.6209

Epoch 00009: val_loss improved from 1.53067 to 1.52890, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 10/60
 - 4s - loss: 1.4963 - acc: 0.6371 - val_loss: 1.5141 - val_acc: 0.6209

Epoch 00010: val_loss improved from 1.52890 to 1.51411, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 11/60
 - 4s - loss: 1.4819 - acc: 0.6371 - val_loss: 1.5203 - val_acc: 0.6209

Epoch 00011: val_loss did not improve from 1.51411
Epoch 12/60
 - 4s - loss: 1.4629 - acc: 0.6371 - val_loss: 1.4890 - val_acc: 0.6209

Epoch 00012: val_loss improved from 1.51411 to 1.48902, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 13/60
 - 4s - loss: 1.4543 - acc: 0.6371 - val_loss: 1.4853 - val_acc: 0.6209

Epoch 00013: val_loss improved from 1.48902 to 1.48529, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 14/60
 - 4s - loss: 1.4373 - acc: 0.6371 - val_loss: 1.4831 - val_acc: 0.6209

Epoch 00014: val_loss improved from 1.48529 to 1.48306, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 15/60
 - 4s - loss: 1.4303 - acc: 0.6371 - val_loss: 1.4605 - val_acc: 0.6209

Epoch 00015: val_loss improved from 1.48306 to 1.46049, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 16/60
 - 4s - loss: 1.4245 - acc: 0.6371 - val_loss: 1.4375 - val_acc: 0.6209

Epoch 00016: val_loss improved from 1.46049 to 1.43752, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 17/60
 - 4s - loss: 1.4140 - acc: 0.6371 - val_loss: 1.4356 - val_acc: 0.6209

Epoch 00017: val_loss improved from 1.43752 to 1.43565, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 18/60
 - 4s - loss: 1.4039 - acc: 0.6371 - val_loss: 1.4495 - val_acc: 0.6209

Epoch 00018: val_loss did not improve from 1.43565
Epoch 19/60
 - 4s - loss: 1.3930 - acc: 0.6371 - val_loss: 1.4540 - val_acc: 0.6209

Epoch 00019: val_loss did not improve from 1.43565
Epoch 20/60
 - 4s - loss: 1.3871 - acc: 0.6371 - val_loss: 1.4863 - val_acc: 0.6209

Epoch 00020: val_loss did not improve from 1.43565
Epoch 21/60
 - 4s - loss: 1.3832 - acc: 0.6371 - val_loss: 1.4080 - val_acc: 0.6209

Epoch 00021: val_loss improved from 1.43565 to 1.40800, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 22/60
 - 4s - loss: 1.3737 - acc: 0.6371 - val_loss: 1.4371 - val_acc: 0.6209

Epoch 00022: val_loss did not improve from 1.40800
Epoch 23/60
 - 4s - loss: 1.3667 - acc: 0.6371 - val_loss: 1.4326 - val_acc: 0.6209

Epoch 00023: val_loss did not improve from 1.40800
Epoch 24/60
 - 4s - loss: 1.3636 - acc: 0.6371 - val_loss: 1.4054 - val_acc: 0.6209

Epoch 00024: val_loss improved from 1.40800 to 1.40542, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 25/60
 - 4s - loss: 1.3590 - acc: 0.6371 - val_loss: 1.4556 - val_acc: 0.6209

Epoch 00025: val_loss did not improve from 1.40542
Epoch 26/60
 - 4s - loss: 1.3543 - acc: 0.6371 - val_loss: 1.4241 - val_acc: 0.6209

Epoch 00026: val_loss did not improve from 1.40542
Epoch 27/60
 - 4s - loss: 1.3497 - acc: 0.6371 - val_loss: 1.4104 - val_acc: 0.6209

Epoch 00027: val_loss did not improve from 1.40542
Epoch 28/60
 - 4s - loss: 1.3461 - acc: 0.6371 - val_loss: 1.4290 - val_acc: 0.6209

Epoch 00028: val_loss did not improve from 1.40542
Epoch 29/60
 - 4s - loss: 1.3445 - acc: 0.6371 - val_loss: 1.4379 - val_acc: 0.6209

Epoch 00029: val_loss did not improve from 1.40542
Epoch 30/60
 - 4s - loss: 1.3415 - acc: 0.6371 - val_loss: 1.3838 - val_acc: 0.6209

Epoch 00030: val_loss improved from 1.40542 to 1.38375, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 31/60
 - 4s - loss: 1.3386 - acc: 0.6371 - val_loss: 1.4115 - val_acc: 0.6209

Epoch 00031: val_loss did not improve from 1.38375
Epoch 32/60
 - 4s - loss: 1.3362 - acc: 0.6371 - val_loss: 1.4040 - val_acc: 0.6209

Epoch 00032: val_loss did not improve from 1.38375
Epoch 33/60
 - 4s - loss: 1.3351 - acc: 0.6371 - val_loss: 1.3636 - val_acc: 0.6209

Epoch 00033: val_loss improved from 1.38375 to 1.36364, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 34/60
 - 4s - loss: 1.3348 - acc: 0.6371 - val_loss: 1.3737 - val_acc: 0.6209

Epoch 00034: val_loss did not improve from 1.36364
Epoch 35/60
 - 4s - loss: 1.3313 - acc: 0.6371 - val_loss: 1.3659 - val_acc: 0.6209

Epoch 00035: val_loss did not improve from 1.36364
Epoch 36/60
 - 4s - loss: 1.3282 - acc: 0.6371 - val_loss: 1.3740 - val_acc: 0.6209

Epoch 00036: val_loss did not improve from 1.36364
Epoch 37/60
 - 4s - loss: 1.3247 - acc: 0.6371 - val_loss: 1.3602 - val_acc: 0.6209

Epoch 00037: val_loss improved from 1.36364 to 1.36020, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 38/60
 - 4s - loss: 1.3275 - acc: 0.6371 - val_loss: 1.4018 - val_acc: 0.6209

Epoch 00038: val_loss did not improve from 1.36020
Epoch 39/60
 - 4s - loss: 1.3249 - acc: 0.6371 - val_loss: 1.3659 - val_acc: 0.6209

Epoch 00039: val_loss did not improve from 1.36020
Epoch 40/60
 - 4s - loss: 1.3249 - acc: 0.6371 - val_loss: 1.3451 - val_acc: 0.6209

Epoch 00040: val_loss improved from 1.36020 to 1.34511, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 41/60
 - 4s - loss: 1.3261 - acc: 0.6371 - val_loss: 1.3937 - val_acc: 0.6209

Epoch 00041: val_loss did not improve from 1.34511
Epoch 42/60
 - 4s - loss: 1.3180 - acc: 0.6371 - val_loss: 1.4197 - val_acc: 0.6209

Epoch 00042: val_loss did not improve from 1.34511
Epoch 43/60
 - 4s - loss: 1.3223 - acc: 0.6371 - val_loss: 1.3785 - val_acc: 0.6209

Epoch 00043: val_loss did not improve from 1.34511
Epoch 44/60
 - 4s - loss: 1.3221 - acc: 0.6371 - val_loss: 1.3452 - val_acc: 0.6209

Epoch 00044: val_loss did not improve from 1.34511
Epoch 45/60
 - 4s - loss: 1.3203 - acc: 0.6371 - val_loss: 1.3820 - val_acc: 0.6209

Epoch 00045: val_loss did not improve from 1.34511
Epoch 46/60
 - 4s - loss: 1.3173 - acc: 0.6371 - val_loss: 1.4024 - val_acc: 0.6209

Epoch 00046: val_loss did not improve from 1.34511
Epoch 47/60
 - 4s - loss: 1.3155 - acc: 0.6371 - val_loss: 1.4233 - val_acc: 0.6209

Epoch 00047: val_loss did not improve from 1.34511
Epoch 48/60
 - 4s - loss: 1.3152 - acc: 0.6371 - val_loss: 1.3321 - val_acc: 0.6209

Epoch 00048: val_loss improved from 1.34511 to 1.33213, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 49/60
 - 4s - loss: 1.3190 - acc: 0.6371 - val_loss: 1.3308 - val_acc: 0.6209

Epoch 00049: val_loss improved from 1.33213 to 1.33082, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 50/60
 - 4s - loss: 1.3135 - acc: 0.6371 - val_loss: 1.4028 - val_acc: 0.6209

Epoch 00050: val_loss did not improve from 1.33082
Epoch 51/60
 - 4s - loss: 1.3124 - acc: 0.6370 - val_loss: 1.3637 - val_acc: 0.6209

Epoch 00051: val_loss did not improve from 1.33082
Epoch 52/60
 - 4s - loss: 1.3112 - acc: 0.6371 - val_loss: 1.4090 - val_acc: 0.6209

Epoch 00052: val_loss did not improve from 1.33082
Epoch 53/60
 - 4s - loss: 1.3146 - acc: 0.6371 - val_loss: 1.3388 - val_acc: 0.6209

Epoch 00053: val_loss did not improve from 1.33082
Epoch 54/60
 - 4s - loss: 1.3094 - acc: 0.6371 - val_loss: 1.3457 - val_acc: 0.6209

Epoch 00054: val_loss did not improve from 1.33082
Epoch 55/60
 - 4s - loss: 1.3104 - acc: 0.6371 - val_loss: 1.3296 - val_acc: 0.6209

Epoch 00055: val_loss improved from 1.33082 to 1.32961, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5
Epoch 56/60
 - 4s - loss: 1.3114 - acc: 0.6371 - val_loss: 1.3563 - val_acc: 0.6209

Epoch 00056: val_loss did not improve from 1.32961
Epoch 57/60
 - 4s - loss: 1.3072 - acc: 0.6371 - val_loss: 1.3468 - val_acc: 0.6209

Epoch 00057: val_loss did not improve from 1.32961
Epoch 58/60
 - 4s - loss: 1.3064 - acc: 0.6370 - val_loss: 1.3983 - val_acc: 0.6209

Epoch 00058: val_loss did not improve from 1.32961
Epoch 59/60
 - 4s - loss: 1.3096 - acc: 0.6370 - val_loss: 1.3521 - val_acc: 0.6209

Epoch 00059: val_loss did not improve from 1.32961
Epoch 60/60
 - 4s - loss: 1.3075 - acc: 0.6371 - val_loss: 1.3335 - val_acc: 0.6209

Epoch 00060: val_loss did not improve from 1.32961
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 2.6350 - acc: 0.4956 - val_loss: 2.0886 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 2.08856, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 2/60
 - 5s - loss: 1.6842 - acc: 0.6335 - val_loss: 1.9101 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.08856 to 1.91014, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 3/60
 - 5s - loss: 1.5697 - acc: 0.6371 - val_loss: 1.8611 - val_acc: 0.6209

Epoch 00003: val_loss improved from 1.91014 to 1.86107, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 4/60
 - 5s - loss: 1.5235 - acc: 0.6371 - val_loss: 1.7602 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.86107 to 1.76024, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 5/60
 - 5s - loss: 1.4906 - acc: 0.6371 - val_loss: 1.6808 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.76024 to 1.68080, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 6/60
 - 5s - loss: 1.4760 - acc: 0.6371 - val_loss: 1.6236 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.68080 to 1.62356, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 7/60
 - 5s - loss: 1.4521 - acc: 0.6371 - val_loss: 1.5927 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.62356 to 1.59274, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 8/60
 - 6s - loss: 1.4317 - acc: 0.6371 - val_loss: 1.5133 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.59274 to 1.51334, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 9/60
 - 5s - loss: 1.4004 - acc: 0.6369 - val_loss: 1.4485 - val_acc: 0.6209

Epoch 00009: val_loss improved from 1.51334 to 1.44850, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 10/60
 - 5s - loss: 1.3629 - acc: 0.6355 - val_loss: 1.3873 - val_acc: 0.6209

Epoch 00010: val_loss improved from 1.44850 to 1.38735, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 11/60
 - 5s - loss: 1.3350 - acc: 0.6362 - val_loss: 1.3867 - val_acc: 0.6208

Epoch 00011: val_loss improved from 1.38735 to 1.38671, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 12/60
 - 5s - loss: 1.3059 - acc: 0.6356 - val_loss: 1.3818 - val_acc: 0.6209

Epoch 00012: val_loss improved from 1.38671 to 1.38182, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 13/60
 - 5s - loss: 1.2889 - acc: 0.6372 - val_loss: 1.3817 - val_acc: 0.6212

Epoch 00013: val_loss improved from 1.38182 to 1.38174, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 14/60
 - 5s - loss: 1.2777 - acc: 0.6381 - val_loss: 1.3754 - val_acc: 0.6209

Epoch 00014: val_loss improved from 1.38174 to 1.37543, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 15/60
 - 5s - loss: 1.2614 - acc: 0.6389 - val_loss: 1.4026 - val_acc: 0.6211

Epoch 00015: val_loss did not improve from 1.37543
Epoch 16/60
 - 5s - loss: 1.2518 - acc: 0.6398 - val_loss: 1.3454 - val_acc: 0.6218

Epoch 00016: val_loss improved from 1.37543 to 1.34536, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 17/60
 - 5s - loss: 1.2438 - acc: 0.6401 - val_loss: 1.4349 - val_acc: 0.6211

Epoch 00017: val_loss did not improve from 1.34536
Epoch 18/60
 - 5s - loss: 1.2352 - acc: 0.6412 - val_loss: 1.4080 - val_acc: 0.6209

Epoch 00018: val_loss did not improve from 1.34536
Epoch 19/60
 - 5s - loss: 1.2285 - acc: 0.6420 - val_loss: 1.3945 - val_acc: 0.6211

Epoch 00019: val_loss did not improve from 1.34536
Epoch 20/60
 - 5s - loss: 1.2199 - acc: 0.6432 - val_loss: 1.3307 - val_acc: 0.6233

Epoch 00020: val_loss improved from 1.34536 to 1.33071, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 21/60
 - 5s - loss: 1.2143 - acc: 0.6441 - val_loss: 1.3357 - val_acc: 0.6214

Epoch 00021: val_loss did not improve from 1.33071
Epoch 22/60
 - 5s - loss: 1.2081 - acc: 0.6447 - val_loss: 1.3386 - val_acc: 0.6265

Epoch 00022: val_loss did not improve from 1.33071
Epoch 23/60
 - 5s - loss: 1.2017 - acc: 0.6467 - val_loss: 1.3483 - val_acc: 0.6237

Epoch 00023: val_loss did not improve from 1.33071
Epoch 24/60
 - 5s - loss: 1.1970 - acc: 0.6471 - val_loss: 1.3569 - val_acc: 0.6240

Epoch 00024: val_loss did not improve from 1.33071
Epoch 25/60
 - 5s - loss: 1.1942 - acc: 0.6470 - val_loss: 1.3356 - val_acc: 0.6258

Epoch 00025: val_loss did not improve from 1.33071
Epoch 26/60
 - 5s - loss: 1.1884 - acc: 0.6486 - val_loss: 1.2937 - val_acc: 0.6269

Epoch 00026: val_loss improved from 1.33071 to 1.29371, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 27/60
 - 5s - loss: 1.1817 - acc: 0.6491 - val_loss: 1.3161 - val_acc: 0.6302

Epoch 00027: val_loss did not improve from 1.29371
Epoch 28/60
 - 5s - loss: 1.1815 - acc: 0.6503 - val_loss: 1.3240 - val_acc: 0.6346

Epoch 00028: val_loss did not improve from 1.29371
Epoch 29/60
 - 5s - loss: 1.1763 - acc: 0.6510 - val_loss: 1.3230 - val_acc: 0.6367

Epoch 00029: val_loss did not improve from 1.29371
Epoch 30/60
 - 5s - loss: 1.1723 - acc: 0.6508 - val_loss: 1.2554 - val_acc: 0.6318

Epoch 00030: val_loss improved from 1.29371 to 1.25542, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 31/60
 - 5s - loss: 1.1669 - acc: 0.6521 - val_loss: 1.3394 - val_acc: 0.6372

Epoch 00031: val_loss did not improve from 1.25542
Epoch 32/60
 - 5s - loss: 1.1649 - acc: 0.6544 - val_loss: 1.2867 - val_acc: 0.6365

Epoch 00032: val_loss did not improve from 1.25542
Epoch 33/60
 - 5s - loss: 1.1608 - acc: 0.6544 - val_loss: 1.3068 - val_acc: 0.6386

Epoch 00033: val_loss did not improve from 1.25542
Epoch 34/60
 - 5s - loss: 1.1575 - acc: 0.6535 - val_loss: 1.2489 - val_acc: 0.6405

Epoch 00034: val_loss improved from 1.25542 to 1.24892, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 35/60
 - 5s - loss: 1.1575 - acc: 0.6545 - val_loss: 1.2718 - val_acc: 0.6380

Epoch 00035: val_loss did not improve from 1.24892
Epoch 36/60
 - 5s - loss: 1.1529 - acc: 0.6549 - val_loss: 1.2667 - val_acc: 0.6378

Epoch 00036: val_loss did not improve from 1.24892
Epoch 37/60
 - 5s - loss: 1.1522 - acc: 0.6545 - val_loss: 1.2135 - val_acc: 0.6446

Epoch 00037: val_loss improved from 1.24892 to 1.21351, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 38/60
 - 5s - loss: 1.1495 - acc: 0.6557 - val_loss: 1.2226 - val_acc: 0.6393

Epoch 00038: val_loss did not improve from 1.21351
Epoch 39/60
 - 5s - loss: 1.1457 - acc: 0.6570 - val_loss: 1.2546 - val_acc: 0.6499

Epoch 00039: val_loss did not improve from 1.21351
Epoch 40/60
 - 5s - loss: 1.1439 - acc: 0.6559 - val_loss: 1.2826 - val_acc: 0.6471

Epoch 00040: val_loss did not improve from 1.21351
Epoch 41/60
 - 5s - loss: 1.1382 - acc: 0.6576 - val_loss: 1.2631 - val_acc: 0.6467

Epoch 00041: val_loss did not improve from 1.21351
Epoch 42/60
 - 5s - loss: 1.1320 - acc: 0.6595 - val_loss: 1.2187 - val_acc: 0.6486

Epoch 00042: val_loss did not improve from 1.21351
Epoch 43/60
 - 5s - loss: 1.1321 - acc: 0.6567 - val_loss: 1.2236 - val_acc: 0.6489

Epoch 00043: val_loss did not improve from 1.21351
Epoch 44/60
 - 5s - loss: 1.1303 - acc: 0.6574 - val_loss: 1.2275 - val_acc: 0.6433

Epoch 00044: val_loss did not improve from 1.21351
Epoch 45/60
 - 5s - loss: 1.1245 - acc: 0.6589 - val_loss: 1.2414 - val_acc: 0.6495

Epoch 00045: val_loss did not improve from 1.21351
Epoch 46/60
 - 5s - loss: 1.1245 - acc: 0.6595 - val_loss: 1.2022 - val_acc: 0.6467

Epoch 00046: val_loss improved from 1.21351 to 1.20221, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 47/60
 - 5s - loss: 1.1216 - acc: 0.6607 - val_loss: 1.1199 - val_acc: 0.6493

Epoch 00047: val_loss improved from 1.20221 to 1.11988, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 48/60
 - 5s - loss: 1.1197 - acc: 0.6596 - val_loss: 1.1877 - val_acc: 0.6514

Epoch 00048: val_loss did not improve from 1.11988
Epoch 49/60
 - 5s - loss: 1.1193 - acc: 0.6613 - val_loss: 1.1749 - val_acc: 0.6555

Epoch 00049: val_loss did not improve from 1.11988
Epoch 50/60
 - 5s - loss: 1.1163 - acc: 0.6624 - val_loss: 1.1216 - val_acc: 0.6570

Epoch 00050: val_loss did not improve from 1.11988
Epoch 51/60
 - 5s - loss: 1.1107 - acc: 0.6623 - val_loss: 1.2036 - val_acc: 0.6543

Epoch 00051: val_loss did not improve from 1.11988
Epoch 52/60
 - 5s - loss: 1.1127 - acc: 0.6607 - val_loss: 1.1772 - val_acc: 0.6577

Epoch 00052: val_loss did not improve from 1.11988
Epoch 53/60
 - 5s - loss: 1.1111 - acc: 0.6620 - val_loss: 1.1383 - val_acc: 0.6486

Epoch 00053: val_loss did not improve from 1.11988
Epoch 54/60
 - 5s - loss: 1.1094 - acc: 0.6604 - val_loss: 1.0837 - val_acc: 0.6515

Epoch 00054: val_loss improved from 1.11988 to 1.08371, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5
Epoch 55/60
 - 5s - loss: 1.0996 - acc: 0.6617 - val_loss: 1.1649 - val_acc: 0.6592

Epoch 00055: val_loss did not improve from 1.08371
Epoch 56/60
 - 5s - loss: 1.1006 - acc: 0.6629 - val_loss: 1.1019 - val_acc: 0.6565

Epoch 00056: val_loss did not improve from 1.08371
Epoch 57/60
 - 5s - loss: 1.1021 - acc: 0.6613 - val_loss: 1.1540 - val_acc: 0.6570

Epoch 00057: val_loss did not improve from 1.08371
Epoch 58/60
 - 5s - loss: 1.1011 - acc: 0.6630 - val_loss: 1.1606 - val_acc: 0.6578

Epoch 00058: val_loss did not improve from 1.08371
Epoch 59/60
 - 5s - loss: 1.0973 - acc: 0.6638 - val_loss: 1.1211 - val_acc: 0.6574

Epoch 00059: val_loss did not improve from 1.08371
Epoch 60/60
 - 5s - loss: 1.0931 - acc: 0.6637 - val_loss: 1.0876 - val_acc: 0.6559

Epoch 00060: val_loss did not improve from 1.08371
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 2.2372 - acc: 0.5553 - val_loss: 1.3331 - val_acc: 0.6414

Epoch 00001: val_loss improved from inf to 1.33309, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 2/60
 - 5s - loss: 1.3452 - acc: 0.6347 - val_loss: 1.1943 - val_acc: 0.6662

Epoch 00002: val_loss improved from 1.33309 to 1.19427, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 3/60
 - 5s - loss: 1.1981 - acc: 0.6545 - val_loss: 1.0841 - val_acc: 0.6930

Epoch 00003: val_loss improved from 1.19427 to 1.08407, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 4/60
 - 5s - loss: 1.1003 - acc: 0.6672 - val_loss: 0.9115 - val_acc: 0.7251

Epoch 00004: val_loss improved from 1.08407 to 0.91146, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 5/60
 - 5s - loss: 1.0239 - acc: 0.6851 - val_loss: 0.8077 - val_acc: 0.7315

Epoch 00005: val_loss improved from 0.91146 to 0.80770, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 6/60
 - 5s - loss: 0.9655 - acc: 0.6967 - val_loss: 0.7442 - val_acc: 0.7565

Epoch 00006: val_loss improved from 0.80770 to 0.74420, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 7/60
 - 5s - loss: 0.9176 - acc: 0.7100 - val_loss: 0.7192 - val_acc: 0.7527

Epoch 00007: val_loss improved from 0.74420 to 0.71922, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 8/60
 - 5s - loss: 0.8823 - acc: 0.7220 - val_loss: 0.6739 - val_acc: 0.7863

Epoch 00008: val_loss improved from 0.71922 to 0.67386, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 9/60
 - 5s - loss: 0.8523 - acc: 0.7304 - val_loss: 0.6729 - val_acc: 0.7941

Epoch 00009: val_loss improved from 0.67386 to 0.67289, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 10/60
 - 5s - loss: 0.8302 - acc: 0.7355 - val_loss: 0.6121 - val_acc: 0.8049

Epoch 00010: val_loss improved from 0.67289 to 0.61210, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 11/60
 - 5s - loss: 0.8081 - acc: 0.7438 - val_loss: 0.6223 - val_acc: 0.8119

Epoch 00011: val_loss did not improve from 0.61210
Epoch 12/60
 - 5s - loss: 0.7831 - acc: 0.7516 - val_loss: 0.5973 - val_acc: 0.8058

Epoch 00012: val_loss improved from 0.61210 to 0.59729, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 13/60
 - 5s - loss: 0.7739 - acc: 0.7541 - val_loss: 0.5793 - val_acc: 0.8099

Epoch 00013: val_loss improved from 0.59729 to 0.57929, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 14/60
 - 5s - loss: 0.7572 - acc: 0.7595 - val_loss: 0.5984 - val_acc: 0.8035

Epoch 00014: val_loss did not improve from 0.57929
Epoch 15/60
 - 5s - loss: 0.7462 - acc: 0.7621 - val_loss: 0.5506 - val_acc: 0.8213

Epoch 00015: val_loss improved from 0.57929 to 0.55058, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 16/60
 - 5s - loss: 0.7369 - acc: 0.7646 - val_loss: 0.5474 - val_acc: 0.8364

Epoch 00016: val_loss improved from 0.55058 to 0.54737, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 17/60
 - 5s - loss: 0.7232 - acc: 0.7702 - val_loss: 0.5601 - val_acc: 0.8241

Epoch 00017: val_loss did not improve from 0.54737
Epoch 18/60
 - 5s - loss: 0.7142 - acc: 0.7725 - val_loss: 0.5298 - val_acc: 0.8336

Epoch 00018: val_loss improved from 0.54737 to 0.52978, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 19/60
 - 5s - loss: 0.7023 - acc: 0.7766 - val_loss: 0.5116 - val_acc: 0.8395

Epoch 00019: val_loss improved from 0.52978 to 0.51163, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 20/60
 - 5s - loss: 0.6910 - acc: 0.7792 - val_loss: 0.5107 - val_acc: 0.8451

Epoch 00020: val_loss improved from 0.51163 to 0.51066, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 21/60
 - 5s - loss: 0.6845 - acc: 0.7821 - val_loss: 0.5249 - val_acc: 0.8467

Epoch 00021: val_loss did not improve from 0.51066
Epoch 22/60
 - 5s - loss: 0.6842 - acc: 0.7802 - val_loss: 0.5240 - val_acc: 0.8430

Epoch 00022: val_loss did not improve from 0.51066
Epoch 23/60
 - 5s - loss: 0.6811 - acc: 0.7817 - val_loss: 0.5093 - val_acc: 0.8482

Epoch 00023: val_loss improved from 0.51066 to 0.50926, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 24/60
 - 5s - loss: 0.6756 - acc: 0.7838 - val_loss: 0.5110 - val_acc: 0.8404

Epoch 00024: val_loss did not improve from 0.50926
Epoch 25/60
 - 5s - loss: 0.6733 - acc: 0.7848 - val_loss: 0.5035 - val_acc: 0.8392

Epoch 00025: val_loss improved from 0.50926 to 0.50347, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 26/60
 - 5s - loss: 0.6642 - acc: 0.7879 - val_loss: 0.5080 - val_acc: 0.8369

Epoch 00026: val_loss did not improve from 0.50347
Epoch 27/60
 - 5s - loss: 0.6618 - acc: 0.7897 - val_loss: 0.4893 - val_acc: 0.8516

Epoch 00027: val_loss improved from 0.50347 to 0.48929, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 28/60
 - 5s - loss: 0.6547 - acc: 0.7921 - val_loss: 0.4920 - val_acc: 0.8383

Epoch 00028: val_loss did not improve from 0.48929
Epoch 29/60
 - 5s - loss: 0.6498 - acc: 0.7927 - val_loss: 0.4925 - val_acc: 0.8498

Epoch 00029: val_loss did not improve from 0.48929
Epoch 30/60
 - 5s - loss: 0.6444 - acc: 0.7949 - val_loss: 0.4812 - val_acc: 0.8519

Epoch 00030: val_loss improved from 0.48929 to 0.48120, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 31/60
 - 5s - loss: 0.6433 - acc: 0.7939 - val_loss: 0.4744 - val_acc: 0.8535

Epoch 00031: val_loss improved from 0.48120 to 0.47444, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 32/60
 - 5s - loss: 0.6384 - acc: 0.7949 - val_loss: 0.4704 - val_acc: 0.8488

Epoch 00032: val_loss improved from 0.47444 to 0.47041, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 33/60
 - 5s - loss: 0.6386 - acc: 0.7959 - val_loss: 0.4667 - val_acc: 0.8550

Epoch 00033: val_loss improved from 0.47041 to 0.46671, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 34/60
 - 5s - loss: 0.6376 - acc: 0.7955 - val_loss: 0.4808 - val_acc: 0.8373

Epoch 00034: val_loss did not improve from 0.46671
Epoch 35/60
 - 5s - loss: 0.6293 - acc: 0.7983 - val_loss: 0.4757 - val_acc: 0.8469

Epoch 00035: val_loss did not improve from 0.46671
Epoch 36/60
 - 5s - loss: 0.6274 - acc: 0.8010 - val_loss: 0.4720 - val_acc: 0.8566

Epoch 00036: val_loss did not improve from 0.46671
Epoch 37/60
 - 5s - loss: 0.6281 - acc: 0.7984 - val_loss: 0.4829 - val_acc: 0.8508

Epoch 00037: val_loss did not improve from 0.46671
Epoch 38/60
 - 5s - loss: 0.6241 - acc: 0.7983 - val_loss: 0.4650 - val_acc: 0.8555

Epoch 00038: val_loss improved from 0.46671 to 0.46500, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 39/60
 - 5s - loss: 0.6260 - acc: 0.7994 - val_loss: 0.4640 - val_acc: 0.8554

Epoch 00039: val_loss improved from 0.46500 to 0.46404, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 40/60
 - 5s - loss: 0.6233 - acc: 0.8010 - val_loss: 0.4541 - val_acc: 0.8629

Epoch 00040: val_loss improved from 0.46404 to 0.45406, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 41/60
 - 5s - loss: 0.6200 - acc: 0.8039 - val_loss: 0.4553 - val_acc: 0.8579

Epoch 00041: val_loss did not improve from 0.45406
Epoch 42/60
 - 5s - loss: 0.6170 - acc: 0.8011 - val_loss: 0.4618 - val_acc: 0.8541

Epoch 00042: val_loss did not improve from 0.45406
Epoch 43/60
 - 5s - loss: 0.6172 - acc: 0.8029 - val_loss: 0.4542 - val_acc: 0.8578

Epoch 00043: val_loss did not improve from 0.45406
Epoch 44/60
 - 5s - loss: 0.6151 - acc: 0.8021 - val_loss: 0.4723 - val_acc: 0.8614

Epoch 00044: val_loss did not improve from 0.45406
Epoch 45/60
 - 5s - loss: 0.6059 - acc: 0.8050 - val_loss: 0.4783 - val_acc: 0.8500

Epoch 00045: val_loss did not improve from 0.45406
Epoch 46/60
 - 5s - loss: 0.6107 - acc: 0.8042 - val_loss: 0.4651 - val_acc: 0.8628

Epoch 00046: val_loss did not improve from 0.45406
Epoch 47/60
 - 5s - loss: 0.6040 - acc: 0.8049 - val_loss: 0.4472 - val_acc: 0.8661

Epoch 00047: val_loss improved from 0.45406 to 0.44724, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 48/60
 - 5s - loss: 0.6046 - acc: 0.8069 - val_loss: 0.4410 - val_acc: 0.8558

Epoch 00048: val_loss improved from 0.44724 to 0.44103, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 49/60
 - 5s - loss: 0.6065 - acc: 0.8049 - val_loss: 0.4578 - val_acc: 0.8611

Epoch 00049: val_loss did not improve from 0.44103
Epoch 50/60
 - 5s - loss: 0.5997 - acc: 0.8074 - val_loss: 0.4570 - val_acc: 0.8563

Epoch 00050: val_loss did not improve from 0.44103
Epoch 51/60
 - 5s - loss: 0.6090 - acc: 0.8051 - val_loss: 0.4495 - val_acc: 0.8591

Epoch 00051: val_loss did not improve from 0.44103
Epoch 52/60
 - 5s - loss: 0.5918 - acc: 0.8093 - val_loss: 0.4389 - val_acc: 0.8641

Epoch 00052: val_loss improved from 0.44103 to 0.43894, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 53/60
 - 5s - loss: 0.5995 - acc: 0.8074 - val_loss: 0.4519 - val_acc: 0.8558

Epoch 00053: val_loss did not improve from 0.43894
Epoch 54/60
 - 5s - loss: 0.5931 - acc: 0.8087 - val_loss: 0.4415 - val_acc: 0.8663

Epoch 00054: val_loss did not improve from 0.43894
Epoch 55/60
 - 5s - loss: 0.5978 - acc: 0.8054 - val_loss: 0.4554 - val_acc: 0.8548

Epoch 00055: val_loss did not improve from 0.43894
Epoch 56/60
 - 5s - loss: 0.5968 - acc: 0.8082 - val_loss: 0.4425 - val_acc: 0.8632

Epoch 00056: val_loss did not improve from 0.43894
Epoch 57/60
 - 5s - loss: 0.5907 - acc: 0.8103 - val_loss: 0.4396 - val_acc: 0.8639

Epoch 00057: val_loss did not improve from 0.43894
Epoch 58/60
 - 5s - loss: 0.5952 - acc: 0.8095 - val_loss: 0.4424 - val_acc: 0.8619

Epoch 00058: val_loss did not improve from 0.43894
Epoch 59/60
 - 5s - loss: 0.5861 - acc: 0.8121 - val_loss: 0.4459 - val_acc: 0.8575

Epoch 00059: val_loss did not improve from 0.43894
Epoch 60/60
 - 5s - loss: 0.5927 - acc: 0.8100 - val_loss: 0.4407 - val_acc: 0.8576

Epoch 00060: val_loss did not improve from 0.43894
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 5.0538 - acc: 0.3097 - val_loss: 2.2075 - val_acc: 0.6208

Epoch 00001: val_loss improved from inf to 2.20747, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 2/60
 - 4s - loss: 2.0034 - acc: 0.5221 - val_loss: 2.1230 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.20747 to 2.12299, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 3/60
 - 4s - loss: 1.7674 - acc: 0.6249 - val_loss: 1.9749 - val_acc: 0.6209

Epoch 00003: val_loss improved from 2.12299 to 1.97495, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 4/60
 - 4s - loss: 1.6633 - acc: 0.6365 - val_loss: 1.8234 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.97495 to 1.82344, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 5/60
 - 4s - loss: 1.5978 - acc: 0.6371 - val_loss: 1.7031 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.82344 to 1.70308, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 6/60
 - 4s - loss: 1.5561 - acc: 0.6371 - val_loss: 1.6366 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.70308 to 1.63664, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 7/60
 - 4s - loss: 1.5305 - acc: 0.6371 - val_loss: 1.5734 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.63664 to 1.57343, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 8/60
 - 4s - loss: 1.5148 - acc: 0.6371 - val_loss: 1.5602 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.57343 to 1.56018, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 9/60
 - 4s - loss: 1.5014 - acc: 0.6371 - val_loss: 1.5536 - val_acc: 0.6209

Epoch 00009: val_loss improved from 1.56018 to 1.55358, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 10/60
 - 4s - loss: 1.4876 - acc: 0.6371 - val_loss: 1.5426 - val_acc: 0.6209

Epoch 00010: val_loss improved from 1.55358 to 1.54261, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 11/60
 - 4s - loss: 1.4772 - acc: 0.6371 - val_loss: 1.5200 - val_acc: 0.6209

Epoch 00011: val_loss improved from 1.54261 to 1.52004, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 12/60
 - 4s - loss: 1.4660 - acc: 0.6371 - val_loss: 1.4925 - val_acc: 0.6209

Epoch 00012: val_loss improved from 1.52004 to 1.49250, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 13/60
 - 4s - loss: 1.4549 - acc: 0.6371 - val_loss: 1.4955 - val_acc: 0.6209

Epoch 00013: val_loss did not improve from 1.49250
Epoch 14/60
 - 4s - loss: 1.4404 - acc: 0.6371 - val_loss: 1.4885 - val_acc: 0.6209

Epoch 00014: val_loss improved from 1.49250 to 1.48845, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 15/60
 - 4s - loss: 1.4305 - acc: 0.6371 - val_loss: 1.4843 - val_acc: 0.6209

Epoch 00015: val_loss improved from 1.48845 to 1.48429, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 16/60
 - 4s - loss: 1.4206 - acc: 0.6370 - val_loss: 1.4885 - val_acc: 0.6209

Epoch 00016: val_loss did not improve from 1.48429
Epoch 17/60
 - 4s - loss: 1.4126 - acc: 0.6371 - val_loss: 1.4680 - val_acc: 0.6209

Epoch 00017: val_loss improved from 1.48429 to 1.46802, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 18/60
 - 4s - loss: 1.4002 - acc: 0.6371 - val_loss: 1.4769 - val_acc: 0.6209

Epoch 00018: val_loss did not improve from 1.46802
Epoch 19/60
 - 4s - loss: 1.3914 - acc: 0.6371 - val_loss: 1.4554 - val_acc: 0.6209

Epoch 00019: val_loss improved from 1.46802 to 1.45535, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 20/60
 - 4s - loss: 1.3824 - acc: 0.6371 - val_loss: 1.4187 - val_acc: 0.6209

Epoch 00020: val_loss improved from 1.45535 to 1.41869, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 21/60
 - 4s - loss: 1.3732 - acc: 0.6371 - val_loss: 1.4065 - val_acc: 0.6209

Epoch 00021: val_loss improved from 1.41869 to 1.40654, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 22/60
 - 4s - loss: 1.3704 - acc: 0.6371 - val_loss: 1.4496 - val_acc: 0.6209

Epoch 00022: val_loss did not improve from 1.40654
Epoch 23/60
 - 4s - loss: 1.3603 - acc: 0.6371 - val_loss: 1.3978 - val_acc: 0.6209

Epoch 00023: val_loss improved from 1.40654 to 1.39778, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 24/60
 - 4s - loss: 1.3559 - acc: 0.6371 - val_loss: 1.4079 - val_acc: 0.6209

Epoch 00024: val_loss did not improve from 1.39778
Epoch 25/60
 - 4s - loss: 1.3540 - acc: 0.6371 - val_loss: 1.4054 - val_acc: 0.6209

Epoch 00025: val_loss did not improve from 1.39778
Epoch 26/60
 - 4s - loss: 1.3478 - acc: 0.6371 - val_loss: 1.4078 - val_acc: 0.6209

Epoch 00026: val_loss did not improve from 1.39778
Epoch 27/60
 - 4s - loss: 1.3439 - acc: 0.6371 - val_loss: 1.4168 - val_acc: 0.6209

Epoch 00027: val_loss did not improve from 1.39778
Epoch 28/60
 - 4s - loss: 1.3440 - acc: 0.6371 - val_loss: 1.4276 - val_acc: 0.6209

Epoch 00028: val_loss did not improve from 1.39778
Epoch 29/60
 - 4s - loss: 1.3397 - acc: 0.6371 - val_loss: 1.4044 - val_acc: 0.6209

Epoch 00029: val_loss did not improve from 1.39778
Epoch 30/60
 - 4s - loss: 1.3366 - acc: 0.6371 - val_loss: 1.3960 - val_acc: 0.6209

Epoch 00030: val_loss improved from 1.39778 to 1.39605, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 31/60
 - 4s - loss: 1.3308 - acc: 0.6371 - val_loss: 1.4030 - val_acc: 0.6209

Epoch 00031: val_loss did not improve from 1.39605
Epoch 32/60
 - 4s - loss: 1.3295 - acc: 0.6371 - val_loss: 1.3658 - val_acc: 0.6209

Epoch 00032: val_loss improved from 1.39605 to 1.36584, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 33/60
 - 4s - loss: 1.3284 - acc: 0.6371 - val_loss: 1.4059 - val_acc: 0.6209

Epoch 00033: val_loss did not improve from 1.36584
Epoch 34/60
 - 4s - loss: 1.3279 - acc: 0.6370 - val_loss: 1.3932 - val_acc: 0.6209

Epoch 00034: val_loss did not improve from 1.36584
Epoch 35/60
 - 4s - loss: 1.3232 - acc: 0.6371 - val_loss: 1.3991 - val_acc: 0.6209

Epoch 00035: val_loss did not improve from 1.36584
Epoch 36/60
 - 4s - loss: 1.3218 - acc: 0.6369 - val_loss: 1.3699 - val_acc: 0.6209

Epoch 00036: val_loss did not improve from 1.36584
Epoch 37/60
 - 4s - loss: 1.3243 - acc: 0.6370 - val_loss: 1.3795 - val_acc: 0.6209

Epoch 00037: val_loss did not improve from 1.36584
Epoch 38/60
 - 4s - loss: 1.3218 - acc: 0.6371 - val_loss: 1.3837 - val_acc: 0.6209

Epoch 00038: val_loss did not improve from 1.36584
Epoch 39/60
 - 4s - loss: 1.3189 - acc: 0.6371 - val_loss: 1.3819 - val_acc: 0.6209

Epoch 00039: val_loss did not improve from 1.36584
Epoch 40/60
 - 4s - loss: 1.3188 - acc: 0.6371 - val_loss: 1.4033 - val_acc: 0.6209

Epoch 00040: val_loss did not improve from 1.36584
Epoch 41/60
 - 4s - loss: 1.3174 - acc: 0.6371 - val_loss: 1.3748 - val_acc: 0.6209

Epoch 00041: val_loss did not improve from 1.36584
Epoch 42/60
 - 4s - loss: 1.3164 - acc: 0.6370 - val_loss: 1.3433 - val_acc: 0.6209

Epoch 00042: val_loss improved from 1.36584 to 1.34328, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 43/60
 - 5s - loss: 1.3164 - acc: 0.6369 - val_loss: 1.3741 - val_acc: 0.6209

Epoch 00043: val_loss did not improve from 1.34328
Epoch 44/60
 - 4s - loss: 1.3123 - acc: 0.6370 - val_loss: 1.3733 - val_acc: 0.6209

Epoch 00044: val_loss did not improve from 1.34328
Epoch 45/60
 - 4s - loss: 1.3158 - acc: 0.6371 - val_loss: 1.4293 - val_acc: 0.6209

Epoch 00045: val_loss did not improve from 1.34328
Epoch 46/60
 - 4s - loss: 1.3087 - acc: 0.6369 - val_loss: 1.3932 - val_acc: 0.6209

Epoch 00046: val_loss did not improve from 1.34328
Epoch 47/60
 - 4s - loss: 1.3117 - acc: 0.6370 - val_loss: 1.3511 - val_acc: 0.6209

Epoch 00047: val_loss did not improve from 1.34328
Epoch 48/60
 - 4s - loss: 1.3096 - acc: 0.6370 - val_loss: 1.3622 - val_acc: 0.6209

Epoch 00048: val_loss did not improve from 1.34328
Epoch 49/60
 - 4s - loss: 1.3064 - acc: 0.6370 - val_loss: 1.3699 - val_acc: 0.6209

Epoch 00049: val_loss did not improve from 1.34328
Epoch 50/60
 - 4s - loss: 1.3085 - acc: 0.6370 - val_loss: 1.3399 - val_acc: 0.6209

Epoch 00050: val_loss improved from 1.34328 to 1.33990, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 51/60
 - 4s - loss: 1.3073 - acc: 0.6370 - val_loss: 1.3656 - val_acc: 0.6209

Epoch 00051: val_loss did not improve from 1.33990
Epoch 52/60
 - 4s - loss: 1.3047 - acc: 0.6371 - val_loss: 1.3457 - val_acc: 0.6209

Epoch 00052: val_loss did not improve from 1.33990
Epoch 53/60
 - 4s - loss: 1.3041 - acc: 0.6370 - val_loss: 1.3698 - val_acc: 0.6209

Epoch 00053: val_loss did not improve from 1.33990
Epoch 54/60
 - 4s - loss: 1.3046 - acc: 0.6370 - val_loss: 1.3740 - val_acc: 0.6209

Epoch 00054: val_loss did not improve from 1.33990
Epoch 55/60
 - 4s - loss: 1.3033 - acc: 0.6370 - val_loss: 1.3271 - val_acc: 0.6209

Epoch 00055: val_loss improved from 1.33990 to 1.32707, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 56/60
 - 4s - loss: 1.3003 - acc: 0.6371 - val_loss: 1.3716 - val_acc: 0.6209

Epoch 00056: val_loss did not improve from 1.32707
Epoch 57/60
 - 4s - loss: 1.3002 - acc: 0.6371 - val_loss: 1.3153 - val_acc: 0.6209

Epoch 00057: val_loss improved from 1.32707 to 1.31530, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 58/60
 - 4s - loss: 1.3023 - acc: 0.6370 - val_loss: 1.3265 - val_acc: 0.6209

Epoch 00058: val_loss did not improve from 1.31530
Epoch 59/60
 - 4s - loss: 1.3021 - acc: 0.6371 - val_loss: 1.3617 - val_acc: 0.6209

Epoch 00059: val_loss did not improve from 1.31530
Epoch 60/60
 - 4s - loss: 1.2985 - acc: 0.6371 - val_loss: 1.3797 - val_acc: 0.6209

Epoch 00060: val_loss did not improve from 1.31530
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 4.5606 - acc: 0.5112 - val_loss: 2.2279 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 2.22786, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 2/60
 - 5s - loss: 1.7695 - acc: 0.6130 - val_loss: 2.1119 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.22786 to 2.11185, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 3/60
 - 5s - loss: 1.6023 - acc: 0.6367 - val_loss: 1.8851 - val_acc: 0.6209

Epoch 00003: val_loss improved from 2.11185 to 1.88509, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 4/60
 - 5s - loss: 1.5399 - acc: 0.6371 - val_loss: 1.8041 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.88509 to 1.80408, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 5/60
 - 6s - loss: 1.5052 - acc: 0.6371 - val_loss: 1.7103 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.80408 to 1.71027, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 6/60
 - 5s - loss: 1.4761 - acc: 0.6371 - val_loss: 1.6755 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.71027 to 1.67553, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 7/60
 - 5s - loss: 1.4544 - acc: 0.6371 - val_loss: 1.5801 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.67553 to 1.58014, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 8/60
 - 5s - loss: 1.4328 - acc: 0.6371 - val_loss: 1.4993 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.58014 to 1.49934, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 9/60
 - 5s - loss: 1.4099 - acc: 0.6371 - val_loss: 1.4929 - val_acc: 0.6209

Epoch 00009: val_loss improved from 1.49934 to 1.49289, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 10/60
 - 5s - loss: 1.3892 - acc: 0.6371 - val_loss: 1.4454 - val_acc: 0.6209

Epoch 00010: val_loss improved from 1.49289 to 1.44539, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 11/60
 - 5s - loss: 1.3747 - acc: 0.6368 - val_loss: 1.4405 - val_acc: 0.6209

Epoch 00011: val_loss improved from 1.44539 to 1.44049, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 12/60
 - 5s - loss: 1.3522 - acc: 0.6365 - val_loss: 1.4661 - val_acc: 0.6209

Epoch 00012: val_loss did not improve from 1.44049
Epoch 13/60
 - 5s - loss: 1.3290 - acc: 0.6376 - val_loss: 1.4292 - val_acc: 0.6212

Epoch 00013: val_loss improved from 1.44049 to 1.42922, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 14/60
 - 5s - loss: 1.3107 - acc: 0.6384 - val_loss: 1.3697 - val_acc: 0.6214

Epoch 00014: val_loss improved from 1.42922 to 1.36970, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 15/60
 - 5s - loss: 1.2897 - acc: 0.6395 - val_loss: 1.4241 - val_acc: 0.6222

Epoch 00015: val_loss did not improve from 1.36970
Epoch 16/60
 - 5s - loss: 1.2763 - acc: 0.6407 - val_loss: 1.3333 - val_acc: 0.6219

Epoch 00016: val_loss improved from 1.36970 to 1.33330, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 17/60
 - 5s - loss: 1.2611 - acc: 0.6421 - val_loss: 1.3091 - val_acc: 0.6236

Epoch 00017: val_loss improved from 1.33330 to 1.30909, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 18/60
 - 5s - loss: 1.2527 - acc: 0.6423 - val_loss: 1.3770 - val_acc: 0.6222

Epoch 00018: val_loss did not improve from 1.30909
Epoch 19/60
 - 5s - loss: 1.2394 - acc: 0.6434 - val_loss: 1.3613 - val_acc: 0.6239

Epoch 00019: val_loss did not improve from 1.30909
Epoch 20/60
 - 5s - loss: 1.2325 - acc: 0.6440 - val_loss: 1.3367 - val_acc: 0.6222

Epoch 00020: val_loss did not improve from 1.30909
Epoch 21/60
 - 5s - loss: 1.2218 - acc: 0.6447 - val_loss: 1.3124 - val_acc: 0.6227

Epoch 00021: val_loss did not improve from 1.30909
Epoch 22/60
 - 5s - loss: 1.2147 - acc: 0.6452 - val_loss: 1.2648 - val_acc: 0.6214

Epoch 00022: val_loss improved from 1.30909 to 1.26482, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 23/60
 - 5s - loss: 1.2100 - acc: 0.6466 - val_loss: 1.3112 - val_acc: 0.6212

Epoch 00023: val_loss did not improve from 1.26482
Epoch 24/60
 - 5s - loss: 1.1938 - acc: 0.6482 - val_loss: 1.2119 - val_acc: 0.6293

Epoch 00024: val_loss improved from 1.26482 to 1.21189, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 25/60
 - 5s - loss: 1.1919 - acc: 0.6488 - val_loss: 1.2252 - val_acc: 0.6289

Epoch 00025: val_loss did not improve from 1.21189
Epoch 26/60
 - 5s - loss: 1.1872 - acc: 0.6510 - val_loss: 1.2337 - val_acc: 0.6359

Epoch 00026: val_loss did not improve from 1.21189
Epoch 27/60
 - 5s - loss: 1.1775 - acc: 0.6509 - val_loss: 1.2214 - val_acc: 0.6342

Epoch 00027: val_loss did not improve from 1.21189
Epoch 28/60
 - 5s - loss: 1.1689 - acc: 0.6517 - val_loss: 1.1821 - val_acc: 0.6347

Epoch 00028: val_loss improved from 1.21189 to 1.18215, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 29/60
 - 5s - loss: 1.1675 - acc: 0.6522 - val_loss: 1.2402 - val_acc: 0.6430

Epoch 00029: val_loss did not improve from 1.18215
Epoch 30/60
 - 5s - loss: 1.1632 - acc: 0.6521 - val_loss: 1.2006 - val_acc: 0.6330

Epoch 00030: val_loss did not improve from 1.18215
Epoch 31/60
 - 5s - loss: 1.1549 - acc: 0.6552 - val_loss: 1.2117 - val_acc: 0.6389

Epoch 00031: val_loss did not improve from 1.18215
Epoch 32/60
 - 5s - loss: 1.1532 - acc: 0.6564 - val_loss: 1.1889 - val_acc: 0.6496

Epoch 00032: val_loss did not improve from 1.18215
Epoch 33/60
 - 5s - loss: 1.1434 - acc: 0.6557 - val_loss: 1.1765 - val_acc: 0.6403

Epoch 00033: val_loss improved from 1.18215 to 1.17653, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 34/60
 - 5s - loss: 1.1432 - acc: 0.6573 - val_loss: 1.1607 - val_acc: 0.6470

Epoch 00034: val_loss improved from 1.17653 to 1.16072, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 35/60
 - 5s - loss: 1.1370 - acc: 0.6564 - val_loss: 1.1514 - val_acc: 0.6497

Epoch 00035: val_loss improved from 1.16072 to 1.15141, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 36/60
 - 5s - loss: 1.1369 - acc: 0.6569 - val_loss: 1.1709 - val_acc: 0.6425

Epoch 00036: val_loss did not improve from 1.15141
Epoch 37/60
 - 5s - loss: 1.1327 - acc: 0.6582 - val_loss: 1.1299 - val_acc: 0.6417

Epoch 00037: val_loss improved from 1.15141 to 1.12991, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 38/60
 - 5s - loss: 1.1282 - acc: 0.6603 - val_loss: 1.1232 - val_acc: 0.6523

Epoch 00038: val_loss improved from 1.12991 to 1.12317, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 39/60
 - 5s - loss: 1.1254 - acc: 0.6588 - val_loss: 1.0968 - val_acc: 0.6574

Epoch 00039: val_loss improved from 1.12317 to 1.09684, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 40/60
 - 5s - loss: 1.1221 - acc: 0.6596 - val_loss: 1.0950 - val_acc: 0.6500

Epoch 00040: val_loss improved from 1.09684 to 1.09502, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 41/60
 - 5s - loss: 1.1197 - acc: 0.6604 - val_loss: 1.0930 - val_acc: 0.6574

Epoch 00041: val_loss improved from 1.09502 to 1.09303, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 42/60
 - 5s - loss: 1.1115 - acc: 0.6612 - val_loss: 1.0971 - val_acc: 0.6499

Epoch 00042: val_loss did not improve from 1.09303
Epoch 43/60
 - 5s - loss: 1.1092 - acc: 0.6610 - val_loss: 1.0815 - val_acc: 0.6587

Epoch 00043: val_loss improved from 1.09303 to 1.08154, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 44/60
 - 5s - loss: 1.1062 - acc: 0.6623 - val_loss: 1.0984 - val_acc: 0.6580

Epoch 00044: val_loss did not improve from 1.08154
Epoch 45/60
 - 5s - loss: 1.1050 - acc: 0.6627 - val_loss: 1.0530 - val_acc: 0.6552

Epoch 00045: val_loss improved from 1.08154 to 1.05299, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 46/60
 - 5s - loss: 1.0995 - acc: 0.6642 - val_loss: 1.0637 - val_acc: 0.6623

Epoch 00046: val_loss did not improve from 1.05299
Epoch 47/60
 - 5s - loss: 1.1018 - acc: 0.6612 - val_loss: 1.0703 - val_acc: 0.6668

Epoch 00047: val_loss did not improve from 1.05299
Epoch 48/60
 - 5s - loss: 1.0923 - acc: 0.6653 - val_loss: 1.0878 - val_acc: 0.6670

Epoch 00048: val_loss did not improve from 1.05299
Epoch 49/60
 - 5s - loss: 1.0946 - acc: 0.6649 - val_loss: 1.0384 - val_acc: 0.6703

Epoch 00049: val_loss improved from 1.05299 to 1.03842, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 50/60
 - 5s - loss: 1.0909 - acc: 0.6647 - val_loss: 1.0288 - val_acc: 0.6581

Epoch 00050: val_loss improved from 1.03842 to 1.02881, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 51/60
 - 5s - loss: 1.0860 - acc: 0.6647 - val_loss: 0.9963 - val_acc: 0.6714

Epoch 00051: val_loss improved from 1.02881 to 0.99629, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 52/60
 - 5s - loss: 1.0846 - acc: 0.6667 - val_loss: 1.0421 - val_acc: 0.6642

Epoch 00052: val_loss did not improve from 0.99629
Epoch 53/60
 - 5s - loss: 1.0832 - acc: 0.6665 - val_loss: 1.0222 - val_acc: 0.6684

Epoch 00053: val_loss did not improve from 0.99629
Epoch 54/60
 - 5s - loss: 1.0821 - acc: 0.6664 - val_loss: 0.9962 - val_acc: 0.6705

Epoch 00054: val_loss improved from 0.99629 to 0.99622, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 55/60
 - 5s - loss: 1.0751 - acc: 0.6682 - val_loss: 1.0122 - val_acc: 0.6776

Epoch 00055: val_loss did not improve from 0.99622
Epoch 56/60
 - 5s - loss: 1.0730 - acc: 0.6683 - val_loss: 1.0337 - val_acc: 0.6736

Epoch 00056: val_loss did not improve from 0.99622
Epoch 57/60
 - 5s - loss: 1.0682 - acc: 0.6695 - val_loss: 0.9808 - val_acc: 0.6765

Epoch 00057: val_loss improved from 0.99622 to 0.98081, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Epoch 58/60
 - 5s - loss: 1.0677 - acc: 0.6692 - val_loss: 1.0227 - val_acc: 0.6731

Epoch 00058: val_loss did not improve from 0.98081
Epoch 59/60
 - 6s - loss: 1.0681 - acc: 0.6705 - val_loss: 1.0233 - val_acc: 0.6687

Epoch 00059: val_loss did not improve from 0.98081
Epoch 60/60
 - 6s - loss: 1.0699 - acc: 0.6674 - val_loss: 0.9807 - val_acc: 0.6680

Epoch 00060: val_loss improved from 0.98081 to 0.98075, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 2.5308 - acc: 0.5553 - val_loss: 1.2946 - val_acc: 0.6290

Epoch 00001: val_loss improved from inf to 1.29464, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 2/60
 - 5s - loss: 1.3653 - acc: 0.6326 - val_loss: 1.2700 - val_acc: 0.6573

Epoch 00002: val_loss improved from 1.29464 to 1.26996, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 3/60
 - 5s - loss: 1.2143 - acc: 0.6504 - val_loss: 1.0171 - val_acc: 0.6827

Epoch 00003: val_loss improved from 1.26996 to 1.01713, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 4/60
 - 5s - loss: 1.1148 - acc: 0.6664 - val_loss: 0.9074 - val_acc: 0.6943

Epoch 00004: val_loss improved from 1.01713 to 0.90738, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 5/60
 - 5s - loss: 1.0310 - acc: 0.6807 - val_loss: 0.8086 - val_acc: 0.7321

Epoch 00005: val_loss improved from 0.90738 to 0.80859, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 6/60
 - 5s - loss: 0.9669 - acc: 0.6985 - val_loss: 0.7309 - val_acc: 0.7549

Epoch 00006: val_loss improved from 0.80859 to 0.73093, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 7/60
 - 5s - loss: 0.9177 - acc: 0.7109 - val_loss: 0.7038 - val_acc: 0.7579

Epoch 00007: val_loss improved from 0.73093 to 0.70380, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 8/60
 - 5s - loss: 0.8745 - acc: 0.7227 - val_loss: 0.6562 - val_acc: 0.7980

Epoch 00008: val_loss improved from 0.70380 to 0.65619, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 9/60
 - 5s - loss: 0.8481 - acc: 0.7318 - val_loss: 0.6890 - val_acc: 0.8049

Epoch 00009: val_loss did not improve from 0.65619
Epoch 10/60
 - 5s - loss: 0.8177 - acc: 0.7410 - val_loss: 0.6134 - val_acc: 0.8092

Epoch 00010: val_loss improved from 0.65619 to 0.61344, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 11/60
 - 5s - loss: 0.8021 - acc: 0.7449 - val_loss: 0.6097 - val_acc: 0.8152

Epoch 00011: val_loss improved from 0.61344 to 0.60966, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 12/60
 - 5s - loss: 0.7818 - acc: 0.7488 - val_loss: 0.5853 - val_acc: 0.8069

Epoch 00012: val_loss improved from 0.60966 to 0.58531, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 13/60
 - 5s - loss: 0.7671 - acc: 0.7550 - val_loss: 0.5786 - val_acc: 0.8154

Epoch 00013: val_loss improved from 0.58531 to 0.57864, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 14/60
 - 5s - loss: 0.7522 - acc: 0.7610 - val_loss: 0.5965 - val_acc: 0.8213

Epoch 00014: val_loss did not improve from 0.57864
Epoch 15/60
 - 5s - loss: 0.7368 - acc: 0.7663 - val_loss: 0.5711 - val_acc: 0.8336

Epoch 00015: val_loss improved from 0.57864 to 0.57107, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 16/60
 - 5s - loss: 0.7237 - acc: 0.7695 - val_loss: 0.5328 - val_acc: 0.8332

Epoch 00016: val_loss improved from 0.57107 to 0.53280, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 17/60
 - 5s - loss: 0.7231 - acc: 0.7709 - val_loss: 0.5472 - val_acc: 0.8241

Epoch 00017: val_loss did not improve from 0.53280
Epoch 18/60
 - 5s - loss: 0.7141 - acc: 0.7733 - val_loss: 0.5131 - val_acc: 0.8401

Epoch 00018: val_loss improved from 0.53280 to 0.51311, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 19/60
 - 5s - loss: 0.7039 - acc: 0.7745 - val_loss: 0.5453 - val_acc: 0.8376

Epoch 00019: val_loss did not improve from 0.51311
Epoch 20/60
 - 5s - loss: 0.6933 - acc: 0.7778 - val_loss: 0.5093 - val_acc: 0.8467

Epoch 00020: val_loss improved from 0.51311 to 0.50928, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 21/60
 - 5s - loss: 0.6916 - acc: 0.7788 - val_loss: 0.5062 - val_acc: 0.8457

Epoch 00021: val_loss improved from 0.50928 to 0.50621, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 22/60
 - 5s - loss: 0.6769 - acc: 0.7851 - val_loss: 0.5052 - val_acc: 0.8341

Epoch 00022: val_loss improved from 0.50621 to 0.50521, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 23/60
 - 5s - loss: 0.6735 - acc: 0.7851 - val_loss: 0.4929 - val_acc: 0.8501

Epoch 00023: val_loss improved from 0.50521 to 0.49288, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 24/60
 - 5s - loss: 0.6659 - acc: 0.7854 - val_loss: 0.5141 - val_acc: 0.8330

Epoch 00024: val_loss did not improve from 0.49288
Epoch 25/60
 - 5s - loss: 0.6630 - acc: 0.7896 - val_loss: 0.4803 - val_acc: 0.8494

Epoch 00025: val_loss improved from 0.49288 to 0.48027, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 26/60
 - 5s - loss: 0.6600 - acc: 0.7890 - val_loss: 0.4776 - val_acc: 0.8564

Epoch 00026: val_loss improved from 0.48027 to 0.47756, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 27/60
 - 5s - loss: 0.6558 - acc: 0.7903 - val_loss: 0.5018 - val_acc: 0.8557

Epoch 00027: val_loss did not improve from 0.47756
Epoch 28/60
 - 5s - loss: 0.6575 - acc: 0.7902 - val_loss: 0.4840 - val_acc: 0.8503

Epoch 00028: val_loss did not improve from 0.47756
Epoch 29/60
 - 5s - loss: 0.6504 - acc: 0.7917 - val_loss: 0.4803 - val_acc: 0.8498

Epoch 00029: val_loss did not improve from 0.47756
Epoch 30/60
 - 5s - loss: 0.6476 - acc: 0.7946 - val_loss: 0.4637 - val_acc: 0.8550

Epoch 00030: val_loss improved from 0.47756 to 0.46375, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 31/60
 - 5s - loss: 0.6398 - acc: 0.7946 - val_loss: 0.4729 - val_acc: 0.8495

Epoch 00031: val_loss did not improve from 0.46375
Epoch 32/60
 - 5s - loss: 0.6404 - acc: 0.7973 - val_loss: 0.4835 - val_acc: 0.8429

Epoch 00032: val_loss did not improve from 0.46375
Epoch 33/60
 - 5s - loss: 0.6363 - acc: 0.7993 - val_loss: 0.4735 - val_acc: 0.8451

Epoch 00033: val_loss did not improve from 0.46375
Epoch 34/60
 - 5s - loss: 0.6330 - acc: 0.7980 - val_loss: 0.4538 - val_acc: 0.8588

Epoch 00034: val_loss improved from 0.46375 to 0.45376, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 35/60
 - 5s - loss: 0.6254 - acc: 0.7993 - val_loss: 0.4651 - val_acc: 0.8641

Epoch 00035: val_loss did not improve from 0.45376
Epoch 36/60
 - 5s - loss: 0.6326 - acc: 0.7963 - val_loss: 0.4607 - val_acc: 0.8536

Epoch 00036: val_loss did not improve from 0.45376
Epoch 37/60
 - 5s - loss: 0.6284 - acc: 0.7988 - val_loss: 0.4684 - val_acc: 0.8519

Epoch 00037: val_loss did not improve from 0.45376
Epoch 38/60
 - 5s - loss: 0.6188 - acc: 0.8033 - val_loss: 0.4730 - val_acc: 0.8511

Epoch 00038: val_loss did not improve from 0.45376
Epoch 39/60
 - 5s - loss: 0.6220 - acc: 0.7986 - val_loss: 0.4613 - val_acc: 0.8557

Epoch 00039: val_loss did not improve from 0.45376
Epoch 40/60
 - 5s - loss: 0.6238 - acc: 0.8006 - val_loss: 0.4535 - val_acc: 0.8575

Epoch 00040: val_loss improved from 0.45376 to 0.45352, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 41/60
 - 5s - loss: 0.6150 - acc: 0.8031 - val_loss: 0.4611 - val_acc: 0.8504

Epoch 00041: val_loss did not improve from 0.45352
Epoch 42/60
 - 5s - loss: 0.6167 - acc: 0.8013 - val_loss: 0.4540 - val_acc: 0.8598

Epoch 00042: val_loss did not improve from 0.45352
Epoch 43/60
 - 5s - loss: 0.6172 - acc: 0.8021 - val_loss: 0.4430 - val_acc: 0.8611

Epoch 00043: val_loss improved from 0.45352 to 0.44301, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 44/60
 - 5s - loss: 0.6058 - acc: 0.8038 - val_loss: 0.4464 - val_acc: 0.8667

Epoch 00044: val_loss did not improve from 0.44301
Epoch 45/60
 - 5s - loss: 0.6138 - acc: 0.8027 - val_loss: 0.4547 - val_acc: 0.8517

Epoch 00045: val_loss did not improve from 0.44301
Epoch 46/60
 - 5s - loss: 0.6145 - acc: 0.8041 - val_loss: 0.4417 - val_acc: 0.8617

Epoch 00046: val_loss improved from 0.44301 to 0.44166, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 47/60
 - 5s - loss: 0.6064 - acc: 0.8069 - val_loss: 0.4636 - val_acc: 0.8589

Epoch 00047: val_loss did not improve from 0.44166
Epoch 48/60
 - 5s - loss: 0.6055 - acc: 0.8078 - val_loss: 0.4513 - val_acc: 0.8498

Epoch 00048: val_loss did not improve from 0.44166
Epoch 49/60
 - 5s - loss: 0.5993 - acc: 0.8083 - val_loss: 0.4380 - val_acc: 0.8591

Epoch 00049: val_loss improved from 0.44166 to 0.43796, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 50/60
 - 5s - loss: 0.6011 - acc: 0.8079 - val_loss: 0.4494 - val_acc: 0.8603

Epoch 00050: val_loss did not improve from 0.43796
Epoch 51/60
 - 5s - loss: 0.6077 - acc: 0.8067 - val_loss: 0.4563 - val_acc: 0.8505

Epoch 00051: val_loss did not improve from 0.43796
Epoch 52/60
 - 5s - loss: 0.5952 - acc: 0.8083 - val_loss: 0.4532 - val_acc: 0.8538

Epoch 00052: val_loss did not improve from 0.43796
Epoch 53/60
 - 5s - loss: 0.5978 - acc: 0.8085 - val_loss: 0.4419 - val_acc: 0.8628

Epoch 00053: val_loss did not improve from 0.43796
Epoch 54/60
 - 5s - loss: 0.5997 - acc: 0.8074 - val_loss: 0.4675 - val_acc: 0.8630

Epoch 00054: val_loss did not improve from 0.43796
Epoch 55/60
 - 5s - loss: 0.5927 - acc: 0.8111 - val_loss: 0.4425 - val_acc: 0.8611

Epoch 00055: val_loss did not improve from 0.43796
Epoch 56/60
 - 5s - loss: 0.5926 - acc: 0.8093 - val_loss: 0.4306 - val_acc: 0.8630

Epoch 00056: val_loss improved from 0.43796 to 0.43063, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 57/60
 - 5s - loss: 0.5913 - acc: 0.8099 - val_loss: 0.4549 - val_acc: 0.8570

Epoch 00057: val_loss did not improve from 0.43063
Epoch 58/60
 - 5s - loss: 0.5900 - acc: 0.8123 - val_loss: 0.4517 - val_acc: 0.8483

Epoch 00058: val_loss did not improve from 0.43063
Epoch 59/60
 - 5s - loss: 0.5916 - acc: 0.8078 - val_loss: 0.4311 - val_acc: 0.8669

Epoch 00059: val_loss did not improve from 0.43063
Epoch 60/60
 - 5s - loss: 0.5843 - acc: 0.8132 - val_loss: 0.4434 - val_acc: 0.8589

Epoch 00060: val_loss did not improve from 0.43063
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 4.3585 - acc: 0.2935 - val_loss: 2.2203 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 2.22032, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 2/60
 - 4s - loss: 2.0063 - acc: 0.5425 - val_loss: 2.1226 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.22032 to 2.12265, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 3/60
 - 4s - loss: 1.7915 - acc: 0.6253 - val_loss: 1.9965 - val_acc: 0.6209

Epoch 00003: val_loss improved from 2.12265 to 1.99647, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 4/60
 - 4s - loss: 1.6811 - acc: 0.6361 - val_loss: 1.8593 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.99647 to 1.85931, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 5/60
 - 4s - loss: 1.6141 - acc: 0.6370 - val_loss: 1.7687 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.85931 to 1.76874, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 6/60
 - 4s - loss: 1.5745 - acc: 0.6371 - val_loss: 1.6649 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.76874 to 1.66485, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 7/60
 - 4s - loss: 1.5431 - acc: 0.6371 - val_loss: 1.5937 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.66485 to 1.59372, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 8/60
 - 4s - loss: 1.5240 - acc: 0.6371 - val_loss: 1.5704 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.59372 to 1.57040, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 9/60
 - 4s - loss: 1.5141 - acc: 0.6371 - val_loss: 1.5704 - val_acc: 0.6209

Epoch 00009: val_loss improved from 1.57040 to 1.57035, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 10/60
 - 4s - loss: 1.4924 - acc: 0.6371 - val_loss: 1.5386 - val_acc: 0.6209

Epoch 00010: val_loss improved from 1.57035 to 1.53857, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 11/60
 - 4s - loss: 1.4777 - acc: 0.6371 - val_loss: 1.5626 - val_acc: 0.6209

Epoch 00011: val_loss did not improve from 1.53857
Epoch 12/60
 - 4s - loss: 1.4696 - acc: 0.6371 - val_loss: 1.5247 - val_acc: 0.6209

Epoch 00012: val_loss improved from 1.53857 to 1.52475, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 13/60
 - 4s - loss: 1.4559 - acc: 0.6371 - val_loss: 1.4990 - val_acc: 0.6209

Epoch 00013: val_loss improved from 1.52475 to 1.49903, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 14/60
 - 4s - loss: 1.4421 - acc: 0.6371 - val_loss: 1.5046 - val_acc: 0.6209

Epoch 00014: val_loss did not improve from 1.49903
Epoch 15/60
 - 4s - loss: 1.4317 - acc: 0.6371 - val_loss: 1.4908 - val_acc: 0.6209

Epoch 00015: val_loss improved from 1.49903 to 1.49081, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 16/60
 - 4s - loss: 1.4189 - acc: 0.6371 - val_loss: 1.4627 - val_acc: 0.6209

Epoch 00016: val_loss improved from 1.49081 to 1.46271, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 17/60
 - 4s - loss: 1.4033 - acc: 0.6371 - val_loss: 1.4547 - val_acc: 0.6209

Epoch 00017: val_loss improved from 1.46271 to 1.45467, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 18/60
 - 4s - loss: 1.3958 - acc: 0.6371 - val_loss: 1.4565 - val_acc: 0.6209

Epoch 00018: val_loss did not improve from 1.45467
Epoch 19/60
 - 4s - loss: 1.3864 - acc: 0.6371 - val_loss: 1.4598 - val_acc: 0.6209

Epoch 00019: val_loss did not improve from 1.45467
Epoch 20/60
 - 4s - loss: 1.3803 - acc: 0.6371 - val_loss: 1.4408 - val_acc: 0.6209

Epoch 00020: val_loss improved from 1.45467 to 1.44085, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 21/60
 - 4s - loss: 1.3734 - acc: 0.6371 - val_loss: 1.4753 - val_acc: 0.6209

Epoch 00021: val_loss did not improve from 1.44085
Epoch 22/60
 - 4s - loss: 1.3657 - acc: 0.6371 - val_loss: 1.4097 - val_acc: 0.6209

Epoch 00022: val_loss improved from 1.44085 to 1.40967, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 23/60
 - 4s - loss: 1.3610 - acc: 0.6371 - val_loss: 1.4160 - val_acc: 0.6209

Epoch 00023: val_loss did not improve from 1.40967
Epoch 24/60
 - 4s - loss: 1.3543 - acc: 0.6371 - val_loss: 1.4154 - val_acc: 0.6209

Epoch 00024: val_loss did not improve from 1.40967
Epoch 25/60
 - 4s - loss: 1.3520 - acc: 0.6371 - val_loss: 1.4255 - val_acc: 0.6209

Epoch 00025: val_loss did not improve from 1.40967
Epoch 26/60
 - 4s - loss: 1.3489 - acc: 0.6371 - val_loss: 1.4410 - val_acc: 0.6209

Epoch 00026: val_loss did not improve from 1.40967
Epoch 27/60
 - 4s - loss: 1.3450 - acc: 0.6371 - val_loss: 1.3985 - val_acc: 0.6209

Epoch 00027: val_loss improved from 1.40967 to 1.39845, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 28/60
 - 4s - loss: 1.3419 - acc: 0.6371 - val_loss: 1.4036 - val_acc: 0.6209

Epoch 00028: val_loss did not improve from 1.39845
Epoch 29/60
 - 4s - loss: 1.3376 - acc: 0.6371 - val_loss: 1.4033 - val_acc: 0.6209

Epoch 00029: val_loss did not improve from 1.39845
Epoch 30/60
 - 4s - loss: 1.3353 - acc: 0.6371 - val_loss: 1.4434 - val_acc: 0.6209

Epoch 00030: val_loss did not improve from 1.39845
Epoch 31/60
 - 4s - loss: 1.3331 - acc: 0.6371 - val_loss: 1.3833 - val_acc: 0.6209

Epoch 00031: val_loss improved from 1.39845 to 1.38332, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 32/60
 - 4s - loss: 1.3327 - acc: 0.6371 - val_loss: 1.3507 - val_acc: 0.6209

Epoch 00032: val_loss improved from 1.38332 to 1.35074, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 33/60
 - 4s - loss: 1.3295 - acc: 0.6371 - val_loss: 1.3703 - val_acc: 0.6209

Epoch 00033: val_loss did not improve from 1.35074
Epoch 34/60
 - 4s - loss: 1.3267 - acc: 0.6371 - val_loss: 1.3933 - val_acc: 0.6209

Epoch 00034: val_loss did not improve from 1.35074
Epoch 35/60
 - 4s - loss: 1.3262 - acc: 0.6370 - val_loss: 1.3436 - val_acc: 0.6209

Epoch 00035: val_loss improved from 1.35074 to 1.34357, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 36/60
 - 4s - loss: 1.3249 - acc: 0.6371 - val_loss: 1.4111 - val_acc: 0.6209

Epoch 00036: val_loss did not improve from 1.34357
Epoch 37/60
 - 4s - loss: 1.3258 - acc: 0.6370 - val_loss: 1.4045 - val_acc: 0.6209

Epoch 00037: val_loss did not improve from 1.34357
Epoch 38/60
 - 4s - loss: 1.3199 - acc: 0.6370 - val_loss: 1.3781 - val_acc: 0.6209

Epoch 00038: val_loss did not improve from 1.34357
Epoch 39/60
 - 4s - loss: 1.3200 - acc: 0.6370 - val_loss: 1.3901 - val_acc: 0.6209

Epoch 00039: val_loss did not improve from 1.34357
Epoch 40/60
 - 4s - loss: 1.3179 - acc: 0.6371 - val_loss: 1.3619 - val_acc: 0.6209

Epoch 00040: val_loss did not improve from 1.34357
Epoch 41/60
 - 4s - loss: 1.3209 - acc: 0.6371 - val_loss: 1.3609 - val_acc: 0.6209

Epoch 00041: val_loss did not improve from 1.34357
Epoch 42/60
 - 4s - loss: 1.3183 - acc: 0.6371 - val_loss: 1.4132 - val_acc: 0.6209

Epoch 00042: val_loss did not improve from 1.34357
Epoch 43/60
 - 4s - loss: 1.3164 - acc: 0.6370 - val_loss: 1.3442 - val_acc: 0.6209

Epoch 00043: val_loss did not improve from 1.34357
Epoch 44/60
 - 4s - loss: 1.3139 - acc: 0.6370 - val_loss: 1.3734 - val_acc: 0.6209

Epoch 00044: val_loss did not improve from 1.34357
Epoch 45/60
 - 4s - loss: 1.3138 - acc: 0.6371 - val_loss: 1.4155 - val_acc: 0.6209

Epoch 00045: val_loss did not improve from 1.34357
Epoch 00045: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 2.8550 - acc: 0.4846 - val_loss: 2.1622 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 2.16220, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 2/60
 - 5s - loss: 1.6671 - acc: 0.6321 - val_loss: 1.9733 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.16220 to 1.97330, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 3/60
 - 5s - loss: 1.5680 - acc: 0.6371 - val_loss: 1.8612 - val_acc: 0.6209

Epoch 00003: val_loss improved from 1.97330 to 1.86119, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 4/60
 - 5s - loss: 1.5215 - acc: 0.6371 - val_loss: 1.7181 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.86119 to 1.71814, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 5/60
 - 5s - loss: 1.4940 - acc: 0.6371 - val_loss: 1.6510 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.71814 to 1.65098, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 6/60
 - 5s - loss: 1.4718 - acc: 0.6371 - val_loss: 1.6189 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.65098 to 1.61886, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 7/60
 - 5s - loss: 1.4506 - acc: 0.6371 - val_loss: 1.5102 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.61886 to 1.51022, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 8/60
 - 5s - loss: 1.4112 - acc: 0.6368 - val_loss: 1.4504 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.51022 to 1.45041, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 9/60
 - 5s - loss: 1.3701 - acc: 0.6358 - val_loss: 1.3825 - val_acc: 0.6217

Epoch 00009: val_loss improved from 1.45041 to 1.38245, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 10/60
 - 5s - loss: 1.3412 - acc: 0.6362 - val_loss: 1.4308 - val_acc: 0.6212

Epoch 00010: val_loss did not improve from 1.38245
Epoch 11/60
 - 6s - loss: 1.3189 - acc: 0.6369 - val_loss: 1.3887 - val_acc: 0.6215

Epoch 00011: val_loss did not improve from 1.38245
Epoch 12/60
 - 5s - loss: 1.3005 - acc: 0.6371 - val_loss: 1.3513 - val_acc: 0.6221

Epoch 00012: val_loss improved from 1.38245 to 1.35132, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 13/60
 - 5s - loss: 1.2818 - acc: 0.6388 - val_loss: 1.3758 - val_acc: 0.6227

Epoch 00013: val_loss did not improve from 1.35132
Epoch 14/60
 - 5s - loss: 1.2678 - acc: 0.6390 - val_loss: 1.3658 - val_acc: 0.6219

Epoch 00014: val_loss did not improve from 1.35132
Epoch 15/60
 - 5s - loss: 1.2569 - acc: 0.6411 - val_loss: 1.3382 - val_acc: 0.6240

Epoch 00015: val_loss improved from 1.35132 to 1.33821, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 16/60
 - 5s - loss: 1.2448 - acc: 0.6421 - val_loss: 1.2918 - val_acc: 0.6243

Epoch 00016: val_loss improved from 1.33821 to 1.29178, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 17/60
 - 5s - loss: 1.2424 - acc: 0.6418 - val_loss: 1.3013 - val_acc: 0.6227

Epoch 00017: val_loss did not improve from 1.29178
Epoch 18/60
 - 5s - loss: 1.2341 - acc: 0.6427 - val_loss: 1.3272 - val_acc: 0.6239

Epoch 00018: val_loss did not improve from 1.29178
Epoch 19/60
 - 5s - loss: 1.2238 - acc: 0.6445 - val_loss: 1.3655 - val_acc: 0.6242

Epoch 00019: val_loss did not improve from 1.29178
Epoch 20/60
 - 5s - loss: 1.2162 - acc: 0.6451 - val_loss: 1.3059 - val_acc: 0.6267

Epoch 00020: val_loss did not improve from 1.29178
Epoch 21/60
 - 5s - loss: 1.2097 - acc: 0.6454 - val_loss: 1.2670 - val_acc: 0.6264

Epoch 00021: val_loss improved from 1.29178 to 1.26699, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 22/60
 - 5s - loss: 1.2034 - acc: 0.6473 - val_loss: 1.2717 - val_acc: 0.6277

Epoch 00022: val_loss did not improve from 1.26699
Epoch 23/60
 - 5s - loss: 1.1984 - acc: 0.6468 - val_loss: 1.2762 - val_acc: 0.6283

Epoch 00023: val_loss did not improve from 1.26699
Epoch 24/60
 - 5s - loss: 1.1986 - acc: 0.6480 - val_loss: 1.2535 - val_acc: 0.6278

Epoch 00024: val_loss improved from 1.26699 to 1.25349, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 25/60
 - 5s - loss: 1.1875 - acc: 0.6488 - val_loss: 1.2886 - val_acc: 0.6302

Epoch 00025: val_loss did not improve from 1.25349
Epoch 26/60
 - 5s - loss: 1.1835 - acc: 0.6504 - val_loss: 1.2733 - val_acc: 0.6337

Epoch 00026: val_loss did not improve from 1.25349
Epoch 27/60
 - 5s - loss: 1.1810 - acc: 0.6513 - val_loss: 1.2228 - val_acc: 0.6374

Epoch 00027: val_loss improved from 1.25349 to 1.22277, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 28/60
 - 5s - loss: 1.1746 - acc: 0.6512 - val_loss: 1.2442 - val_acc: 0.6378

Epoch 00028: val_loss did not improve from 1.22277
Epoch 29/60
 - 5s - loss: 1.1704 - acc: 0.6517 - val_loss: 1.1665 - val_acc: 0.6353

Epoch 00029: val_loss improved from 1.22277 to 1.16654, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 30/60
 - 5s - loss: 1.1653 - acc: 0.6530 - val_loss: 1.2005 - val_acc: 0.6471

Epoch 00030: val_loss did not improve from 1.16654
Epoch 31/60
 - 5s - loss: 1.1621 - acc: 0.6542 - val_loss: 1.1708 - val_acc: 0.6439

Epoch 00031: val_loss did not improve from 1.16654
Epoch 32/60
 - 5s - loss: 1.1593 - acc: 0.6546 - val_loss: 1.1971 - val_acc: 0.6411

Epoch 00032: val_loss did not improve from 1.16654
Epoch 33/60
 - 5s - loss: 1.1494 - acc: 0.6555 - val_loss: 1.1771 - val_acc: 0.6430

Epoch 00033: val_loss did not improve from 1.16654
Epoch 34/60
 - 5s - loss: 1.1500 - acc: 0.6540 - val_loss: 1.1724 - val_acc: 0.6478

Epoch 00034: val_loss did not improve from 1.16654
Epoch 35/60
 - 5s - loss: 1.1422 - acc: 0.6566 - val_loss: 1.1735 - val_acc: 0.6472

Epoch 00035: val_loss did not improve from 1.16654
Epoch 36/60
 - 5s - loss: 1.1446 - acc: 0.6563 - val_loss: 1.1340 - val_acc: 0.6496

Epoch 00036: val_loss improved from 1.16654 to 1.13395, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 37/60
 - 5s - loss: 1.1343 - acc: 0.6598 - val_loss: 1.1835 - val_acc: 0.6556

Epoch 00037: val_loss did not improve from 1.13395
Epoch 38/60
 - 5s - loss: 1.1352 - acc: 0.6598 - val_loss: 1.2178 - val_acc: 0.6520

Epoch 00038: val_loss did not improve from 1.13395
Epoch 39/60
 - 5s - loss: 1.1354 - acc: 0.6576 - val_loss: 1.1347 - val_acc: 0.6525

Epoch 00039: val_loss did not improve from 1.13395
Epoch 40/60
 - 5s - loss: 1.1273 - acc: 0.6593 - val_loss: 1.0774 - val_acc: 0.6580

Epoch 00040: val_loss improved from 1.13395 to 1.07742, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 41/60
 - 5s - loss: 1.1252 - acc: 0.6596 - val_loss: 1.1045 - val_acc: 0.6553

Epoch 00041: val_loss did not improve from 1.07742
Epoch 42/60
 - 5s - loss: 1.1233 - acc: 0.6602 - val_loss: 1.1206 - val_acc: 0.6562

Epoch 00042: val_loss did not improve from 1.07742
Epoch 43/60
 - 5s - loss: 1.1166 - acc: 0.6603 - val_loss: 1.1468 - val_acc: 0.6570

Epoch 00043: val_loss did not improve from 1.07742
Epoch 44/60
 - 5s - loss: 1.1159 - acc: 0.6603 - val_loss: 1.1134 - val_acc: 0.6608

Epoch 00044: val_loss did not improve from 1.07742
Epoch 45/60
 - 5s - loss: 1.1183 - acc: 0.6604 - val_loss: 1.0825 - val_acc: 0.6617

Epoch 00045: val_loss did not improve from 1.07742
Epoch 46/60
 - 5s - loss: 1.1080 - acc: 0.6615 - val_loss: 1.1039 - val_acc: 0.6575

Epoch 00046: val_loss did not improve from 1.07742
Epoch 47/60
 - 5s - loss: 1.1107 - acc: 0.6633 - val_loss: 1.0793 - val_acc: 0.6593

Epoch 00047: val_loss did not improve from 1.07742
Epoch 48/60
 - 5s - loss: 1.1082 - acc: 0.6630 - val_loss: 1.0958 - val_acc: 0.6587

Epoch 00048: val_loss did not improve from 1.07742
Epoch 49/60
 - 5s - loss: 1.0994 - acc: 0.6643 - val_loss: 1.0514 - val_acc: 0.6577

Epoch 00049: val_loss improved from 1.07742 to 1.05141, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 50/60
 - 5s - loss: 1.1013 - acc: 0.6633 - val_loss: 1.0781 - val_acc: 0.6592

Epoch 00050: val_loss did not improve from 1.05141
Epoch 51/60
 - 5s - loss: 1.0982 - acc: 0.6642 - val_loss: 1.0727 - val_acc: 0.6620

Epoch 00051: val_loss did not improve from 1.05141
Epoch 52/60
 - 5s - loss: 1.1020 - acc: 0.6640 - val_loss: 1.0988 - val_acc: 0.6655

Epoch 00052: val_loss did not improve from 1.05141
Epoch 53/60
 - 5s - loss: 1.0954 - acc: 0.6651 - val_loss: 1.1262 - val_acc: 0.6623

Epoch 00053: val_loss did not improve from 1.05141
Epoch 54/60
 - 5s - loss: 1.0918 - acc: 0.6661 - val_loss: 1.0962 - val_acc: 0.6615

Epoch 00054: val_loss did not improve from 1.05141
Epoch 55/60
 - 5s - loss: 1.0915 - acc: 0.6664 - val_loss: 1.0306 - val_acc: 0.6580

Epoch 00055: val_loss improved from 1.05141 to 1.03063, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 56/60
 - 5s - loss: 1.0919 - acc: 0.6660 - val_loss: 1.0544 - val_acc: 0.6628

Epoch 00056: val_loss did not improve from 1.03063
Epoch 57/60
 - 5s - loss: 1.0892 - acc: 0.6635 - val_loss: 1.0703 - val_acc: 0.6595

Epoch 00057: val_loss did not improve from 1.03063
Epoch 58/60
 - 5s - loss: 1.0877 - acc: 0.6652 - val_loss: 1.0149 - val_acc: 0.6618

Epoch 00058: val_loss improved from 1.03063 to 1.01488, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5
Epoch 59/60
 - 5s - loss: 1.0861 - acc: 0.6652 - val_loss: 1.1080 - val_acc: 0.6643

Epoch 00059: val_loss did not improve from 1.01488
Epoch 60/60
 - 5s - loss: 1.0802 - acc: 0.6658 - val_loss: 1.0690 - val_acc: 0.6659

Epoch 00060: val_loss did not improve from 1.01488
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 2.9559 - acc: 0.5525 - val_loss: 1.4513 - val_acc: 0.6289

Epoch 00001: val_loss improved from inf to 1.45131, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 2/60
 - 5s - loss: 1.3682 - acc: 0.6255 - val_loss: 1.1737 - val_acc: 0.6637

Epoch 00002: val_loss improved from 1.45131 to 1.17368, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 3/60
 - 5s - loss: 1.1921 - acc: 0.6500 - val_loss: 0.9880 - val_acc: 0.7030

Epoch 00003: val_loss improved from 1.17368 to 0.98798, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 4/60
 - 5s - loss: 1.0781 - acc: 0.6701 - val_loss: 0.8828 - val_acc: 0.7255

Epoch 00004: val_loss improved from 0.98798 to 0.88283, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 5/60
 - 5s - loss: 0.9962 - acc: 0.6885 - val_loss: 0.7843 - val_acc: 0.7520

Epoch 00005: val_loss improved from 0.88283 to 0.78430, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 6/60
 - 5s - loss: 0.9415 - acc: 0.7050 - val_loss: 0.7288 - val_acc: 0.7635

Epoch 00006: val_loss improved from 0.78430 to 0.72879, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 7/60
 - 6s - loss: 0.8964 - acc: 0.7174 - val_loss: 0.7260 - val_acc: 0.7698

Epoch 00007: val_loss improved from 0.72879 to 0.72602, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 8/60
 - 5s - loss: 0.8559 - acc: 0.7312 - val_loss: 0.6535 - val_acc: 0.7964

Epoch 00008: val_loss improved from 0.72602 to 0.65354, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 9/60
 - 5s - loss: 0.8263 - acc: 0.7392 - val_loss: 0.6139 - val_acc: 0.7966

Epoch 00009: val_loss improved from 0.65354 to 0.61388, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 10/60
 - 5s - loss: 0.8016 - acc: 0.7471 - val_loss: 0.6337 - val_acc: 0.7932

Epoch 00010: val_loss did not improve from 0.61388
Epoch 11/60
 - 5s - loss: 0.7802 - acc: 0.7525 - val_loss: 0.5948 - val_acc: 0.8219

Epoch 00011: val_loss improved from 0.61388 to 0.59476, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 12/60
 - 5s - loss: 0.7575 - acc: 0.7607 - val_loss: 0.5821 - val_acc: 0.8261

Epoch 00012: val_loss improved from 0.59476 to 0.58210, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 13/60
 - 5s - loss: 0.7452 - acc: 0.7618 - val_loss: 0.5507 - val_acc: 0.8298

Epoch 00013: val_loss improved from 0.58210 to 0.55074, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 14/60
 - 5s - loss: 0.7323 - acc: 0.7652 - val_loss: 0.5655 - val_acc: 0.8208

Epoch 00014: val_loss did not improve from 0.55074
Epoch 15/60
 - 5s - loss: 0.7228 - acc: 0.7711 - val_loss: 0.5510 - val_acc: 0.8345

Epoch 00015: val_loss did not improve from 0.55074
Epoch 16/60
 - 5s - loss: 0.7107 - acc: 0.7761 - val_loss: 0.5503 - val_acc: 0.8302

Epoch 00016: val_loss improved from 0.55074 to 0.55025, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 17/60
 - 5s - loss: 0.6936 - acc: 0.7795 - val_loss: 0.5141 - val_acc: 0.8411

Epoch 00017: val_loss improved from 0.55025 to 0.51414, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 18/60
 - 5s - loss: 0.6933 - acc: 0.7806 - val_loss: 0.5067 - val_acc: 0.8433

Epoch 00018: val_loss improved from 0.51414 to 0.50670, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 19/60
 - 5s - loss: 0.6848 - acc: 0.7805 - val_loss: 0.5089 - val_acc: 0.8329

Epoch 00019: val_loss did not improve from 0.50670
Epoch 20/60
 - 5s - loss: 0.6796 - acc: 0.7836 - val_loss: 0.5102 - val_acc: 0.8477

Epoch 00020: val_loss did not improve from 0.50670
Epoch 21/60
 - 5s - loss: 0.6747 - acc: 0.7849 - val_loss: 0.5112 - val_acc: 0.8386

Epoch 00021: val_loss did not improve from 0.50670
Epoch 22/60
 - 5s - loss: 0.6635 - acc: 0.7886 - val_loss: 0.5083 - val_acc: 0.8314

Epoch 00022: val_loss did not improve from 0.50670
Epoch 23/60
 - 5s - loss: 0.6617 - acc: 0.7879 - val_loss: 0.5016 - val_acc: 0.8422

Epoch 00023: val_loss improved from 0.50670 to 0.50162, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 24/60
 - 5s - loss: 0.6551 - acc: 0.7911 - val_loss: 0.4763 - val_acc: 0.8416

Epoch 00024: val_loss improved from 0.50162 to 0.47635, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 25/60
 - 5s - loss: 0.6503 - acc: 0.7930 - val_loss: 0.4920 - val_acc: 0.8470

Epoch 00025: val_loss did not improve from 0.47635
Epoch 26/60
 - 5s - loss: 0.6456 - acc: 0.7953 - val_loss: 0.4989 - val_acc: 0.8472

Epoch 00026: val_loss did not improve from 0.47635
Epoch 27/60
 - 5s - loss: 0.6440 - acc: 0.7949 - val_loss: 0.4818 - val_acc: 0.8510

Epoch 00027: val_loss did not improve from 0.47635
Epoch 28/60
 - 5s - loss: 0.6370 - acc: 0.7975 - val_loss: 0.4817 - val_acc: 0.8472

Epoch 00028: val_loss did not improve from 0.47635
Epoch 29/60
 - 5s - loss: 0.6363 - acc: 0.7969 - val_loss: 0.4707 - val_acc: 0.8491

Epoch 00029: val_loss improved from 0.47635 to 0.47070, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 30/60
 - 5s - loss: 0.6348 - acc: 0.7972 - val_loss: 0.4754 - val_acc: 0.8529

Epoch 00030: val_loss did not improve from 0.47070
Epoch 31/60
 - 5s - loss: 0.6280 - acc: 0.7976 - val_loss: 0.4699 - val_acc: 0.8470

Epoch 00031: val_loss improved from 0.47070 to 0.46990, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 32/60
 - 5s - loss: 0.6298 - acc: 0.8001 - val_loss: 0.4740 - val_acc: 0.8442

Epoch 00032: val_loss did not improve from 0.46990
Epoch 33/60
 - 5s - loss: 0.6238 - acc: 0.7995 - val_loss: 0.4569 - val_acc: 0.8488

Epoch 00033: val_loss improved from 0.46990 to 0.45687, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 34/60
 - 5s - loss: 0.6220 - acc: 0.8022 - val_loss: 0.4697 - val_acc: 0.8561

Epoch 00034: val_loss did not improve from 0.45687
Epoch 35/60
 - 5s - loss: 0.6197 - acc: 0.8018 - val_loss: 0.4834 - val_acc: 0.8523

Epoch 00035: val_loss did not improve from 0.45687
Epoch 36/60
 - 5s - loss: 0.6146 - acc: 0.8048 - val_loss: 0.4684 - val_acc: 0.8594

Epoch 00036: val_loss did not improve from 0.45687
Epoch 37/60
 - 5s - loss: 0.6116 - acc: 0.8065 - val_loss: 0.4752 - val_acc: 0.8457

Epoch 00037: val_loss did not improve from 0.45687
Epoch 38/60
 - 5s - loss: 0.6142 - acc: 0.8030 - val_loss: 0.4620 - val_acc: 0.8575

Epoch 00038: val_loss did not improve from 0.45687
Epoch 39/60
 - 5s - loss: 0.6166 - acc: 0.8035 - val_loss: 0.4677 - val_acc: 0.8603

Epoch 00039: val_loss did not improve from 0.45687
Epoch 40/60
 - 5s - loss: 0.6082 - acc: 0.8047 - val_loss: 0.4586 - val_acc: 0.8541

Epoch 00040: val_loss did not improve from 0.45687
Epoch 41/60
 - 5s - loss: 0.6038 - acc: 0.8074 - val_loss: 0.4753 - val_acc: 0.8572

Epoch 00041: val_loss did not improve from 0.45687
Epoch 42/60
 - 5s - loss: 0.6048 - acc: 0.8070 - val_loss: 0.4842 - val_acc: 0.8438

Epoch 00042: val_loss did not improve from 0.45687
Epoch 43/60
 - 5s - loss: 0.5985 - acc: 0.8089 - val_loss: 0.4415 - val_acc: 0.8633

Epoch 00043: val_loss improved from 0.45687 to 0.44152, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 44/60
 - 5s - loss: 0.5971 - acc: 0.8074 - val_loss: 0.4501 - val_acc: 0.8573

Epoch 00044: val_loss did not improve from 0.44152
Epoch 45/60
 - 5s - loss: 0.6010 - acc: 0.8089 - val_loss: 0.4387 - val_acc: 0.8592

Epoch 00045: val_loss improved from 0.44152 to 0.43870, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 46/60
 - 5s - loss: 0.6011 - acc: 0.8071 - val_loss: 0.4557 - val_acc: 0.8511

Epoch 00046: val_loss did not improve from 0.43870
Epoch 47/60
 - 5s - loss: 0.5951 - acc: 0.8089 - val_loss: 0.4502 - val_acc: 0.8535

Epoch 00047: val_loss did not improve from 0.43870
Epoch 48/60
 - 5s - loss: 0.5947 - acc: 0.8081 - val_loss: 0.4424 - val_acc: 0.8636

Epoch 00048: val_loss did not improve from 0.43870
Epoch 49/60
 - 5s - loss: 0.5912 - acc: 0.8113 - val_loss: 0.4633 - val_acc: 0.8436

Epoch 00049: val_loss did not improve from 0.43870
Epoch 50/60
 - 5s - loss: 0.5926 - acc: 0.8107 - val_loss: 0.4592 - val_acc: 0.8463

Epoch 00050: val_loss did not improve from 0.43870
Epoch 51/60
 - 5s - loss: 0.5905 - acc: 0.8102 - val_loss: 0.4355 - val_acc: 0.8608

Epoch 00051: val_loss improved from 0.43870 to 0.43546, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 52/60
 - 5s - loss: 0.5892 - acc: 0.8105 - val_loss: 0.4575 - val_acc: 0.8444

Epoch 00052: val_loss did not improve from 0.43546
Epoch 53/60
 - 5s - loss: 0.5872 - acc: 0.8128 - val_loss: 0.4481 - val_acc: 0.8563

Epoch 00053: val_loss did not improve from 0.43546
Epoch 54/60
 - 5s - loss: 0.5915 - acc: 0.8103 - val_loss: 0.4353 - val_acc: 0.8578

Epoch 00054: val_loss improved from 0.43546 to 0.43529, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 55/60
 - 5s - loss: 0.5826 - acc: 0.8116 - val_loss: 0.4295 - val_acc: 0.8655

Epoch 00055: val_loss improved from 0.43529 to 0.42954, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 56/60
 - 5s - loss: 0.5840 - acc: 0.8133 - val_loss: 0.4378 - val_acc: 0.8598

Epoch 00056: val_loss did not improve from 0.42954
Epoch 57/60
 - 5s - loss: 0.5805 - acc: 0.8129 - val_loss: 0.4498 - val_acc: 0.8548

Epoch 00057: val_loss did not improve from 0.42954
Epoch 58/60
 - 5s - loss: 0.5838 - acc: 0.8143 - val_loss: 0.4414 - val_acc: 0.8613

Epoch 00058: val_loss did not improve from 0.42954
Epoch 59/60
 - 5s - loss: 0.5832 - acc: 0.8119 - val_loss: 0.4203 - val_acc: 0.8663

Epoch 00059: val_loss improved from 0.42954 to 0.42033, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5
Epoch 60/60
 - 5s - loss: 0.5795 - acc: 0.8144 - val_loss: 0.4328 - val_acc: 0.8573

Epoch 00060: val_loss did not improve from 0.42033
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 3.7549 - acc: 0.3570 - val_loss: 2.2593 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 2.25927, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 2/60
 - 4s - loss: 1.9351 - acc: 0.5543 - val_loss: 2.1133 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.25927 to 2.11329, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 3/60
 - 4s - loss: 1.7577 - acc: 0.6285 - val_loss: 1.9879 - val_acc: 0.6209

Epoch 00003: val_loss improved from 2.11329 to 1.98787, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 4/60
 - 4s - loss: 1.6672 - acc: 0.6366 - val_loss: 1.8470 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.98787 to 1.84701, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 5/60
 - 4s - loss: 1.5981 - acc: 0.6372 - val_loss: 1.7374 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.84701 to 1.73736, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 6/60
 - 4s - loss: 1.5621 - acc: 0.6371 - val_loss: 1.6511 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.73736 to 1.65108, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 7/60
 - 4s - loss: 1.5276 - acc: 0.6371 - val_loss: 1.6001 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.65108 to 1.60014, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 8/60
 - 4s - loss: 1.5095 - acc: 0.6371 - val_loss: 1.5689 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.60014 to 1.56892, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 9/60
 - 4s - loss: 1.4910 - acc: 0.6371 - val_loss: 1.5515 - val_acc: 0.6209

Epoch 00009: val_loss improved from 1.56892 to 1.55153, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 10/60
 - 4s - loss: 1.4768 - acc: 0.6371 - val_loss: 1.5344 - val_acc: 0.6209

Epoch 00010: val_loss improved from 1.55153 to 1.53440, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 11/60
 - 4s - loss: 1.4652 - acc: 0.6371 - val_loss: 1.5341 - val_acc: 0.6209

Epoch 00011: val_loss improved from 1.53440 to 1.53406, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 12/60
 - 4s - loss: 1.4485 - acc: 0.6371 - val_loss: 1.5017 - val_acc: 0.6209

Epoch 00012: val_loss improved from 1.53406 to 1.50169, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 13/60
 - 4s - loss: 1.4393 - acc: 0.6371 - val_loss: 1.5002 - val_acc: 0.6209

Epoch 00013: val_loss improved from 1.50169 to 1.50015, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 14/60
 - 4s - loss: 1.4221 - acc: 0.6371 - val_loss: 1.4952 - val_acc: 0.6209

Epoch 00014: val_loss improved from 1.50015 to 1.49524, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 15/60
 - 4s - loss: 1.4127 - acc: 0.6371 - val_loss: 1.4716 - val_acc: 0.6209

Epoch 00015: val_loss improved from 1.49524 to 1.47164, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 16/60
 - 4s - loss: 1.4033 - acc: 0.6371 - val_loss: 1.4705 - val_acc: 0.6209

Epoch 00016: val_loss improved from 1.47164 to 1.47048, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 17/60
 - 4s - loss: 1.3970 - acc: 0.6371 - val_loss: 1.4398 - val_acc: 0.6209

Epoch 00017: val_loss improved from 1.47048 to 1.43984, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 18/60
 - 4s - loss: 1.3901 - acc: 0.6371 - val_loss: 1.4627 - val_acc: 0.6209

Epoch 00018: val_loss did not improve from 1.43984
Epoch 19/60
 - 4s - loss: 1.3798 - acc: 0.6371 - val_loss: 1.4434 - val_acc: 0.6209

Epoch 00019: val_loss did not improve from 1.43984
Epoch 20/60
 - 4s - loss: 1.3718 - acc: 0.6371 - val_loss: 1.4486 - val_acc: 0.6209

Epoch 00020: val_loss did not improve from 1.43984
Epoch 21/60
 - 4s - loss: 1.3641 - acc: 0.6371 - val_loss: 1.4348 - val_acc: 0.6209

Epoch 00021: val_loss improved from 1.43984 to 1.43484, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 22/60
 - 4s - loss: 1.3613 - acc: 0.6371 - val_loss: 1.4043 - val_acc: 0.6209

Epoch 00022: val_loss improved from 1.43484 to 1.40429, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 23/60
 - 4s - loss: 1.3566 - acc: 0.6371 - val_loss: 1.4081 - val_acc: 0.6209

Epoch 00023: val_loss did not improve from 1.40429
Epoch 24/60
 - 4s - loss: 1.3507 - acc: 0.6371 - val_loss: 1.3971 - val_acc: 0.6209

Epoch 00024: val_loss improved from 1.40429 to 1.39708, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 25/60
 - 4s - loss: 1.3484 - acc: 0.6371 - val_loss: 1.3662 - val_acc: 0.6209

Epoch 00025: val_loss improved from 1.39708 to 1.36619, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 26/60
 - 4s - loss: 1.3457 - acc: 0.6371 - val_loss: 1.3892 - val_acc: 0.6209

Epoch 00026: val_loss did not improve from 1.36619
Epoch 27/60
 - 4s - loss: 1.3443 - acc: 0.6371 - val_loss: 1.4223 - val_acc: 0.6209

Epoch 00027: val_loss did not improve from 1.36619
Epoch 28/60
 - 4s - loss: 1.3391 - acc: 0.6371 - val_loss: 1.3707 - val_acc: 0.6209

Epoch 00028: val_loss did not improve from 1.36619
Epoch 29/60
 - 4s - loss: 1.3392 - acc: 0.6371 - val_loss: 1.4231 - val_acc: 0.6209

Epoch 00029: val_loss did not improve from 1.36619
Epoch 30/60
 - 4s - loss: 1.3338 - acc: 0.6371 - val_loss: 1.3931 - val_acc: 0.6209

Epoch 00030: val_loss did not improve from 1.36619
Epoch 31/60
 - 4s - loss: 1.3324 - acc: 0.6371 - val_loss: 1.4056 - val_acc: 0.6209

Epoch 00031: val_loss did not improve from 1.36619
Epoch 32/60
 - 4s - loss: 1.3293 - acc: 0.6371 - val_loss: 1.4324 - val_acc: 0.6209

Epoch 00032: val_loss did not improve from 1.36619
Epoch 33/60
 - 4s - loss: 1.3279 - acc: 0.6371 - val_loss: 1.3630 - val_acc: 0.6209

Epoch 00033: val_loss improved from 1.36619 to 1.36298, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 34/60
 - 4s - loss: 1.3248 - acc: 0.6371 - val_loss: 1.3597 - val_acc: 0.6209

Epoch 00034: val_loss improved from 1.36298 to 1.35971, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 35/60
 - 4s - loss: 1.3270 - acc: 0.6371 - val_loss: 1.4201 - val_acc: 0.6209

Epoch 00035: val_loss did not improve from 1.35971
Epoch 36/60
 - 4s - loss: 1.3238 - acc: 0.6371 - val_loss: 1.3821 - val_acc: 0.6209

Epoch 00036: val_loss did not improve from 1.35971
Epoch 37/60
 - 4s - loss: 1.3201 - acc: 0.6371 - val_loss: 1.3436 - val_acc: 0.6209

Epoch 00037: val_loss improved from 1.35971 to 1.34356, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 38/60
 - 4s - loss: 1.3215 - acc: 0.6370 - val_loss: 1.3789 - val_acc: 0.6209

Epoch 00038: val_loss did not improve from 1.34356
Epoch 39/60
 - 4s - loss: 1.3165 - acc: 0.6371 - val_loss: 1.3417 - val_acc: 0.6209

Epoch 00039: val_loss improved from 1.34356 to 1.34166, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 40/60
 - 4s - loss: 1.3182 - acc: 0.6370 - val_loss: 1.3665 - val_acc: 0.6209

Epoch 00040: val_loss did not improve from 1.34166
Epoch 41/60
 - 4s - loss: 1.3142 - acc: 0.6370 - val_loss: 1.3778 - val_acc: 0.6209

Epoch 00041: val_loss did not improve from 1.34166
Epoch 42/60
 - 4s - loss: 1.3153 - acc: 0.6370 - val_loss: 1.4081 - val_acc: 0.6209

Epoch 00042: val_loss did not improve from 1.34166
Epoch 43/60
 - 4s - loss: 1.3136 - acc: 0.6369 - val_loss: 1.3449 - val_acc: 0.6209

Epoch 00043: val_loss did not improve from 1.34166
Epoch 44/60
 - 4s - loss: 1.3137 - acc: 0.6369 - val_loss: 1.3401 - val_acc: 0.6209

Epoch 00044: val_loss improved from 1.34166 to 1.34014, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 45/60
 - 4s - loss: 1.3086 - acc: 0.6369 - val_loss: 1.3791 - val_acc: 0.6209

Epoch 00045: val_loss did not improve from 1.34014
Epoch 46/60
 - 5s - loss: 1.3112 - acc: 0.6370 - val_loss: 1.3805 - val_acc: 0.6209

Epoch 00046: val_loss did not improve from 1.34014
Epoch 47/60
 - 4s - loss: 1.3121 - acc: 0.6370 - val_loss: 1.3949 - val_acc: 0.6209

Epoch 00047: val_loss did not improve from 1.34014
Epoch 48/60
 - 4s - loss: 1.3073 - acc: 0.6367 - val_loss: 1.3495 - val_acc: 0.6209

Epoch 00048: val_loss did not improve from 1.34014
Epoch 49/60
 - 4s - loss: 1.3092 - acc: 0.6370 - val_loss: 1.3388 - val_acc: 0.6209

Epoch 00049: val_loss improved from 1.34014 to 1.33882, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 50/60
 - 4s - loss: 1.3064 - acc: 0.6369 - val_loss: 1.3335 - val_acc: 0.6209

Epoch 00050: val_loss improved from 1.33882 to 1.33352, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 51/60
 - 4s - loss: 1.3040 - acc: 0.6370 - val_loss: 1.3407 - val_acc: 0.6209

Epoch 00051: val_loss did not improve from 1.33352
Epoch 52/60
 - 4s - loss: 1.3045 - acc: 0.6370 - val_loss: 1.3675 - val_acc: 0.6209

Epoch 00052: val_loss did not improve from 1.33352
Epoch 53/60
 - 4s - loss: 1.3073 - acc: 0.6370 - val_loss: 1.4111 - val_acc: 0.6209

Epoch 00053: val_loss did not improve from 1.33352
Epoch 54/60
 - 4s - loss: 1.3052 - acc: 0.6370 - val_loss: 1.3574 - val_acc: 0.6209

Epoch 00054: val_loss did not improve from 1.33352
Epoch 55/60
 - 4s - loss: 1.3014 - acc: 0.6370 - val_loss: 1.3962 - val_acc: 0.6209

Epoch 00055: val_loss did not improve from 1.33352
Epoch 56/60
 - 4s - loss: 1.3031 - acc: 0.6367 - val_loss: 1.3366 - val_acc: 0.6209

Epoch 00056: val_loss did not improve from 1.33352
Epoch 57/60
 - 4s - loss: 1.2980 - acc: 0.6368 - val_loss: 1.3434 - val_acc: 0.6209

Epoch 00057: val_loss did not improve from 1.33352
Epoch 58/60
 - 4s - loss: 1.3000 - acc: 0.6367 - val_loss: 1.3249 - val_acc: 0.6209

Epoch 00058: val_loss improved from 1.33352 to 1.32487, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5
Epoch 59/60
 - 4s - loss: 1.2993 - acc: 0.6369 - val_loss: 1.3541 - val_acc: 0.6209

Epoch 00059: val_loss did not improve from 1.32487
Epoch 60/60
 - 4s - loss: 1.3000 - acc: 0.6368 - val_loss: 1.3676 - val_acc: 0.6209

Epoch 00060: val_loss did not improve from 1.32487
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 2.8180 - acc: 0.5022 - val_loss: 2.1462 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 2.14624, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 2/60
 - 5s - loss: 1.6476 - acc: 0.6320 - val_loss: 2.0315 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.14624 to 2.03151, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 3/60
 - 5s - loss: 1.5557 - acc: 0.6369 - val_loss: 1.8645 - val_acc: 0.6209

Epoch 00003: val_loss improved from 2.03151 to 1.86453, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 4/60
 - 5s - loss: 1.5131 - acc: 0.6371 - val_loss: 1.7656 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.86453 to 1.76563, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 5/60
 - 5s - loss: 1.4832 - acc: 0.6371 - val_loss: 1.7152 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.76563 to 1.71524, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 6/60
 - 5s - loss: 1.4666 - acc: 0.6371 - val_loss: 1.6315 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.71524 to 1.63146, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 7/60
 - 5s - loss: 1.4454 - acc: 0.6371 - val_loss: 1.6146 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.63146 to 1.61463, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 8/60
 - 6s - loss: 1.4286 - acc: 0.6371 - val_loss: 1.5771 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.61463 to 1.57712, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 9/60
 - 5s - loss: 1.4083 - acc: 0.6371 - val_loss: 1.5553 - val_acc: 0.6209

Epoch 00009: val_loss improved from 1.57712 to 1.55533, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 10/60
 - 5s - loss: 1.3951 - acc: 0.6371 - val_loss: 1.5217 - val_acc: 0.6209

Epoch 00010: val_loss improved from 1.55533 to 1.52170, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 11/60
 - 5s - loss: 1.3660 - acc: 0.6371 - val_loss: 1.4449 - val_acc: 0.6209

Epoch 00011: val_loss improved from 1.52170 to 1.44495, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 12/60
 - 5s - loss: 1.3270 - acc: 0.6365 - val_loss: 1.3749 - val_acc: 0.6214

Epoch 00012: val_loss improved from 1.44495 to 1.37493, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 13/60
 - 5s - loss: 1.3060 - acc: 0.6372 - val_loss: 1.3685 - val_acc: 0.6219

Epoch 00013: val_loss improved from 1.37493 to 1.36851, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 14/60
 - 5s - loss: 1.2865 - acc: 0.6382 - val_loss: 1.4323 - val_acc: 0.6217

Epoch 00014: val_loss did not improve from 1.36851
Epoch 15/60
 - 5s - loss: 1.2731 - acc: 0.6388 - val_loss: 1.4021 - val_acc: 0.6230

Epoch 00015: val_loss did not improve from 1.36851
Epoch 16/60
 - 5s - loss: 1.2610 - acc: 0.6401 - val_loss: 1.3673 - val_acc: 0.6264

Epoch 00016: val_loss improved from 1.36851 to 1.36727, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 17/60
 - 5s - loss: 1.2480 - acc: 0.6417 - val_loss: 1.3144 - val_acc: 0.6268

Epoch 00017: val_loss improved from 1.36727 to 1.31441, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 18/60
 - 5s - loss: 1.2353 - acc: 0.6418 - val_loss: 1.3979 - val_acc: 0.6267

Epoch 00018: val_loss did not improve from 1.31441
Epoch 19/60
 - 5s - loss: 1.2226 - acc: 0.6445 - val_loss: 1.3112 - val_acc: 0.6283

Epoch 00019: val_loss improved from 1.31441 to 1.31117, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 20/60
 - 5s - loss: 1.2195 - acc: 0.6438 - val_loss: 1.3316 - val_acc: 0.6296

Epoch 00020: val_loss did not improve from 1.31117
Epoch 21/60
 - 5s - loss: 1.2142 - acc: 0.6456 - val_loss: 1.2845 - val_acc: 0.6280

Epoch 00021: val_loss improved from 1.31117 to 1.28452, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 22/60
 - 5s - loss: 1.2082 - acc: 0.6461 - val_loss: 1.3281 - val_acc: 0.6312

Epoch 00022: val_loss did not improve from 1.28452
Epoch 23/60
 - 5s - loss: 1.1984 - acc: 0.6469 - val_loss: 1.3068 - val_acc: 0.6346

Epoch 00023: val_loss did not improve from 1.28452
Epoch 24/60
 - 5s - loss: 1.1945 - acc: 0.6472 - val_loss: 1.2451 - val_acc: 0.6327

Epoch 00024: val_loss improved from 1.28452 to 1.24505, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 25/60
 - 5s - loss: 1.1895 - acc: 0.6483 - val_loss: 1.2362 - val_acc: 0.6359

Epoch 00025: val_loss improved from 1.24505 to 1.23617, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 26/60
 - 5s - loss: 1.1869 - acc: 0.6485 - val_loss: 1.3376 - val_acc: 0.6361

Epoch 00026: val_loss did not improve from 1.23617
Epoch 27/60
 - 5s - loss: 1.1826 - acc: 0.6496 - val_loss: 1.2340 - val_acc: 0.6381

Epoch 00027: val_loss improved from 1.23617 to 1.23398, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 28/60
 - 5s - loss: 1.1811 - acc: 0.6510 - val_loss: 1.2031 - val_acc: 0.6396

Epoch 00028: val_loss improved from 1.23398 to 1.20315, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 29/60
 - 5s - loss: 1.1747 - acc: 0.6524 - val_loss: 1.2373 - val_acc: 0.6395

Epoch 00029: val_loss did not improve from 1.20315
Epoch 30/60
 - 5s - loss: 1.1729 - acc: 0.6517 - val_loss: 1.3346 - val_acc: 0.6339

Epoch 00030: val_loss did not improve from 1.20315
Epoch 31/60
 - 5s - loss: 1.1704 - acc: 0.6522 - val_loss: 1.2229 - val_acc: 0.6420

Epoch 00031: val_loss did not improve from 1.20315
Epoch 32/60
 - 5s - loss: 1.1624 - acc: 0.6526 - val_loss: 1.2989 - val_acc: 0.6367

Epoch 00032: val_loss did not improve from 1.20315
Epoch 33/60
 - 5s - loss: 1.1627 - acc: 0.6542 - val_loss: 1.2198 - val_acc: 0.6415

Epoch 00033: val_loss did not improve from 1.20315
Epoch 34/60
 - 5s - loss: 1.1608 - acc: 0.6544 - val_loss: 1.1979 - val_acc: 0.6409

Epoch 00034: val_loss improved from 1.20315 to 1.19794, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 35/60
 - 5s - loss: 1.1596 - acc: 0.6546 - val_loss: 1.2012 - val_acc: 0.6420

Epoch 00035: val_loss did not improve from 1.19794
Epoch 36/60
 - 5s - loss: 1.1568 - acc: 0.6545 - val_loss: 1.1634 - val_acc: 0.6480

Epoch 00036: val_loss improved from 1.19794 to 1.16344, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 37/60
 - 5s - loss: 1.1538 - acc: 0.6553 - val_loss: 1.1958 - val_acc: 0.6511

Epoch 00037: val_loss did not improve from 1.16344
Epoch 38/60
 - 5s - loss: 1.1491 - acc: 0.6566 - val_loss: 1.2108 - val_acc: 0.6475

Epoch 00038: val_loss did not improve from 1.16344
Epoch 39/60
 - 5s - loss: 1.1463 - acc: 0.6562 - val_loss: 1.2290 - val_acc: 0.6440

Epoch 00039: val_loss did not improve from 1.16344
Epoch 40/60
 - 5s - loss: 1.1459 - acc: 0.6559 - val_loss: 1.1559 - val_acc: 0.6553

Epoch 00040: val_loss improved from 1.16344 to 1.15586, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 41/60
 - 5s - loss: 1.1429 - acc: 0.6561 - val_loss: 1.1901 - val_acc: 0.6534

Epoch 00041: val_loss did not improve from 1.15586
Epoch 42/60
 - 5s - loss: 1.1376 - acc: 0.6578 - val_loss: 1.1982 - val_acc: 0.6478

Epoch 00042: val_loss did not improve from 1.15586
Epoch 43/60
 - 5s - loss: 1.1379 - acc: 0.6579 - val_loss: 1.2201 - val_acc: 0.6503

Epoch 00043: val_loss did not improve from 1.15586
Epoch 44/60
 - 5s - loss: 1.1387 - acc: 0.6579 - val_loss: 1.1312 - val_acc: 0.6496

Epoch 00044: val_loss improved from 1.15586 to 1.13115, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 45/60
 - 5s - loss: 1.1365 - acc: 0.6590 - val_loss: 1.1615 - val_acc: 0.6450

Epoch 00045: val_loss did not improve from 1.13115
Epoch 46/60
 - 5s - loss: 1.1321 - acc: 0.6569 - val_loss: 1.1609 - val_acc: 0.6474

Epoch 00046: val_loss did not improve from 1.13115
Epoch 47/60
 - 5s - loss: 1.1302 - acc: 0.6583 - val_loss: 1.2652 - val_acc: 0.6470

Epoch 00047: val_loss did not improve from 1.13115
Epoch 48/60
 - 5s - loss: 1.1285 - acc: 0.6597 - val_loss: 1.1421 - val_acc: 0.6514

Epoch 00048: val_loss did not improve from 1.13115
Epoch 49/60
 - 5s - loss: 1.1263 - acc: 0.6594 - val_loss: 1.1091 - val_acc: 0.6499

Epoch 00049: val_loss improved from 1.13115 to 1.10912, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 50/60
 - 5s - loss: 1.1278 - acc: 0.6584 - val_loss: 1.0893 - val_acc: 0.6530

Epoch 00050: val_loss improved from 1.10912 to 1.08935, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5
Epoch 51/60
 - 5s - loss: 1.1261 - acc: 0.6595 - val_loss: 1.1800 - val_acc: 0.6481

Epoch 00051: val_loss did not improve from 1.08935
Epoch 52/60
 - 5s - loss: 1.1221 - acc: 0.6590 - val_loss: 1.1211 - val_acc: 0.6515

Epoch 00052: val_loss did not improve from 1.08935
Epoch 53/60
 - 5s - loss: 1.1181 - acc: 0.6599 - val_loss: 1.1436 - val_acc: 0.6556

Epoch 00053: val_loss did not improve from 1.08935
Epoch 54/60
 - 5s - loss: 1.1239 - acc: 0.6589 - val_loss: 1.1407 - val_acc: 0.6555

Epoch 00054: val_loss did not improve from 1.08935
Epoch 55/60
 - 5s - loss: 1.1143 - acc: 0.6594 - val_loss: 1.1013 - val_acc: 0.6467

Epoch 00055: val_loss did not improve from 1.08935
Epoch 56/60
 - 5s - loss: 1.1172 - acc: 0.6591 - val_loss: 1.1667 - val_acc: 0.6455

Epoch 00056: val_loss did not improve from 1.08935
Epoch 57/60
 - 5s - loss: 1.1149 - acc: 0.6594 - val_loss: 1.2022 - val_acc: 0.6474

Epoch 00057: val_loss did not improve from 1.08935
Epoch 58/60
 - 5s - loss: 1.1153 - acc: 0.6596 - val_loss: 1.1437 - val_acc: 0.6520

Epoch 00058: val_loss did not improve from 1.08935
Epoch 59/60
 - 5s - loss: 1.1119 - acc: 0.6584 - val_loss: 1.1298 - val_acc: 0.6428

Epoch 00059: val_loss did not improve from 1.08935
Epoch 60/60
 - 5s - loss: 1.1095 - acc: 0.6602 - val_loss: 1.1839 - val_acc: 0.6496

Epoch 00060: val_loss did not improve from 1.08935
Epoch 00060: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 2.7032 - acc: 0.5559 - val_loss: 1.3646 - val_acc: 0.6362

Epoch 00001: val_loss improved from inf to 1.36459, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 2/60
 - 5s - loss: 1.3711 - acc: 0.6311 - val_loss: 1.1354 - val_acc: 0.6589

Epoch 00002: val_loss improved from 1.36459 to 1.13539, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 3/60
 - 5s - loss: 1.2064 - acc: 0.6554 - val_loss: 0.9997 - val_acc: 0.6965

Epoch 00003: val_loss improved from 1.13539 to 0.99971, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 4/60
 - 5s - loss: 1.1000 - acc: 0.6716 - val_loss: 0.9368 - val_acc: 0.7211

Epoch 00004: val_loss improved from 0.99971 to 0.93677, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 5/60
 - 5s - loss: 1.0193 - acc: 0.6861 - val_loss: 0.7949 - val_acc: 0.7346

Epoch 00005: val_loss improved from 0.93677 to 0.79486, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 6/60
 - 5s - loss: 0.9591 - acc: 0.7014 - val_loss: 0.7395 - val_acc: 0.7657

Epoch 00006: val_loss improved from 0.79486 to 0.73951, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 7/60
 - 5s - loss: 0.9009 - acc: 0.7193 - val_loss: 0.6860 - val_acc: 0.7952

Epoch 00007: val_loss improved from 0.73951 to 0.68601, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 8/60
 - 5s - loss: 0.8672 - acc: 0.7289 - val_loss: 0.6461 - val_acc: 0.7882

Epoch 00008: val_loss improved from 0.68601 to 0.64606, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 9/60
 - 5s - loss: 0.8381 - acc: 0.7358 - val_loss: 0.6860 - val_acc: 0.7966

Epoch 00009: val_loss did not improve from 0.64606
Epoch 10/60
 - 5s - loss: 0.8158 - acc: 0.7433 - val_loss: 0.6296 - val_acc: 0.8005

Epoch 00010: val_loss improved from 0.64606 to 0.62960, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 11/60
 - 5s - loss: 0.7972 - acc: 0.7503 - val_loss: 0.6171 - val_acc: 0.8086

Epoch 00011: val_loss improved from 0.62960 to 0.61705, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 12/60
 - 5s - loss: 0.7750 - acc: 0.7558 - val_loss: 0.5983 - val_acc: 0.8198

Epoch 00012: val_loss improved from 0.61705 to 0.59834, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 13/60
 - 5s - loss: 0.7574 - acc: 0.7621 - val_loss: 0.6300 - val_acc: 0.8020

Epoch 00013: val_loss did not improve from 0.59834
Epoch 14/60
 - 5s - loss: 0.7392 - acc: 0.7653 - val_loss: 0.5500 - val_acc: 0.8289

Epoch 00014: val_loss improved from 0.59834 to 0.54996, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 15/60
 - 5s - loss: 0.7271 - acc: 0.7696 - val_loss: 0.5418 - val_acc: 0.8266

Epoch 00015: val_loss improved from 0.54996 to 0.54181, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 16/60
 - 5s - loss: 0.7204 - acc: 0.7713 - val_loss: 0.5707 - val_acc: 0.8347

Epoch 00016: val_loss did not improve from 0.54181
Epoch 17/60
 - 5s - loss: 0.7121 - acc: 0.7750 - val_loss: 0.5462 - val_acc: 0.8199

Epoch 00017: val_loss did not improve from 0.54181
Epoch 18/60
 - 5s - loss: 0.7053 - acc: 0.7753 - val_loss: 0.5202 - val_acc: 0.8302

Epoch 00018: val_loss improved from 0.54181 to 0.52024, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 19/60
 - 5s - loss: 0.6923 - acc: 0.7796 - val_loss: 0.5386 - val_acc: 0.8307

Epoch 00019: val_loss did not improve from 0.52024
Epoch 20/60
 - 5s - loss: 0.6851 - acc: 0.7820 - val_loss: 0.5023 - val_acc: 0.8391

Epoch 00020: val_loss improved from 0.52024 to 0.50233, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 21/60
 - 5s - loss: 0.6809 - acc: 0.7835 - val_loss: 0.5222 - val_acc: 0.8333

Epoch 00021: val_loss did not improve from 0.50233
Epoch 22/60
 - 5s - loss: 0.6704 - acc: 0.7873 - val_loss: 0.5569 - val_acc: 0.8155

Epoch 00022: val_loss did not improve from 0.50233
Epoch 23/60
 - 5s - loss: 0.6721 - acc: 0.7843 - val_loss: 0.5102 - val_acc: 0.8333

Epoch 00023: val_loss did not improve from 0.50233
Epoch 24/60
 - 5s - loss: 0.6645 - acc: 0.7904 - val_loss: 0.5166 - val_acc: 0.8385

Epoch 00024: val_loss did not improve from 0.50233
Epoch 25/60
 - 5s - loss: 0.6638 - acc: 0.7904 - val_loss: 0.4902 - val_acc: 0.8513

Epoch 00025: val_loss improved from 0.50233 to 0.49016, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 26/60
 - 5s - loss: 0.6513 - acc: 0.7951 - val_loss: 0.4900 - val_acc: 0.8508

Epoch 00026: val_loss improved from 0.49016 to 0.49001, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 27/60
 - 5s - loss: 0.6484 - acc: 0.7932 - val_loss: 0.4819 - val_acc: 0.8498

Epoch 00027: val_loss improved from 0.49001 to 0.48193, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 28/60
 - 5s - loss: 0.6437 - acc: 0.7945 - val_loss: 0.4644 - val_acc: 0.8530

Epoch 00028: val_loss improved from 0.48193 to 0.46444, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 29/60
 - 5s - loss: 0.6420 - acc: 0.7967 - val_loss: 0.4708 - val_acc: 0.8470

Epoch 00029: val_loss did not improve from 0.46444
Epoch 30/60
 - 5s - loss: 0.6349 - acc: 0.7988 - val_loss: 0.4648 - val_acc: 0.8547

Epoch 00030: val_loss did not improve from 0.46444
Epoch 31/60
 - 5s - loss: 0.6361 - acc: 0.7976 - val_loss: 0.4723 - val_acc: 0.8486

Epoch 00031: val_loss did not improve from 0.46444
Epoch 32/60
 - 5s - loss: 0.6306 - acc: 0.7989 - val_loss: 0.4590 - val_acc: 0.8566

Epoch 00032: val_loss improved from 0.46444 to 0.45898, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 33/60
 - 5s - loss: 0.6296 - acc: 0.8007 - val_loss: 0.4613 - val_acc: 0.8516

Epoch 00033: val_loss did not improve from 0.45898
Epoch 34/60
 - 5s - loss: 0.6295 - acc: 0.7991 - val_loss: 0.4746 - val_acc: 0.8519

Epoch 00034: val_loss did not improve from 0.45898
Epoch 35/60
 - 5s - loss: 0.6212 - acc: 0.8019 - val_loss: 0.4848 - val_acc: 0.8455

Epoch 00035: val_loss did not improve from 0.45898
Epoch 36/60
 - 5s - loss: 0.6179 - acc: 0.8029 - val_loss: 0.4522 - val_acc: 0.8585

Epoch 00036: val_loss improved from 0.45898 to 0.45223, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 37/60
 - 5s - loss: 0.6173 - acc: 0.8019 - val_loss: 0.4643 - val_acc: 0.8572

Epoch 00037: val_loss did not improve from 0.45223
Epoch 38/60
 - 5s - loss: 0.6158 - acc: 0.8024 - val_loss: 0.4562 - val_acc: 0.8588

Epoch 00038: val_loss did not improve from 0.45223
Epoch 39/60
 - 5s - loss: 0.6127 - acc: 0.8047 - val_loss: 0.4698 - val_acc: 0.8467

Epoch 00039: val_loss did not improve from 0.45223
Epoch 40/60
 - 5s - loss: 0.6147 - acc: 0.8027 - val_loss: 0.4732 - val_acc: 0.8541

Epoch 00040: val_loss did not improve from 0.45223
Epoch 41/60
 - 5s - loss: 0.6108 - acc: 0.8047 - val_loss: 0.4637 - val_acc: 0.8560

Epoch 00041: val_loss did not improve from 0.45223
Epoch 42/60
 - 5s - loss: 0.6069 - acc: 0.8068 - val_loss: 0.4599 - val_acc: 0.8575

Epoch 00042: val_loss did not improve from 0.45223
Epoch 43/60
 - 5s - loss: 0.6063 - acc: 0.8051 - val_loss: 0.4566 - val_acc: 0.8489

Epoch 00043: val_loss did not improve from 0.45223
Epoch 44/60
 - 5s - loss: 0.6039 - acc: 0.8074 - val_loss: 0.4580 - val_acc: 0.8582

Epoch 00044: val_loss did not improve from 0.45223
Epoch 45/60
 - 5s - loss: 0.5957 - acc: 0.8091 - val_loss: 0.4324 - val_acc: 0.8635

Epoch 00045: val_loss improved from 0.45223 to 0.43239, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 46/60
 - 5s - loss: 0.5939 - acc: 0.8124 - val_loss: 0.4396 - val_acc: 0.8642

Epoch 00046: val_loss did not improve from 0.43239
Epoch 47/60
 - 5s - loss: 0.5990 - acc: 0.8079 - val_loss: 0.4441 - val_acc: 0.8617

Epoch 00047: val_loss did not improve from 0.43239
Epoch 48/60
 - 5s - loss: 0.5981 - acc: 0.8093 - val_loss: 0.4576 - val_acc: 0.8463

Epoch 00048: val_loss did not improve from 0.43239
Epoch 49/60
 - 5s - loss: 0.5944 - acc: 0.8110 - val_loss: 0.4403 - val_acc: 0.8628

Epoch 00049: val_loss did not improve from 0.43239
Epoch 50/60
 - 5s - loss: 0.5915 - acc: 0.8091 - val_loss: 0.4330 - val_acc: 0.8614

Epoch 00050: val_loss did not improve from 0.43239
Epoch 51/60
 - 5s - loss: 0.5879 - acc: 0.8110 - val_loss: 0.4390 - val_acc: 0.8601

Epoch 00051: val_loss did not improve from 0.43239
Epoch 52/60
 - 5s - loss: 0.5880 - acc: 0.8127 - val_loss: 0.4334 - val_acc: 0.8610

Epoch 00052: val_loss did not improve from 0.43239
Epoch 53/60
 - 5s - loss: 0.5887 - acc: 0.8113 - val_loss: 0.4347 - val_acc: 0.8601

Epoch 00053: val_loss did not improve from 0.43239
Epoch 54/60
 - 5s - loss: 0.5933 - acc: 0.8119 - val_loss: 0.4445 - val_acc: 0.8592

Epoch 00054: val_loss did not improve from 0.43239
Epoch 55/60
 - 5s - loss: 0.5869 - acc: 0.8126 - val_loss: 0.4336 - val_acc: 0.8607

Epoch 00055: val_loss did not improve from 0.43239
Epoch 00055: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 6.2138 - acc: 0.2059 - val_loss: 2.2374 - val_acc: 0.6208

Epoch 00001: val_loss improved from inf to 2.23736, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 2/60
 - 4s - loss: 2.1070 - acc: 0.4824 - val_loss: 2.1110 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.23736 to 2.11104, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 3/60
 - 4s - loss: 1.8222 - acc: 0.6207 - val_loss: 1.9223 - val_acc: 0.6209

Epoch 00003: val_loss improved from 2.11104 to 1.92228, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 4/60
 - 4s - loss: 1.6899 - acc: 0.6357 - val_loss: 1.7769 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.92228 to 1.77686, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 5/60
 - 4s - loss: 1.6129 - acc: 0.6370 - val_loss: 1.6906 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.77686 to 1.69058, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 6/60
 - 4s - loss: 1.5712 - acc: 0.6371 - val_loss: 1.6059 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.69058 to 1.60586, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 7/60
 - 4s - loss: 1.5430 - acc: 0.6371 - val_loss: 1.5502 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.60586 to 1.55019, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 8/60
 - 4s - loss: 1.5213 - acc: 0.6371 - val_loss: 1.5240 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.55019 to 1.52398, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 9/60
 - 4s - loss: 1.5043 - acc: 0.6371 - val_loss: 1.5167 - val_acc: 0.6209

Epoch 00009: val_loss improved from 1.52398 to 1.51675, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 10/60
 - 4s - loss: 1.4901 - acc: 0.6371 - val_loss: 1.5028 - val_acc: 0.6209

Epoch 00010: val_loss improved from 1.51675 to 1.50282, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 11/60
 - 4s - loss: 1.4804 - acc: 0.6371 - val_loss: 1.4833 - val_acc: 0.6209

Epoch 00011: val_loss improved from 1.50282 to 1.48335, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 12/60
 - 4s - loss: 1.4726 - acc: 0.6371 - val_loss: 1.4938 - val_acc: 0.6209

Epoch 00012: val_loss did not improve from 1.48335
Epoch 13/60
 - 4s - loss: 1.4539 - acc: 0.6371 - val_loss: 1.4727 - val_acc: 0.6209

Epoch 00013: val_loss improved from 1.48335 to 1.47269, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 14/60
 - 4s - loss: 1.4438 - acc: 0.6371 - val_loss: 1.4627 - val_acc: 0.6209

Epoch 00014: val_loss improved from 1.47269 to 1.46267, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 15/60
 - 4s - loss: 1.4335 - acc: 0.6371 - val_loss: 1.4820 - val_acc: 0.6209

Epoch 00015: val_loss did not improve from 1.46267
Epoch 16/60
 - 4s - loss: 1.4202 - acc: 0.6371 - val_loss: 1.4411 - val_acc: 0.6209

Epoch 00016: val_loss improved from 1.46267 to 1.44105, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 17/60
 - 4s - loss: 1.4117 - acc: 0.6371 - val_loss: 1.4608 - val_acc: 0.6209

Epoch 00017: val_loss did not improve from 1.44105
Epoch 18/60
 - 4s - loss: 1.4052 - acc: 0.6371 - val_loss: 1.4627 - val_acc: 0.6209

Epoch 00018: val_loss did not improve from 1.44105
Epoch 19/60
 - 4s - loss: 1.3947 - acc: 0.6371 - val_loss: 1.4421 - val_acc: 0.6209

Epoch 00019: val_loss did not improve from 1.44105
Epoch 20/60
 - 4s - loss: 1.3856 - acc: 0.6371 - val_loss: 1.4217 - val_acc: 0.6209

Epoch 00020: val_loss improved from 1.44105 to 1.42170, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 21/60
 - 4s - loss: 1.3787 - acc: 0.6371 - val_loss: 1.4372 - val_acc: 0.6209

Epoch 00021: val_loss did not improve from 1.42170
Epoch 22/60
 - 4s - loss: 1.3729 - acc: 0.6371 - val_loss: 1.3927 - val_acc: 0.6209

Epoch 00022: val_loss improved from 1.42170 to 1.39268, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 23/60
 - 4s - loss: 1.3678 - acc: 0.6371 - val_loss: 1.4043 - val_acc: 0.6209

Epoch 00023: val_loss did not improve from 1.39268
Epoch 24/60
 - 4s - loss: 1.3628 - acc: 0.6371 - val_loss: 1.4058 - val_acc: 0.6209

Epoch 00024: val_loss did not improve from 1.39268
Epoch 25/60
 - 4s - loss: 1.3571 - acc: 0.6371 - val_loss: 1.4321 - val_acc: 0.6209

Epoch 00025: val_loss did not improve from 1.39268
Epoch 26/60
 - 4s - loss: 1.3538 - acc: 0.6371 - val_loss: 1.3994 - val_acc: 0.6209

Epoch 00026: val_loss did not improve from 1.39268
Epoch 27/60
 - 4s - loss: 1.3516 - acc: 0.6371 - val_loss: 1.4114 - val_acc: 0.6209

Epoch 00027: val_loss did not improve from 1.39268
Epoch 28/60
 - 4s - loss: 1.3486 - acc: 0.6371 - val_loss: 1.4150 - val_acc: 0.6209

Epoch 00028: val_loss did not improve from 1.39268
Epoch 29/60
 - 4s - loss: 1.3422 - acc: 0.6371 - val_loss: 1.3650 - val_acc: 0.6209

Epoch 00029: val_loss improved from 1.39268 to 1.36500, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 30/60
 - 4s - loss: 1.3423 - acc: 0.6371 - val_loss: 1.3893 - val_acc: 0.6209

Epoch 00030: val_loss did not improve from 1.36500
Epoch 31/60
 - 4s - loss: 1.3385 - acc: 0.6371 - val_loss: 1.3613 - val_acc: 0.6209

Epoch 00031: val_loss improved from 1.36500 to 1.36129, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 32/60
 - 4s - loss: 1.3399 - acc: 0.6371 - val_loss: 1.4109 - val_acc: 0.6209

Epoch 00032: val_loss did not improve from 1.36129
Epoch 33/60
 - 4s - loss: 1.3384 - acc: 0.6371 - val_loss: 1.3828 - val_acc: 0.6209

Epoch 00033: val_loss did not improve from 1.36129
Epoch 34/60
 - 4s - loss: 1.3328 - acc: 0.6371 - val_loss: 1.4214 - val_acc: 0.6209

Epoch 00034: val_loss did not improve from 1.36129
Epoch 35/60
 - 4s - loss: 1.3284 - acc: 0.6371 - val_loss: 1.4204 - val_acc: 0.6209

Epoch 00035: val_loss did not improve from 1.36129
Epoch 36/60
 - 4s - loss: 1.3302 - acc: 0.6371 - val_loss: 1.4096 - val_acc: 0.6209

Epoch 00036: val_loss did not improve from 1.36129
Epoch 37/60
 - 4s - loss: 1.3293 - acc: 0.6371 - val_loss: 1.3846 - val_acc: 0.6209

Epoch 00037: val_loss did not improve from 1.36129
Epoch 38/60
 - 4s - loss: 1.3264 - acc: 0.6371 - val_loss: 1.3506 - val_acc: 0.6209

Epoch 00038: val_loss improved from 1.36129 to 1.35059, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 39/60
 - 4s - loss: 1.3249 - acc: 0.6371 - val_loss: 1.3463 - val_acc: 0.6209

Epoch 00039: val_loss improved from 1.35059 to 1.34629, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 40/60
 - 4s - loss: 1.3249 - acc: 0.6371 - val_loss: 1.3892 - val_acc: 0.6209

Epoch 00040: val_loss did not improve from 1.34629
Epoch 41/60
 - 4s - loss: 1.3215 - acc: 0.6371 - val_loss: 1.4163 - val_acc: 0.6209

Epoch 00041: val_loss did not improve from 1.34629
Epoch 42/60
 - 4s - loss: 1.3219 - acc: 0.6371 - val_loss: 1.3862 - val_acc: 0.6209

Epoch 00042: val_loss did not improve from 1.34629
Epoch 43/60
 - 4s - loss: 1.3180 - acc: 0.6372 - val_loss: 1.3928 - val_acc: 0.6209

Epoch 00043: val_loss did not improve from 1.34629
Epoch 44/60
 - 4s - loss: 1.3213 - acc: 0.6371 - val_loss: 1.3888 - val_acc: 0.6209

Epoch 00044: val_loss did not improve from 1.34629
Epoch 45/60
 - 4s - loss: 1.3187 - acc: 0.6371 - val_loss: 1.4202 - val_acc: 0.6209

Epoch 00045: val_loss did not improve from 1.34629
Epoch 46/60
 - 4s - loss: 1.3201 - acc: 0.6371 - val_loss: 1.3920 - val_acc: 0.6209

Epoch 00046: val_loss did not improve from 1.34629
Epoch 47/60
 - 4s - loss: 1.3168 - acc: 0.6371 - val_loss: 1.4015 - val_acc: 0.6209

Epoch 00047: val_loss did not improve from 1.34629
Epoch 48/60
 - 4s - loss: 1.3156 - acc: 0.6371 - val_loss: 1.3885 - val_acc: 0.6209

Epoch 00048: val_loss did not improve from 1.34629
Epoch 49/60
 - 4s - loss: 1.3142 - acc: 0.6371 - val_loss: 1.4111 - val_acc: 0.6209

Epoch 00049: val_loss did not improve from 1.34629
Epoch 00049: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 3.3535 - acc: 0.5072 - val_loss: 2.2641 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 2.26415, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 2/60
 - 5s - loss: 1.6840 - acc: 0.6268 - val_loss: 2.1629 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.26415 to 2.16288, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 3/60
 - 5s - loss: 1.5713 - acc: 0.6369 - val_loss: 2.0255 - val_acc: 0.6209

Epoch 00003: val_loss improved from 2.16288 to 2.02546, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 4/60
 - 5s - loss: 1.5271 - acc: 0.6371 - val_loss: 1.9107 - val_acc: 0.6209

Epoch 00004: val_loss improved from 2.02546 to 1.91065, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 5/60
 - 5s - loss: 1.4953 - acc: 0.6371 - val_loss: 1.8263 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.91065 to 1.82628, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 6/60
 - 5s - loss: 1.4717 - acc: 0.6371 - val_loss: 1.7225 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.82628 to 1.72250, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 7/60
 - 5s - loss: 1.4515 - acc: 0.6371 - val_loss: 1.6806 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.72250 to 1.68064, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 8/60
 - 5s - loss: 1.4310 - acc: 0.6371 - val_loss: 1.5866 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.68064 to 1.58663, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 9/60
 - 5s - loss: 1.4016 - acc: 0.6371 - val_loss: 1.5842 - val_acc: 0.6209

Epoch 00009: val_loss improved from 1.58663 to 1.58419, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 10/60
 - 5s - loss: 1.3828 - acc: 0.6371 - val_loss: 1.5373 - val_acc: 0.6209

Epoch 00010: val_loss improved from 1.58419 to 1.53726, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 11/60
 - 5s - loss: 1.3629 - acc: 0.6372 - val_loss: 1.5529 - val_acc: 0.6209

Epoch 00011: val_loss did not improve from 1.53726
Epoch 12/60
 - 5s - loss: 1.3435 - acc: 0.6371 - val_loss: 1.4619 - val_acc: 0.6212

Epoch 00012: val_loss improved from 1.53726 to 1.46193, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 13/60
 - 5s - loss: 1.3178 - acc: 0.6378 - val_loss: 1.4630 - val_acc: 0.6239

Epoch 00013: val_loss did not improve from 1.46193
Epoch 14/60
 - 5s - loss: 1.2945 - acc: 0.6388 - val_loss: 1.3901 - val_acc: 0.6228

Epoch 00014: val_loss improved from 1.46193 to 1.39006, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 15/60
 - 5s - loss: 1.2767 - acc: 0.6402 - val_loss: 1.3761 - val_acc: 0.6249

Epoch 00015: val_loss improved from 1.39006 to 1.37609, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 16/60
 - 5s - loss: 1.2607 - acc: 0.6408 - val_loss: 1.3344 - val_acc: 0.6228

Epoch 00016: val_loss improved from 1.37609 to 1.33444, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 17/60
 - 5s - loss: 1.2505 - acc: 0.6413 - val_loss: 1.3318 - val_acc: 0.6286

Epoch 00017: val_loss improved from 1.33444 to 1.33185, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 18/60
 - 5s - loss: 1.2366 - acc: 0.6429 - val_loss: 1.2728 - val_acc: 0.6252

Epoch 00018: val_loss improved from 1.33185 to 1.27280, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 19/60
 - 5s - loss: 1.2208 - acc: 0.6449 - val_loss: 1.2580 - val_acc: 0.6274

Epoch 00019: val_loss improved from 1.27280 to 1.25801, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 20/60
 - 5s - loss: 1.2118 - acc: 0.6465 - val_loss: 1.2875 - val_acc: 0.6275

Epoch 00020: val_loss did not improve from 1.25801
Epoch 21/60
 - 5s - loss: 1.2027 - acc: 0.6463 - val_loss: 1.2705 - val_acc: 0.6274

Epoch 00021: val_loss did not improve from 1.25801
Epoch 22/60
 - 5s - loss: 1.1962 - acc: 0.6478 - val_loss: 1.2473 - val_acc: 0.6334

Epoch 00022: val_loss improved from 1.25801 to 1.24726, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 23/60
 - 5s - loss: 1.1871 - acc: 0.6485 - val_loss: 1.2641 - val_acc: 0.6302

Epoch 00023: val_loss did not improve from 1.24726
Epoch 24/60
 - 5s - loss: 1.1795 - acc: 0.6505 - val_loss: 1.2893 - val_acc: 0.6339

Epoch 00024: val_loss did not improve from 1.24726
Epoch 25/60
 - 5s - loss: 1.1697 - acc: 0.6530 - val_loss: 1.2218 - val_acc: 0.6343

Epoch 00025: val_loss improved from 1.24726 to 1.22176, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 26/60
 - 5s - loss: 1.1665 - acc: 0.6502 - val_loss: 1.2763 - val_acc: 0.6422

Epoch 00026: val_loss did not improve from 1.22176
Epoch 27/60
 - 5s - loss: 1.1567 - acc: 0.6508 - val_loss: 1.2528 - val_acc: 0.6365

Epoch 00027: val_loss did not improve from 1.22176
Epoch 28/60
 - 5s - loss: 1.1504 - acc: 0.6553 - val_loss: 1.1686 - val_acc: 0.6396

Epoch 00028: val_loss improved from 1.22176 to 1.16861, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 29/60
 - 5s - loss: 1.1479 - acc: 0.6565 - val_loss: 1.1450 - val_acc: 0.6442

Epoch 00029: val_loss improved from 1.16861 to 1.14496, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 30/60
 - 5s - loss: 1.1433 - acc: 0.6558 - val_loss: 1.2022 - val_acc: 0.6486

Epoch 00030: val_loss did not improve from 1.14496
Epoch 31/60
 - 5s - loss: 1.1380 - acc: 0.6566 - val_loss: 1.2253 - val_acc: 0.6481

Epoch 00031: val_loss did not improve from 1.14496
Epoch 32/60
 - 5s - loss: 1.1329 - acc: 0.6590 - val_loss: 1.1862 - val_acc: 0.6502

Epoch 00032: val_loss did not improve from 1.14496
Epoch 33/60
 - 5s - loss: 1.1323 - acc: 0.6567 - val_loss: 1.1826 - val_acc: 0.6492

Epoch 00033: val_loss did not improve from 1.14496
Epoch 34/60
 - 5s - loss: 1.1290 - acc: 0.6586 - val_loss: 1.1652 - val_acc: 0.6471

Epoch 00034: val_loss did not improve from 1.14496
Epoch 35/60
 - 5s - loss: 1.1243 - acc: 0.6582 - val_loss: 1.1578 - val_acc: 0.6449

Epoch 00035: val_loss did not improve from 1.14496
Epoch 36/60
 - 5s - loss: 1.1189 - acc: 0.6609 - val_loss: 1.1414 - val_acc: 0.6486

Epoch 00036: val_loss improved from 1.14496 to 1.14141, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 37/60
 - 5s - loss: 1.1133 - acc: 0.6595 - val_loss: 1.1860 - val_acc: 0.6553

Epoch 00037: val_loss did not improve from 1.14141
Epoch 38/60
 - 5s - loss: 1.1129 - acc: 0.6602 - val_loss: 1.1185 - val_acc: 0.6534

Epoch 00038: val_loss improved from 1.14141 to 1.11845, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 39/60
 - 5s - loss: 1.1105 - acc: 0.6600 - val_loss: 1.1641 - val_acc: 0.6555

Epoch 00039: val_loss did not improve from 1.11845
Epoch 40/60
 - 5s - loss: 1.1071 - acc: 0.6610 - val_loss: 1.1009 - val_acc: 0.6496

Epoch 00040: val_loss improved from 1.11845 to 1.10087, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 41/60
 - 5s - loss: 1.1031 - acc: 0.6610 - val_loss: 1.1059 - val_acc: 0.6586

Epoch 00041: val_loss did not improve from 1.10087
Epoch 42/60
 - 5s - loss: 1.0973 - acc: 0.6624 - val_loss: 1.1506 - val_acc: 0.6550

Epoch 00042: val_loss did not improve from 1.10087
Epoch 43/60
 - 5s - loss: 1.0962 - acc: 0.6628 - val_loss: 1.1357 - val_acc: 0.6586

Epoch 00043: val_loss did not improve from 1.10087
Epoch 44/60
 - 5s - loss: 1.0936 - acc: 0.6634 - val_loss: 1.0767 - val_acc: 0.6586

Epoch 00044: val_loss improved from 1.10087 to 1.07668, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 45/60
 - 5s - loss: 1.0900 - acc: 0.6643 - val_loss: 1.0831 - val_acc: 0.6587

Epoch 00045: val_loss did not improve from 1.07668
Epoch 46/60
 - 5s - loss: 1.0873 - acc: 0.6650 - val_loss: 1.0802 - val_acc: 0.6574

Epoch 00046: val_loss did not improve from 1.07668
Epoch 47/60
 - 5s - loss: 1.0888 - acc: 0.6637 - val_loss: 1.0948 - val_acc: 0.6543

Epoch 00047: val_loss did not improve from 1.07668
Epoch 48/60
 - 5s - loss: 1.0837 - acc: 0.6647 - val_loss: 1.0475 - val_acc: 0.6649

Epoch 00048: val_loss improved from 1.07668 to 1.04752, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 49/60
 - 5s - loss: 1.0810 - acc: 0.6653 - val_loss: 1.1126 - val_acc: 0.6665

Epoch 00049: val_loss did not improve from 1.04752
Epoch 50/60
 - 5s - loss: 1.0785 - acc: 0.6652 - val_loss: 1.0729 - val_acc: 0.6652

Epoch 00050: val_loss did not improve from 1.04752
Epoch 51/60
 - 5s - loss: 1.0799 - acc: 0.6668 - val_loss: 1.1266 - val_acc: 0.6625

Epoch 00051: val_loss did not improve from 1.04752
Epoch 52/60
 - 5s - loss: 1.0741 - acc: 0.6652 - val_loss: 1.0485 - val_acc: 0.6608

Epoch 00052: val_loss did not improve from 1.04752
Epoch 53/60
 - 5s - loss: 1.0738 - acc: 0.6648 - val_loss: 1.0134 - val_acc: 0.6705

Epoch 00053: val_loss improved from 1.04752 to 1.01344, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 54/60
 - 5s - loss: 1.0701 - acc: 0.6666 - val_loss: 1.0517 - val_acc: 0.6612

Epoch 00054: val_loss did not improve from 1.01344
Epoch 55/60
 - 5s - loss: 1.0663 - acc: 0.6685 - val_loss: 1.0589 - val_acc: 0.6709

Epoch 00055: val_loss did not improve from 1.01344
Epoch 56/60
 - 5s - loss: 1.0671 - acc: 0.6685 - val_loss: 1.0342 - val_acc: 0.6721

Epoch 00056: val_loss did not improve from 1.01344
Epoch 57/60
 - 5s - loss: 1.0662 - acc: 0.6668 - val_loss: 1.0231 - val_acc: 0.6662

Epoch 00057: val_loss did not improve from 1.01344
Epoch 58/60
 - 5s - loss: 1.0661 - acc: 0.6672 - val_loss: 0.9901 - val_acc: 0.6737

Epoch 00058: val_loss improved from 1.01344 to 0.99013, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5
Epoch 59/60
 - 5s - loss: 1.0683 - acc: 0.6668 - val_loss: 0.9909 - val_acc: 0.6745

Epoch 00059: val_loss did not improve from 0.99013
Epoch 60/60
 - 5s - loss: 1.0621 - acc: 0.6681 - val_loss: 1.0203 - val_acc: 0.6643

Epoch 00060: val_loss did not improve from 0.99013
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 2.3451 - acc: 0.5578 - val_loss: 1.3763 - val_acc: 0.6374

Epoch 00001: val_loss improved from inf to 1.37629, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 2/60
 - 5s - loss: 1.3450 - acc: 0.6349 - val_loss: 1.0806 - val_acc: 0.6658

Epoch 00002: val_loss improved from 1.37629 to 1.08060, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 3/60
 - 5s - loss: 1.1991 - acc: 0.6498 - val_loss: 0.9932 - val_acc: 0.6836

Epoch 00003: val_loss improved from 1.08060 to 0.99321, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 4/60
 - 5s - loss: 1.1044 - acc: 0.6675 - val_loss: 0.8981 - val_acc: 0.7064

Epoch 00004: val_loss improved from 0.99321 to 0.89806, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 5/60
 - 5s - loss: 1.0391 - acc: 0.6781 - val_loss: 0.8778 - val_acc: 0.7126

Epoch 00005: val_loss improved from 0.89806 to 0.87784, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 6/60
 - 5s - loss: 0.9796 - acc: 0.6921 - val_loss: 0.8245 - val_acc: 0.7410

Epoch 00006: val_loss improved from 0.87784 to 0.82446, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 7/60
 - 5s - loss: 0.9285 - acc: 0.7029 - val_loss: 0.7212 - val_acc: 0.7602

Epoch 00007: val_loss improved from 0.82446 to 0.72124, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 8/60
 - 5s - loss: 0.8919 - acc: 0.7155 - val_loss: 0.7016 - val_acc: 0.7799

Epoch 00008: val_loss improved from 0.72124 to 0.70157, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 9/60
 - 5s - loss: 0.8636 - acc: 0.7240 - val_loss: 0.6727 - val_acc: 0.7851

Epoch 00009: val_loss improved from 0.70157 to 0.67269, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 10/60
 - 5s - loss: 0.8306 - acc: 0.7365 - val_loss: 0.6488 - val_acc: 0.8013

Epoch 00010: val_loss improved from 0.67269 to 0.64877, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 11/60
 - 5s - loss: 0.8114 - acc: 0.7403 - val_loss: 0.6195 - val_acc: 0.8016

Epoch 00011: val_loss improved from 0.64877 to 0.61954, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 12/60
 - 5s - loss: 0.7909 - acc: 0.7463 - val_loss: 0.5871 - val_acc: 0.8208

Epoch 00012: val_loss improved from 0.61954 to 0.58712, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 13/60
 - 5s - loss: 0.7774 - acc: 0.7511 - val_loss: 0.6052 - val_acc: 0.7954

Epoch 00013: val_loss did not improve from 0.58712
Epoch 14/60
 - 5s - loss: 0.7644 - acc: 0.7553 - val_loss: 0.5923 - val_acc: 0.7971

Epoch 00014: val_loss did not improve from 0.58712
Epoch 15/60
 - 5s - loss: 0.7537 - acc: 0.7605 - val_loss: 0.5810 - val_acc: 0.8094

Epoch 00015: val_loss improved from 0.58712 to 0.58096, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 16/60
 - 5s - loss: 0.7365 - acc: 0.7623 - val_loss: 0.5596 - val_acc: 0.8201

Epoch 00016: val_loss improved from 0.58096 to 0.55962, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 17/60
 - 5s - loss: 0.7247 - acc: 0.7678 - val_loss: 0.5629 - val_acc: 0.8214

Epoch 00017: val_loss did not improve from 0.55962
Epoch 18/60
 - 5s - loss: 0.7192 - acc: 0.7710 - val_loss: 0.5349 - val_acc: 0.8264

Epoch 00018: val_loss improved from 0.55962 to 0.53486, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 19/60
 - 5s - loss: 0.7152 - acc: 0.7725 - val_loss: 0.5269 - val_acc: 0.8348

Epoch 00019: val_loss improved from 0.53486 to 0.52689, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 20/60
 - 5s - loss: 0.7010 - acc: 0.7736 - val_loss: 0.5249 - val_acc: 0.8288

Epoch 00020: val_loss improved from 0.52689 to 0.52491, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 21/60
 - 5s - loss: 0.6981 - acc: 0.7772 - val_loss: 0.5197 - val_acc: 0.8330

Epoch 00021: val_loss improved from 0.52491 to 0.51970, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 22/60
 - 5s - loss: 0.6878 - acc: 0.7808 - val_loss: 0.5209 - val_acc: 0.8363

Epoch 00022: val_loss did not improve from 0.51970
Epoch 23/60
 - 5s - loss: 0.6807 - acc: 0.7821 - val_loss: 0.5115 - val_acc: 0.8325

Epoch 00023: val_loss improved from 0.51970 to 0.51155, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 24/60
 - 5s - loss: 0.6814 - acc: 0.7816 - val_loss: 0.5042 - val_acc: 0.8414

Epoch 00024: val_loss improved from 0.51155 to 0.50423, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 25/60
 - 5s - loss: 0.6755 - acc: 0.7838 - val_loss: 0.4992 - val_acc: 0.8528

Epoch 00025: val_loss improved from 0.50423 to 0.49919, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 26/60
 - 5s - loss: 0.6657 - acc: 0.7858 - val_loss: 0.4892 - val_acc: 0.8407

Epoch 00026: val_loss improved from 0.49919 to 0.48923, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 27/60
 - 5s - loss: 0.6615 - acc: 0.7869 - val_loss: 0.5103 - val_acc: 0.8479

Epoch 00027: val_loss did not improve from 0.48923
Epoch 28/60
 - 5s - loss: 0.6572 - acc: 0.7864 - val_loss: 0.4867 - val_acc: 0.8457

Epoch 00028: val_loss improved from 0.48923 to 0.48670, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 29/60
 - 5s - loss: 0.6582 - acc: 0.7886 - val_loss: 0.4872 - val_acc: 0.8438

Epoch 00029: val_loss did not improve from 0.48670
Epoch 30/60
 - 5s - loss: 0.6546 - acc: 0.7915 - val_loss: 0.5244 - val_acc: 0.8395

Epoch 00030: val_loss did not improve from 0.48670
Epoch 31/60
 - 5s - loss: 0.6537 - acc: 0.7896 - val_loss: 0.4667 - val_acc: 0.8495

Epoch 00031: val_loss improved from 0.48670 to 0.46672, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 32/60
 - 5s - loss: 0.6469 - acc: 0.7919 - val_loss: 0.4915 - val_acc: 0.8477

Epoch 00032: val_loss did not improve from 0.46672
Epoch 33/60
 - 5s - loss: 0.6429 - acc: 0.7944 - val_loss: 0.4834 - val_acc: 0.8485

Epoch 00033: val_loss did not improve from 0.46672
Epoch 34/60
 - 5s - loss: 0.6341 - acc: 0.7969 - val_loss: 0.4772 - val_acc: 0.8397

Epoch 00034: val_loss did not improve from 0.46672
Epoch 35/60
 - 5s - loss: 0.6340 - acc: 0.7978 - val_loss: 0.4567 - val_acc: 0.8563

Epoch 00035: val_loss improved from 0.46672 to 0.45673, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 36/60
 - 5s - loss: 0.6353 - acc: 0.7983 - val_loss: 0.4606 - val_acc: 0.8504

Epoch 00036: val_loss did not improve from 0.45673
Epoch 37/60
 - 5s - loss: 0.6325 - acc: 0.7973 - val_loss: 0.4693 - val_acc: 0.8591

Epoch 00037: val_loss did not improve from 0.45673
Epoch 38/60
 - 5s - loss: 0.6322 - acc: 0.7969 - val_loss: 0.4678 - val_acc: 0.8482

Epoch 00038: val_loss did not improve from 0.45673
Epoch 39/60
 - 5s - loss: 0.6266 - acc: 0.8001 - val_loss: 0.4613 - val_acc: 0.8530

Epoch 00039: val_loss did not improve from 0.45673
Epoch 40/60
 - 5s - loss: 0.6221 - acc: 0.8023 - val_loss: 0.4550 - val_acc: 0.8580

Epoch 00040: val_loss improved from 0.45673 to 0.45503, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 41/60
 - 5s - loss: 0.6182 - acc: 0.8025 - val_loss: 0.4598 - val_acc: 0.8505

Epoch 00041: val_loss did not improve from 0.45503
Epoch 42/60
 - 5s - loss: 0.6146 - acc: 0.8035 - val_loss: 0.4433 - val_acc: 0.8635

Epoch 00042: val_loss improved from 0.45503 to 0.44325, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 43/60
 - 5s - loss: 0.6151 - acc: 0.8038 - val_loss: 0.4537 - val_acc: 0.8582

Epoch 00043: val_loss did not improve from 0.44325
Epoch 44/60
 - 5s - loss: 0.6140 - acc: 0.8030 - val_loss: 0.4493 - val_acc: 0.8601

Epoch 00044: val_loss did not improve from 0.44325
Epoch 45/60
 - 5s - loss: 0.6106 - acc: 0.8058 - val_loss: 0.4486 - val_acc: 0.8476

Epoch 00045: val_loss did not improve from 0.44325
Epoch 46/60
 - 5s - loss: 0.6068 - acc: 0.8050 - val_loss: 0.4440 - val_acc: 0.8617

Epoch 00046: val_loss did not improve from 0.44325
Epoch 47/60
 - 5s - loss: 0.6068 - acc: 0.8071 - val_loss: 0.4578 - val_acc: 0.8575

Epoch 00047: val_loss did not improve from 0.44325
Epoch 48/60
 - 5s - loss: 0.6100 - acc: 0.8042 - val_loss: 0.4558 - val_acc: 0.8561

Epoch 00048: val_loss did not improve from 0.44325
Epoch 49/60
 - 5s - loss: 0.6076 - acc: 0.8077 - val_loss: 0.4463 - val_acc: 0.8636

Epoch 00049: val_loss did not improve from 0.44325
Epoch 50/60
 - 5s - loss: 0.6024 - acc: 0.8065 - val_loss: 0.4492 - val_acc: 0.8520

Epoch 00050: val_loss did not improve from 0.44325
Epoch 51/60
 - 5s - loss: 0.6032 - acc: 0.8049 - val_loss: 0.4475 - val_acc: 0.8561

Epoch 00051: val_loss did not improve from 0.44325
Epoch 52/60
 - 5s - loss: 0.6027 - acc: 0.8082 - val_loss: 0.4362 - val_acc: 0.8635

Epoch 00052: val_loss improved from 0.44325 to 0.43620, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 53/60
 - 5s - loss: 0.6013 - acc: 0.8072 - val_loss: 0.4532 - val_acc: 0.8519

Epoch 00053: val_loss did not improve from 0.43620
Epoch 54/60
 - 5s - loss: 0.5983 - acc: 0.8085 - val_loss: 0.4386 - val_acc: 0.8664

Epoch 00054: val_loss did not improve from 0.43620
Epoch 55/60
 - 5s - loss: 0.5939 - acc: 0.8084 - val_loss: 0.4423 - val_acc: 0.8633

Epoch 00055: val_loss did not improve from 0.43620
Epoch 56/60
 - 5s - loss: 0.5936 - acc: 0.8104 - val_loss: 0.4434 - val_acc: 0.8558

Epoch 00056: val_loss did not improve from 0.43620
Epoch 57/60
 - 5s - loss: 0.5929 - acc: 0.8086 - val_loss: 0.4548 - val_acc: 0.8567

Epoch 00057: val_loss did not improve from 0.43620
Epoch 58/60
 - 5s - loss: 0.5834 - acc: 0.8129 - val_loss: 0.4339 - val_acc: 0.8653

Epoch 00058: val_loss improved from 0.43620 to 0.43387, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 59/60
 - 5s - loss: 0.5850 - acc: 0.8127 - val_loss: 0.4347 - val_acc: 0.8655

Epoch 00059: val_loss did not improve from 0.43387
Epoch 60/60
 - 5s - loss: 0.5887 - acc: 0.8110 - val_loss: 0.4232 - val_acc: 0.8667

Epoch 00060: val_loss improved from 0.43387 to 0.42316, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 8s - loss: 4.2611 - acc: 0.2126 - val_loss: 2.2587 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 2.25866, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 2/60
 - 4s - loss: 1.9894 - acc: 0.5181 - val_loss: 2.1013 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.25866 to 2.10134, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 3/60
 - 4s - loss: 1.7804 - acc: 0.6267 - val_loss: 1.9559 - val_acc: 0.6209

Epoch 00003: val_loss improved from 2.10134 to 1.95592, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 4/60
 - 4s - loss: 1.6682 - acc: 0.6365 - val_loss: 1.7906 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.95592 to 1.79063, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 5/60
 - 4s - loss: 1.5977 - acc: 0.6370 - val_loss: 1.6821 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.79063 to 1.68205, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 6/60
 - 4s - loss: 1.5556 - acc: 0.6371 - val_loss: 1.6317 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.68205 to 1.63165, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 7/60
 - 4s - loss: 1.5306 - acc: 0.6371 - val_loss: 1.6000 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.63165 to 1.59999, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 8/60
 - 4s - loss: 1.5133 - acc: 0.6371 - val_loss: 1.5644 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.59999 to 1.56441, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 9/60
 - 4s - loss: 1.4931 - acc: 0.6371 - val_loss: 1.5655 - val_acc: 0.6209

Epoch 00009: val_loss did not improve from 1.56441
Epoch 10/60
 - 4s - loss: 1.4761 - acc: 0.6371 - val_loss: 1.5612 - val_acc: 0.6209

Epoch 00010: val_loss improved from 1.56441 to 1.56116, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 11/60
 - 4s - loss: 1.4620 - acc: 0.6371 - val_loss: 1.5334 - val_acc: 0.6209

Epoch 00011: val_loss improved from 1.56116 to 1.53340, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 12/60
 - 4s - loss: 1.4509 - acc: 0.6371 - val_loss: 1.5257 - val_acc: 0.6209

Epoch 00012: val_loss improved from 1.53340 to 1.52571, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 13/60
 - 4s - loss: 1.4363 - acc: 0.6371 - val_loss: 1.5140 - val_acc: 0.6209

Epoch 00013: val_loss improved from 1.52571 to 1.51395, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 14/60
 - 4s - loss: 1.4262 - acc: 0.6371 - val_loss: 1.5094 - val_acc: 0.6209

Epoch 00014: val_loss improved from 1.51395 to 1.50941, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 15/60
 - 4s - loss: 1.4151 - acc: 0.6371 - val_loss: 1.4654 - val_acc: 0.6209

Epoch 00015: val_loss improved from 1.50941 to 1.46537, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 16/60
 - 4s - loss: 1.4050 - acc: 0.6371 - val_loss: 1.4703 - val_acc: 0.6209

Epoch 00016: val_loss did not improve from 1.46537
Epoch 17/60
 - 4s - loss: 1.3925 - acc: 0.6371 - val_loss: 1.4754 - val_acc: 0.6209

Epoch 00017: val_loss did not improve from 1.46537
Epoch 18/60
 - 4s - loss: 1.3867 - acc: 0.6371 - val_loss: 1.4320 - val_acc: 0.6209

Epoch 00018: val_loss improved from 1.46537 to 1.43203, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 19/60
 - 4s - loss: 1.3783 - acc: 0.6371 - val_loss: 1.4628 - val_acc: 0.6209

Epoch 00019: val_loss did not improve from 1.43203
Epoch 20/60
 - 4s - loss: 1.3724 - acc: 0.6371 - val_loss: 1.4385 - val_acc: 0.6209

Epoch 00020: val_loss did not improve from 1.43203
Epoch 21/60
 - 4s - loss: 1.3673 - acc: 0.6371 - val_loss: 1.4246 - val_acc: 0.6209

Epoch 00021: val_loss improved from 1.43203 to 1.42461, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 22/60
 - 4s - loss: 1.3642 - acc: 0.6371 - val_loss: 1.4508 - val_acc: 0.6209

Epoch 00022: val_loss did not improve from 1.42461
Epoch 23/60
 - 4s - loss: 1.3514 - acc: 0.6371 - val_loss: 1.4590 - val_acc: 0.6209

Epoch 00023: val_loss did not improve from 1.42461
Epoch 24/60
 - 4s - loss: 1.3499 - acc: 0.6371 - val_loss: 1.4454 - val_acc: 0.6209

Epoch 00024: val_loss did not improve from 1.42461
Epoch 25/60
 - 4s - loss: 1.3472 - acc: 0.6371 - val_loss: 1.4394 - val_acc: 0.6209

Epoch 00025: val_loss did not improve from 1.42461
Epoch 26/60
 - 4s - loss: 1.3418 - acc: 0.6371 - val_loss: 1.3815 - val_acc: 0.6209

Epoch 00026: val_loss improved from 1.42461 to 1.38151, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 27/60
 - 4s - loss: 1.3418 - acc: 0.6371 - val_loss: 1.3909 - val_acc: 0.6209

Epoch 00027: val_loss did not improve from 1.38151
Epoch 28/60
 - 4s - loss: 1.3386 - acc: 0.6371 - val_loss: 1.4130 - val_acc: 0.6209

Epoch 00028: val_loss did not improve from 1.38151
Epoch 29/60
 - 4s - loss: 1.3366 - acc: 0.6371 - val_loss: 1.4227 - val_acc: 0.6209

Epoch 00029: val_loss did not improve from 1.38151
Epoch 30/60
 - 4s - loss: 1.3330 - acc: 0.6371 - val_loss: 1.4349 - val_acc: 0.6209

Epoch 00030: val_loss did not improve from 1.38151
Epoch 31/60
 - 4s - loss: 1.3310 - acc: 0.6371 - val_loss: 1.3803 - val_acc: 0.6209

Epoch 00031: val_loss improved from 1.38151 to 1.38034, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 32/60
 - 4s - loss: 1.3296 - acc: 0.6371 - val_loss: 1.4148 - val_acc: 0.6209

Epoch 00032: val_loss did not improve from 1.38034
Epoch 33/60
 - 4s - loss: 1.3276 - acc: 0.6371 - val_loss: 1.3873 - val_acc: 0.6209

Epoch 00033: val_loss did not improve from 1.38034
Epoch 34/60
 - 4s - loss: 1.3274 - acc: 0.6371 - val_loss: 1.3790 - val_acc: 0.6209

Epoch 00034: val_loss improved from 1.38034 to 1.37901, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 35/60
 - 4s - loss: 1.3282 - acc: 0.6371 - val_loss: 1.3896 - val_acc: 0.6209

Epoch 00035: val_loss did not improve from 1.37901
Epoch 36/60
 - 4s - loss: 1.3258 - acc: 0.6371 - val_loss: 1.3701 - val_acc: 0.6209

Epoch 00036: val_loss improved from 1.37901 to 1.37005, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 37/60
 - 4s - loss: 1.3240 - acc: 0.6371 - val_loss: 1.3849 - val_acc: 0.6209

Epoch 00037: val_loss did not improve from 1.37005
Epoch 38/60
 - 4s - loss: 1.3192 - acc: 0.6371 - val_loss: 1.4227 - val_acc: 0.6209

Epoch 00038: val_loss did not improve from 1.37005
Epoch 39/60
 - 4s - loss: 1.3185 - acc: 0.6371 - val_loss: 1.3957 - val_acc: 0.6209

Epoch 00039: val_loss did not improve from 1.37005
Epoch 40/60
 - 4s - loss: 1.3171 - acc: 0.6371 - val_loss: 1.3475 - val_acc: 0.6209

Epoch 00040: val_loss improved from 1.37005 to 1.34748, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 41/60
 - 4s - loss: 1.3174 - acc: 0.6371 - val_loss: 1.3529 - val_acc: 0.6209

Epoch 00041: val_loss did not improve from 1.34748
Epoch 42/60
 - 4s - loss: 1.3145 - acc: 0.6371 - val_loss: 1.3723 - val_acc: 0.6209

Epoch 00042: val_loss did not improve from 1.34748
Epoch 43/60
 - 4s - loss: 1.3156 - acc: 0.6371 - val_loss: 1.3964 - val_acc: 0.6209

Epoch 00043: val_loss did not improve from 1.34748
Epoch 44/60
 - 4s - loss: 1.3128 - acc: 0.6371 - val_loss: 1.3876 - val_acc: 0.6209

Epoch 00044: val_loss did not improve from 1.34748
Epoch 45/60
 - 4s - loss: 1.3155 - acc: 0.6371 - val_loss: 1.3370 - val_acc: 0.6209

Epoch 00045: val_loss improved from 1.34748 to 1.33699, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 46/60
 - 4s - loss: 1.3129 - acc: 0.6371 - val_loss: 1.3735 - val_acc: 0.6209

Epoch 00046: val_loss did not improve from 1.33699
Epoch 47/60
 - 4s - loss: 1.3088 - acc: 0.6371 - val_loss: 1.4064 - val_acc: 0.6209

Epoch 00047: val_loss did not improve from 1.33699
Epoch 48/60
 - 4s - loss: 1.3082 - acc: 0.6371 - val_loss: 1.3346 - val_acc: 0.6209

Epoch 00048: val_loss improved from 1.33699 to 1.33457, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 49/60
 - 4s - loss: 1.3076 - acc: 0.6371 - val_loss: 1.3511 - val_acc: 0.6209

Epoch 00049: val_loss did not improve from 1.33457
Epoch 50/60
 - 4s - loss: 1.3061 - acc: 0.6371 - val_loss: 1.3676 - val_acc: 0.6209

Epoch 00050: val_loss did not improve from 1.33457
Epoch 51/60
 - 4s - loss: 1.3040 - acc: 0.6371 - val_loss: 1.3462 - val_acc: 0.6209

Epoch 00051: val_loss did not improve from 1.33457
Epoch 52/60
 - 4s - loss: 1.3044 - acc: 0.6371 - val_loss: 1.3752 - val_acc: 0.6209

Epoch 00052: val_loss did not improve from 1.33457
Epoch 53/60
 - 4s - loss: 1.3041 - acc: 0.6371 - val_loss: 1.3409 - val_acc: 0.6209

Epoch 00053: val_loss did not improve from 1.33457
Epoch 54/60
 - 4s - loss: 1.3051 - acc: 0.6371 - val_loss: 1.3319 - val_acc: 0.6209

Epoch 00054: val_loss improved from 1.33457 to 1.33189, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 55/60
 - 4s - loss: 1.3041 - acc: 0.6370 - val_loss: 1.3433 - val_acc: 0.6209

Epoch 00055: val_loss did not improve from 1.33189
Epoch 56/60
 - 4s - loss: 1.3013 - acc: 0.6371 - val_loss: 1.3629 - val_acc: 0.6209

Epoch 00056: val_loss did not improve from 1.33189
Epoch 57/60
 - 4s - loss: 1.3036 - acc: 0.6371 - val_loss: 1.3682 - val_acc: 0.6209

Epoch 00057: val_loss did not improve from 1.33189
Epoch 58/60
 - 4s - loss: 1.2998 - acc: 0.6370 - val_loss: 1.3396 - val_acc: 0.6209

Epoch 00058: val_loss did not improve from 1.33189
Epoch 59/60
 - 4s - loss: 1.3005 - acc: 0.6370 - val_loss: 1.3369 - val_acc: 0.6209

Epoch 00059: val_loss did not improve from 1.33189
Epoch 60/60
 - 4s - loss: 1.3004 - acc: 0.6371 - val_loss: 1.3578 - val_acc: 0.6209

Epoch 00060: val_loss did not improve from 1.33189
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 10s - loss: 2.5959 - acc: 0.5060 - val_loss: 2.1453 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 2.14531, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 2/60
 - 5s - loss: 1.6412 - acc: 0.6321 - val_loss: 1.9901 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.14531 to 1.99006, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 3/60
 - 5s - loss: 1.5458 - acc: 0.6370 - val_loss: 1.8656 - val_acc: 0.6209

Epoch 00003: val_loss improved from 1.99006 to 1.86564, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 4/60
 - 5s - loss: 1.5045 - acc: 0.6371 - val_loss: 1.8193 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.86564 to 1.81926, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 5/60
 - 5s - loss: 1.4788 - acc: 0.6371 - val_loss: 1.7030 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.81926 to 1.70297, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 6/60
 - 5s - loss: 1.4582 - acc: 0.6371 - val_loss: 1.6400 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.70297 to 1.63999, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 7/60
 - 5s - loss: 1.4381 - acc: 0.6371 - val_loss: 1.6307 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.63999 to 1.63072, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 8/60
 - 5s - loss: 1.4177 - acc: 0.6371 - val_loss: 1.5610 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.63072 to 1.56098, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 9/60
 - 5s - loss: 1.3987 - acc: 0.6371 - val_loss: 1.4794 - val_acc: 0.6209

Epoch 00009: val_loss improved from 1.56098 to 1.47942, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 10/60
 - 5s - loss: 1.3637 - acc: 0.6373 - val_loss: 1.4434 - val_acc: 0.6214

Epoch 00010: val_loss improved from 1.47942 to 1.44336, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 11/60
 - 5s - loss: 1.3273 - acc: 0.6364 - val_loss: 1.3930 - val_acc: 0.6224

Epoch 00011: val_loss improved from 1.44336 to 1.39303, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 12/60
 - 5s - loss: 1.3051 - acc: 0.6377 - val_loss: 1.3766 - val_acc: 0.6222

Epoch 00012: val_loss improved from 1.39303 to 1.37655, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 13/60
 - 5s - loss: 1.2868 - acc: 0.6381 - val_loss: 1.3453 - val_acc: 0.6230

Epoch 00013: val_loss improved from 1.37655 to 1.34528, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 14/60
 - 5s - loss: 1.2642 - acc: 0.6396 - val_loss: 1.3475 - val_acc: 0.6222

Epoch 00014: val_loss did not improve from 1.34528
Epoch 15/60
 - 6s - loss: 1.2569 - acc: 0.6411 - val_loss: 1.2878 - val_acc: 0.6227

Epoch 00015: val_loss improved from 1.34528 to 1.28778, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 16/60
 - 5s - loss: 1.2477 - acc: 0.6418 - val_loss: 1.3136 - val_acc: 0.6237

Epoch 00016: val_loss did not improve from 1.28778
Epoch 17/60
 - 5s - loss: 1.2386 - acc: 0.6414 - val_loss: 1.3567 - val_acc: 0.6246

Epoch 00017: val_loss did not improve from 1.28778
Epoch 18/60
 - 5s - loss: 1.2314 - acc: 0.6440 - val_loss: 1.3111 - val_acc: 0.6258

Epoch 00018: val_loss did not improve from 1.28778
Epoch 19/60
 - 5s - loss: 1.2204 - acc: 0.6435 - val_loss: 1.3348 - val_acc: 0.6231

Epoch 00019: val_loss did not improve from 1.28778
Epoch 20/60
 - 5s - loss: 1.2145 - acc: 0.6446 - val_loss: 1.2932 - val_acc: 0.6243

Epoch 00020: val_loss did not improve from 1.28778
Epoch 21/60
 - 5s - loss: 1.2100 - acc: 0.6451 - val_loss: 1.3520 - val_acc: 0.6272

Epoch 00021: val_loss did not improve from 1.28778
Epoch 22/60
 - 5s - loss: 1.2076 - acc: 0.6461 - val_loss: 1.3430 - val_acc: 0.6269

Epoch 00022: val_loss did not improve from 1.28778
Epoch 23/60
 - 5s - loss: 1.1976 - acc: 0.6475 - val_loss: 1.3270 - val_acc: 0.6293

Epoch 00023: val_loss did not improve from 1.28778
Epoch 24/60
 - 5s - loss: 1.1941 - acc: 0.6493 - val_loss: 1.3174 - val_acc: 0.6294

Epoch 00024: val_loss did not improve from 1.28778
Epoch 25/60
 - 5s - loss: 1.1905 - acc: 0.6481 - val_loss: 1.2761 - val_acc: 0.6277

Epoch 00025: val_loss improved from 1.28778 to 1.27609, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 26/60
 - 5s - loss: 1.1861 - acc: 0.6497 - val_loss: 1.2831 - val_acc: 0.6299

Epoch 00026: val_loss did not improve from 1.27609
Epoch 27/60
 - 5s - loss: 1.1795 - acc: 0.6513 - val_loss: 1.2576 - val_acc: 0.6331

Epoch 00027: val_loss improved from 1.27609 to 1.25758, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 28/60
 - 5s - loss: 1.1737 - acc: 0.6516 - val_loss: 1.2187 - val_acc: 0.6306

Epoch 00028: val_loss improved from 1.25758 to 1.21872, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 29/60
 - 5s - loss: 1.1784 - acc: 0.6508 - val_loss: 1.2259 - val_acc: 0.6411

Epoch 00029: val_loss did not improve from 1.21872
Epoch 30/60
 - 5s - loss: 1.1722 - acc: 0.6533 - val_loss: 1.2094 - val_acc: 0.6436

Epoch 00030: val_loss improved from 1.21872 to 1.20938, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 31/60
 - 5s - loss: 1.1679 - acc: 0.6528 - val_loss: 1.2910 - val_acc: 0.6397

Epoch 00031: val_loss did not improve from 1.20938
Epoch 32/60
 - 5s - loss: 1.1644 - acc: 0.6523 - val_loss: 1.2155 - val_acc: 0.6424

Epoch 00032: val_loss did not improve from 1.20938
Epoch 33/60
 - 5s - loss: 1.1634 - acc: 0.6552 - val_loss: 1.2048 - val_acc: 0.6459

Epoch 00033: val_loss improved from 1.20938 to 1.20477, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 34/60
 - 5s - loss: 1.1562 - acc: 0.6541 - val_loss: 1.2372 - val_acc: 0.6471

Epoch 00034: val_loss did not improve from 1.20477
Epoch 35/60
 - 5s - loss: 1.1551 - acc: 0.6551 - val_loss: 1.1767 - val_acc: 0.6524

Epoch 00035: val_loss improved from 1.20477 to 1.17668, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5
Epoch 36/60
 - 5s - loss: 1.1567 - acc: 0.6560 - val_loss: 1.1922 - val_acc: 0.6440

Epoch 00036: val_loss did not improve from 1.17668
Epoch 37/60
 - 5s - loss: 1.1518 - acc: 0.6561 - val_loss: 1.1933 - val_acc: 0.6545

Epoch 00037: val_loss did not improve from 1.17668
Epoch 38/60
 - 5s - loss: 1.1515 - acc: 0.6554 - val_loss: 1.2941 - val_acc: 0.6440

Epoch 00038: val_loss did not improve from 1.17668
Epoch 39/60
 - 5s - loss: 1.1477 - acc: 0.6561 - val_loss: 1.1882 - val_acc: 0.6446

Epoch 00039: val_loss did not improve from 1.17668
Epoch 40/60
 - 5s - loss: 1.1464 - acc: 0.6566 - val_loss: 1.2113 - val_acc: 0.6447

Epoch 00040: val_loss did not improve from 1.17668
Epoch 41/60
 - 5s - loss: 1.1444 - acc: 0.6571 - val_loss: 1.2070 - val_acc: 0.6506

Epoch 00041: val_loss did not improve from 1.17668
Epoch 42/60
 - 5s - loss: 1.1428 - acc: 0.6584 - val_loss: 1.2080 - val_acc: 0.6489

Epoch 00042: val_loss did not improve from 1.17668
Epoch 43/60
 - 5s - loss: 1.1370 - acc: 0.6580 - val_loss: 1.2432 - val_acc: 0.6425

Epoch 00043: val_loss did not improve from 1.17668
Epoch 44/60
 - 5s - loss: 1.1397 - acc: 0.6580 - val_loss: 1.1898 - val_acc: 0.6542

Epoch 00044: val_loss did not improve from 1.17668
Epoch 45/60
 - 5s - loss: 1.1318 - acc: 0.6600 - val_loss: 1.1970 - val_acc: 0.6489

Epoch 00045: val_loss did not improve from 1.17668
Epoch 00045: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 2.1699 - acc: 0.5612 - val_loss: 1.2892 - val_acc: 0.6345

Epoch 00001: val_loss improved from inf to 1.28920, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 2/60
 - 5s - loss: 1.3485 - acc: 0.6378 - val_loss: 1.1220 - val_acc: 0.6677

Epoch 00002: val_loss improved from 1.28920 to 1.12200, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 3/60
 - 5s - loss: 1.2041 - acc: 0.6540 - val_loss: 0.9738 - val_acc: 0.6895

Epoch 00003: val_loss improved from 1.12200 to 0.97381, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 4/60
 - 5s - loss: 1.1047 - acc: 0.6694 - val_loss: 0.8986 - val_acc: 0.6952

Epoch 00004: val_loss improved from 0.97381 to 0.89859, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 5/60
 - 5s - loss: 1.0315 - acc: 0.6834 - val_loss: 0.8386 - val_acc: 0.7427

Epoch 00005: val_loss improved from 0.89859 to 0.83857, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 6/60
 - 5s - loss: 0.9682 - acc: 0.6977 - val_loss: 0.7456 - val_acc: 0.7436

Epoch 00006: val_loss improved from 0.83857 to 0.74560, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 7/60
 - 5s - loss: 0.9267 - acc: 0.7086 - val_loss: 0.7159 - val_acc: 0.7552

Epoch 00007: val_loss improved from 0.74560 to 0.71585, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 8/60
 - 5s - loss: 0.8881 - acc: 0.7190 - val_loss: 0.6678 - val_acc: 0.7929

Epoch 00008: val_loss improved from 0.71585 to 0.66782, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 9/60
 - 5s - loss: 0.8510 - acc: 0.7292 - val_loss: 0.6685 - val_acc: 0.7873

Epoch 00009: val_loss did not improve from 0.66782
Epoch 10/60
 - 5s - loss: 0.8294 - acc: 0.7350 - val_loss: 0.6661 - val_acc: 0.8017

Epoch 00010: val_loss improved from 0.66782 to 0.66606, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 11/60
 - 5s - loss: 0.8092 - acc: 0.7430 - val_loss: 0.6221 - val_acc: 0.8151

Epoch 00011: val_loss improved from 0.66606 to 0.62210, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 12/60
 - 5s - loss: 0.7885 - acc: 0.7501 - val_loss: 0.5735 - val_acc: 0.8205

Epoch 00012: val_loss improved from 0.62210 to 0.57354, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 13/60
 - 5s - loss: 0.7747 - acc: 0.7528 - val_loss: 0.5895 - val_acc: 0.8242

Epoch 00013: val_loss did not improve from 0.57354
Epoch 14/60
 - 5s - loss: 0.7545 - acc: 0.7616 - val_loss: 0.5612 - val_acc: 0.8099

Epoch 00014: val_loss improved from 0.57354 to 0.56123, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 15/60
 - 5s - loss: 0.7414 - acc: 0.7629 - val_loss: 0.5582 - val_acc: 0.8274

Epoch 00015: val_loss improved from 0.56123 to 0.55821, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 16/60
 - 5s - loss: 0.7318 - acc: 0.7650 - val_loss: 0.5413 - val_acc: 0.8208

Epoch 00016: val_loss improved from 0.55821 to 0.54126, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 17/60
 - 5s - loss: 0.7220 - acc: 0.7714 - val_loss: 0.5732 - val_acc: 0.8338

Epoch 00017: val_loss did not improve from 0.54126
Epoch 18/60
 - 5s - loss: 0.7165 - acc: 0.7716 - val_loss: 0.5261 - val_acc: 0.8425

Epoch 00018: val_loss improved from 0.54126 to 0.52607, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 19/60
 - 5s - loss: 0.7043 - acc: 0.7752 - val_loss: 0.5229 - val_acc: 0.8272

Epoch 00019: val_loss improved from 0.52607 to 0.52292, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 20/60
 - 5s - loss: 0.7001 - acc: 0.7772 - val_loss: 0.5083 - val_acc: 0.8420

Epoch 00020: val_loss improved from 0.52292 to 0.50828, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 21/60
 - 5s - loss: 0.6887 - acc: 0.7785 - val_loss: 0.5110 - val_acc: 0.8347

Epoch 00021: val_loss did not improve from 0.50828
Epoch 22/60
 - 5s - loss: 0.6864 - acc: 0.7812 - val_loss: 0.5305 - val_acc: 0.8438

Epoch 00022: val_loss did not improve from 0.50828
Epoch 23/60
 - 5s - loss: 0.6791 - acc: 0.7829 - val_loss: 0.5078 - val_acc: 0.8445

Epoch 00023: val_loss improved from 0.50828 to 0.50778, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 24/60
 - 5s - loss: 0.6767 - acc: 0.7840 - val_loss: 0.4823 - val_acc: 0.8500

Epoch 00024: val_loss improved from 0.50778 to 0.48234, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 25/60
 - 6s - loss: 0.6684 - acc: 0.7855 - val_loss: 0.4986 - val_acc: 0.8438

Epoch 00025: val_loss did not improve from 0.48234
Epoch 26/60
 - 6s - loss: 0.6632 - acc: 0.7871 - val_loss: 0.4913 - val_acc: 0.8376

Epoch 00026: val_loss did not improve from 0.48234
Epoch 27/60
 - 7s - loss: 0.6614 - acc: 0.7892 - val_loss: 0.5082 - val_acc: 0.8580

Epoch 00027: val_loss did not improve from 0.48234
Epoch 28/60
 - 5s - loss: 0.6547 - acc: 0.7905 - val_loss: 0.4784 - val_acc: 0.8420

Epoch 00028: val_loss improved from 0.48234 to 0.47845, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 29/60
 - 5s - loss: 0.6540 - acc: 0.7914 - val_loss: 0.4644 - val_acc: 0.8547

Epoch 00029: val_loss improved from 0.47845 to 0.46444, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 30/60
 - 5s - loss: 0.6468 - acc: 0.7928 - val_loss: 0.4583 - val_acc: 0.8575

Epoch 00030: val_loss improved from 0.46444 to 0.45831, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 31/60
 - 5s - loss: 0.6447 - acc: 0.7940 - val_loss: 0.4701 - val_acc: 0.8573

Epoch 00031: val_loss did not improve from 0.45831
Epoch 32/60
 - 5s - loss: 0.6398 - acc: 0.7960 - val_loss: 0.4699 - val_acc: 0.8504

Epoch 00032: val_loss did not improve from 0.45831
Epoch 33/60
 - 5s - loss: 0.6450 - acc: 0.7957 - val_loss: 0.4781 - val_acc: 0.8575

Epoch 00033: val_loss did not improve from 0.45831
Epoch 34/60
 - 5s - loss: 0.6313 - acc: 0.7978 - val_loss: 0.4695 - val_acc: 0.8517

Epoch 00034: val_loss did not improve from 0.45831
Epoch 35/60
 - 5s - loss: 0.6285 - acc: 0.7992 - val_loss: 0.4705 - val_acc: 0.8604

Epoch 00035: val_loss did not improve from 0.45831
Epoch 36/60
 - 5s - loss: 0.6271 - acc: 0.8005 - val_loss: 0.4662 - val_acc: 0.8553

Epoch 00036: val_loss did not improve from 0.45831
Epoch 37/60
 - 5s - loss: 0.6245 - acc: 0.7983 - val_loss: 0.4676 - val_acc: 0.8533

Epoch 00037: val_loss did not improve from 0.45831
Epoch 38/60
 - 5s - loss: 0.6252 - acc: 0.7999 - val_loss: 0.4484 - val_acc: 0.8607

Epoch 00038: val_loss improved from 0.45831 to 0.44842, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 39/60
 - 5s - loss: 0.6198 - acc: 0.8016 - val_loss: 0.4660 - val_acc: 0.8542

Epoch 00039: val_loss did not improve from 0.44842
Epoch 40/60
 - 5s - loss: 0.6138 - acc: 0.8028 - val_loss: 0.4891 - val_acc: 0.8466

Epoch 00040: val_loss did not improve from 0.44842
Epoch 41/60
 - 5s - loss: 0.6195 - acc: 0.8025 - val_loss: 0.4679 - val_acc: 0.8570

Epoch 00041: val_loss did not improve from 0.44842
Epoch 42/60
 - 5s - loss: 0.6135 - acc: 0.8030 - val_loss: 0.4882 - val_acc: 0.8519

Epoch 00042: val_loss did not improve from 0.44842
Epoch 43/60
 - 5s - loss: 0.6152 - acc: 0.8029 - val_loss: 0.4473 - val_acc: 0.8617

Epoch 00043: val_loss improved from 0.44842 to 0.44734, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 44/60
 - 5s - loss: 0.6129 - acc: 0.8042 - val_loss: 0.4489 - val_acc: 0.8619

Epoch 00044: val_loss did not improve from 0.44734
Epoch 45/60
 - 5s - loss: 0.6059 - acc: 0.8048 - val_loss: 0.4529 - val_acc: 0.8607

Epoch 00045: val_loss did not improve from 0.44734
Epoch 46/60
 - 5s - loss: 0.6095 - acc: 0.8042 - val_loss: 0.4475 - val_acc: 0.8648

Epoch 00046: val_loss did not improve from 0.44734
Epoch 47/60
 - 5s - loss: 0.6091 - acc: 0.8060 - val_loss: 0.4563 - val_acc: 0.8507

Epoch 00047: val_loss did not improve from 0.44734
Epoch 48/60
 - 5s - loss: 0.6074 - acc: 0.8080 - val_loss: 0.4458 - val_acc: 0.8535

Epoch 00048: val_loss improved from 0.44734 to 0.44576, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 49/60
 - 5s - loss: 0.6028 - acc: 0.8081 - val_loss: 0.4391 - val_acc: 0.8641

Epoch 00049: val_loss improved from 0.44576 to 0.43905, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 50/60
 - 5s - loss: 0.5991 - acc: 0.8096 - val_loss: 0.4539 - val_acc: 0.8480

Epoch 00050: val_loss did not improve from 0.43905
Epoch 51/60
 - 5s - loss: 0.5957 - acc: 0.8087 - val_loss: 0.4388 - val_acc: 0.8641

Epoch 00051: val_loss improved from 0.43905 to 0.43876, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 52/60
 - 5s - loss: 0.5984 - acc: 0.8095 - val_loss: 0.4500 - val_acc: 0.8663

Epoch 00052: val_loss did not improve from 0.43876
Epoch 53/60
 - 5s - loss: 0.5943 - acc: 0.8094 - val_loss: 0.4287 - val_acc: 0.8664

Epoch 00053: val_loss improved from 0.43876 to 0.42873, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5
Epoch 54/60
 - 5s - loss: 0.5947 - acc: 0.8079 - val_loss: 0.4415 - val_acc: 0.8654

Epoch 00054: val_loss did not improve from 0.42873
Epoch 55/60
 - 5s - loss: 0.5903 - acc: 0.8111 - val_loss: 0.4369 - val_acc: 0.8683

Epoch 00055: val_loss did not improve from 0.42873
Epoch 56/60
 - 5s - loss: 0.5917 - acc: 0.8109 - val_loss: 0.4383 - val_acc: 0.8607

Epoch 00056: val_loss did not improve from 0.42873
Epoch 57/60
 - 5s - loss: 0.5879 - acc: 0.8117 - val_loss: 0.4453 - val_acc: 0.8653

Epoch 00057: val_loss did not improve from 0.42873
Epoch 58/60
 - 5s - loss: 0.5937 - acc: 0.8111 - val_loss: 0.4420 - val_acc: 0.8673

Epoch 00058: val_loss did not improve from 0.42873
Epoch 59/60
 - 5s - loss: 0.5876 - acc: 0.8106 - val_loss: 0.4383 - val_acc: 0.8597

Epoch 00059: val_loss did not improve from 0.42873
Epoch 60/60
 - 5s - loss: 0.5876 - acc: 0.8126 - val_loss: 0.4295 - val_acc: 0.8697

Epoch 00060: val_loss did not improve from 0.42873
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 4.2221 - acc: 0.1573 - val_loss: 2.2282 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 2.22824, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 2/60
 - 4s - loss: 2.0064 - acc: 0.5008 - val_loss: 2.0646 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.22824 to 2.06459, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 3/60
 - 5s - loss: 1.7688 - acc: 0.6236 - val_loss: 1.8555 - val_acc: 0.6209

Epoch 00003: val_loss improved from 2.06459 to 1.85550, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 4/60
 - 4s - loss: 1.6523 - acc: 0.6360 - val_loss: 1.7014 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.85550 to 1.70143, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 5/60
 - 4s - loss: 1.5930 - acc: 0.6371 - val_loss: 1.6013 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.70143 to 1.60128, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 6/60
 - 4s - loss: 1.5541 - acc: 0.6371 - val_loss: 1.5377 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.60128 to 1.53766, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 7/60
 - 4s - loss: 1.5236 - acc: 0.6371 - val_loss: 1.5312 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.53766 to 1.53124, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 8/60
 - 4s - loss: 1.5058 - acc: 0.6371 - val_loss: 1.5263 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.53124 to 1.52634, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 9/60
 - 4s - loss: 1.4921 - acc: 0.6371 - val_loss: 1.4828 - val_acc: 0.6209

Epoch 00009: val_loss improved from 1.52634 to 1.48282, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 10/60
 - 4s - loss: 1.4716 - acc: 0.6371 - val_loss: 1.4492 - val_acc: 0.6209

Epoch 00010: val_loss improved from 1.48282 to 1.44917, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 11/60
 - 4s - loss: 1.4609 - acc: 0.6371 - val_loss: 1.4616 - val_acc: 0.6209

Epoch 00011: val_loss did not improve from 1.44917
Epoch 12/60
 - 4s - loss: 1.4454 - acc: 0.6371 - val_loss: 1.4422 - val_acc: 0.6209

Epoch 00012: val_loss improved from 1.44917 to 1.44224, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 13/60
 - 4s - loss: 1.4344 - acc: 0.6371 - val_loss: 1.4425 - val_acc: 0.6209

Epoch 00013: val_loss did not improve from 1.44224
Epoch 14/60
 - 4s - loss: 1.4248 - acc: 0.6371 - val_loss: 1.4260 - val_acc: 0.6209

Epoch 00014: val_loss improved from 1.44224 to 1.42595, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 15/60
 - 4s - loss: 1.4119 - acc: 0.6371 - val_loss: 1.4221 - val_acc: 0.6209

Epoch 00015: val_loss improved from 1.42595 to 1.42214, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 16/60
 - 4s - loss: 1.4003 - acc: 0.6371 - val_loss: 1.4049 - val_acc: 0.6209

Epoch 00016: val_loss improved from 1.42214 to 1.40492, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 17/60
 - 4s - loss: 1.3897 - acc: 0.6371 - val_loss: 1.4264 - val_acc: 0.6209

Epoch 00017: val_loss did not improve from 1.40492
Epoch 18/60
 - 4s - loss: 1.3804 - acc: 0.6371 - val_loss: 1.3853 - val_acc: 0.6209

Epoch 00018: val_loss improved from 1.40492 to 1.38528, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 19/60
 - 4s - loss: 1.3731 - acc: 0.6371 - val_loss: 1.4100 - val_acc: 0.6209

Epoch 00019: val_loss did not improve from 1.38528
Epoch 20/60
 - 4s - loss: 1.3677 - acc: 0.6371 - val_loss: 1.4319 - val_acc: 0.6209

Epoch 00020: val_loss did not improve from 1.38528
Epoch 21/60
 - 4s - loss: 1.3594 - acc: 0.6371 - val_loss: 1.4467 - val_acc: 0.6209

Epoch 00021: val_loss did not improve from 1.38528
Epoch 22/60
 - 4s - loss: 1.3554 - acc: 0.6371 - val_loss: 1.3700 - val_acc: 0.6209

Epoch 00022: val_loss improved from 1.38528 to 1.36996, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 23/60
 - 4s - loss: 1.3506 - acc: 0.6371 - val_loss: 1.3432 - val_acc: 0.6209

Epoch 00023: val_loss improved from 1.36996 to 1.34324, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 24/60
 - 4s - loss: 1.3453 - acc: 0.6371 - val_loss: 1.3860 - val_acc: 0.6209

Epoch 00024: val_loss did not improve from 1.34324
Epoch 25/60
 - 4s - loss: 1.3399 - acc: 0.6371 - val_loss: 1.4093 - val_acc: 0.6209

Epoch 00025: val_loss did not improve from 1.34324
Epoch 26/60
 - 4s - loss: 1.3376 - acc: 0.6371 - val_loss: 1.4150 - val_acc: 0.6209

Epoch 00026: val_loss did not improve from 1.34324
Epoch 27/60
 - 4s - loss: 1.3376 - acc: 0.6371 - val_loss: 1.3773 - val_acc: 0.6209

Epoch 00027: val_loss did not improve from 1.34324
Epoch 28/60
 - 4s - loss: 1.3335 - acc: 0.6371 - val_loss: 1.3671 - val_acc: 0.6209

Epoch 00028: val_loss did not improve from 1.34324
Epoch 29/60
 - 4s - loss: 1.3282 - acc: 0.6371 - val_loss: 1.3326 - val_acc: 0.6209

Epoch 00029: val_loss improved from 1.34324 to 1.33260, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5
Epoch 30/60
 - 4s - loss: 1.3268 - acc: 0.6371 - val_loss: 1.4039 - val_acc: 0.6209

Epoch 00030: val_loss did not improve from 1.33260
Epoch 31/60
 - 4s - loss: 1.3257 - acc: 0.6371 - val_loss: 1.3601 - val_acc: 0.6209

Epoch 00031: val_loss did not improve from 1.33260
Epoch 32/60
 - 4s - loss: 1.3209 - acc: 0.6371 - val_loss: 1.3544 - val_acc: 0.6209

Epoch 00032: val_loss did not improve from 1.33260
Epoch 33/60
 - 4s - loss: 1.3225 - acc: 0.6371 - val_loss: 1.3490 - val_acc: 0.6209

Epoch 00033: val_loss did not improve from 1.33260
Epoch 34/60
 - 4s - loss: 1.3198 - acc: 0.6371 - val_loss: 1.3627 - val_acc: 0.6209

Epoch 00034: val_loss did not improve from 1.33260
Epoch 35/60
 - 4s - loss: 1.3159 - acc: 0.6371 - val_loss: 1.3618 - val_acc: 0.6209

Epoch 00035: val_loss did not improve from 1.33260
Epoch 36/60
 - 4s - loss: 1.3148 - acc: 0.6371 - val_loss: 1.3412 - val_acc: 0.6209

Epoch 00036: val_loss did not improve from 1.33260
Epoch 37/60
 - 4s - loss: 1.3121 - acc: 0.6371 - val_loss: 1.3389 - val_acc: 0.6209

Epoch 00037: val_loss did not improve from 1.33260
Epoch 38/60
 - 4s - loss: 1.3126 - acc: 0.6371 - val_loss: 1.3517 - val_acc: 0.6209

Epoch 00038: val_loss did not improve from 1.33260
Epoch 39/60
 - 4s - loss: 1.3102 - acc: 0.6371 - val_loss: 1.3646 - val_acc: 0.6209

Epoch 00039: val_loss did not improve from 1.33260
Epoch 00039: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 2.7053 - acc: 0.5161 - val_loss: 2.1379 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 2.13792, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 2/60
 - 5s - loss: 1.6477 - acc: 0.6336 - val_loss: 1.9961 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.13792 to 1.99613, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 3/60
 - 5s - loss: 1.5544 - acc: 0.6371 - val_loss: 1.8183 - val_acc: 0.6209

Epoch 00003: val_loss improved from 1.99613 to 1.81834, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 4/60
 - 5s - loss: 1.5122 - acc: 0.6371 - val_loss: 1.7952 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.81834 to 1.79524, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 5/60
 - 5s - loss: 1.4806 - acc: 0.6371 - val_loss: 1.7037 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.79524 to 1.70367, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 6/60
 - 5s - loss: 1.4623 - acc: 0.6371 - val_loss: 1.6380 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.70367 to 1.63805, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 7/60
 - 5s - loss: 1.4363 - acc: 0.6371 - val_loss: 1.5569 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.63805 to 1.55689, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 8/60
 - 5s - loss: 1.4146 - acc: 0.6371 - val_loss: 1.5552 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.55689 to 1.55519, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 9/60
 - 5s - loss: 1.3872 - acc: 0.6371 - val_loss: 1.4502 - val_acc: 0.6209

Epoch 00009: val_loss improved from 1.55519 to 1.45016, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 10/60
 - 5s - loss: 1.3457 - acc: 0.6361 - val_loss: 1.4021 - val_acc: 0.6209

Epoch 00010: val_loss improved from 1.45016 to 1.40208, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 11/60
 - 5s - loss: 1.3165 - acc: 0.6368 - val_loss: 1.3584 - val_acc: 0.6211

Epoch 00011: val_loss improved from 1.40208 to 1.35843, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 12/60
 - 5s - loss: 1.2956 - acc: 0.6372 - val_loss: 1.3515 - val_acc: 0.6233

Epoch 00012: val_loss improved from 1.35843 to 1.35150, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 13/60
 - 5s - loss: 1.2789 - acc: 0.6381 - val_loss: 1.3627 - val_acc: 0.6212

Epoch 00013: val_loss did not improve from 1.35150
Epoch 14/60
 - 5s - loss: 1.2613 - acc: 0.6390 - val_loss: 1.3545 - val_acc: 0.6224

Epoch 00014: val_loss did not improve from 1.35150
Epoch 15/60
 - 5s - loss: 1.2491 - acc: 0.6400 - val_loss: 1.3106 - val_acc: 0.6221

Epoch 00015: val_loss improved from 1.35150 to 1.31059, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 16/60
 - 5s - loss: 1.2427 - acc: 0.6402 - val_loss: 1.3300 - val_acc: 0.6234

Epoch 00016: val_loss did not improve from 1.31059
Epoch 17/60
 - 5s - loss: 1.2332 - acc: 0.6413 - val_loss: 1.2603 - val_acc: 0.6233

Epoch 00017: val_loss improved from 1.31059 to 1.26028, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 18/60
 - 5s - loss: 1.2226 - acc: 0.6432 - val_loss: 1.2835 - val_acc: 0.6221

Epoch 00018: val_loss did not improve from 1.26028
Epoch 19/60
 - 5s - loss: 1.2195 - acc: 0.6439 - val_loss: 1.3004 - val_acc: 0.6261

Epoch 00019: val_loss did not improve from 1.26028
Epoch 20/60
 - 5s - loss: 1.2108 - acc: 0.6452 - val_loss: 1.2903 - val_acc: 0.6253

Epoch 00020: val_loss did not improve from 1.26028
Epoch 21/60
 - 5s - loss: 1.2065 - acc: 0.6454 - val_loss: 1.2346 - val_acc: 0.6292

Epoch 00021: val_loss improved from 1.26028 to 1.23459, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 22/60
 - 5s - loss: 1.2017 - acc: 0.6464 - val_loss: 1.2921 - val_acc: 0.6287

Epoch 00022: val_loss did not improve from 1.23459
Epoch 23/60
 - 5s - loss: 1.1951 - acc: 0.6463 - val_loss: 1.2822 - val_acc: 0.6278

Epoch 00023: val_loss did not improve from 1.23459
Epoch 24/60
 - 5s - loss: 1.1861 - acc: 0.6476 - val_loss: 1.2581 - val_acc: 0.6325

Epoch 00024: val_loss did not improve from 1.23459
Epoch 25/60
 - 5s - loss: 1.1827 - acc: 0.6480 - val_loss: 1.2368 - val_acc: 0.6361

Epoch 00025: val_loss did not improve from 1.23459
Epoch 26/60
 - 5s - loss: 1.1806 - acc: 0.6494 - val_loss: 1.2343 - val_acc: 0.6337

Epoch 00026: val_loss improved from 1.23459 to 1.23434, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 27/60
 - 5s - loss: 1.1773 - acc: 0.6503 - val_loss: 1.2027 - val_acc: 0.6328

Epoch 00027: val_loss improved from 1.23434 to 1.20270, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 28/60
 - 5s - loss: 1.1673 - acc: 0.6497 - val_loss: 1.3040 - val_acc: 0.6320

Epoch 00028: val_loss did not improve from 1.20270
Epoch 29/60
 - 5s - loss: 1.1680 - acc: 0.6516 - val_loss: 1.2691 - val_acc: 0.6378

Epoch 00029: val_loss did not improve from 1.20270
Epoch 30/60
 - 5s - loss: 1.1674 - acc: 0.6527 - val_loss: 1.2757 - val_acc: 0.6405

Epoch 00030: val_loss did not improve from 1.20270
Epoch 31/60
 - 5s - loss: 1.1598 - acc: 0.6539 - val_loss: 1.2453 - val_acc: 0.6359

Epoch 00031: val_loss did not improve from 1.20270
Epoch 32/60
 - 5s - loss: 1.1618 - acc: 0.6528 - val_loss: 1.1831 - val_acc: 0.6399

Epoch 00032: val_loss improved from 1.20270 to 1.18315, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 33/60
 - 5s - loss: 1.1581 - acc: 0.6539 - val_loss: 1.2212 - val_acc: 0.6400

Epoch 00033: val_loss did not improve from 1.18315
Epoch 34/60
 - 5s - loss: 1.1577 - acc: 0.6533 - val_loss: 1.1533 - val_acc: 0.6393

Epoch 00034: val_loss improved from 1.18315 to 1.15335, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 35/60
 - 5s - loss: 1.1521 - acc: 0.6549 - val_loss: 1.2633 - val_acc: 0.6399

Epoch 00035: val_loss did not improve from 1.15335
Epoch 36/60
 - 5s - loss: 1.1487 - acc: 0.6545 - val_loss: 1.2386 - val_acc: 0.6427

Epoch 00036: val_loss did not improve from 1.15335
Epoch 37/60
 - 5s - loss: 1.1494 - acc: 0.6546 - val_loss: 1.1675 - val_acc: 0.6411

Epoch 00037: val_loss did not improve from 1.15335
Epoch 38/60
 - 5s - loss: 1.1451 - acc: 0.6572 - val_loss: 1.1771 - val_acc: 0.6493

Epoch 00038: val_loss did not improve from 1.15335
Epoch 39/60
 - 5s - loss: 1.1466 - acc: 0.6561 - val_loss: 1.1421 - val_acc: 0.6475

Epoch 00039: val_loss improved from 1.15335 to 1.14206, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 40/60
 - 5s - loss: 1.1397 - acc: 0.6567 - val_loss: 1.1598 - val_acc: 0.6489

Epoch 00040: val_loss did not improve from 1.14206
Epoch 41/60
 - 5s - loss: 1.1438 - acc: 0.6577 - val_loss: 1.1514 - val_acc: 0.6458

Epoch 00041: val_loss did not improve from 1.14206
Epoch 42/60
 - 5s - loss: 1.1416 - acc: 0.6581 - val_loss: 1.1233 - val_acc: 0.6542

Epoch 00042: val_loss improved from 1.14206 to 1.12331, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 43/60
 - 5s - loss: 1.1372 - acc: 0.6574 - val_loss: 1.2065 - val_acc: 0.6459

Epoch 00043: val_loss did not improve from 1.12331
Epoch 44/60
 - 5s - loss: 1.1326 - acc: 0.6578 - val_loss: 1.1929 - val_acc: 0.6487

Epoch 00044: val_loss did not improve from 1.12331
Epoch 45/60
 - 5s - loss: 1.1348 - acc: 0.6563 - val_loss: 1.1353 - val_acc: 0.6537

Epoch 00045: val_loss did not improve from 1.12331
Epoch 46/60
 - 5s - loss: 1.1246 - acc: 0.6594 - val_loss: 1.1444 - val_acc: 0.6487

Epoch 00046: val_loss did not improve from 1.12331
Epoch 47/60
 - 5s - loss: 1.1282 - acc: 0.6581 - val_loss: 1.1513 - val_acc: 0.6556

Epoch 00047: val_loss did not improve from 1.12331
Epoch 48/60
 - 5s - loss: 1.1231 - acc: 0.6589 - val_loss: 1.1252 - val_acc: 0.6584

Epoch 00048: val_loss did not improve from 1.12331
Epoch 49/60
 - 5s - loss: 1.1255 - acc: 0.6581 - val_loss: 1.0986 - val_acc: 0.6571

Epoch 00049: val_loss improved from 1.12331 to 1.09860, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 50/60
 - 5s - loss: 1.1238 - acc: 0.6603 - val_loss: 1.0802 - val_acc: 0.6549

Epoch 00050: val_loss improved from 1.09860 to 1.08022, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5
Epoch 51/60
 - 5s - loss: 1.1190 - acc: 0.6600 - val_loss: 1.1307 - val_acc: 0.6539

Epoch 00051: val_loss did not improve from 1.08022
Epoch 52/60
 - 5s - loss: 1.1217 - acc: 0.6599 - val_loss: 1.1276 - val_acc: 0.6499

Epoch 00052: val_loss did not improve from 1.08022
Epoch 53/60
 - 5s - loss: 1.1219 - acc: 0.6596 - val_loss: 1.1739 - val_acc: 0.6489

Epoch 00053: val_loss did not improve from 1.08022
Epoch 54/60
 - 5s - loss: 1.1170 - acc: 0.6590 - val_loss: 1.1250 - val_acc: 0.6523

Epoch 00054: val_loss did not improve from 1.08022
Epoch 55/60
 - 5s - loss: 1.1109 - acc: 0.6604 - val_loss: 1.1636 - val_acc: 0.6524

Epoch 00055: val_loss did not improve from 1.08022
Epoch 56/60
 - 5s - loss: 1.1136 - acc: 0.6616 - val_loss: 1.1359 - val_acc: 0.6539

Epoch 00056: val_loss did not improve from 1.08022
Epoch 57/60
 - 5s - loss: 1.1121 - acc: 0.6593 - val_loss: 1.0971 - val_acc: 0.6605

Epoch 00057: val_loss did not improve from 1.08022
Epoch 58/60
 - 5s - loss: 1.1114 - acc: 0.6612 - val_loss: 1.0970 - val_acc: 0.6587

Epoch 00058: val_loss did not improve from 1.08022
Epoch 59/60
 - 5s - loss: 1.1064 - acc: 0.6599 - val_loss: 1.0991 - val_acc: 0.6546

Epoch 00059: val_loss did not improve from 1.08022
Epoch 60/60
 - 5s - loss: 1.1066 - acc: 0.6615 - val_loss: 1.1278 - val_acc: 0.6520

Epoch 00060: val_loss did not improve from 1.08022
Epoch 00060: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 2.3844 - acc: 0.5557 - val_loss: 1.3782 - val_acc: 0.6359

Epoch 00001: val_loss improved from inf to 1.37821, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 2/60
 - 5s - loss: 1.3408 - acc: 0.6321 - val_loss: 1.1456 - val_acc: 0.6631

Epoch 00002: val_loss improved from 1.37821 to 1.14559, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 3/60
 - 5s - loss: 1.1910 - acc: 0.6515 - val_loss: 0.9632 - val_acc: 0.6853

Epoch 00003: val_loss improved from 1.14559 to 0.96325, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 4/60
 - 5s - loss: 1.0906 - acc: 0.6652 - val_loss: 0.8783 - val_acc: 0.7009

Epoch 00004: val_loss improved from 0.96325 to 0.87828, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 5/60
 - 5s - loss: 1.0201 - acc: 0.6823 - val_loss: 0.8175 - val_acc: 0.7349

Epoch 00005: val_loss improved from 0.87828 to 0.81753, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 6/60
 - 5s - loss: 0.9605 - acc: 0.6981 - val_loss: 0.7519 - val_acc: 0.7536

Epoch 00006: val_loss improved from 0.81753 to 0.75187, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 7/60
 - 5s - loss: 0.9153 - acc: 0.7084 - val_loss: 0.7044 - val_acc: 0.7773

Epoch 00007: val_loss improved from 0.75187 to 0.70443, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 8/60
 - 5s - loss: 0.8736 - acc: 0.7221 - val_loss: 0.6806 - val_acc: 0.7723

Epoch 00008: val_loss improved from 0.70443 to 0.68058, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 9/60
 - 5s - loss: 0.8373 - acc: 0.7313 - val_loss: 0.6426 - val_acc: 0.7848

Epoch 00009: val_loss improved from 0.68058 to 0.64263, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 10/60
 - 5s - loss: 0.8186 - acc: 0.7385 - val_loss: 0.6592 - val_acc: 0.7861

Epoch 00010: val_loss did not improve from 0.64263
Epoch 11/60
 - 5s - loss: 0.7995 - acc: 0.7458 - val_loss: 0.5905 - val_acc: 0.8132

Epoch 00011: val_loss improved from 0.64263 to 0.59055, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 12/60
 - 5s - loss: 0.7780 - acc: 0.7508 - val_loss: 0.6052 - val_acc: 0.7905

Epoch 00012: val_loss did not improve from 0.59055
Epoch 13/60
 - 5s - loss: 0.7645 - acc: 0.7553 - val_loss: 0.5986 - val_acc: 0.8045

Epoch 00013: val_loss did not improve from 0.59055
Epoch 14/60
 - 5s - loss: 0.7512 - acc: 0.7601 - val_loss: 0.5786 - val_acc: 0.8085

Epoch 00014: val_loss improved from 0.59055 to 0.57863, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 15/60
 - 5s - loss: 0.7406 - acc: 0.7640 - val_loss: 0.5551 - val_acc: 0.8155

Epoch 00015: val_loss improved from 0.57863 to 0.55514, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 16/60
 - 5s - loss: 0.7308 - acc: 0.7672 - val_loss: 0.5498 - val_acc: 0.8273

Epoch 00016: val_loss improved from 0.55514 to 0.54980, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 17/60
 - 5s - loss: 0.7181 - acc: 0.7682 - val_loss: 0.5330 - val_acc: 0.8257

Epoch 00017: val_loss improved from 0.54980 to 0.53297, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 18/60
 - 5s - loss: 0.7083 - acc: 0.7728 - val_loss: 0.5225 - val_acc: 0.8311

Epoch 00018: val_loss improved from 0.53297 to 0.52255, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 19/60
 - 5s - loss: 0.6981 - acc: 0.7758 - val_loss: 0.5199 - val_acc: 0.8335

Epoch 00019: val_loss improved from 0.52255 to 0.51993, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 20/60
 - 5s - loss: 0.6895 - acc: 0.7787 - val_loss: 0.5486 - val_acc: 0.8154

Epoch 00020: val_loss did not improve from 0.51993
Epoch 21/60
 - 5s - loss: 0.6905 - acc: 0.7776 - val_loss: 0.5137 - val_acc: 0.8341

Epoch 00021: val_loss improved from 0.51993 to 0.51370, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 22/60
 - 5s - loss: 0.6823 - acc: 0.7807 - val_loss: 0.5083 - val_acc: 0.8402

Epoch 00022: val_loss improved from 0.51370 to 0.50826, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 23/60
 - 5s - loss: 0.6681 - acc: 0.7838 - val_loss: 0.5200 - val_acc: 0.8239

Epoch 00023: val_loss did not improve from 0.50826
Epoch 24/60
 - 5s - loss: 0.6690 - acc: 0.7839 - val_loss: 0.4980 - val_acc: 0.8435

Epoch 00024: val_loss improved from 0.50826 to 0.49797, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 25/60
 - 5s - loss: 0.6614 - acc: 0.7868 - val_loss: 0.4906 - val_acc: 0.8448

Epoch 00025: val_loss improved from 0.49797 to 0.49057, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 26/60
 - 5s - loss: 0.6617 - acc: 0.7894 - val_loss: 0.4915 - val_acc: 0.8433

Epoch 00026: val_loss did not improve from 0.49057
Epoch 27/60
 - 5s - loss: 0.6540 - acc: 0.7900 - val_loss: 0.4796 - val_acc: 0.8532

Epoch 00027: val_loss improved from 0.49057 to 0.47959, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 28/60
 - 5s - loss: 0.6554 - acc: 0.7891 - val_loss: 0.4765 - val_acc: 0.8482

Epoch 00028: val_loss improved from 0.47959 to 0.47652, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 29/60
 - 5s - loss: 0.6464 - acc: 0.7907 - val_loss: 0.4951 - val_acc: 0.8395

Epoch 00029: val_loss did not improve from 0.47652
Epoch 30/60
 - 5s - loss: 0.6437 - acc: 0.7944 - val_loss: 0.4789 - val_acc: 0.8463

Epoch 00030: val_loss did not improve from 0.47652
Epoch 31/60
 - 5s - loss: 0.6364 - acc: 0.7987 - val_loss: 0.4905 - val_acc: 0.8408

Epoch 00031: val_loss did not improve from 0.47652
Epoch 32/60
 - 5s - loss: 0.6437 - acc: 0.7921 - val_loss: 0.4711 - val_acc: 0.8447

Epoch 00032: val_loss improved from 0.47652 to 0.47107, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 33/60
 - 5s - loss: 0.6370 - acc: 0.7957 - val_loss: 0.4777 - val_acc: 0.8416

Epoch 00033: val_loss did not improve from 0.47107
Epoch 34/60
 - 5s - loss: 0.6305 - acc: 0.7965 - val_loss: 0.4585 - val_acc: 0.8578

Epoch 00034: val_loss improved from 0.47107 to 0.45846, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 35/60
 - 5s - loss: 0.6373 - acc: 0.7961 - val_loss: 0.4780 - val_acc: 0.8554

Epoch 00035: val_loss did not improve from 0.45846
Epoch 36/60
 - 5s - loss: 0.6280 - acc: 0.7976 - val_loss: 0.4596 - val_acc: 0.8508

Epoch 00036: val_loss did not improve from 0.45846
Epoch 37/60
 - 5s - loss: 0.6261 - acc: 0.7988 - val_loss: 0.4645 - val_acc: 0.8432

Epoch 00037: val_loss did not improve from 0.45846
Epoch 38/60
 - 5s - loss: 0.6190 - acc: 0.8019 - val_loss: 0.4774 - val_acc: 0.8469

Epoch 00038: val_loss did not improve from 0.45846
Epoch 39/60
 - 5s - loss: 0.6225 - acc: 0.8006 - val_loss: 0.4557 - val_acc: 0.8504

Epoch 00039: val_loss improved from 0.45846 to 0.45572, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 40/60
 - 5s - loss: 0.6160 - acc: 0.8023 - val_loss: 0.4631 - val_acc: 0.8554

Epoch 00040: val_loss did not improve from 0.45572
Epoch 41/60
 - 5s - loss: 0.6263 - acc: 0.7973 - val_loss: 0.4555 - val_acc: 0.8614

Epoch 00041: val_loss improved from 0.45572 to 0.45548, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 42/60
 - 5s - loss: 0.6129 - acc: 0.8056 - val_loss: 0.4621 - val_acc: 0.8450

Epoch 00042: val_loss did not improve from 0.45548
Epoch 43/60
 - 5s - loss: 0.6142 - acc: 0.8033 - val_loss: 0.4587 - val_acc: 0.8608

Epoch 00043: val_loss did not improve from 0.45548
Epoch 44/60
 - 5s - loss: 0.6095 - acc: 0.8043 - val_loss: 0.5181 - val_acc: 0.8410

Epoch 00044: val_loss did not improve from 0.45548
Epoch 45/60
 - 5s - loss: 0.6085 - acc: 0.8041 - val_loss: 0.4428 - val_acc: 0.8580

Epoch 00045: val_loss improved from 0.45548 to 0.44275, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 46/60
 - 5s - loss: 0.6000 - acc: 0.8067 - val_loss: 0.4656 - val_acc: 0.8626

Epoch 00046: val_loss did not improve from 0.44275
Epoch 47/60
 - 5s - loss: 0.6004 - acc: 0.8078 - val_loss: 0.4502 - val_acc: 0.8583

Epoch 00047: val_loss did not improve from 0.44275
Epoch 48/60
 - 5s - loss: 0.6055 - acc: 0.8039 - val_loss: 0.4647 - val_acc: 0.8582

Epoch 00048: val_loss did not improve from 0.44275
Epoch 49/60
 - 5s - loss: 0.6009 - acc: 0.8067 - val_loss: 0.4471 - val_acc: 0.8604

Epoch 00049: val_loss did not improve from 0.44275
Epoch 50/60
 - 5s - loss: 0.6026 - acc: 0.8079 - val_loss: 0.4440 - val_acc: 0.8642

Epoch 00050: val_loss did not improve from 0.44275
Epoch 51/60
 - 5s - loss: 0.5986 - acc: 0.8079 - val_loss: 0.4441 - val_acc: 0.8611

Epoch 00051: val_loss did not improve from 0.44275
Epoch 52/60
 - 5s - loss: 0.5992 - acc: 0.8063 - val_loss: 0.4510 - val_acc: 0.8550

Epoch 00052: val_loss did not improve from 0.44275
Epoch 53/60
 - 5s - loss: 0.5991 - acc: 0.8064 - val_loss: 0.4429 - val_acc: 0.8576

Epoch 00053: val_loss did not improve from 0.44275
Epoch 54/60
 - 5s - loss: 0.5954 - acc: 0.8088 - val_loss: 0.4606 - val_acc: 0.8495

Epoch 00054: val_loss did not improve from 0.44275
Epoch 55/60
 - 5s - loss: 0.5927 - acc: 0.8078 - val_loss: 0.4492 - val_acc: 0.8622

Epoch 00055: val_loss did not improve from 0.44275
Epoch 00055: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 4.2199 - acc: 0.4161 - val_loss: 2.2172 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 2.21724, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 2/60
 - 4s - loss: 1.9586 - acc: 0.5642 - val_loss: 2.1128 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.21724 to 2.11283, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 3/60
 - 4s - loss: 1.7682 - acc: 0.6275 - val_loss: 1.9936 - val_acc: 0.6209

Epoch 00003: val_loss improved from 2.11283 to 1.99355, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 4/60
 - 4s - loss: 1.6785 - acc: 0.6365 - val_loss: 1.8184 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.99355 to 1.81835, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 5/60
 - 4s - loss: 1.6132 - acc: 0.6371 - val_loss: 1.7061 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.81835 to 1.70611, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 6/60
 - 5s - loss: 1.5722 - acc: 0.6371 - val_loss: 1.6292 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.70611 to 1.62917, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 7/60
 - 4s - loss: 1.5409 - acc: 0.6371 - val_loss: 1.5975 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.62917 to 1.59747, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 8/60
 - 4s - loss: 1.5199 - acc: 0.6371 - val_loss: 1.5679 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.59747 to 1.56791, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 9/60
 - 4s - loss: 1.5026 - acc: 0.6371 - val_loss: 1.5527 - val_acc: 0.6209

Epoch 00009: val_loss improved from 1.56791 to 1.55269, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 10/60
 - 4s - loss: 1.4884 - acc: 0.6371 - val_loss: 1.5333 - val_acc: 0.6209

Epoch 00010: val_loss improved from 1.55269 to 1.53329, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 11/60
 - 4s - loss: 1.4746 - acc: 0.6371 - val_loss: 1.5304 - val_acc: 0.6209

Epoch 00011: val_loss improved from 1.53329 to 1.53041, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 12/60
 - 4s - loss: 1.4618 - acc: 0.6371 - val_loss: 1.5110 - val_acc: 0.6209

Epoch 00012: val_loss improved from 1.53041 to 1.51095, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 13/60
 - 4s - loss: 1.4505 - acc: 0.6371 - val_loss: 1.5099 - val_acc: 0.6209

Epoch 00013: val_loss improved from 1.51095 to 1.50991, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 14/60
 - 4s - loss: 1.4382 - acc: 0.6371 - val_loss: 1.5225 - val_acc: 0.6209

Epoch 00014: val_loss did not improve from 1.50991
Epoch 15/60
 - 4s - loss: 1.4253 - acc: 0.6371 - val_loss: 1.4777 - val_acc: 0.6209

Epoch 00015: val_loss improved from 1.50991 to 1.47773, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 16/60
 - 4s - loss: 1.4130 - acc: 0.6371 - val_loss: 1.4559 - val_acc: 0.6209

Epoch 00016: val_loss improved from 1.47773 to 1.45592, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 17/60
 - 4s - loss: 1.4059 - acc: 0.6371 - val_loss: 1.4854 - val_acc: 0.6209

Epoch 00017: val_loss did not improve from 1.45592
Epoch 18/60
 - 4s - loss: 1.3938 - acc: 0.6371 - val_loss: 1.4455 - val_acc: 0.6209

Epoch 00018: val_loss improved from 1.45592 to 1.44552, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 19/60
 - 4s - loss: 1.3869 - acc: 0.6371 - val_loss: 1.4403 - val_acc: 0.6209

Epoch 00019: val_loss improved from 1.44552 to 1.44030, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 20/60
 - 4s - loss: 1.3803 - acc: 0.6371 - val_loss: 1.4145 - val_acc: 0.6209

Epoch 00020: val_loss improved from 1.44030 to 1.41450, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 21/60
 - 4s - loss: 1.3752 - acc: 0.6371 - val_loss: 1.4500 - val_acc: 0.6209

Epoch 00021: val_loss did not improve from 1.41450
Epoch 22/60
 - 4s - loss: 1.3658 - acc: 0.6371 - val_loss: 1.3963 - val_acc: 0.6209

Epoch 00022: val_loss improved from 1.41450 to 1.39634, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 23/60
 - 4s - loss: 1.3623 - acc: 0.6371 - val_loss: 1.4103 - val_acc: 0.6209

Epoch 00023: val_loss did not improve from 1.39634
Epoch 24/60
 - 4s - loss: 1.3576 - acc: 0.6371 - val_loss: 1.4060 - val_acc: 0.6209

Epoch 00024: val_loss did not improve from 1.39634
Epoch 25/60
 - 4s - loss: 1.3516 - acc: 0.6371 - val_loss: 1.4121 - val_acc: 0.6209

Epoch 00025: val_loss did not improve from 1.39634
Epoch 26/60
 - 4s - loss: 1.3500 - acc: 0.6371 - val_loss: 1.3808 - val_acc: 0.6209

Epoch 00026: val_loss improved from 1.39634 to 1.38075, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 27/60
 - 4s - loss: 1.3471 - acc: 0.6371 - val_loss: 1.3929 - val_acc: 0.6209

Epoch 00027: val_loss did not improve from 1.38075
Epoch 28/60
 - 4s - loss: 1.3414 - acc: 0.6371 - val_loss: 1.3877 - val_acc: 0.6209

Epoch 00028: val_loss did not improve from 1.38075
Epoch 29/60
 - 4s - loss: 1.3410 - acc: 0.6371 - val_loss: 1.3714 - val_acc: 0.6209

Epoch 00029: val_loss improved from 1.38075 to 1.37141, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 30/60
 - 4s - loss: 1.3395 - acc: 0.6371 - val_loss: 1.3941 - val_acc: 0.6209

Epoch 00030: val_loss did not improve from 1.37141
Epoch 31/60
 - 4s - loss: 1.3348 - acc: 0.6371 - val_loss: 1.3611 - val_acc: 0.6209

Epoch 00031: val_loss improved from 1.37141 to 1.36114, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 32/60
 - 4s - loss: 1.3332 - acc: 0.6371 - val_loss: 1.4427 - val_acc: 0.6209

Epoch 00032: val_loss did not improve from 1.36114
Epoch 33/60
 - 4s - loss: 1.3289 - acc: 0.6371 - val_loss: 1.4270 - val_acc: 0.6209

Epoch 00033: val_loss did not improve from 1.36114
Epoch 34/60
 - 4s - loss: 1.3300 - acc: 0.6371 - val_loss: 1.3643 - val_acc: 0.6209

Epoch 00034: val_loss did not improve from 1.36114
Epoch 35/60
 - 4s - loss: 1.3263 - acc: 0.6371 - val_loss: 1.3550 - val_acc: 0.6209

Epoch 00035: val_loss improved from 1.36114 to 1.35499, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 36/60
 - 4s - loss: 1.3248 - acc: 0.6371 - val_loss: 1.4047 - val_acc: 0.6209

Epoch 00036: val_loss did not improve from 1.35499
Epoch 37/60
 - 4s - loss: 1.3224 - acc: 0.6371 - val_loss: 1.3568 - val_acc: 0.6209

Epoch 00037: val_loss did not improve from 1.35499
Epoch 38/60
 - 4s - loss: 1.3221 - acc: 0.6371 - val_loss: 1.4113 - val_acc: 0.6209

Epoch 00038: val_loss did not improve from 1.35499
Epoch 39/60
 - 4s - loss: 1.3174 - acc: 0.6371 - val_loss: 1.3791 - val_acc: 0.6209

Epoch 00039: val_loss did not improve from 1.35499
Epoch 40/60
 - 4s - loss: 1.3167 - acc: 0.6371 - val_loss: 1.3965 - val_acc: 0.6209

Epoch 00040: val_loss did not improve from 1.35499
Epoch 41/60
 - 4s - loss: 1.3169 - acc: 0.6371 - val_loss: 1.3868 - val_acc: 0.6209

Epoch 00041: val_loss did not improve from 1.35499
Epoch 42/60
 - 4s - loss: 1.3156 - acc: 0.6371 - val_loss: 1.3617 - val_acc: 0.6209

Epoch 00042: val_loss did not improve from 1.35499
Epoch 43/60
 - 4s - loss: 1.3144 - acc: 0.6371 - val_loss: 1.3948 - val_acc: 0.6209

Epoch 00043: val_loss did not improve from 1.35499
Epoch 44/60
 - 4s - loss: 1.3132 - acc: 0.6371 - val_loss: 1.3512 - val_acc: 0.6209

Epoch 00044: val_loss improved from 1.35499 to 1.35116, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 45/60
 - 4s - loss: 1.3156 - acc: 0.6371 - val_loss: 1.4249 - val_acc: 0.6209

Epoch 00045: val_loss did not improve from 1.35116
Epoch 46/60
 - 4s - loss: 1.3103 - acc: 0.6371 - val_loss: 1.3805 - val_acc: 0.6209

Epoch 00046: val_loss did not improve from 1.35116
Epoch 47/60
 - 4s - loss: 1.3136 - acc: 0.6371 - val_loss: 1.3996 - val_acc: 0.6209

Epoch 00047: val_loss did not improve from 1.35116
Epoch 48/60
 - 5s - loss: 1.3116 - acc: 0.6371 - val_loss: 1.3826 - val_acc: 0.6209

Epoch 00048: val_loss did not improve from 1.35116
Epoch 49/60
 - 4s - loss: 1.3109 - acc: 0.6371 - val_loss: 1.4311 - val_acc: 0.6209

Epoch 00049: val_loss did not improve from 1.35116
Epoch 50/60
 - 4s - loss: 1.3089 - acc: 0.6371 - val_loss: 1.3639 - val_acc: 0.6209

Epoch 00050: val_loss did not improve from 1.35116
Epoch 51/60
 - 4s - loss: 1.3087 - acc: 0.6371 - val_loss: 1.3680 - val_acc: 0.6209

Epoch 00051: val_loss did not improve from 1.35116
Epoch 52/60
 - 4s - loss: 1.3063 - acc: 0.6371 - val_loss: 1.3535 - val_acc: 0.6209

Epoch 00052: val_loss did not improve from 1.35116
Epoch 53/60
 - 4s - loss: 1.3071 - acc: 0.6372 - val_loss: 1.3869 - val_acc: 0.6209

Epoch 00053: val_loss did not improve from 1.35116
Epoch 54/60
 - 4s - loss: 1.3054 - acc: 0.6372 - val_loss: 1.3547 - val_acc: 0.6209

Epoch 00054: val_loss did not improve from 1.35116
Epoch 00054: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 10s - loss: 2.8137 - acc: 0.5078 - val_loss: 2.1668 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 2.16684, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 2/60
 - 5s - loss: 1.6597 - acc: 0.6329 - val_loss: 1.9762 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.16684 to 1.97617, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 3/60
 - 5s - loss: 1.5561 - acc: 0.6371 - val_loss: 1.8319 - val_acc: 0.6209

Epoch 00003: val_loss improved from 1.97617 to 1.83195, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 4/60
 - 5s - loss: 1.5134 - acc: 0.6371 - val_loss: 1.7554 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.83195 to 1.75536, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 5/60
 - 5s - loss: 1.4835 - acc: 0.6371 - val_loss: 1.7067 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.75536 to 1.70668, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 6/60
 - 5s - loss: 1.4679 - acc: 0.6371 - val_loss: 1.6524 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.70668 to 1.65241, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 7/60
 - 5s - loss: 1.4467 - acc: 0.6371 - val_loss: 1.6608 - val_acc: 0.6209

Epoch 00007: val_loss did not improve from 1.65241
Epoch 8/60
 - 5s - loss: 1.4278 - acc: 0.6371 - val_loss: 1.5864 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.65241 to 1.58638, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 9/60
 - 5s - loss: 1.4103 - acc: 0.6371 - val_loss: 1.5959 - val_acc: 0.6209

Epoch 00009: val_loss did not improve from 1.58638
Epoch 10/60
 - 5s - loss: 1.3897 - acc: 0.6371 - val_loss: 1.5729 - val_acc: 0.6209

Epoch 00010: val_loss improved from 1.58638 to 1.57286, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 11/60
 - 5s - loss: 1.3637 - acc: 0.6372 - val_loss: 1.4345 - val_acc: 0.6214

Epoch 00011: val_loss improved from 1.57286 to 1.43447, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 12/60
 - 5s - loss: 1.3294 - acc: 0.6366 - val_loss: 1.4482 - val_acc: 0.6212

Epoch 00012: val_loss did not improve from 1.43447
Epoch 13/60
 - 5s - loss: 1.3058 - acc: 0.6374 - val_loss: 1.4028 - val_acc: 0.6224

Epoch 00013: val_loss improved from 1.43447 to 1.40283, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 14/60
 - 5s - loss: 1.2854 - acc: 0.6388 - val_loss: 1.4229 - val_acc: 0.6211

Epoch 00014: val_loss did not improve from 1.40283
Epoch 15/60
 - 5s - loss: 1.2685 - acc: 0.6399 - val_loss: 1.3943 - val_acc: 0.6227

Epoch 00015: val_loss improved from 1.40283 to 1.39433, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 16/60
 - 5s - loss: 1.2605 - acc: 0.6399 - val_loss: 1.3833 - val_acc: 0.6234

Epoch 00016: val_loss improved from 1.39433 to 1.38328, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 17/60
 - 5s - loss: 1.2453 - acc: 0.6419 - val_loss: 1.3990 - val_acc: 0.6214

Epoch 00017: val_loss did not improve from 1.38328
Epoch 18/60
 - 5s - loss: 1.2351 - acc: 0.6423 - val_loss: 1.3086 - val_acc: 0.6227

Epoch 00018: val_loss improved from 1.38328 to 1.30859, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 19/60
 - 5s - loss: 1.2300 - acc: 0.6434 - val_loss: 1.4238 - val_acc: 0.6225

Epoch 00019: val_loss did not improve from 1.30859
Epoch 20/60
 - 5s - loss: 1.2220 - acc: 0.6447 - val_loss: 1.3840 - val_acc: 0.6253

Epoch 00020: val_loss did not improve from 1.30859
Epoch 21/60
 - 5s - loss: 1.2120 - acc: 0.6446 - val_loss: 1.4074 - val_acc: 0.6246

Epoch 00021: val_loss did not improve from 1.30859
Epoch 22/60
 - 5s - loss: 1.2072 - acc: 0.6463 - val_loss: 1.3191 - val_acc: 0.6274

Epoch 00022: val_loss did not improve from 1.30859
Epoch 23/60
 - 5s - loss: 1.2044 - acc: 0.6465 - val_loss: 1.3469 - val_acc: 0.6269

Epoch 00023: val_loss did not improve from 1.30859
Epoch 24/60
 - 5s - loss: 1.1982 - acc: 0.6478 - val_loss: 1.3264 - val_acc: 0.6293

Epoch 00024: val_loss did not improve from 1.30859
Epoch 25/60
 - 5s - loss: 1.1898 - acc: 0.6486 - val_loss: 1.3542 - val_acc: 0.6277

Epoch 00025: val_loss did not improve from 1.30859
Epoch 26/60
 - 5s - loss: 1.1903 - acc: 0.6495 - val_loss: 1.2837 - val_acc: 0.6264

Epoch 00026: val_loss improved from 1.30859 to 1.28374, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 27/60
 - 5s - loss: 1.1823 - acc: 0.6502 - val_loss: 1.3574 - val_acc: 0.6324

Epoch 00027: val_loss did not improve from 1.28374
Epoch 28/60
 - 5s - loss: 1.1768 - acc: 0.6507 - val_loss: 1.3504 - val_acc: 0.6337

Epoch 00028: val_loss did not improve from 1.28374
Epoch 29/60
 - 5s - loss: 1.1731 - acc: 0.6523 - val_loss: 1.2340 - val_acc: 0.6347

Epoch 00029: val_loss improved from 1.28374 to 1.23398, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 30/60
 - 5s - loss: 1.1745 - acc: 0.6522 - val_loss: 1.2300 - val_acc: 0.6365

Epoch 00030: val_loss improved from 1.23398 to 1.22998, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 31/60
 - 5s - loss: 1.1688 - acc: 0.6524 - val_loss: 1.2328 - val_acc: 0.6437

Epoch 00031: val_loss did not improve from 1.22998
Epoch 32/60
 - 5s - loss: 1.1639 - acc: 0.6541 - val_loss: 1.3171 - val_acc: 0.6390

Epoch 00032: val_loss did not improve from 1.22998
Epoch 33/60
 - 5s - loss: 1.1631 - acc: 0.6547 - val_loss: 1.2398 - val_acc: 0.6375

Epoch 00033: val_loss did not improve from 1.22998
Epoch 34/60
 - 5s - loss: 1.1622 - acc: 0.6537 - val_loss: 1.2380 - val_acc: 0.6412

Epoch 00034: val_loss did not improve from 1.22998
Epoch 35/60
 - 5s - loss: 1.1577 - acc: 0.6559 - val_loss: 1.2510 - val_acc: 0.6439

Epoch 00035: val_loss did not improve from 1.22998
Epoch 36/60
 - 5s - loss: 1.1558 - acc: 0.6544 - val_loss: 1.3148 - val_acc: 0.6400

Epoch 00036: val_loss did not improve from 1.22998
Epoch 37/60
 - 5s - loss: 1.1513 - acc: 0.6570 - val_loss: 1.1980 - val_acc: 0.6434

Epoch 00037: val_loss improved from 1.22998 to 1.19799, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 38/60
 - 5s - loss: 1.1476 - acc: 0.6565 - val_loss: 1.2545 - val_acc: 0.6387

Epoch 00038: val_loss did not improve from 1.19799
Epoch 39/60
 - 5s - loss: 1.1461 - acc: 0.6588 - val_loss: 1.2360 - val_acc: 0.6424

Epoch 00039: val_loss did not improve from 1.19799
Epoch 40/60
 - 5s - loss: 1.1421 - acc: 0.6585 - val_loss: 1.2105 - val_acc: 0.6487

Epoch 00040: val_loss did not improve from 1.19799
Epoch 41/60
 - 5s - loss: 1.1455 - acc: 0.6565 - val_loss: 1.2498 - val_acc: 0.6439

Epoch 00041: val_loss did not improve from 1.19799
Epoch 42/60
 - 5s - loss: 1.1457 - acc: 0.6572 - val_loss: 1.2566 - val_acc: 0.6417

Epoch 00042: val_loss did not improve from 1.19799
Epoch 43/60
 - 5s - loss: 1.1412 - acc: 0.6572 - val_loss: 1.3083 - val_acc: 0.6358

Epoch 00043: val_loss did not improve from 1.19799
Epoch 44/60
 - 5s - loss: 1.1333 - acc: 0.6583 - val_loss: 1.2373 - val_acc: 0.6470

Epoch 00044: val_loss did not improve from 1.19799
Epoch 45/60
 - 5s - loss: 1.1300 - acc: 0.6603 - val_loss: 1.2433 - val_acc: 0.6428

Epoch 00045: val_loss did not improve from 1.19799
Epoch 46/60
 - 5s - loss: 1.1351 - acc: 0.6590 - val_loss: 1.2761 - val_acc: 0.6465

Epoch 00046: val_loss did not improve from 1.19799
Epoch 47/60
 - 5s - loss: 1.1339 - acc: 0.6594 - val_loss: 1.1790 - val_acc: 0.6493

Epoch 00047: val_loss improved from 1.19799 to 1.17901, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 48/60
 - 6s - loss: 1.1294 - acc: 0.6602 - val_loss: 1.1938 - val_acc: 0.6499

Epoch 00048: val_loss did not improve from 1.17901
Epoch 49/60
 - 5s - loss: 1.1243 - acc: 0.6606 - val_loss: 1.2235 - val_acc: 0.6484

Epoch 00049: val_loss did not improve from 1.17901
Epoch 50/60
 - 5s - loss: 1.1213 - acc: 0.6596 - val_loss: 1.2096 - val_acc: 0.6533

Epoch 00050: val_loss did not improve from 1.17901
Epoch 51/60
 - 5s - loss: 1.1228 - acc: 0.6611 - val_loss: 1.2136 - val_acc: 0.6492

Epoch 00051: val_loss did not improve from 1.17901
Epoch 52/60
 - 5s - loss: 1.1279 - acc: 0.6601 - val_loss: 1.2172 - val_acc: 0.6471

Epoch 00052: val_loss did not improve from 1.17901
Epoch 53/60
 - 5s - loss: 1.1195 - acc: 0.6595 - val_loss: 1.1757 - val_acc: 0.6509

Epoch 00053: val_loss improved from 1.17901 to 1.17567, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 54/60
 - 5s - loss: 1.1185 - acc: 0.6622 - val_loss: 1.1441 - val_acc: 0.6595

Epoch 00054: val_loss improved from 1.17567 to 1.14407, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5
Epoch 55/60
 - 5s - loss: 1.1177 - acc: 0.6606 - val_loss: 1.1931 - val_acc: 0.6500

Epoch 00055: val_loss did not improve from 1.14407
Epoch 56/60
 - 5s - loss: 1.1188 - acc: 0.6620 - val_loss: 1.2048 - val_acc: 0.6518

Epoch 00056: val_loss did not improve from 1.14407
Epoch 57/60
 - 5s - loss: 1.1143 - acc: 0.6609 - val_loss: 1.1514 - val_acc: 0.6574

Epoch 00057: val_loss did not improve from 1.14407
Epoch 58/60
 - 5s - loss: 1.1126 - acc: 0.6622 - val_loss: 1.2036 - val_acc: 0.6564

Epoch 00058: val_loss did not improve from 1.14407
Epoch 59/60
 - 5s - loss: 1.1152 - acc: 0.6620 - val_loss: 1.1749 - val_acc: 0.6595

Epoch 00059: val_loss did not improve from 1.14407
Epoch 60/60
 - 5s - loss: 1.1094 - acc: 0.6634 - val_loss: 1.2059 - val_acc: 0.6493

Epoch 00060: val_loss did not improve from 1.14407
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 2.4901 - acc: 0.5622 - val_loss: 1.3459 - val_acc: 0.6368

Epoch 00001: val_loss improved from inf to 1.34593, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 2/60
 - 5s - loss: 1.3512 - acc: 0.6330 - val_loss: 1.1072 - val_acc: 0.6608

Epoch 00002: val_loss improved from 1.34593 to 1.10717, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 3/60
 - 5s - loss: 1.2036 - acc: 0.6536 - val_loss: 0.9899 - val_acc: 0.6777

Epoch 00003: val_loss improved from 1.10717 to 0.98987, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 4/60
 - 5s - loss: 1.1020 - acc: 0.6690 - val_loss: 0.8687 - val_acc: 0.7001

Epoch 00004: val_loss improved from 0.98987 to 0.86872, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 5/60
 - 5s - loss: 1.0285 - acc: 0.6835 - val_loss: 0.8335 - val_acc: 0.7505

Epoch 00005: val_loss improved from 0.86872 to 0.83347, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 6/60
 - 5s - loss: 0.9664 - acc: 0.6977 - val_loss: 0.7699 - val_acc: 0.7627

Epoch 00006: val_loss improved from 0.83347 to 0.76986, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 7/60
 - 5s - loss: 0.9212 - acc: 0.7091 - val_loss: 0.7102 - val_acc: 0.7713

Epoch 00007: val_loss improved from 0.76986 to 0.71018, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 8/60
 - 5s - loss: 0.8835 - acc: 0.7204 - val_loss: 0.7054 - val_acc: 0.7783

Epoch 00008: val_loss improved from 0.71018 to 0.70536, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 9/60
 - 5s - loss: 0.8523 - acc: 0.7299 - val_loss: 0.6422 - val_acc: 0.7930

Epoch 00009: val_loss improved from 0.70536 to 0.64223, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 10/60
 - 5s - loss: 0.8286 - acc: 0.7352 - val_loss: 0.6374 - val_acc: 0.7963

Epoch 00010: val_loss improved from 0.64223 to 0.63743, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 11/60
 - 5s - loss: 0.8019 - acc: 0.7455 - val_loss: 0.6074 - val_acc: 0.8036

Epoch 00011: val_loss improved from 0.63743 to 0.60742, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 12/60
 - 5s - loss: 0.7799 - acc: 0.7519 - val_loss: 0.6267 - val_acc: 0.8096

Epoch 00012: val_loss did not improve from 0.60742
Epoch 13/60
 - 5s - loss: 0.7677 - acc: 0.7545 - val_loss: 0.5935 - val_acc: 0.8213

Epoch 00013: val_loss improved from 0.60742 to 0.59348, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 14/60
 - 5s - loss: 0.7495 - acc: 0.7603 - val_loss: 0.5691 - val_acc: 0.8232

Epoch 00014: val_loss improved from 0.59348 to 0.56911, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 15/60
 - 5s - loss: 0.7416 - acc: 0.7649 - val_loss: 0.5556 - val_acc: 0.8210

Epoch 00015: val_loss improved from 0.56911 to 0.55561, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 16/60
 - 5s - loss: 0.7273 - acc: 0.7677 - val_loss: 0.5485 - val_acc: 0.8239

Epoch 00016: val_loss improved from 0.55561 to 0.54846, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 17/60
 - 5s - loss: 0.7173 - acc: 0.7693 - val_loss: 0.5301 - val_acc: 0.8297

Epoch 00017: val_loss improved from 0.54846 to 0.53013, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 18/60
 - 5s - loss: 0.7094 - acc: 0.7704 - val_loss: 0.5348 - val_acc: 0.8249

Epoch 00018: val_loss did not improve from 0.53013
Epoch 19/60
 - 5s - loss: 0.7003 - acc: 0.7767 - val_loss: 0.5408 - val_acc: 0.8304

Epoch 00019: val_loss did not improve from 0.53013
Epoch 20/60
 - 5s - loss: 0.6959 - acc: 0.7763 - val_loss: 0.5109 - val_acc: 0.8395

Epoch 00020: val_loss improved from 0.53013 to 0.51093, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 21/60
 - 5s - loss: 0.6858 - acc: 0.7804 - val_loss: 0.5408 - val_acc: 0.8255

Epoch 00021: val_loss did not improve from 0.51093
Epoch 22/60
 - 5s - loss: 0.6783 - acc: 0.7828 - val_loss: 0.4985 - val_acc: 0.8414

Epoch 00022: val_loss improved from 0.51093 to 0.49845, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 23/60
 - 5s - loss: 0.6703 - acc: 0.7858 - val_loss: 0.4944 - val_acc: 0.8429

Epoch 00023: val_loss improved from 0.49845 to 0.49442, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 24/60
 - 5s - loss: 0.6691 - acc: 0.7856 - val_loss: 0.5013 - val_acc: 0.8413

Epoch 00024: val_loss did not improve from 0.49442
Epoch 25/60
 - 5s - loss: 0.6656 - acc: 0.7874 - val_loss: 0.4899 - val_acc: 0.8497

Epoch 00025: val_loss improved from 0.49442 to 0.48992, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 26/60
 - 5s - loss: 0.6623 - acc: 0.7884 - val_loss: 0.5085 - val_acc: 0.8386

Epoch 00026: val_loss did not improve from 0.48992
Epoch 27/60
 - 5s - loss: 0.6525 - acc: 0.7914 - val_loss: 0.5068 - val_acc: 0.8375

Epoch 00027: val_loss did not improve from 0.48992
Epoch 28/60
 - 5s - loss: 0.6496 - acc: 0.7903 - val_loss: 0.4933 - val_acc: 0.8385

Epoch 00028: val_loss did not improve from 0.48992
Epoch 29/60
 - 5s - loss: 0.6484 - acc: 0.7902 - val_loss: 0.4776 - val_acc: 0.8561

Epoch 00029: val_loss improved from 0.48992 to 0.47756, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 30/60
 - 5s - loss: 0.6449 - acc: 0.7946 - val_loss: 0.4719 - val_acc: 0.8547

Epoch 00030: val_loss improved from 0.47756 to 0.47189, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 31/60
 - 5s - loss: 0.6415 - acc: 0.7937 - val_loss: 0.4903 - val_acc: 0.8476

Epoch 00031: val_loss did not improve from 0.47189
Epoch 32/60
 - 5s - loss: 0.6410 - acc: 0.7967 - val_loss: 0.4787 - val_acc: 0.8450

Epoch 00032: val_loss did not improve from 0.47189
Epoch 33/60
 - 5s - loss: 0.6340 - acc: 0.7957 - val_loss: 0.4863 - val_acc: 0.8451

Epoch 00033: val_loss did not improve from 0.47189
Epoch 34/60
 - 5s - loss: 0.6306 - acc: 0.7977 - val_loss: 0.4648 - val_acc: 0.8561

Epoch 00034: val_loss improved from 0.47189 to 0.46476, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 35/60
 - 5s - loss: 0.6286 - acc: 0.7983 - val_loss: 0.4538 - val_acc: 0.8588

Epoch 00035: val_loss improved from 0.46476 to 0.45381, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 36/60
 - 5s - loss: 0.6272 - acc: 0.7988 - val_loss: 0.4596 - val_acc: 0.8570

Epoch 00036: val_loss did not improve from 0.45381
Epoch 37/60
 - 5s - loss: 0.6266 - acc: 0.8003 - val_loss: 0.4739 - val_acc: 0.8575

Epoch 00037: val_loss did not improve from 0.45381
Epoch 38/60
 - 5s - loss: 0.6178 - acc: 0.8017 - val_loss: 0.4562 - val_acc: 0.8566

Epoch 00038: val_loss did not improve from 0.45381
Epoch 39/60
 - 5s - loss: 0.6180 - acc: 0.8025 - val_loss: 0.4562 - val_acc: 0.8561

Epoch 00039: val_loss did not improve from 0.45381
Epoch 40/60
 - 5s - loss: 0.6132 - acc: 0.8034 - val_loss: 0.4707 - val_acc: 0.8545

Epoch 00040: val_loss did not improve from 0.45381
Epoch 41/60
 - 5s - loss: 0.6146 - acc: 0.8022 - val_loss: 0.4694 - val_acc: 0.8585

Epoch 00041: val_loss did not improve from 0.45381
Epoch 42/60
 - 5s - loss: 0.6165 - acc: 0.8032 - val_loss: 0.4670 - val_acc: 0.8632

Epoch 00042: val_loss did not improve from 0.45381
Epoch 43/60
 - 5s - loss: 0.6082 - acc: 0.8048 - val_loss: 0.4447 - val_acc: 0.8592

Epoch 00043: val_loss improved from 0.45381 to 0.44465, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 44/60
 - 5s - loss: 0.6101 - acc: 0.8049 - val_loss: 0.4539 - val_acc: 0.8557

Epoch 00044: val_loss did not improve from 0.44465
Epoch 45/60
 - 5s - loss: 0.6094 - acc: 0.8047 - val_loss: 0.4611 - val_acc: 0.8495

Epoch 00045: val_loss did not improve from 0.44465
Epoch 46/60
 - 5s - loss: 0.6058 - acc: 0.8061 - val_loss: 0.4493 - val_acc: 0.8611

Epoch 00046: val_loss did not improve from 0.44465
Epoch 47/60
 - 5s - loss: 0.6052 - acc: 0.8053 - val_loss: 0.4388 - val_acc: 0.8605

Epoch 00047: val_loss improved from 0.44465 to 0.43882, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 48/60
 - 5s - loss: 0.6023 - acc: 0.8074 - val_loss: 0.4382 - val_acc: 0.8601

Epoch 00048: val_loss improved from 0.43882 to 0.43820, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 49/60
 - 5s - loss: 0.5971 - acc: 0.8067 - val_loss: 0.4472 - val_acc: 0.8595

Epoch 00049: val_loss did not improve from 0.43820
Epoch 50/60
 - 5s - loss: 0.5926 - acc: 0.8072 - val_loss: 0.4541 - val_acc: 0.8613

Epoch 00050: val_loss did not improve from 0.43820
Epoch 51/60
 - 5s - loss: 0.5982 - acc: 0.8073 - val_loss: 0.4343 - val_acc: 0.8651

Epoch 00051: val_loss improved from 0.43820 to 0.43435, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 52/60
 - 5s - loss: 0.5997 - acc: 0.8083 - val_loss: 0.4411 - val_acc: 0.8666

Epoch 00052: val_loss did not improve from 0.43435
Epoch 53/60
 - 5s - loss: 0.5895 - acc: 0.8107 - val_loss: 0.4280 - val_acc: 0.8666

Epoch 00053: val_loss improved from 0.43435 to 0.42801, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 54/60
 - 5s - loss: 0.5955 - acc: 0.8083 - val_loss: 0.4439 - val_acc: 0.8545

Epoch 00054: val_loss did not improve from 0.42801
Epoch 55/60
 - 5s - loss: 0.5888 - acc: 0.8098 - val_loss: 0.4413 - val_acc: 0.8633

Epoch 00055: val_loss did not improve from 0.42801
Epoch 56/60
 - 5s - loss: 0.5930 - acc: 0.8102 - val_loss: 0.4289 - val_acc: 0.8647

Epoch 00056: val_loss did not improve from 0.42801
Epoch 57/60
 - 5s - loss: 0.5875 - acc: 0.8112 - val_loss: 0.4412 - val_acc: 0.8622

Epoch 00057: val_loss did not improve from 0.42801
Epoch 58/60
 - 5s - loss: 0.5852 - acc: 0.8139 - val_loss: 0.4370 - val_acc: 0.8630

Epoch 00058: val_loss did not improve from 0.42801
Epoch 59/60
 - 5s - loss: 0.5858 - acc: 0.8131 - val_loss: 0.4542 - val_acc: 0.8492

Epoch 00059: val_loss did not improve from 0.42801
Epoch 60/60
 - 5s - loss: 0.5878 - acc: 0.8109 - val_loss: 0.4566 - val_acc: 0.8523

Epoch 00060: val_loss did not improve from 0.42801
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 9s - loss: 4.6281 - acc: 0.2729 - val_loss: 2.2043 - val_acc: 0.6206

Epoch 00001: val_loss improved from inf to 2.20430, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 2/60
 - 4s - loss: 2.0052 - acc: 0.5363 - val_loss: 2.0893 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.20430 to 2.08926, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 3/60
 - 4s - loss: 1.7859 - acc: 0.6254 - val_loss: 1.9430 - val_acc: 0.6209

Epoch 00003: val_loss improved from 2.08926 to 1.94297, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 4/60
 - 4s - loss: 1.6876 - acc: 0.6359 - val_loss: 1.8073 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.94297 to 1.80734, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 5/60
 - 4s - loss: 1.6112 - acc: 0.6370 - val_loss: 1.6625 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.80734 to 1.66252, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 6/60
 - 4s - loss: 1.5726 - acc: 0.6371 - val_loss: 1.6345 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.66252 to 1.63453, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 7/60
 - 4s - loss: 1.5422 - acc: 0.6371 - val_loss: 1.5634 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.63453 to 1.56339, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 8/60
 - 4s - loss: 1.5179 - acc: 0.6371 - val_loss: 1.5567 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.56339 to 1.55665, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 9/60
 - 4s - loss: 1.5008 - acc: 0.6371 - val_loss: 1.5283 - val_acc: 0.6209

Epoch 00009: val_loss improved from 1.55665 to 1.52830, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 10/60
 - 4s - loss: 1.4892 - acc: 0.6371 - val_loss: 1.5364 - val_acc: 0.6209

Epoch 00010: val_loss did not improve from 1.52830
Epoch 11/60
 - 4s - loss: 1.4709 - acc: 0.6371 - val_loss: 1.5220 - val_acc: 0.6209

Epoch 00011: val_loss improved from 1.52830 to 1.52199, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 12/60
 - 4s - loss: 1.4604 - acc: 0.6371 - val_loss: 1.5111 - val_acc: 0.6209

Epoch 00012: val_loss improved from 1.52199 to 1.51109, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 13/60
 - 4s - loss: 1.4460 - acc: 0.6371 - val_loss: 1.4643 - val_acc: 0.6209

Epoch 00013: val_loss improved from 1.51109 to 1.46434, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 14/60
 - 4s - loss: 1.4330 - acc: 0.6371 - val_loss: 1.4648 - val_acc: 0.6209

Epoch 00014: val_loss did not improve from 1.46434
Epoch 15/60
 - 4s - loss: 1.4222 - acc: 0.6371 - val_loss: 1.4435 - val_acc: 0.6209

Epoch 00015: val_loss improved from 1.46434 to 1.44353, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 16/60
 - 4s - loss: 1.4091 - acc: 0.6371 - val_loss: 1.4123 - val_acc: 0.6209

Epoch 00016: val_loss improved from 1.44353 to 1.41235, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 17/60
 - 4s - loss: 1.4031 - acc: 0.6371 - val_loss: 1.4385 - val_acc: 0.6209

Epoch 00017: val_loss did not improve from 1.41235
Epoch 18/60
 - 4s - loss: 1.3925 - acc: 0.6371 - val_loss: 1.4361 - val_acc: 0.6209

Epoch 00018: val_loss did not improve from 1.41235
Epoch 19/60
 - 4s - loss: 1.3830 - acc: 0.6371 - val_loss: 1.4073 - val_acc: 0.6209

Epoch 00019: val_loss improved from 1.41235 to 1.40726, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 20/60
 - 4s - loss: 1.3770 - acc: 0.6371 - val_loss: 1.4393 - val_acc: 0.6209

Epoch 00020: val_loss did not improve from 1.40726
Epoch 21/60
 - 4s - loss: 1.3721 - acc: 0.6371 - val_loss: 1.4403 - val_acc: 0.6209

Epoch 00021: val_loss did not improve from 1.40726
Epoch 22/60
 - 4s - loss: 1.3653 - acc: 0.6371 - val_loss: 1.4534 - val_acc: 0.6209

Epoch 00022: val_loss did not improve from 1.40726
Epoch 23/60
 - 4s - loss: 1.3581 - acc: 0.6371 - val_loss: 1.3965 - val_acc: 0.6209

Epoch 00023: val_loss improved from 1.40726 to 1.39650, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 24/60
 - 4s - loss: 1.3574 - acc: 0.6371 - val_loss: 1.3843 - val_acc: 0.6209

Epoch 00024: val_loss improved from 1.39650 to 1.38428, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 25/60
 - 4s - loss: 1.3480 - acc: 0.6372 - val_loss: 1.3716 - val_acc: 0.6209

Epoch 00025: val_loss improved from 1.38428 to 1.37158, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 26/60
 - 4s - loss: 1.3511 - acc: 0.6371 - val_loss: 1.3841 - val_acc: 0.6209

Epoch 00026: val_loss did not improve from 1.37158
Epoch 27/60
 - 4s - loss: 1.3429 - acc: 0.6371 - val_loss: 1.3998 - val_acc: 0.6209

Epoch 00027: val_loss did not improve from 1.37158
Epoch 28/60
 - 4s - loss: 1.3434 - acc: 0.6371 - val_loss: 1.3647 - val_acc: 0.6209

Epoch 00028: val_loss improved from 1.37158 to 1.36468, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 29/60
 - 4s - loss: 1.3373 - acc: 0.6371 - val_loss: 1.4250 - val_acc: 0.6209

Epoch 00029: val_loss did not improve from 1.36468
Epoch 30/60
 - 4s - loss: 1.3349 - acc: 0.6371 - val_loss: 1.4318 - val_acc: 0.6209

Epoch 00030: val_loss did not improve from 1.36468
Epoch 31/60
 - 4s - loss: 1.3371 - acc: 0.6371 - val_loss: 1.3861 - val_acc: 0.6209

Epoch 00031: val_loss did not improve from 1.36468
Epoch 32/60
 - 4s - loss: 1.3322 - acc: 0.6371 - val_loss: 1.3591 - val_acc: 0.6209

Epoch 00032: val_loss improved from 1.36468 to 1.35910, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 33/60
 - 4s - loss: 1.3291 - acc: 0.6371 - val_loss: 1.3613 - val_acc: 0.6209

Epoch 00033: val_loss did not improve from 1.35910
Epoch 34/60
 - 4s - loss: 1.3277 - acc: 0.6371 - val_loss: 1.3942 - val_acc: 0.6209

Epoch 00034: val_loss did not improve from 1.35910
Epoch 35/60
 - 4s - loss: 1.3297 - acc: 0.6371 - val_loss: 1.3575 - val_acc: 0.6209

Epoch 00035: val_loss improved from 1.35910 to 1.35750, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 36/60
 - 4s - loss: 1.3268 - acc: 0.6371 - val_loss: 1.4248 - val_acc: 0.6209

Epoch 00036: val_loss did not improve from 1.35750
Epoch 37/60
 - 4s - loss: 1.3257 - acc: 0.6371 - val_loss: 1.3385 - val_acc: 0.6209

Epoch 00037: val_loss improved from 1.35750 to 1.33853, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 38/60
 - 4s - loss: 1.3242 - acc: 0.6371 - val_loss: 1.3705 - val_acc: 0.6209

Epoch 00038: val_loss did not improve from 1.33853
Epoch 39/60
 - 4s - loss: 1.3228 - acc: 0.6371 - val_loss: 1.3462 - val_acc: 0.6209

Epoch 00039: val_loss did not improve from 1.33853
Epoch 40/60
 - 4s - loss: 1.3189 - acc: 0.6371 - val_loss: 1.4295 - val_acc: 0.6209

Epoch 00040: val_loss did not improve from 1.33853
Epoch 41/60
 - 4s - loss: 1.3203 - acc: 0.6370 - val_loss: 1.3550 - val_acc: 0.6209

Epoch 00041: val_loss did not improve from 1.33853
Epoch 42/60
 - 4s - loss: 1.3205 - acc: 0.6371 - val_loss: 1.3516 - val_acc: 0.6209

Epoch 00042: val_loss did not improve from 1.33853
Epoch 43/60
 - 4s - loss: 1.3145 - acc: 0.6370 - val_loss: 1.3756 - val_acc: 0.6209

Epoch 00043: val_loss did not improve from 1.33853
Epoch 44/60
 - 4s - loss: 1.3169 - acc: 0.6370 - val_loss: 1.3387 - val_acc: 0.6209

Epoch 00044: val_loss did not improve from 1.33853
Epoch 45/60
 - 4s - loss: 1.3152 - acc: 0.6371 - val_loss: 1.4053 - val_acc: 0.6209

Epoch 00045: val_loss did not improve from 1.33853
Epoch 46/60
 - 4s - loss: 1.3175 - acc: 0.6370 - val_loss: 1.3598 - val_acc: 0.6209

Epoch 00046: val_loss did not improve from 1.33853
Epoch 47/60
 - 4s - loss: 1.3125 - acc: 0.6370 - val_loss: 1.3669 - val_acc: 0.6209

Epoch 00047: val_loss did not improve from 1.33853
Epoch 00047: early stopping
Train on 51088 samples, validate on 6798 samples
Epoch 1/60
 - 10s - loss: 3.1349 - acc: 0.5134 - val_loss: 2.1987 - val_acc: 0.6209

Epoch 00001: val_loss improved from inf to 2.19874, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 2/60
 - 6s - loss: 1.6873 - acc: 0.6310 - val_loss: 2.0705 - val_acc: 0.6209

Epoch 00002: val_loss improved from 2.19874 to 2.07046, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 3/60
 - 5s - loss: 1.5795 - acc: 0.6371 - val_loss: 1.9267 - val_acc: 0.6209

Epoch 00003: val_loss improved from 2.07046 to 1.92672, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 4/60
 - 5s - loss: 1.5267 - acc: 0.6371 - val_loss: 1.8142 - val_acc: 0.6209

Epoch 00004: val_loss improved from 1.92672 to 1.81420, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 5/60
 - 5s - loss: 1.4987 - acc: 0.6371 - val_loss: 1.7035 - val_acc: 0.6209

Epoch 00005: val_loss improved from 1.81420 to 1.70352, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 6/60
 - 5s - loss: 1.4735 - acc: 0.6371 - val_loss: 1.6992 - val_acc: 0.6209

Epoch 00006: val_loss improved from 1.70352 to 1.69922, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 7/60
 - 5s - loss: 1.4571 - acc: 0.6371 - val_loss: 1.6094 - val_acc: 0.6209

Epoch 00007: val_loss improved from 1.69922 to 1.60940, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 8/60
 - 5s - loss: 1.4317 - acc: 0.6371 - val_loss: 1.5764 - val_acc: 0.6209

Epoch 00008: val_loss improved from 1.60940 to 1.57638, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 9/60
 - 5s - loss: 1.4151 - acc: 0.6371 - val_loss: 1.5345 - val_acc: 0.6209

Epoch 00009: val_loss improved from 1.57638 to 1.53450, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 10/60
 - 5s - loss: 1.3964 - acc: 0.6371 - val_loss: 1.4873 - val_acc: 0.6209

Epoch 00010: val_loss improved from 1.53450 to 1.48729, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 11/60
 - 5s - loss: 1.3597 - acc: 0.6368 - val_loss: 1.4044 - val_acc: 0.6209

Epoch 00011: val_loss improved from 1.48729 to 1.40442, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 12/60
 - 5s - loss: 1.3283 - acc: 0.6360 - val_loss: 1.4406 - val_acc: 0.6211

Epoch 00012: val_loss did not improve from 1.40442
Epoch 13/60
 - 5s - loss: 1.3068 - acc: 0.6367 - val_loss: 1.4236 - val_acc: 0.6225

Epoch 00013: val_loss did not improve from 1.40442
Epoch 14/60
 - 5s - loss: 1.2859 - acc: 0.6382 - val_loss: 1.3447 - val_acc: 0.6224

Epoch 00014: val_loss improved from 1.40442 to 1.34475, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 15/60
 - 5s - loss: 1.2708 - acc: 0.6379 - val_loss: 1.3676 - val_acc: 0.6222

Epoch 00015: val_loss did not improve from 1.34475
Epoch 16/60
 - 5s - loss: 1.2546 - acc: 0.6411 - val_loss: 1.3520 - val_acc: 0.6219

Epoch 00016: val_loss did not improve from 1.34475
Epoch 17/60
 - 5s - loss: 1.2431 - acc: 0.6407 - val_loss: 1.3381 - val_acc: 0.6209

Epoch 00017: val_loss improved from 1.34475 to 1.33815, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 18/60
 - 5s - loss: 1.2369 - acc: 0.6409 - val_loss: 1.3669 - val_acc: 0.6217

Epoch 00018: val_loss did not improve from 1.33815
Epoch 19/60
 - 5s - loss: 1.2278 - acc: 0.6427 - val_loss: 1.3235 - val_acc: 0.6217

Epoch 00019: val_loss improved from 1.33815 to 1.32353, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 20/60
 - 6s - loss: 1.2221 - acc: 0.6434 - val_loss: 1.2709 - val_acc: 0.6234

Epoch 00020: val_loss improved from 1.32353 to 1.27092, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 21/60
 - 6s - loss: 1.2163 - acc: 0.6448 - val_loss: 1.3165 - val_acc: 0.6247

Epoch 00021: val_loss did not improve from 1.27092
Epoch 22/60
 - 6s - loss: 1.2082 - acc: 0.6443 - val_loss: 1.3357 - val_acc: 0.6209

Epoch 00022: val_loss did not improve from 1.27092
Epoch 23/60
 - 6s - loss: 1.2020 - acc: 0.6454 - val_loss: 1.3332 - val_acc: 0.6258

Epoch 00023: val_loss did not improve from 1.27092
Epoch 24/60
 - 6s - loss: 1.1968 - acc: 0.6483 - val_loss: 1.2685 - val_acc: 0.6242

Epoch 00024: val_loss improved from 1.27092 to 1.26851, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 25/60
 - 6s - loss: 1.1932 - acc: 0.6470 - val_loss: 1.2828 - val_acc: 0.6300

Epoch 00025: val_loss did not improve from 1.26851
Epoch 26/60
 - 6s - loss: 1.1885 - acc: 0.6496 - val_loss: 1.3249 - val_acc: 0.6267

Epoch 00026: val_loss did not improve from 1.26851
Epoch 27/60
 - 6s - loss: 1.1850 - acc: 0.6508 - val_loss: 1.2469 - val_acc: 0.6312

Epoch 00027: val_loss improved from 1.26851 to 1.24695, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 28/60
 - 6s - loss: 1.1834 - acc: 0.6496 - val_loss: 1.2504 - val_acc: 0.6277

Epoch 00028: val_loss did not improve from 1.24695
Epoch 29/60
 - 6s - loss: 1.1734 - acc: 0.6515 - val_loss: 1.3093 - val_acc: 0.6339

Epoch 00029: val_loss did not improve from 1.24695
Epoch 30/60
 - 6s - loss: 1.1756 - acc: 0.6511 - val_loss: 1.2695 - val_acc: 0.6361

Epoch 00030: val_loss did not improve from 1.24695
Epoch 31/60
 - 6s - loss: 1.1690 - acc: 0.6525 - val_loss: 1.2518 - val_acc: 0.6405

Epoch 00031: val_loss did not improve from 1.24695
Epoch 32/60
 - 6s - loss: 1.1664 - acc: 0.6535 - val_loss: 1.2460 - val_acc: 0.6418

Epoch 00032: val_loss improved from 1.24695 to 1.24602, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 33/60
 - 6s - loss: 1.1641 - acc: 0.6533 - val_loss: 1.2411 - val_acc: 0.6425

Epoch 00033: val_loss improved from 1.24602 to 1.24112, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 34/60
 - 6s - loss: 1.1524 - acc: 0.6548 - val_loss: 1.1921 - val_acc: 0.6467

Epoch 00034: val_loss improved from 1.24112 to 1.19213, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 35/60
 - 6s - loss: 1.1525 - acc: 0.6557 - val_loss: 1.2409 - val_acc: 0.6436

Epoch 00035: val_loss did not improve from 1.19213
Epoch 36/60
 - 6s - loss: 1.1484 - acc: 0.6549 - val_loss: 1.1675 - val_acc: 0.6474

Epoch 00036: val_loss improved from 1.19213 to 1.16754, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 37/60
 - 6s - loss: 1.1444 - acc: 0.6559 - val_loss: 1.1464 - val_acc: 0.6468

Epoch 00037: val_loss improved from 1.16754 to 1.14644, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 38/60
 - 6s - loss: 1.1453 - acc: 0.6577 - val_loss: 1.1243 - val_acc: 0.6521

Epoch 00038: val_loss improved from 1.14644 to 1.12429, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 39/60
 - 6s - loss: 1.1402 - acc: 0.6583 - val_loss: 1.1789 - val_acc: 0.6518

Epoch 00039: val_loss did not improve from 1.12429
Epoch 40/60
 - 6s - loss: 1.1366 - acc: 0.6590 - val_loss: 1.1803 - val_acc: 0.6524

Epoch 00040: val_loss did not improve from 1.12429
Epoch 41/60
 - 6s - loss: 1.1327 - acc: 0.6599 - val_loss: 1.1281 - val_acc: 0.6565

Epoch 00041: val_loss did not improve from 1.12429
Epoch 42/60
 - 6s - loss: 1.1362 - acc: 0.6583 - val_loss: 1.1192 - val_acc: 0.6514

Epoch 00042: val_loss improved from 1.12429 to 1.11924, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 43/60
 - 6s - loss: 1.1237 - acc: 0.6610 - val_loss: 1.1043 - val_acc: 0.6630

Epoch 00043: val_loss improved from 1.11924 to 1.10428, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 44/60
 - 6s - loss: 1.1236 - acc: 0.6600 - val_loss: 1.1239 - val_acc: 0.6536

Epoch 00044: val_loss did not improve from 1.10428
Epoch 45/60
 - 6s - loss: 1.1232 - acc: 0.6603 - val_loss: 1.0925 - val_acc: 0.6556

Epoch 00045: val_loss improved from 1.10428 to 1.09255, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 46/60
 - 6s - loss: 1.1187 - acc: 0.6621 - val_loss: 1.1700 - val_acc: 0.6595

Epoch 00046: val_loss did not improve from 1.09255
Epoch 47/60
 - 6s - loss: 1.1159 - acc: 0.6626 - val_loss: 1.1804 - val_acc: 0.6586

Epoch 00047: val_loss did not improve from 1.09255
Epoch 48/60
 - 6s - loss: 1.1111 - acc: 0.6637 - val_loss: 1.0956 - val_acc: 0.6631

Epoch 00048: val_loss did not improve from 1.09255
Epoch 49/60
 - 6s - loss: 1.1073 - acc: 0.6641 - val_loss: 1.0801 - val_acc: 0.6627

Epoch 00049: val_loss improved from 1.09255 to 1.08012, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 50/60
 - 6s - loss: 1.1061 - acc: 0.6655 - val_loss: 1.1284 - val_acc: 0.6598

Epoch 00050: val_loss did not improve from 1.08012
Epoch 51/60
 - 6s - loss: 1.1076 - acc: 0.6640 - val_loss: 1.0668 - val_acc: 0.6583

Epoch 00051: val_loss improved from 1.08012 to 1.06681, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 52/60
 - 6s - loss: 1.1024 - acc: 0.6640 - val_loss: 1.0835 - val_acc: 0.6574

Epoch 00052: val_loss did not improve from 1.06681
Epoch 53/60
 - 6s - loss: 1.0988 - acc: 0.6667 - val_loss: 1.1107 - val_acc: 0.6642

Epoch 00053: val_loss did not improve from 1.06681
Epoch 54/60
 - 6s - loss: 1.0955 - acc: 0.6663 - val_loss: 1.0943 - val_acc: 0.6639

Epoch 00054: val_loss did not improve from 1.06681
Epoch 55/60
 - 6s - loss: 1.0951 - acc: 0.6670 - val_loss: 1.0684 - val_acc: 0.6634

Epoch 00055: val_loss did not improve from 1.06681
Epoch 56/60
 - 6s - loss: 1.0930 - acc: 0.6656 - val_loss: 1.0516 - val_acc: 0.6611

Epoch 00056: val_loss improved from 1.06681 to 1.05161, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 57/60
 - 6s - loss: 1.0889 - acc: 0.6666 - val_loss: 1.0800 - val_acc: 0.6587

Epoch 00057: val_loss did not improve from 1.05161
Epoch 58/60
 - 6s - loss: 1.0878 - acc: 0.6682 - val_loss: 1.0421 - val_acc: 0.6655

Epoch 00058: val_loss improved from 1.05161 to 1.04205, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
Epoch 59/60
 - 6s - loss: 1.0860 - acc: 0.6674 - val_loss: 1.0614 - val_acc: 0.6587

Epoch 00059: val_loss did not improve from 1.04205
Epoch 60/60
 - 6s - loss: 1.0859 - acc: 0.6668 - val_loss: 1.0103 - val_acc: 0.6678

Epoch 00060: val_loss improved from 1.04205 to 1.01028, saving model to C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="7.-Model-Evaluation-and-Selection">7. Model Evaluation and Selection<a class="anchor-link" href="#7.-Model-Evaluation-and-Selection">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_testing</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">x_testing</span><span class="p">,</span> <span class="n">y_testing</span><span class="p">):</span>
    <span class="c1"># load model with minimal validation log loss</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    
    <span class="c1"># score model against testing data</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_testing</span><span class="p">,</span> <span class="n">y_testing</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Filename: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span><span class="o">+</span> <span class="s1">&#39; | Test accuracy:&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># retrieve filepaths of all models</span>
<span class="n">dir_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s1">&#39;__file__&#39;</span><span class="p">)),</span><span class="s1">&#39;models&#39;</span><span class="p">)</span>
<span class="n">models</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">))</span>

<span class="c1"># load testing data into memory</span>
<span class="n">x_testing</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;data/x_testing.npy&#39;</span><span class="p">)</span>
<span class="n">y_testing</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;data/y_testing.npy&#39;</span><span class="p">)</span>

<span class="c1"># testing each model against the testing data</span>
<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">test</span> <span class="o">=</span> <span class="n">model_testing</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_testing</span><span class="p">,</span> <span class="n">y_testing</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>6835/6835 [==============================] - 1s 77us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.1.hdf5 | Test accuracy: 0.8343818580397918
6835/6835 [==============================] - 1s 82us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra-0.5.hdf5 | Test accuracy: 0.8411119238773923
6835/6835 [==============================] - 1s 84us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.01_ra0.hdf5 | Test accuracy: 0.8460863204096561
6835/6835 [==============================] - 1s 86us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.1.hdf5 | Test accuracy: 0.8495976591685783
6835/6835 [==============================] - 1s 93us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra-0.5.hdf5 | Test accuracy: 0.8466715435870128
6835/6835 [==============================] - 1s 92us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.05_ra0.hdf5 | Test accuracy: 0.8304316020482809
6835/6835 [==============================] - 1s 94us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.1.hdf5 | Test accuracy: 0.8292611558156547
6835/6835 [==============================] - 1s 96us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra-0.5.hdf5 | Test accuracy: 0.8422823701536211
6835/6835 [==============================] - 1s 103us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.0_lr0.1_ra0.hdf5 | Test accuracy: 0.8463789319678128
6835/6835 [==============================] - 1s 106us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.1.hdf5 | Test accuracy: 0.8721287490855889
6835/6835 [==============================] - 1s 109us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra-0.5.hdf5 | Test accuracy: 0.8795903437749784
6835/6835 [==============================] - 1s 111us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.01_ra0.hdf5 | Test accuracy: 0.8794440380395026
6835/6835 [==============================] - 1s 116us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.1.hdf5 | Test accuracy: 0.8727139722019019
6835/6835 [==============================] - 1s 116us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra-0.5.hdf5 | Test accuracy: 0.8756400877834675
6835/6835 [==============================] - 1s 118us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.05_ra0.hdf5 | Test accuracy: 0.8820775420629114
6835/6835 [==============================] - 1s 123us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.1.hdf5 | Test accuracy: 0.8820775421239551
6835/6835 [==============================] - 1s 127us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra-0.5.hdf5 | Test accuracy: 0.860131675262214
6835/6835 [==============================] - 1s 125us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.25_lr0.1_ra0.hdf5 | Test accuracy: 0.8769568397951719
6835/6835 [==============================] - 1s 130us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.1.hdf5 | Test accuracy: 0.8479882955376737
6835/6835 [==============================] - 1s 138us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra-0.5.hdf5 | Test accuracy: 0.8471104609242476
6835/6835 [==============================] - 1s 131us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.01_ra0.hdf5 | Test accuracy: 0.8472567666422823
6835/6835 [==============================] - 1s 144us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.1.hdf5 | Test accuracy: 0.8450621800171518
6835/6835 [==============================] - 1s 137us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra-0.5.hdf5 | Test accuracy: 0.852962692026335
6835/6835 [==============================] - 1s 144us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.05_ra0.hdf5 | Test accuracy: 0.8541331382589612
6835/6835 [==============================] - 1s 147us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.1.hdf5 | Test accuracy: 0.846525237746891
6835/6835 [==============================] - 1s 145us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra-0.5.hdf5 | Test accuracy: 0.8476956839795172
6835/6835 [==============================] - 1s 151us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model1_dr0.5_lr0.1_ra0.hdf5 | Test accuracy: 0.8520848573518653
6835/6835 [==============================] - 1s 138us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.1.hdf5 | Test accuracy: 0.8001463058401218
6835/6835 [==============================] - 1s 145us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra-0.5.hdf5 | Test accuracy: 0.8210680322483149
6835/6835 [==============================] - 1s 154us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.01_ra0.hdf5 | Test accuracy: 0.8226773958181759
6835/6835 [==============================] - 1s 149us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.1.hdf5 | Test accuracy: 0.819458668678454
6835/6835 [==============================] - 1s 152us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra-0.5.hdf5 | Test accuracy: 0.8149231894659839
6835/6835 [==============================] - 1s 152us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.05_ra0.hdf5 | Test accuracy: 0.8210680321872714
6835/6835 [==============================] - 1s 167us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.1.hdf5 | Test accuracy: 0.8244330651060717
6835/6835 [==============================] - 1s 162us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra-0.5.hdf5 | Test accuracy: 0.8106803219337575
6835/6835 [==============================] - 1s 175us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.0_lr0.1_ra0.hdf5 | Test accuracy: 0.8220921726408194
6835/6835 [==============================] - 1s 178us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.1.hdf5 | Test accuracy: 0.71016825164594
6835/6835 [==============================] - 1s 185us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra-0.5.hdf5 | Test accuracy: 0.7227505486466715
6835/6835 [==============================] - 1s 213us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.01_ra0.hdf5 | Test accuracy: 0.7130943672275055
6835/6835 [==============================] - 2s 222us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.1.hdf5 | Test accuracy: 0.7448427212874908
6835/6835 [==============================] - 1s 201us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra-0.5.hdf5 | Test accuracy: 0.7312362838332114
6835/6835 [==============================] - 1s 199us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.05_ra0.hdf5 | Test accuracy: 0.7231894659839063
6835/6835 [==============================] - 1s 201us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.1.hdf5 | Test accuracy: 0.7003657644476957
6835/6835 [==============================] - 1s 210us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra-0.5.hdf5 | Test accuracy: 0.7492318946598391
6835/6835 [==============================] - 2s 226us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.25_lr0.1_ra0.hdf5 | Test accuracy: 0.7211411850768106
6835/6835 [==============================] - 2s 227us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.1.hdf5 | Test accuracy: 0.6244330651060717
6835/6835 [==============================] - 2s 227us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra-0.5.hdf5 | Test accuracy: 0.6244330651060717
6835/6835 [==============================] - 2s 239us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.01_ra0.hdf5 | Test accuracy: 0.6244330651060717
6835/6835 [==============================] - 2s 225us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.1.hdf5 | Test accuracy: 0.6244330651060717
6835/6835 [==============================] - 2s 246us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra-0.5.hdf5 | Test accuracy: 0.6244330651060717
6835/6835 [==============================] - 2s 237us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.05_ra0.hdf5 | Test accuracy: 0.6244330651060717
6835/6835 [==============================] - 2s 234us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.1.hdf5 | Test accuracy: 0.6244330651060717
6835/6835 [==============================] - 2s 241us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra-0.5.hdf5 | Test accuracy: 0.6244330651060717
6835/6835 [==============================] - 2s 264us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model2_dr0.5_lr0.1_ra0.hdf5 | Test accuracy: 0.6244330651060717
6835/6835 [==============================] - 2s 273us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.1.hdf5 | Test accuracy: 0.8361375274933771
6835/6835 [==============================] - 2s 272us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra-0.5.hdf5 | Test accuracy: 0.8361375274933771
6835/6835 [==============================] - 2s 269us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.01_ra0.hdf5 | Test accuracy: 0.8348207754816727
6835/6835 [==============================] - 2s 265us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.1.hdf5 | Test accuracy: 0.8279444038039503
6835/6835 [==============================] - 2s 295us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra-0.5.hdf5 | Test accuracy: 0.8238478419897586
6835/6835 [==============================] - 2s 272us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.05_ra0.hdf5 | Test accuracy: 0.8207754206901584
6835/6835 [==============================] - 2s 292us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.1.hdf5 | Test accuracy: 0.8215069495245062
6835/6835 [==============================] - 2s 287us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra-0.5.hdf5 | Test accuracy: 0.8343818580833943
6835/6835 [==============================] - 2s 294us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.0_lr0.1_ra0.hdf5 | Test accuracy: 0.8276517923068373
6835/6835 [==============================] - 2s 304us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.1.hdf5 | Test accuracy: 0.8318946599001071
6835/6835 [==============================] - 2s 295us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra-0.5.hdf5 | Test accuracy: 0.8343818580833943
6835/6835 [==============================] - 2s 306us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.01_ra0.hdf5 | Test accuracy: 0.8337966350281247
6835/6835 [==============================] - 2s 321us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.1.hdf5 | Test accuracy: 0.8378931967812728
6835/6835 [==============================] - 2s 308us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra-0.5.hdf5 | Test accuracy: 0.8349670812607509
6835/6835 [==============================] - 2s 319us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.05_ra0.hdf5 | Test accuracy: 0.8283833212022286
6835/6835 [==============================] - 2s 334us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.1.hdf5 | Test accuracy: 0.8215069495245062
6835/6835 [==============================] - 2s 355us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra-0.5.hdf5 | Test accuracy: 0.82911485009762
6835/6835 [==============================] - 2s 351us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.25_lr0.1_ra0.hdf5 | Test accuracy: 0.8247256766642282
6835/6835 [==============================] - 2s 353us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.1.hdf5 | Test accuracy: 0.6699341623994147
6835/6835 [==============================] - 2s 352us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra-0.5.hdf5 | Test accuracy: 0.6618873445501098
6835/6835 [==============================] - 2s 362us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.01_ra0.hdf5 | Test accuracy: 0.6488661302121433
6835/6835 [==============================] - 2s 356us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.1.hdf5 | Test accuracy: 0.6716898317483541
6835/6835 [==============================] - 2s 359us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra-0.5.hdf5 | Test accuracy: 0.6531089978054133
6835/6835 [==============================] - 2s 354us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.05_ra0.hdf5 | Test accuracy: 0.6557425018288222
6835/6835 [==============================] - 3s 391us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.1.hdf5 | Test accuracy: 0.6585223116313095
6835/6835 [==============================] - 3s 407us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra-0.5.hdf5 | Test accuracy: 0.6646671543525969
6835/6835 [==============================] - 3s 402us/step
Filename: C:\Users\Tyler\Desktop\Capstone WIP\models\model3_dr0.5_lr0.1_ra0.hdf5 | Test accuracy: 0.6574981711777615
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below is my test data sorted by model architecture, then by dropout rate, by learning rate, and by ReLU alpha.</p>
<table>
<thead><tr>
<th>Model #</th>
<th>Dropout Rate</th>
<th>Learning Rate</th>
<th>ReLU Alpha</th>
<th>Test Accuracy Score</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0</td>
<td>0.01</td>
<td>0</td>
<td>84.61%</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0.01</td>
<td>0.1</td>
<td>83.44%</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0.01</td>
<td>0.5</td>
<td>84.11%</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0.05</td>
<td>0</td>
<td>83.04%</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0.05</td>
<td>0.1</td>
<td>84.96%</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0.05</td>
<td>0.5</td>
<td>84.67%</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0.1</td>
<td>0</td>
<td>84.64%</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0.1</td>
<td>0.1</td>
<td>82.93%</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0.1</td>
<td>0.5</td>
<td>84.23%</td>
</tr>
<tr>
<td>1</td>
<td>0.25</td>
<td>0.01</td>
<td>0</td>
<td>87.94%</td>
</tr>
<tr>
<td>1</td>
<td>0.25</td>
<td>0.01</td>
<td>0.1</td>
<td>87.21%</td>
</tr>
<tr>
<td>1</td>
<td>0.25</td>
<td>0.01</td>
<td>0.5</td>
<td>87.96%</td>
</tr>
<tr>
<td>1</td>
<td>0.25</td>
<td>0.05</td>
<td>0</td>
<td>88.21%</td>
</tr>
<tr>
<td>1</td>
<td>0.25</td>
<td>0.05</td>
<td>0.1</td>
<td>87.27%</td>
</tr>
<tr>
<td>1</td>
<td>0.25</td>
<td>0.05</td>
<td>0.5</td>
<td>87.56%</td>
</tr>
<tr>
<td>1</td>
<td>0.25</td>
<td>0.1</td>
<td>0</td>
<td>87.70%</td>
</tr>
<tr>
<td>1</td>
<td>0.25</td>
<td>0.1</td>
<td>0.1</td>
<td>88.21%</td>
</tr>
<tr>
<td>1</td>
<td>0.25</td>
<td>0.1</td>
<td>0.5</td>
<td>86.01%</td>
</tr>
<tr>
<td>1</td>
<td>0.5</td>
<td>0.01</td>
<td>0</td>
<td>84.73%</td>
</tr>
<tr>
<td>1</td>
<td>0.5</td>
<td>0.01</td>
<td>0.1</td>
<td>84.80%</td>
</tr>
<tr>
<td>1</td>
<td>0.5</td>
<td>0.01</td>
<td>0.5</td>
<td>84.71%</td>
</tr>
<tr>
<td>1</td>
<td>0.5</td>
<td>0.05</td>
<td>0</td>
<td>85.41%</td>
</tr>
<tr>
<td>1</td>
<td>0.5</td>
<td>0.05</td>
<td>0.1</td>
<td>84.51%</td>
</tr>
<tr>
<td>1</td>
<td>0.5</td>
<td>0.05</td>
<td>0.5</td>
<td>85.30%</td>
</tr>
<tr>
<td>1</td>
<td>0.5</td>
<td>0.1</td>
<td>0</td>
<td>85.21%</td>
</tr>
<tr>
<td>1</td>
<td>0.5</td>
<td>0.1</td>
<td>0.1</td>
<td>84.65%</td>
</tr>
<tr>
<td>1</td>
<td>0.5</td>
<td>0.1</td>
<td>0.5</td>
<td>84.77%</td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>0.01</td>
<td>0</td>
<td>82.27%</td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>0.01</td>
<td>0.1</td>
<td>80.01%</td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>0.01</td>
<td>0.5</td>
<td>82.11%</td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>0.05</td>
<td>0</td>
<td>82.11%</td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>0.05</td>
<td>0.1</td>
<td>81.95%</td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>0.05</td>
<td>0.5</td>
<td>81.49%</td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>0.1</td>
<td>0</td>
<td>82.21%</td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>0.1</td>
<td>0.1</td>
<td>82.44%</td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>0.1</td>
<td>0.5</td>
<td>81.07%</td>
</tr>
<tr>
<td>2</td>
<td>0.25</td>
<td>0.01</td>
<td>0</td>
<td>71.31%</td>
</tr>
<tr>
<td>2</td>
<td>0.25</td>
<td>0.01</td>
<td>0.1</td>
<td>71.02%</td>
</tr>
<tr>
<td>2</td>
<td>0.25</td>
<td>0.01</td>
<td>0.5</td>
<td>72.28%</td>
</tr>
<tr>
<td>2</td>
<td>0.25</td>
<td>0.05</td>
<td>0</td>
<td>72.32%</td>
</tr>
<tr>
<td>2</td>
<td>0.25</td>
<td>0.05</td>
<td>0.1</td>
<td>74.48%</td>
</tr>
<tr>
<td>2</td>
<td>0.25</td>
<td>0.05</td>
<td>0.5</td>
<td>73.12%</td>
</tr>
<tr>
<td>2</td>
<td>0.25</td>
<td>0.1</td>
<td>0</td>
<td>72.11%</td>
</tr>
<tr>
<td>2</td>
<td>0.25</td>
<td>0.1</td>
<td>0.1</td>
<td>70.04%</td>
</tr>
<tr>
<td>2</td>
<td>0.25</td>
<td>0.1</td>
<td>0.5</td>
<td>74.92%</td>
</tr>
<tr>
<td>2</td>
<td>0.5</td>
<td>0.01</td>
<td>0</td>
<td>62.44%</td>
</tr>
<tr>
<td>2</td>
<td>0.5</td>
<td>0.01</td>
<td>0.1</td>
<td>62.44%</td>
</tr>
<tr>
<td>2</td>
<td>0.5</td>
<td>0.01</td>
<td>0.5</td>
<td>62.44%</td>
</tr>
<tr>
<td>2</td>
<td>0.5</td>
<td>0.05</td>
<td>0</td>
<td>62.44%</td>
</tr>
<tr>
<td>2</td>
<td>0.5</td>
<td>0.05</td>
<td>0.1</td>
<td>62.44%</td>
</tr>
<tr>
<td>2</td>
<td>0.5</td>
<td>0.05</td>
<td>0.5</td>
<td>62.44%</td>
</tr>
<tr>
<td>2</td>
<td>0.5</td>
<td>0.1</td>
<td>0</td>
<td>62.44%</td>
</tr>
<tr>
<td>2</td>
<td>0.5</td>
<td>0.1</td>
<td>0.1</td>
<td>62.44%</td>
</tr>
<tr>
<td>2</td>
<td>0.5</td>
<td>0.1</td>
<td>0.5</td>
<td>62.44%</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>0.01</td>
<td>0</td>
<td>83.48%</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>0.01</td>
<td>0.1</td>
<td>83.61%</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>0.01</td>
<td>0.5</td>
<td>83.61%</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>0.05</td>
<td>0</td>
<td>82.08%</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>0.05</td>
<td>0.1</td>
<td>82.79%</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>0.05</td>
<td>0.5</td>
<td>82.38%</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>0.1</td>
<td>0</td>
<td>82.77%</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>0.1</td>
<td>0.1</td>
<td>82.15%</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>0.1</td>
<td>0.5</td>
<td>83.44%</td>
</tr>
<tr>
<td>3</td>
<td>0.25</td>
<td>0.01</td>
<td>0</td>
<td>83.38%</td>
</tr>
<tr>
<td>3</td>
<td>0.25</td>
<td>0.01</td>
<td>0.1</td>
<td>83.19%</td>
</tr>
<tr>
<td>3</td>
<td>0.25</td>
<td>0.01</td>
<td>0.5</td>
<td>83.44%</td>
</tr>
<tr>
<td>3</td>
<td>0.25</td>
<td>0.05</td>
<td>0</td>
<td>82.84%</td>
</tr>
<tr>
<td>3</td>
<td>0.25</td>
<td>0.05</td>
<td>0.1</td>
<td>83.79%</td>
</tr>
<tr>
<td>3</td>
<td>0.25</td>
<td>0.05</td>
<td>0.5</td>
<td>83.50%</td>
</tr>
<tr>
<td>3</td>
<td>0.25</td>
<td>0.1</td>
<td>0</td>
<td>82.47%</td>
</tr>
<tr>
<td>3</td>
<td>0.25</td>
<td>0.1</td>
<td>0.1</td>
<td>82.15%</td>
</tr>
<tr>
<td>3</td>
<td>0.25</td>
<td>0.1</td>
<td>0.5</td>
<td>82.91%</td>
</tr>
<tr>
<td>3</td>
<td>0.5</td>
<td>0.01</td>
<td>0</td>
<td>64.89%</td>
</tr>
<tr>
<td>3</td>
<td>0.5</td>
<td>0.01</td>
<td>0.1</td>
<td>66.99%</td>
</tr>
<tr>
<td>3</td>
<td>0.5</td>
<td>0.01</td>
<td>0.5</td>
<td>66.19%</td>
</tr>
<tr>
<td>3</td>
<td>0.5</td>
<td>0.05</td>
<td>0</td>
<td>65.57%</td>
</tr>
<tr>
<td>3</td>
<td>0.5</td>
<td>0.05</td>
<td>0.1</td>
<td>67.17%</td>
</tr>
<tr>
<td>3</td>
<td>0.5</td>
<td>0.05</td>
<td>0.5</td>
<td>65.31%</td>
</tr>
<tr>
<td>3</td>
<td>0.5</td>
<td>0.1</td>
<td>0</td>
<td>65.75%</td>
</tr>
<tr>
<td>3</td>
<td>0.5</td>
<td>0.1</td>
<td>0.1</td>
<td>65.85%</td>
</tr>
<tr>
<td>3</td>
<td>0.5</td>
<td>0.1</td>
<td>0.5</td>
<td>66.47%</td>
</tr>
</tbody>
</table>
<p>Based on the test data above, two models did equally best in categorizing the test data and beat my 80.0% accuracy objective with 82.2%:</p>
<ol>
<li>Model 1 architecture with a dropout rate of 0.25, learning rate of 0.05, and ReLU Alpha of 0.0</li>
<li>Model 1 architecture with a dropout rate of 0.25, learning rate of 0.1, and ReLU Alpha of 0.1</li>
</ol>
<p>Upholding the concept of the simplier the better, I select the first model since it has a more conservative learning rate and its kernel is a simplier non-leaky ReLU.</p>
<p>A few observations from my test results:</p>
<ul>
<li>Model architecture 1 was vastly superior to the other two models with all scores above the average of the testing data. This suggests to me that a greater convolution window, stride, and number of filters may render direct improvement in classification accuracy in the model</li>
<li>A dropout rate of 0.25 was better than both 0 and 0.5 which isn't surprising considering that a rate of 0 leads to overfitting of test data and a substantial dropout rate will impede training as backpropogated calculations will fail to persist. This suggests an appropriate range of dropout rate should be narrower and skewed toward lower values greater than 0.</li>
<li>In general, a learning rate of 0.05 tested better than rates at 0 and 0.1, suggesting that models tested in a narrower range including 0.05 may train and test better. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Final-Algorithm">Final Algorithm<a class="anchor-link" href="#Final-Algorithm">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below is the final algorithm, using both the mfcc_conversion utility to convert audiofiles into MFCC inputs, and the selected neural network to understand the speech command. I demonstrate the algorithm's ability on some sample files in the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">algo</span><span class="p">(</span><span class="n">audio_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;My prediction for &quot;</span><span class="o">+</span><span class="n">filename</span><span class="o">+</span><span class="s2">&quot; is...&quot;</span><span class="p">)</span>
    <span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s1">&#39;__file__&#39;</span><span class="p">)),</span><span class="s1">&#39;models&#39;</span><span class="p">,</span><span class="s1">&#39;model1_dr0.25_lr0.1_ra0.hdf5&#39;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
    <span class="n">mfccs</span> <span class="o">=</span> <span class="n">mfcc_conversion</span><span class="p">(</span><span class="n">audio_path</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">79</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">mfccs</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">prediction</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="s2">&quot;yes&quot;</span>
    <span class="k">elif</span> <span class="n">prediction</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="s2">&quot;no&quot;</span>
    <span class="k">elif</span> <span class="n">prediction</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="s2">&quot;up&quot;</span>
    <span class="k">elif</span> <span class="n">prediction</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="s2">&quot;down&quot;</span>
    <span class="k">elif</span> <span class="n">prediction</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="s2">&quot;left&quot;</span>
    <span class="k">elif</span> <span class="n">prediction</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="s2">&quot;right&quot;</span>
    <span class="k">elif</span> <span class="n">prediction</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="s2">&quot;on&quot;</span>
    <span class="k">elif</span> <span class="n">prediction</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="s2">&quot;off&quot;</span>
    <span class="k">elif</span> <span class="n">prediction</span> <span class="o">==</span> <span class="mi">9</span><span class="p">:</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="s2">&quot;stop&quot;</span>
    <span class="k">elif</span> <span class="n">prediction</span> <span class="o">==</span> <span class="mi">10</span><span class="p">:</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="s2">&quot;go&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="s2">&quot;UNKNOWN&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>

<span class="c1"># using my own data for demonstration and review</span>
<span class="n">dir_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s1">&#39;__file__&#39;</span><span class="p">)),</span><span class="s1">&#39;tyler_audio&#39;</span><span class="p">)</span>
<span class="n">sample_files</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bed.wav&#39;</span><span class="p">,</span> <span class="s1">&#39;bird.wav&#39;</span><span class="p">,</span> <span class="s1">&#39;cat.wav&#39;</span><span class="p">,</span> <span class="s1">&#39;dog.wav&#39;</span><span class="p">,</span> <span class="s1">&#39;down.wav&#39;</span><span class="p">,</span> <span class="s1">&#39;eight.wav&#39;</span><span class="p">,</span> <span class="s1">&#39;five.wav&#39;</span><span class="p">,</span><span class="s1">&#39;four.wav&#39;</span><span class="p">,</span><span class="s1">&#39;go.wav&#39;</span><span class="p">,</span>
                <span class="s1">&#39;house.wav&#39;</span><span class="p">,</span><span class="s1">&#39;happy.wav&#39;</span><span class="p">,</span><span class="s1">&#39;left.wav&#39;</span><span class="p">,</span><span class="s1">&#39;marvin.wav&#39;</span><span class="p">,</span><span class="s1">&#39;nine.wav&#39;</span><span class="p">,</span><span class="s1">&#39;no.wav&#39;</span><span class="p">,</span><span class="s1">&#39;off.wav&#39;</span><span class="p">,</span><span class="s1">&#39;on.wav&#39;</span><span class="p">,</span><span class="s1">&#39;one.wav&#39;</span><span class="p">,</span>
                <span class="s1">&#39;right.wav&#39;</span><span class="p">,</span><span class="s1">&#39;seven.wav&#39;</span><span class="p">,</span><span class="s1">&#39;sheila.wav&#39;</span><span class="p">,</span><span class="s1">&#39;six.wav&#39;</span><span class="p">,</span><span class="s1">&#39;stop.wav&#39;</span><span class="p">,</span><span class="s1">&#39;three.wav&#39;</span><span class="p">,</span><span class="s1">&#39;tree.wav&#39;</span><span class="p">,</span><span class="s1">&#39;two.wav&#39;</span><span class="p">,</span>
                <span class="s1">&#39;up.wav&#39;</span><span class="p">,</span><span class="s1">&#39;wow.wav&#39;</span><span class="p">,</span><span class="s1">&#39;yes.wav&#39;</span><span class="p">,</span><span class="s1">&#39;zero.wav&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">sample_file</span> <span class="ow">in</span> <span class="n">sample_files</span><span class="p">:</span>
    <span class="n">algo</span><span class="p">(</span><span class="n">dir_path</span><span class="p">,</span><span class="n">sample_file</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>My prediction for bed.wav is...
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\Tyler\Anaconda3\envs\tfspeech\lib\site-packages\scipy\io\wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.
  WavFileWarning)
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>UNKNOWN
My prediction for bird.wav is...
UNKNOWN
My prediction for cat.wav is...
UNKNOWN
My prediction for dog.wav is...
UNKNOWN
My prediction for down.wav is...
down
My prediction for eight.wav is...
UNKNOWN
My prediction for five.wav is...
UNKNOWN
My prediction for four.wav is...
UNKNOWN
My prediction for go.wav is...
go
My prediction for house.wav is...
UNKNOWN
My prediction for happy.wav is...
UNKNOWN
My prediction for left.wav is...
UNKNOWN
My prediction for marvin.wav is...
UNKNOWN
My prediction for nine.wav is...
UNKNOWN
My prediction for no.wav is...
no
My prediction for off.wav is...
off
My prediction for on.wav is...
on
My prediction for one.wav is...
UNKNOWN
My prediction for right.wav is...
right
My prediction for seven.wav is...
UNKNOWN
My prediction for sheila.wav is...
UNKNOWN
My prediction for six.wav is...
UNKNOWN
My prediction for stop.wav is...
stop
My prediction for three.wav is...
UNKNOWN
My prediction for tree.wav is...
UNKNOWN
My prediction for two.wav is...
UNKNOWN
My prediction for up.wav is...
UNKNOWN
My prediction for wow.wav is...
UNKNOWN
My prediction for yes.wav is...
yes
My prediction for zero.wav is...
UNKNOWN
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Summary,-Conclusion-&amp;-Final-Thoughts">Summary, Conclusion &amp; Final Thoughts<a class="anchor-link" href="#Summary,-Conclusion-&amp;-Final-Thoughts">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To summarize, the purpose of this project was to build an algorithm that could understand a small library of 10 simple commands while being able to ignore or not interpret unknown commands. Using Mel-Frequency Capestral Coefficients as the medium with which to regularize and convey communicated information, I trained a 1-dimensional convolutional neural network, using RMSprop to minimize the categorical crossentropy log loss, to process and interpret the information in order to make a prediction as to the intended command.</p>
<p>3 different network architectures were designed and trained. Hyperparameters - dropbout rates, learning rates, and the leaky rectified linear unit alpha - were toggled for each of the 3 architectures resulting in 81 trained models. All 81 models were tested and the algorithm that scored highest - 88.2% - was selected. This score was higher than the 80.0% I originally hoped for.</p>
<p>In conclusion, I want to leave with a few ideas I would like to incorporate into this project - or a similar project - in a future date:</p>
<ul>
<li>Using recurrent networks, or long-short term memory networks, to process the MFCCs. While I used convolutional neural networks to achieve my goal, perhaps other network architectures would be more applicable such as RNNs and LSTMs which are widely used in signal processing and speech recognition. Perhaps I'll repeat my procedures here with such architectures to see if I can improve upon my current accuracy. </li>
<li>Augment and distort signals for testing. While I originally intended to add some random digital distortion to my input data in order to account for more realistic use cases and to aid against overfitting the models to only the noiseless cases, I ultimately decided this wasn't necessary for my purposes here. However, should I decide to incorporate distinctions between the commands, silence, and noise, then I can script the necessary code to do so.</li>
<li>Reduce the sample rate of inputs to see if I can maintain accuracy with less information. While I trained the model with audio files decoded at 16000Mbps, perhaps I can achieve the same accuracy - or perhaps improve upon - with audio sampled at a lower bit rate - maybe 8000Mbps, for example. If successful, this would allow my algorithm to be used with electronics or networks with a more limited capacity.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Works-Cited">Works Cited<a class="anchor-link" href="#Works-Cited">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Alameda Internet Marketing. (2016, 07 06). 39 Experts Share Their Top 3 SEO Trends for 2017 and Beyond. Retrieved from Alameda Internet Marketing: <a href="https://alamedaim.com/seo-trends/">https://alamedaim.com/seo-trends/</a></p>
<p>Practical Cryptography. (2018, 06 01). Mel Frequency Cepstral Coefficient (MFCC) tutorial. (<a href="http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/">http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/</a></p>
<p>Sterling, G. (2016, 05 18). Google says 20 percent of mobile queries are voice searches. Retrieved from Search Engine Land: <a href="https://searchengineland.com/google-reveals-20-percent-queries-voice-queries-249917">https://searchengineland.com/google-reveals-20-percent-queries-voice-queries-249917</a></p>
<p>Young, W. (2016, 06 20). The voice search explosion and how it will change local search. Retrieved from Search Engine Land: <a href="https://searchengineland.com/voice-search-explosion-will-change-local-search-251776">https://searchengineland.com/voice-search-explosion-will-change-local-search-251776</a></p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
